<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="">

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"> <!--320-->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, user-scalable=no">

    <link rel="icon" href="../../mapt/images/favicon.ico">

    <link rel="stylesheet" href="../../mapt/css/font-awesome.css">
    <link rel="stylesheet" href="../../mapt/css/google-fonts.css">
    <link rel="stylesheet" href="../../mapt/css/devicon.css">

    <link rel="stylesheet" href="../../mapt/css/bootstrap.css">
    <link rel="stylesheet" href="../../mapt/css/bootstrap-xl.css">
    <link rel="stylesheet" href="../../mapt/css/magnific-popup.css">
    <link rel="stylesheet" href="../../mapt/css/prism.css">
    <link rel="stylesheet" href="../../mapt/css/hljs-github.css">

    <link rel="stylesheet" href="../../mapt/css/mapt.css">
    <link rel="stylesheet" href="../../mapt/css/custom.css">

    <script src="../../mapt/js/jquery.js"></script>
    <script src="../../mapt/js/bootstrap.js"></script>
    <script src="../../mapt/js/jquery.magnific-popup.js"></script>
    <script src="../../mapt/js/highlight.min.js"></script>

    <script src="../../mapt/js/custom.js"></script>
    
    <title>Mastering C# Concurrency</title>
</head>

<body class="home-body">
    <div id="wrapper">
        <div id="sidebar-wrapper">    
            <ul class="sidebar-nav">
                <div class="list-group" id="sidebar-nav" role="tablist">
                    <li>
                        <a href="../../index.html" class="sidenav-menu-holder back-btn" id="back-link">
                            <span class="sidenav-menu">Book List</span>
                            <span class="pull-left mr5"><i class="fa fa-chevron-left"></i></span>
                        </a>
                    </li>
                    
                    <li class="book-info copyright">
                        <span class="info text-nowrap"><span class="copyleft">&copy;</span><span><strong>RuTracker</strong>.org</span></span>
                    </li>          
                    <li class="book-info copyright">
                        <span class="info text-nowrap">Pub date: <strong>28 Oct 2015</strong></span>
                    </li>         
                    <li class="book-info">
                        <span class="info text-nowrap">Price: €<strong>35.99</strong></span>
                        <span class="info text-nowrap">ISBN: <strong>9781785286650</strong></span>
                    </li>     
            
                    <li>
                        <a href="graphics/cover.jpg" class="sidenav-menu-holder cover-img">
                            <img src="graphics/cover.jpg" class="cover-image">
                        </a>
                    </li>        
            
                    <div class="book_navigation">
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse1">
                                <div class="section-name">1: Traditional Concurrency</div>
                            </a>
                        </li>
                        <div id="collapse1" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="1" class="sub-nav">
                                <a href="#ch01">
                                    <div class="section-name">Chapter 1: Traditional Concurrency</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec08" class="sub-nav">
                                <a href="#ch01lvl1sec08">                    
                                    <div class="section-name">What&#x27;s the problem?</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec09" class="sub-nav">
                                <a href="#ch01lvl1sec09">                    
                                    <div class="section-name">Using locks</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec10" class="sub-nav">
                                <a href="#ch01lvl1sec10">                    
                                    <div class="section-name">Reader-writer lock</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec11" class="sub-nav">
                                <a href="#ch01lvl1sec11">                    
                                    <div class="section-name">Spin lock</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec12" class="sub-nav">
                                <a href="#ch01lvl1sec12">                    
                                    <div class="section-name">Optimization strategy</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec13" class="sub-nav">
                                <a href="#ch01lvl1sec13">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse2">
                                <div class="section-name">2: Lock-Free Concurrency</div>
                            </a>
                        </li>
                        <div id="collapse2" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="2" class="sub-nav">
                                <a href="#ch02">
                                    <div class="section-name">Chapter 2: Lock-Free Concurrency</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec14" class="sub-nav">
                                <a href="#ch02lvl1sec14">                    
                                    <div class="section-name">Memory model and compiler optimizations</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec15" class="sub-nav">
                                <a href="#ch02lvl1sec15">                    
                                    <div class="section-name">The System.Threading.Interlocked class</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec16" class="sub-nav">
                                <a href="#ch02lvl1sec16">                    
                                    <div class="section-name">Interlocked internals</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec17" class="sub-nav">
                                <a href="#ch02lvl1sec17">                    
                                    <div class="section-name">Writing lock-free code</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec18" class="sub-nav">
                                <a href="#ch02lvl1sec18">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse3">
                                <div class="section-name">3: Understanding Parallelism Granularity</div>
                            </a>
                        </li>
                        <div id="collapse3" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="3" class="sub-nav">
                                <a href="#ch03">
                                    <div class="section-name">Chapter 3: Understanding Parallelism Granularity</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec20" class="sub-nav">
                                <a href="#ch03lvl1sec20">                    
                                    <div class="section-name">The number of threads</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec21" class="sub-nav">
                                <a href="#ch03lvl1sec21">                    
                                    <div class="section-name">Using the thread pool</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec22" class="sub-nav">
                                <a href="#ch03lvl1sec22">                    
                                    <div class="section-name">Understanding granularity</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec23" class="sub-nav">
                                <a href="#ch03lvl1sec23">                    
                                    <div class="section-name">Choosing the coarse-grained or fine-grained approach</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec24" class="sub-nav">
                                <a href="#ch03lvl1sec24">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse4">
                                <div class="section-name">4: Task Parallel Library in Depth</div>
                            </a>
                        </li>
                        <div id="collapse4" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="4" class="sub-nav">
                                <a href="#ch04">
                                    <div class="section-name">Chapter 4: Task Parallel Library in Depth</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec25" class="sub-nav">
                                <a href="#ch04lvl1sec25">                    
                                    <div class="section-name">Task composition</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec26" class="sub-nav">
                                <a href="#ch04lvl1sec26">                    
                                    <div class="section-name">Tasks hierarchy</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec27" class="sub-nav">
                                <a href="#ch04lvl1sec27">                    
                                    <div class="section-name">Awaiting task completion</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec28" class="sub-nav">
                                <a href="#ch04lvl1sec28">                    
                                    <div class="section-name">Task cancellation</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec29" class="sub-nav">
                                <a href="#ch04lvl1sec29">                    
                                    <div class="section-name">Latency and the coarse-grained approach with TPL</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec30" class="sub-nav">
                                <a href="#ch04lvl1sec30">                    
                                    <div class="section-name">Exception handling</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec31" class="sub-nav">
                                <a href="#ch04lvl1sec31">                    
                                    <div class="section-name">Using the Parallel class</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec32" class="sub-nav">
                                <a href="#ch04lvl1sec32">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse5">
                                <div class="section-name">5: C# Language Support for Asynchrony</div>
                            </a>
                        </li>
                        <div id="collapse5" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="5" class="sub-nav">
                                <a href="#ch05">
                                    <div class="section-name">Chapter 5: C# Language Support for Asynchrony</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec33" class="sub-nav">
                                <a href="#ch05lvl1sec33">                    
                                    <div class="section-name">Implementing the downloading of images from Bing</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec34" class="sub-nav">
                                <a href="#ch05lvl1sec34">                    
                                    <div class="section-name">Is the async keyword really needed?</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec35" class="sub-nav">
                                <a href="#ch05lvl1sec35">                    
                                    <div class="section-name">Fire-and-forget tasks</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec36" class="sub-nav">
                                <a href="#ch05lvl1sec36">                    
                                    <div class="section-name">Other useful TPL features</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec37" class="sub-nav">
                                <a href="#ch05lvl1sec37">                    
                                    <div class="section-name">Implementing a custom awaitable type</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec38" class="sub-nav">
                                <a href="#ch05lvl1sec38">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse6">
                                <div class="section-name">6: Using Concurrent Data Structures</div>
                            </a>
                        </li>
                        <div id="collapse6" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="6" class="sub-nav">
                                <a href="#ch06">
                                    <div class="section-name">Chapter 6: Using Concurrent Data Structures</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec39" class="sub-nav">
                                <a href="#ch06lvl1sec39">                    
                                    <div class="section-name">Standard collections and synchronization primitives</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec40" class="sub-nav">
                                <a href="#ch06lvl1sec40">                    
                                    <div class="section-name">Implementing a cache with ReaderWriterLockSlim</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec41" class="sub-nav">
                                <a href="#ch06lvl1sec41">                    
                                    <div class="section-name">Concurrent collections in .NET</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec42" class="sub-nav">
                                <a href="#ch06lvl1sec42">                    
                                    <div class="section-name">ConcurrentDictionary</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec43" class="sub-nav">
                                <a href="#ch06lvl1sec43">                    
                                    <div class="section-name">ConcurrentBag&amp;lt;T&amp;gt;</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec44" class="sub-nav">
                                <a href="#ch06lvl1sec44">                    
                                    <div class="section-name">ConcurrentQueue&amp;lt;T&amp;gt;</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec45" class="sub-nav">
                                <a href="#ch06lvl1sec45">                    
                                    <div class="section-name">ConcurrentStack&amp;lt;T&amp;gt;</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec46" class="sub-nav">
                                <a href="#ch06lvl1sec46">                    
                                    <div class="section-name">The Producer/Consumer pattern</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec47" class="sub-nav">
                                <a href="#ch06lvl1sec47">                    
                                    <div class="section-name">The Producer/Consumer pattern in .NET 4.0+</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec48" class="sub-nav">
                                <a href="#ch06lvl1sec48">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse7">
                                <div class="section-name">7: Leveraging Parallel Patterns</div>
                            </a>
                        </li>
                        <div id="collapse7" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="7" class="sub-nav">
                                <a href="#ch07">
                                    <div class="section-name">Chapter 7: Leveraging Parallel Patterns</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec49" class="sub-nav">
                                <a href="#ch07lvl1sec49">                    
                                    <div class="section-name">Concurrent idioms</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec50" class="sub-nav">
                                <a href="#ch07lvl1sec50">                    
                                    <div class="section-name">Asynchronous patterns</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec51" class="sub-nav">
                                <a href="#ch07lvl1sec51">                    
                                    <div class="section-name">Concurrent patterns</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec52" class="sub-nav">
                                <a href="#ch07lvl1sec52">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse8">
                                <div class="section-name">8: Server-side Asynchrony</div>
                            </a>
                        </li>
                        <div id="collapse8" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="8" class="sub-nav">
                                <a href="#ch08">
                                    <div class="section-name">Chapter 8: Server-side Asynchrony</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec53" class="sub-nav">
                                <a href="#ch08lvl1sec53">                    
                                    <div class="section-name">Server applications</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec54" class="sub-nav">
                                <a href="#ch08lvl1sec54">                    
                                    <div class="section-name">The OWIN Web API framework</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec55" class="sub-nav">
                                <a href="#ch08lvl1sec55">                    
                                    <div class="section-name">Load testing and scalability</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec56" class="sub-nav">
                                <a href="#ch08lvl1sec56">                    
                                    <div class="section-name">I/O and CPU-bound tasks</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec57" class="sub-nav">
                                <a href="#ch08lvl1sec57">                    
                                    <div class="section-name">Deep dive into asynchronous I/O</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec58" class="sub-nav">
                                <a href="#ch08lvl1sec58">                    
                                    <div class="section-name">Real and fake asynchronous I/O operations</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec59" class="sub-nav">
                                <a href="#ch08lvl1sec59">                    
                                    <div class="section-name">Synchronization context</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec60" class="sub-nav">
                                <a href="#ch08lvl1sec60">                    
                                    <div class="section-name">CPU-bound tasks and queues</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec61" class="sub-nav">
                                <a href="#ch08lvl1sec61">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse9">
                                <div class="section-name">9: Concurrency in the User Interface</div>
                            </a>
                        </li>
                        <div id="collapse9" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="9" class="sub-nav">
                                <a href="#ch09">
                                    <div class="section-name">Chapter 9: Concurrency in the User Interface</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec62" class="sub-nav">
                                <a href="#ch09lvl1sec62">                    
                                    <div class="section-name">The importance of asynchrony for UI</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec63" class="sub-nav">
                                <a href="#ch09lvl1sec63">                    
                                    <div class="section-name">UI threads and message loops</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec64" class="sub-nav">
                                <a href="#ch09lvl1sec64">                    
                                    <div class="section-name">Common problems and solutions</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec65" class="sub-nav">
                                <a href="#ch09lvl1sec65">                    
                                    <div class="section-name">How the await keyword works</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec66" class="sub-nav">
                                <a href="#ch09lvl1sec66">                    
                                    <div class="section-name">Performance issues</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec67" class="sub-nav">
                                <a href="#ch09lvl1sec67">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse10">
                                <div class="section-name">10: Troubleshooting Parallel Programs</div>
                            </a>
                        </li>
                        <div id="collapse10" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="10" class="sub-nav">
                                <a href="#ch10">
                                    <div class="section-name">Chapter 10: Troubleshooting Parallel Programs</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec68" class="sub-nav">
                                <a href="#ch10lvl1sec68">                    
                                    <div class="section-name">How troubleshooting parallel programs is different</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec69" class="sub-nav">
                                <a href="#ch10lvl1sec69">                    
                                    <div class="section-name">Writing tests</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec70" class="sub-nav">
                                <a href="#ch10lvl1sec70">                    
                                    <div class="section-name">Integration tests</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec71" class="sub-nav">
                                <a href="#ch10lvl1sec71">                    
                                    <div class="section-name">Debugging</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec72" class="sub-nav">
                                <a href="#ch10lvl1sec72">                    
                                    <div class="section-name">Performance measurement and profiling</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec73" class="sub-nav">
                                <a href="#ch10lvl1sec73">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapsebackindex">
                                <div class="section-name">Appendix A: Index</div>
                            </a>
                        </li>
                        <div id="collapsebackindex" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="backindex" class="sub-nav">
                                <a href="#backindex">
                                    <div class="section-name">Chapter Appendix A: Index</div>
                                </a>
                            </li>
                        </div>
                    </div>
                </div>
            </ul>
        </div>
        
        <div id="page-content-wrapper" class="book-page">
            <a href="#" id="menu-toggle" class="toggle-nav"><i class="fa fa-bars fa-2x mr5"></i></a>
            
            <a href="#" id="back_to_top" class="back-to-top"><img src="../../mapt/images/kopimi.svg"></a>
            
            <div class="col-sm-12 col-xl-offset-2 col-xl-8 col-lg-offset-1 col-lg-10">
                <div class="btn-group pull-right mt15 mb30" role="group">
                    <a href="#home" class="btn btn-default">
                        <i class="fa fa-share fa-lg no-text-padding"></i>
                        <span class="hidden-xs ml5">Book Home</span>
                    </a>
                    <button class="btn btn-default" data-nid="23563" id="code-download">
                        <i class="fa fa-file fa-lg"></i>
                        <span class="hidden-xs ml5">Download Code Files</span>
                    </button>
                </div>
            </div>
            <div class="clearfix"></div>
            
            <div id="book-wrapper" class="container-fluid">
                <div class="col-sm-12 col-xl-offset-2 col-xl-8 col-lg-offset-1 col-lg-10" id="home">
                    <h2 class="product-title">Mastering C# Concurrency</h2>
                    <hr>
                    <div class="row">
                        <div class="col-sm-12">
                            <h5 class="mt10">By Eugene Agafonov, Andrew Koryavchenko</h5>
                            <div>
                                <p class="mb20"><b>Create robust and scalable applications along with responsive UI using concurrency and the multi-threading infrastructure in .NET and C#</b></p>
                                <a href="#ch01" class="btn btn-info btn-lg pull-right hidden-xs">
                                    Start Reading <i class="fa fa-chevron-right ml5"></i>
                                </a>
                                <a href="#ch01" class="btn btn-info btn-lg btn-block mt20 mb20 visible-xs">
                                    Start Reading <i class="fa fa-chevron-right ml5"></i>
                                </a>
                                <div class="clearfix"></div>
                                <div class="col-sm-12">
                                    <ul id="myTabs" class="nav nav-tabs nav-justified hidden-xs mt20" role="tablist">
                                        <li class="active">
                                            <a href="#info" role="tab" id="info-tab" data-toggle="tab">
                                                <h5>Info</h5>
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#content" role="tab" id="content-tab" data-toggle="tab">
                                                <h5>Contents</h5>
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#author" role="tab" id="author-tab" data-toggle="tab">
                                                <h5>Author</h5>
                                            </a>
                                        </li>
                                    </ul>
                
                                    <ul id="myTabsMobile" class="nav nav-pills text-center nav-stacked visible-xs mb60" role="tablist">
                                        <li class="active">
                                            <a href="#info" role="tab" id="info-tab-responsive" data-toggle="tab">
                                                Info
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#content" role="tab" id="content-tab-responsive" data-toggle="tab">
                                                Contents
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#author" role="tab" id="author-tab-responsive" data-toggle="tab">
                                                Author
                                            </a>
                                        </li>
                                    </ul>
                
                                    <div id="myTabContent" class="tab-content pt30">
                                    
                                        <div role="tabpanel" class="tab-pane active fade in" id="info">
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">Features</h5>
                                            </div>
                                            <div class="hidden-xs">
                                                <h5>Features</h5>
                                            </div>
                                            <hr>
                                            <div>
                                                <ul>
                <li>Learn to combine your asynchronous operations with Task Parallel Library</li>
                <li>Master C#’s asynchronous infrastructure and use asynchronous APIs effectively to achieve optimal responsiveness of the application</li>
                <li>An easy-to-follow, example-based guide that helps you to build scalable applications using concurrency in C#</li>
                </ul>
                                            </div>
                                            <br>
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">Learning</h5>
                                            </div>
                                            <div class="hidden-xs">
                                                <h5>Learning</h5>
                                            </div>
                                            <hr>
                                            <div>
                                                <ul>
                <li>Apply general multithreading concepts to your application’s design</li>
                <li>Leverage lock-free concurrency and learn about its pros and cons to achieve efficient synchronization between user threads</li>
                <li>Combine your asynchronous operations with Task Parallel Library</li>
                <li>Make your code easier with C#’s asynchrony support</li>
                <li>Use common concurrent collections and programming patterns</li>
                <li>Write scalable and robust server-side asynchronous code</li>
                <li>Create fast and responsible client applications</li>
                <li>Avoid common problems and troubleshoot your multi-threaded and asynchronous applications</li>
                </ul>
                                            </div>
                                            <br>
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">About</h5>
                                            </div>
                                            <div class="hidden-xs">
                                                <h5>About</h5>
                                            </div>
                                            <hr>
                                            <div>
                                                <p>Starting with the traditional approach to concurrency, you will learn how to write multithreaded concurrent programs and compose ways that won't require locking. You will explore the concepts of parallelism granularity, and fine-grained and coarse-grained parallel tasks by choosing a concurrent program structure and parallelizing the workload optimally. You will also learn how to use task parallel library, cancellations, timeouts, and how to handle errors. You will know how to choose the appropriate data structure for a specific parallel algorithm to achieve scalability and performance. Further, you'll learn about server scalability, asynchronous I/O, and thread pools, and write responsive traditional Windows and Windows Store applications.</p>
                <p>By the end of the book, you will be able to diagnose and resolve typical problems that could happen in multithreaded applications.</p>
                                            </div>
                                        </div>
                                        
                                        <div role="tabpanel" class="tab-pane fade in" id="content">
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">Contents</h5>
                                                <hr>
                                            </div>
                                            <ul>
                                                <div>
                                                    <li data-chapter="1">
                                                        <div class="section-name">1: Traditional Concurrency</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="1" class="chapter-section">
                                                                    <a href="#ch01">        
                                                                        <div class="section-name">Chapter 1: Traditional Concurrency</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec08" class="chapter-section">
                                                                    <a href="#ch01lvl1sec08">                    
                                                                        <div class="section-name">What&#x27;s the problem?</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec09" class="chapter-section">
                                                                    <a href="#ch01lvl1sec09">                    
                                                                        <div class="section-name">Using locks</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec10" class="chapter-section">
                                                                    <a href="#ch01lvl1sec10">                    
                                                                        <div class="section-name">Reader-writer lock</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec11" class="chapter-section">
                                                                    <a href="#ch01lvl1sec11">                    
                                                                        <div class="section-name">Spin lock</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec12" class="chapter-section">
                                                                    <a href="#ch01lvl1sec12">                    
                                                                        <div class="section-name">Optimization strategy</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec13" class="chapter-section">
                                                                    <a href="#ch01lvl1sec13">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="2">
                                                        <div class="section-name">2: Lock-Free Concurrency</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="2" class="chapter-section">
                                                                    <a href="#ch02">        
                                                                        <div class="section-name">Chapter 2: Lock-Free Concurrency</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec14" class="chapter-section">
                                                                    <a href="#ch02lvl1sec14">                    
                                                                        <div class="section-name">Memory model and compiler optimizations</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec15" class="chapter-section">
                                                                    <a href="#ch02lvl1sec15">                    
                                                                        <div class="section-name">The System.Threading.Interlocked class</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec16" class="chapter-section">
                                                                    <a href="#ch02lvl1sec16">                    
                                                                        <div class="section-name">Interlocked internals</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec17" class="chapter-section">
                                                                    <a href="#ch02lvl1sec17">                    
                                                                        <div class="section-name">Writing lock-free code</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec18" class="chapter-section">
                                                                    <a href="#ch02lvl1sec18">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="3">
                                                        <div class="section-name">3: Understanding Parallelism Granularity</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="3" class="chapter-section">
                                                                    <a href="#ch03">        
                                                                        <div class="section-name">Chapter 3: Understanding Parallelism Granularity</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec20" class="chapter-section">
                                                                    <a href="#ch03lvl1sec20">                    
                                                                        <div class="section-name">The number of threads</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec21" class="chapter-section">
                                                                    <a href="#ch03lvl1sec21">                    
                                                                        <div class="section-name">Using the thread pool</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec22" class="chapter-section">
                                                                    <a href="#ch03lvl1sec22">                    
                                                                        <div class="section-name">Understanding granularity</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec23" class="chapter-section">
                                                                    <a href="#ch03lvl1sec23">                    
                                                                        <div class="section-name">Choosing the coarse-grained or fine-grained approach</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec24" class="chapter-section">
                                                                    <a href="#ch03lvl1sec24">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="4">
                                                        <div class="section-name">4: Task Parallel Library in Depth</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="4" class="chapter-section">
                                                                    <a href="#ch04">        
                                                                        <div class="section-name">Chapter 4: Task Parallel Library in Depth</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec25" class="chapter-section">
                                                                    <a href="#ch04lvl1sec25">                    
                                                                        <div class="section-name">Task composition</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec26" class="chapter-section">
                                                                    <a href="#ch04lvl1sec26">                    
                                                                        <div class="section-name">Tasks hierarchy</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec27" class="chapter-section">
                                                                    <a href="#ch04lvl1sec27">                    
                                                                        <div class="section-name">Awaiting task completion</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec28" class="chapter-section">
                                                                    <a href="#ch04lvl1sec28">                    
                                                                        <div class="section-name">Task cancellation</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec29" class="chapter-section">
                                                                    <a href="#ch04lvl1sec29">                    
                                                                        <div class="section-name">Latency and the coarse-grained approach with TPL</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec30" class="chapter-section">
                                                                    <a href="#ch04lvl1sec30">                    
                                                                        <div class="section-name">Exception handling</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec31" class="chapter-section">
                                                                    <a href="#ch04lvl1sec31">                    
                                                                        <div class="section-name">Using the Parallel class</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec32" class="chapter-section">
                                                                    <a href="#ch04lvl1sec32">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="5">
                                                        <div class="section-name">5: C# Language Support for Asynchrony</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="5" class="chapter-section">
                                                                    <a href="#ch05">        
                                                                        <div class="section-name">Chapter 5: C# Language Support for Asynchrony</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec33" class="chapter-section">
                                                                    <a href="#ch05lvl1sec33">                    
                                                                        <div class="section-name">Implementing the downloading of images from Bing</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec34" class="chapter-section">
                                                                    <a href="#ch05lvl1sec34">                    
                                                                        <div class="section-name">Is the async keyword really needed?</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec35" class="chapter-section">
                                                                    <a href="#ch05lvl1sec35">                    
                                                                        <div class="section-name">Fire-and-forget tasks</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec36" class="chapter-section">
                                                                    <a href="#ch05lvl1sec36">                    
                                                                        <div class="section-name">Other useful TPL features</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec37" class="chapter-section">
                                                                    <a href="#ch05lvl1sec37">                    
                                                                        <div class="section-name">Implementing a custom awaitable type</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec38" class="chapter-section">
                                                                    <a href="#ch05lvl1sec38">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="6">
                                                        <div class="section-name">6: Using Concurrent Data Structures</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="6" class="chapter-section">
                                                                    <a href="#ch06">        
                                                                        <div class="section-name">Chapter 6: Using Concurrent Data Structures</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec39" class="chapter-section">
                                                                    <a href="#ch06lvl1sec39">                    
                                                                        <div class="section-name">Standard collections and synchronization primitives</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec40" class="chapter-section">
                                                                    <a href="#ch06lvl1sec40">                    
                                                                        <div class="section-name">Implementing a cache with ReaderWriterLockSlim</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec41" class="chapter-section">
                                                                    <a href="#ch06lvl1sec41">                    
                                                                        <div class="section-name">Concurrent collections in .NET</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec42" class="chapter-section">
                                                                    <a href="#ch06lvl1sec42">                    
                                                                        <div class="section-name">ConcurrentDictionary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec43" class="chapter-section">
                                                                    <a href="#ch06lvl1sec43">                    
                                                                        <div class="section-name">ConcurrentBag&amp;lt;T&amp;gt;</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec44" class="chapter-section">
                                                                    <a href="#ch06lvl1sec44">                    
                                                                        <div class="section-name">ConcurrentQueue&amp;lt;T&amp;gt;</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec45" class="chapter-section">
                                                                    <a href="#ch06lvl1sec45">                    
                                                                        <div class="section-name">ConcurrentStack&amp;lt;T&amp;gt;</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec46" class="chapter-section">
                                                                    <a href="#ch06lvl1sec46">                    
                                                                        <div class="section-name">The Producer/Consumer pattern</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec47" class="chapter-section">
                                                                    <a href="#ch06lvl1sec47">                    
                                                                        <div class="section-name">The Producer/Consumer pattern in .NET 4.0+</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec48" class="chapter-section">
                                                                    <a href="#ch06lvl1sec48">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="7">
                                                        <div class="section-name">7: Leveraging Parallel Patterns</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="7" class="chapter-section">
                                                                    <a href="#ch07">        
                                                                        <div class="section-name">Chapter 7: Leveraging Parallel Patterns</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec49" class="chapter-section">
                                                                    <a href="#ch07lvl1sec49">                    
                                                                        <div class="section-name">Concurrent idioms</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec50" class="chapter-section">
                                                                    <a href="#ch07lvl1sec50">                    
                                                                        <div class="section-name">Asynchronous patterns</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec51" class="chapter-section">
                                                                    <a href="#ch07lvl1sec51">                    
                                                                        <div class="section-name">Concurrent patterns</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec52" class="chapter-section">
                                                                    <a href="#ch07lvl1sec52">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="8">
                                                        <div class="section-name">8: Server-side Asynchrony</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="8" class="chapter-section">
                                                                    <a href="#ch08">        
                                                                        <div class="section-name">Chapter 8: Server-side Asynchrony</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec53" class="chapter-section">
                                                                    <a href="#ch08lvl1sec53">                    
                                                                        <div class="section-name">Server applications</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec54" class="chapter-section">
                                                                    <a href="#ch08lvl1sec54">                    
                                                                        <div class="section-name">The OWIN Web API framework</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec55" class="chapter-section">
                                                                    <a href="#ch08lvl1sec55">                    
                                                                        <div class="section-name">Load testing and scalability</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec56" class="chapter-section">
                                                                    <a href="#ch08lvl1sec56">                    
                                                                        <div class="section-name">I/O and CPU-bound tasks</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec57" class="chapter-section">
                                                                    <a href="#ch08lvl1sec57">                    
                                                                        <div class="section-name">Deep dive into asynchronous I/O</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec58" class="chapter-section">
                                                                    <a href="#ch08lvl1sec58">                    
                                                                        <div class="section-name">Real and fake asynchronous I/O operations</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec59" class="chapter-section">
                                                                    <a href="#ch08lvl1sec59">                    
                                                                        <div class="section-name">Synchronization context</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec60" class="chapter-section">
                                                                    <a href="#ch08lvl1sec60">                    
                                                                        <div class="section-name">CPU-bound tasks and queues</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec61" class="chapter-section">
                                                                    <a href="#ch08lvl1sec61">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="9">
                                                        <div class="section-name">9: Concurrency in the User Interface</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="9" class="chapter-section">
                                                                    <a href="#ch09">        
                                                                        <div class="section-name">Chapter 9: Concurrency in the User Interface</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec62" class="chapter-section">
                                                                    <a href="#ch09lvl1sec62">                    
                                                                        <div class="section-name">The importance of asynchrony for UI</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec63" class="chapter-section">
                                                                    <a href="#ch09lvl1sec63">                    
                                                                        <div class="section-name">UI threads and message loops</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec64" class="chapter-section">
                                                                    <a href="#ch09lvl1sec64">                    
                                                                        <div class="section-name">Common problems and solutions</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec65" class="chapter-section">
                                                                    <a href="#ch09lvl1sec65">                    
                                                                        <div class="section-name">How the await keyword works</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec66" class="chapter-section">
                                                                    <a href="#ch09lvl1sec66">                    
                                                                        <div class="section-name">Performance issues</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec67" class="chapter-section">
                                                                    <a href="#ch09lvl1sec67">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="10">
                                                        <div class="section-name">10: Troubleshooting Parallel Programs</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="10" class="chapter-section">
                                                                    <a href="#ch10">        
                                                                        <div class="section-name">Chapter 10: Troubleshooting Parallel Programs</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec68" class="chapter-section">
                                                                    <a href="#ch10lvl1sec68">                    
                                                                        <div class="section-name">How troubleshooting parallel programs is different</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec69" class="chapter-section">
                                                                    <a href="#ch10lvl1sec69">                    
                                                                        <div class="section-name">Writing tests</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec70" class="chapter-section">
                                                                    <a href="#ch10lvl1sec70">                    
                                                                        <div class="section-name">Integration tests</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec71" class="chapter-section">
                                                                    <a href="#ch10lvl1sec71">                    
                                                                        <div class="section-name">Debugging</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec72" class="chapter-section">
                                                                    <a href="#ch10lvl1sec72">                    
                                                                        <div class="section-name">Performance measurement and profiling</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec73" class="chapter-section">
                                                                    <a href="#ch10lvl1sec73">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="backindex">
                                                        <div class="section-name">Appendix A: Index</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="backindex" class="chapter-section">
                                                                    <a href="#backindex">
                                                                        <div class="section-name">Chapter Appendix A: Index</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                            </ul>
                                        </div>
                                        
                                        <div role="tabpanel" class="tab-pane fade" id="author">
                                            <div class="visible-xs">
                                                <h4 class="mobile-title">About the Author</h4>
                                                <hr>
                                            </div>
                                            <p><strong>Eugene Agafonov</strong></p>
                                            <div>
                                                <p>Eugene Agafonov leads the development department at ABBYY and lives in Moscow. He has over 15 years of professional experience in software development, and he started working with C# when it was in beta version. He is a Microsoft MVP in ASP.NET since 2006, and he often speaks at local software development conferences, such as DevCon Russia, about cutting-edge technologies in modern web and server-side application development. His main professional interests are cloud-based software architecture, scalability, and reliability. Eugene is a huge fan of football and plays the guitar with a local rock band. You can reach him at his personal blog, <a href="http://eugeneagafonov.com" target="_blank">eugeneagafonov.com</a>, or find him on Twitter at @eugene_agafonov.</p>
                <p>ABBYY is a global leader in the development of document recognition, content capture, and language-based technologies and solutions that are integrated across the entire information life cycle.</p>
                <p>He is the author of Multhreading in C# 5.0 Cookbook and Mastering C# Concurrency by Packt Publishing.</p>
                                            </div>
                                            <p><strong>Andrew Koryavchenko</strong></p>
                                            <div>
                                                <p>Andrew Koryavchenko is a software developer and an architect who lives in Moscow, Russia. He is one of the founders of rsdn.ru—the largest Russian software developers' community portal.</p>
                <p>His specialty is ERP systems and developer tools. He participated in ReSharper Visual Studio extension development, which is a well-known productivity tool for .NET developers. Currently, he is working on parsing and compilation tools for .NET development and also supports and develops the rsdn.ru portal.</p>
                <p>Andrew regularly speaks at online and offline events and conferences dedicated to Microsoft technologies, and he publishes articles on software development topics. He also used to teach Enterprise Software Development course in Kuban State University.</p>
                <p>Andrew has been a Microsoft MVP in C# since 2005.</p>
                                            </div>
                                        </div>
                                        
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="next-wrapper">
                        <div class="row ns">
                            <hr />
                            <span class="hidden-xs">
                                <h4 class="pull-left">
                                    <strong>Up Next: </strong><span class="section-title"></span>
                                </h4>
                                <a href="#" class="btn btn-primary pull-right btn-lg">
                                    Next Section
                                </a>
                            </span>
                            <span class="visible-xs">
                                <a href="#" class="btn btn-primary btn-block btn-lg">
                                    Next Section
                                </a>
                            </span>
                        </div>
                        <div class="row ns">
                            <hr>
                        </div>
                    </div>
                </div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch01"></a>Chapter 1. Traditional Concurrency</h2></div></div></div><p>Speaking of <a id="id0" class="indexterm"></a>concurrency, we have to start talking about <a id="id1" class="indexterm"></a>threads. Ironically, the reason behind implementing threads was to isolate programs from each other. Back in the early days of Windows, versions 3.* used <a id="id2" class="indexterm"></a>
<span class="strong"><strong>cooperative multitasking</strong></span>. This meant that the operating system executed all the programs on a single execution loop, and if one of those programs hung, every other program and the operating system itself would stop responding as well and then it would be required to reboot the machine to resolve this problem.</p><p>To create a more robust environment, the OS had to learn how to give every program its own piece of CPU, so if one program entered an infinite loop, the others would still be able to use the CPU for their own needs. A thread is an implementation of this concept. The threads allow implementing<a id="id3" class="indexterm"></a> <span class="strong"><strong>preemptive multitasking</strong></span>, where instead of the application deciding when to yield control to another application, the OS controls how much CPU time to give to each application.</p><p>When CPUs started to have multiple cores, it became more beneficial to make full use of the computational capability available. The use of the threads directly by applications suddenly became more worthwhile. However, when exploring multithreading issues, such as how to share the data between the threads safely, the set-up time of the threads immediately become evident.</p><p>In this chapter, we will consider the basic concurrent programming pitfalls and the traditional approach to deal with them.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec08"></a>What's the problem?</h2></div></div><hr /></div><p>Simply using multiple threads in a program is not a very complicated task. If your program can be easily separated into several independent tasks, then you just run them in different threads, and these threads can be scaled along with the number of CPU cores. However, usually real world programs require some interaction between these threads, such as exchanging information to coordinate their work. This cannot be implemented without sharing some data, which requires allocating some RAM space in such a way that it is accessible from all the threads. Dealing with this shared state is the root of almost every problem related to parallel programming.</p><p>The first common problem with shared state is undefined access order. If we have read and write access, this leads to incorrect calculation results. This situation is commonly referred to as a<a id="id4" class="indexterm"></a> <span class="strong"><strong>race condition</strong></span>.</p><p>Following is a sample of a <a id="id5" class="indexterm"></a>race condition. We have a counter, which is being changed from different threads simultaneously. Each thread increments the counter, then does some work, and then decrements the counter.</p><div class="informalexample"><pre class="programlisting">const int iterations = 10000;
var counter = 0;
ThreadStart proc = () =&gt; {
    for (int i = 0; i &lt; iterations; i++) {
      counter++;
      Thread.SpinWait(100);
      counter--;
    }
};
var threads = Enumerable
    .Range(0, 8)
    .Select(n =&gt; new Thread(proc))
    .ToArray();
foreach (var thread in threads)
  thread.Start();
foreach (var thread in threads)
  thread.Join();
Console.WriteLine(counter);</pre></div><p>The expected counter value is 0. However, when you run the program, you get different numbers (which is usually not 0, but it could be) each time. The reason is that incrementing and decrementing the counter is not an atomic operation, but consists of three separate steps – reading the counter value, incrementing or decrementing this value, and writing the result back into the counter.</p><p>Let us assume that we have initial counter value 0, and two threads. The first thread reads 0, increments it to 1, and writes 1 into the counter. The second thread reads 1 from the counter, increments it to 2, and then writes 2 into the counter. This seems to be correct and is exactly what we expected. This scenario is represented in the following diagram:</p><div class="mediaobject"><img src="graphics/4208_01_01.jpg" /></div><p> Now the first thread reads 2<a id="id6" class="indexterm"></a> from the counter, and at the same time it decrements it to 1; the second thread reads 2 from the counter, because the first thread hasn't written 1 into the counter yet. So now, the first thread writes 1 into the counter, and the second thread decrements 2 to 1 and writes the value 1 into the counter. As a result, we have the value 1, while we're expecting 0. This scenario is represented in the following diagram:</p><div class="mediaobject"><img src="graphics/4208_01_02.jpg" /></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip02"></a>Tip</h3><p><span class="strong"><strong>Downloading the example code</strong></span></p><p>You can download the example code files from your account at <a class="ulink" href="http://www.packtpub.com" target="_blank">http://www.packtpub.com</a> for all the Packt Publishing books you have purchased. If you purchased this book elsewhere, you can visit <a class="ulink" href="http://www.packtpub.com/support" target="_blank">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p></div><p>To avoid this, we have to restrict access to the counter so that only one thread reads it at a time, calculates the result, and writes it back. Such a restriction is called a lock. However, by using it to resolve a race condition problem, we create other possibilities for our concurrent code to fail. With such a restriction, we turn our parallel process into a sequential process, which in turn means that our code runs less efficiently. The more time the code runs inside the lock, the less efficient and scalable the whole program is. This is because the lock held by one thread blocks the other threads from performing their work, thereby making the whole program take longer to run. So, we have to minimize the lock time to keep the other threads running, instead of waiting for the lock to be released to start doing their calculations.</p><p>Another problem related to locks is best illustrated by the following example. It shows two threads using two resources, <code class="literal">A</code> and <code class="literal">B</code>. The first thread needs to lock object <code class="literal">A</code> first, then <code class="literal">B</code>, while the second thread starts with locking <code class="literal">B</code> and then <code class="literal">A</code>.</p><div class="informalexample"><pre class="programlisting">const int count = 10000;

var a = new object();
var b = new object();
var thread1 =
  new Thread(
    () =&gt;
    {
      for (int i = 0; i &lt; count; i++)
        lock (a)
          lock (b)
            Thread.SpinWait(100);
    });
var thread2 =
  new Thread(
    () =&gt;
    {
      for (int i = 0; i &lt; count; i++)
        lock (b)
          lock (a)
            Thread.SpinWait(100);
    });

thread1.Start();
thread2.Start();
thread1.Join();
thread2.Join();
Console.WriteLine("Done");</pre></div><p>It looks like this code is<a id="id7" class="indexterm"></a> alright, but if you run it several times, it will eventually hang. The reason for this lies in an issue with the locking order. If the first thread locks <code class="literal">A</code>, and the second locks <code class="literal">B</code> before the first thread does, then the second thread starts waiting for the lock on <code class="literal">A</code> to be released. However, to release the lock on <code class="literal">A</code>, the first thread needs to put a lock on <code class="literal">B</code>, which is already locked by the second thread. Therefore, both the threads will wait forever and the program will hang.</p><p>Such a situation is called a <a id="id8" class="indexterm"></a>
<span class="strong"><strong>deadlock</strong></span>. It is usually quite hard to diagnose deadlocks, because it is hard to reproduce one.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note02"></a>Note</h3><p>The best way to avoid deadlocks is to take preventive measures when writing code. The best practice is to avoid complicated lock structures and nested locks, and minimize the time in locks. If you suspect there could be a deadlock, then there is another way to prevent it from happening, which is by setting a timeout for acquiring a lock.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec09"></a>Using locks</h2></div></div><hr /></div><p>There are different types of<a id="id9" class="indexterm"></a> locks in C# and .NET. We will cover these later in the chapter, and also throughout the book. Let us start with the most common way to use a lock in C#, which is a <code class="literal">lock</code> statement.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec08"></a>Lock statement</h3></div></div></div><p>Lock statement <a id="id10" class="indexterm"></a>in C# uses a single argument, which could be an instance of any class. This instance will represent the lock itself.</p><p>Reading other people's codes, you could see that a lock uses the instance of collection or class, which contains shared data. It is not a good practice, because someone else could use this object for locking, and potentially create a deadlock situation. So, it is recommended to use a special private synchronization object, the sole purpose of which is to serve as a concrete lock:</p><div class="informalexample"><pre class="programlisting">// Bad
lock(myCollection) {
  myCollection.Add(data);
}

// Good
lock(myCollectionLock) {
  myCollection.Add(data);
}`</pre></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note03"></a>Note</h3><p>It is dangerous to use <code class="literal">lock(this)</code> and <code class="literal">lock(typeof(MyType))</code>. The basic idea why it is bad remains the same: the objects you are locking could be publicly accessible, and thus someone else could acquire a lock on it causing a deadlock. However, using the <code class="literal">this</code> keyword makes the situation more implicit; if someone else made the object public, it would be very hard to track that it is being used inside a lock.</p><p>Locking the type object is even worse. In the current versions of .NET, the runtime type objects could be shared across application domains (running in the same process). It is possible because those objects are immutable. However, this means that a deadlock could be caused, not only by another thread, but also by ANOTHER APPLICATION, and I bet that you would hardly understand what's going on in such a case.</p></div><p>Following is how <a id="id11" class="indexterm"></a>we can rewrite the first example with race condition and fix it using C# lock statement. Now the code will be as follows:</p><div class="informalexample"><pre class="programlisting">const int iterations = 10000;
var counter = 0;
var lockFlag = new object();
ThreadStart proc = () =&gt; {
  for (int i = 0; i &lt; iterations; i++)
  {
    lock (lockFlag)
      counter++;
    Thread.SpinWait(100);
    lock (lockFlag)
      counter--;
  }
};
var threads = Enumerable
  .Range(0, 8)
  .Select(n =&gt; new Thread(proc))
  .ToArray();
foreach (var thread in threads)
  thread.Start();
foreach (var thread in threads)
  thread.Join();
Console.WriteLine(counter);</pre></div><p>Now this code works properly, and the result is always 0.</p><p>To understand what is happening when a lock statement is used in the program, let us look at the Intermediate Language code, which is a result of compiling C# program. Consider the following C# code:</p><div class="informalexample"><pre class="programlisting">static void Main()
{
  var ctr = 0;
  var lockFlag = new object();
  lock (lockFlag)
    ctr++;
}</pre></div><p>The preceding block of code will be compiled into the following:</p><div class="informalexample"><pre class="programlisting">.method private hidebysig static void  Main() cil managed {
  .entrypoint
  // Code size       48 (0x30)
  .maxstack  2
  .locals init ([0] int32 ctr,
                [1] object lockFlag,
                [2] bool '&lt;&gt;s__LockTaken0',
                [3] object CS$2$0000,
                [4] bool CS$4$0001)
  IL_0000:  nop
  IL_0001:  ldc.i4.0
  IL_0002:  stloc.0
  IL_0003:  newobj     instance void [mscorlib]System.Object::.ctor()
  IL_0008:  stloc.1
  IL_0009:  ldc.i4.0
  IL_000a:  stloc.2
  .try
  {
    IL_000b:  ldloc.1
    IL_000c:  dup
    IL_000d:  stloc.3
    IL_000e:  ldloca.s   '&lt;&gt;s__LockTaken0'
    IL_0010:  call       void [mscorlib]System.Threading.Monitor::Enter(object, bool&amp;)
    IL_0015:  nop
    IL_0016:  ldloc.0
    IL_0017:  ldc.i4.1
    IL_0018:  add
    IL_0019:  stloc.0
    IL_001a:  leave.s    IL_002e
  }  // end .try
  finally
  {
    IL_001c:  ldloc.2
    IL_001d:  ldc.i4.0
    IL_001e:  ceq
    IL_0020:  stloc.s    CS$4$0001
    IL_0022:  ldloc.s    CS$4$0001
    IL_0024:  brtrue.s   IL_002d
    IL_0026:  ldloc.3
    IL_0027:  call       void [mscorlib]System.Threading.Monitor::Exit(object)
    IL_002c:  nop
    IL_002d:  endfinally
  }  // end handler
  IL_002e:  nop
  IL_002f:  ret
} // end of method Program::Main</pre></div><p>This can be explained with decompilation to C#. It will look like this:</p><div class="informalexample"><pre class="programlisting">static void Main()
{
  var ctr = 0;
  var lockFlag = new object();
  bool lockTaken = false;

  try
  {
    System.Threading.Monitor.Enter(lockFlag, ref lockTaken);
    ctr++;
  }
  finally
  {
    if (lockTaken)
      System.Threading.Monitor.Exit(lockFlag);
  }
}</pre></div><p>It turns out<a id="id12" class="indexterm"></a> that the lock statement turns into calling the <code class="literal">Monitor.Enter</code> and <code class="literal">Monitor.Exit</code> methods, wrapped into a <code class="literal">try</code>-<code class="literal">finally</code> block. The <code class="literal">Enter</code> method acquires an exclusive lock and returns a bool value, indicating that a lock was successfully acquired. If something went wrong, for example an exception has been thrown, the bool value would be set to <code class="literal">false</code>, and the <code class="literal">Exit</code> method would release the acquired lock.</p><p>A <code class="literal">try</code>-<code class="literal">finally</code> block ensures that the acquired lock will be released even if an exception occurs inside the lock statement. If the <code class="literal">Enter</code> method indicates that we cannot acquire a lock, then the <code class="literal">Exit</code> method will not be executed.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec09"></a>Monitor class</h3></div></div></div><p>The <code class="literal">Monitor</code> class<a id="id13" class="indexterm"></a> contains other useful methods that help us to write concurrent code. One of such methods is the <code class="literal">TryEnter</code> method, which allows the provision of a timeout value to it. If a lock could not be obtained before the timeout is expired, the <code class="literal">TryEnter</code> method would return <code class="literal">false</code>. This is quite an efficient method to prevent deadlocks, but you have to write significantly more code.</p><p>Consider the previous deadlock sample refactored in a way that one of the threads uses <code class="literal">Monitor.TryEnter</code> instead of <code class="literal">lock</code>:</p><div class="informalexample"><pre class="programlisting">static void Main()
{
  const int count = 10000;

  var a = new object();
  var b = new object();
  var thread1 = new Thread(
    () =&gt; {
      for (int i = 0; i &lt; count; i++)
        lock (a)
      lock (b)
      Thread.SpinWait(100);
  });
  var thread2 = new Thread(() =&gt; LockTimeout(a, b, count));
  thread1.Start();
  thread2.Start();
  thread1.Join();
  thread2.Join();
  Console.WriteLine("Done");
}

static void LockTimeout(object a, object b, int count)
{
  bool accquiredB = false;
  bool accquiredA = false;
  const int waitSeconds = 5;
  const int retryCount = 3;
  for (int i = 0; i &lt; count; i++)
  {
    int retries = 0;
    while (retries &lt; retryCount)
    {
      try 
      {
        accquiredB = Monitor.TryEnter(b, TimeSpan.FromSeconds(waitSeconds));
        if (accquiredB) {
          try {
            accquiredA = Monitor.TryEnter(a, TimeSpan.FromSeconds(waitSeconds));
            if (accquiredA) {
              Thread.SpinWait(100);
              break;
            }
            else {
              retries++;
            }
          }
          finally {
            if (accquiredA) {
              Monitor.Exit(a);
            }
          }
        }
        else {
          retries++;
        }
      }
      finally {
        if (accquiredB)
          Monitor.Exit(b);
      }
    }
    if (retries &gt;= retryCount)
      Console.WriteLine("could not obtain locks");
  }
}</pre></div><p>In the <code class="literal">LockTimeout</code> method, we implemented a retry strategy. For each loop iteration, we try to acquire lock <code class="literal">B</code> first, and if we cannot do so in 5 seconds, we try again. If we have successfully <a id="id14" class="indexterm"></a>acquired lock <code class="literal">B</code>, then we in turn try to acquire lock <code class="literal">A</code>, and if we wait for it for more than 5 seconds, we try again to acquire both the locks. This guarantees that if someone waits endlessly to acquire a lock on <code class="literal">B</code>, then this operation will eventually succeed.</p><p>If we do not succeed acquiring lock <code class="literal">B</code>, then we try again for a defined number of attempts. Then either we succeed, or we admit that we cannot obtain the needed locks and go to the next iteration.</p><p>In addition, the <code class="literal">Monitor</code> class can be used to orchestrate multiple threads into a workflow with the <code class="literal">Wait</code>, <code class="literal">Pulse</code>, and <code class="literal">PulseAll</code> methods. When a main thread calls the <code class="literal">Wait</code> method, the current lock is released, and the thread is blocked until some other thread calls the <code class="literal">Pulse</code> or <code class="literal">PulseAll</code> methods. This allows the coordination the different threads execution into some sort of sequence.</p><p>A simple example of such workflow is when we have two threads: the main thread and an additional thread that performs some calculation. We would like to pause the main thread until the second thread finishes its work, and then get back to the main thread, and in turn block this additional thread until we have other data to calculate. This can be illustrated by the following code:</p><div class="informalexample"><pre class="programlisting">var arg = 0;
var result = "";
var counter = 0;
var lockHandle = new object();
var calcThread = new Thread(() =&gt; {
  while (true)
  lock (lockHandle) 
  {
    counter++;
    result = arg.ToString();
    Monitor.Pulse(lockHandle);
    Monitor.Wait(lockHandle);
  }
})
{
  IsBackground = true
};
lock (lockHandle) 
{
  calcThread.Start();
  Thread.Sleep(100);
  Console.WriteLine("counter = {0}, result = {1}", counter, result);

  arg = 123;
  Monitor.Pulse(lockHandle);
  Monitor.Wait(lockHandle);
  Console.WriteLine("counter = {0}, result = {1}", counter, result);

  arg = 321;
  Monitor.Pulse(lockHandle);
  Monitor.Wait(lockHandle);
  Console.WriteLine("counter = {0}, result = {1}", counter, result);
}</pre></div><p>As a result of <a id="id15" class="indexterm"></a>running this program, we will get the following output:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>counter = 0, result =</strong></span>
<span class="strong"><strong>counter = 1, result = 123</strong></span>
<span class="strong"><strong>counter = 2, result = 321</strong></span>
</pre></div><p>At first, we start a calculation thread. Then we print the initial values for <code class="literal">counter</code> and <code class="literal">result</code>, and then we call <code class="literal">Pulse</code>. This puts the calculation thread into a queue called<a id="id16" class="indexterm"></a> <span class="strong"><strong>ready queue</strong></span>. This means that this thread is ready to acquire this lock as soon as it gets released. Then we call the <code class="literal">Wait</code> method, which releases the lock and puts the main thread into a <a id="id17" class="indexterm"></a>
<span class="strong"><strong>waiting queue</strong></span>. The first thread in the ready queue, which is our calculation thread, acquires the lock and starts to work. After completing its calculations, the second thread calls <code class="literal">Pulse</code>, which moves a thread at the head of the waiting queue (which is our main thread) into the ready queue. If there are several threads in the waiting queue, only the first one would go into the ready queue. To put all the threads into the ready queue at once, we could use the <code class="literal">PulseAll</code> method. So, when the second thread calls <code class="literal">Wait</code>, our main thread reacquires the lock, changes the calculation data, and repeats the whole process one more time.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note04"></a>Note</h3><p>Note that we can use the <code class="literal">Wait</code>, <code class="literal">Pulse</code>, and <code class="literal">PulseAll</code> methods only when the current thread owns a lock. The <code class="literal">Wait</code> method could block indefinitely in case no other threads call <code class="literal">Pulse</code> or <code class="literal">PulseAll</code>, so it can be a reason for a deadlock. To prevent deadlocks, we can specify a timeout value to the <code class="literal">Wait</code> method to be able to react in case we cannot reacquire the lock for a certain time period.</p></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec10"></a>Reader-writer lock</h2></div></div><hr /></div><p>It is very common to see <a id="id18" class="indexterm"></a>samples of code where the shared state is one of the standard .NET collections: <code class="literal">List&lt;T&gt; </code>or <code class="literal">Dictionary&lt;K,V&gt;</code>. These collections are not thread safe; thus we need synchronization to organize concurrent access.</p><p>There are special concurrent collections that can be used instead of the standard list and dictionary to achieve thread safety. We will review them in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Using Concurrent Data Structures</em></span>. For now, let us assume that we have reasons to organize concurrent access by ourselves.</p><p>The easiest way to achieve synchronization is to use the <code class="literal">lock</code> operator when reading and writing from these collections. However, the MSDN documentation states that if a collection is not modified while being read, synchronization is not required:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>It is safe to perform multiple read operations on a List&lt;T&gt;, but issues can occur if the collection is modified while it's being read.</em></span></p></blockquote></div><p>Another important MSDN page states the following regarding a collection:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>A Dictionary&lt;TKey, TValue&gt; can support multiple readers concurrently, as long as the collection is not modified.</em></span></p></blockquote></div><p>This means that we can perform the read operations from multiple threads if the collection is not being modified. This allows us to avoid excessive locking, and minimizes performance overhead and possible deadlocks in such situations.</p><p>To leverage this, there is a standard .NET Framework class, <code class="literal">System.Threading.ReaderWriterLock</code>. It provides three types of locks: to read something from a resource, to write something, and a special one to upgrade the reader lock to a writer lock. The following method pairs represent these locks: <code class="literal">AcquireReaderLock/ReleaseReaderLock</code>, <code class="literal">AcquireWriterLock/ReleaseWriterLock</code>, and <code class="literal">UpgradeToWriterLock/DowngradeFromWriterLock</code>, correspondingly. It is also possible to provide a timeout value, after which the request to acquire the lock will expire. Providing the <code class="literal">-1</code> value means that a lock has no timeout.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note05"></a>Note</h3><p>It is important to always release a lock after acquiring it. Always put the code for releasing a lock into the <code class="literal">finally</code> block of the <code class="literal">try</code>
<span class="strong"><strong>/</strong></span>
<code class="literal">catch</code> statement, otherwise any exception thrown before releasing this lock would leave the <code class="literal">ReaderWriterLock</code> object in a locked state, preventing any further access to this lock.</p></div><p>A reader lock puts a thread in the blocked state only when there is at least one writer lock acquired. Otherwise, no real thread blocking happens. A writer lock waits until every other lock is released, and then in turn it prevents the acquiring of any other locks, until it's released.</p><p>Upgrading a<a id="id19" class="indexterm"></a> lock is useful; when inside an open reader lock, we need to write something into a collection. For example, we first check if there is an entry with some key in the dictionary, and insert this entry if it does not exist. Acquiring a writer lock would be inefficient, since there could be no write operation, so it is optimal to use this upgrade scenario.</p><p>Note that using any kind of lock is still not as efficient as a simple check, and it makes sense to use patterns such as double-checked locking. Consider the follow code snippet:</p><div class="informalexample"><pre class="programlisting">if(writeRequiredCondition)
{
  _rwLock.AcquireWriterLock();
  try 
  {
    if(writeRequiredCondition)
      // do write
  }
  finally
  {
    _rwLock.ReleaseWriterLock();
  }
}</pre></div><p>The <code class="literal">ReaderWriterLock</code> class has a nested locks counter, and it avoids creating a new lock when trying to acquire it when inside another lock. In such a case, the lock counter is incremented and then decremented when the nested lock is released. The real lock is acquired only when this counter is equal to to 0.</p><p>Nevertheless, this implementation has some serious drawbacks. First, it uses thread blocking, which is quite performance costly, and besides that, adds its own additional overhead. In addition, if the write operation is very short, then using <code class="literal">ReaderWriterLock</code> could be even worse than simply locking the collection for every operation. In addition to that, the method names and semantics are not intuitive, which makes reading and understanding the code much harder.</p><p>This is the reason why the new implementation, <code class="literal">System.Threading.ReaderWriterLockSlim</code>, was introduced in .NET Framework 3.5. It should <span class="emphasis"><em>always </em></span>be used instead of <code class="literal">ReaderWriterLock</code> for the following reasons:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>It is more efficient, especially with short locks.</p></li><li style="list-style-type: disc"><p>Method names became more intuitive: <code class="literal">EnterReadLock/ExitReadLock</code>, <code class="literal">EnterWriteLock/ExitWriteLock</code>, and <code class="literal">EnterUpgradeableReadLock/ExitUpgradeableReadLock</code>.</p></li><li style="list-style-type: disc"><p>If we try to acquire a writer lock inside a reader lock, it will be an upgrade by default.</p></li><li style="list-style-type: disc"><p>Instead of using a timeout value, separate methods have been added: <code class="literal">TryEnterReadLock</code>, <code class="literal">TryEnterWriteLock</code>, and <code class="literal">TryEnterUpgradeableReadLock</code>, which make the code cleaner.</p></li><li style="list-style-type: disc"><p>Using nested locks is now forbidden by default. It is possible to allow nested locks by specifying a constructor parameter, but using nested locks is usually a mistake and this behavior helps to explicitly declare how it is intended to deal with them.</p></li><li style="list-style-type: disc"><p>Internal enhancements help to improve performance and avoid deadlocks.</p></li></ul></div><p>The following is an<a id="id20" class="indexterm"></a> example of different locking strategies for <code class="literal">Dictionary&lt;K,V&gt;</code> in the  multiple readers / single writer scenario. First, we define how many readers and writers we're going to have, how long a read and write operation will take, and how many times to repeat those operations.</p><div class="informalexample"><pre class="programlisting">static class Program
{
  private const int _readersCount = 5;
  private const int _writersCount = 1;
  private const int _readPayload = 100;
  private const int _writePayload = 100;
  private const int _count = 100000;</pre></div><p>Then we define the common test logic. The target dictionary is being created along with the reader and writer methods. The method called <code class="literal">Measure</code> uses LINQ to measure the performance of concurrent access.</p><div class="informalexample"><pre class="programlisting">private static readonly Dictionary&lt;int, string&gt; _map = new Dictionary&lt;int, string&gt;();

private static void ReaderProc()
{
  string val;
  _map.TryGetValue(Environment.TickCount % _count, out val);
  // Do some work
  Thread.SpinWait(_readPayload);
}

private static void WriterProc()
{
   var n = Environment.TickCount % _count;
   // Do some work
  Thread.SpinWait(_writePayload);
  _map[n] = n.ToString();
}

private static long Measure(Action reader, Action writer)
{
  var threads = Enumerable
      .Range(0, _readersCount)
      .Select(n =&gt; new Thread(
        () =&gt; {
          for (int i = 0; i &lt; _count; i++)
            reader();
        }))
      .Concat(Enumerable
        .Range(0, _writersCount)
        .Select(n =&gt; new Thread(
          () =&gt; {
            for (int i = 0; i &lt; _count; i++)
              writer();
      })))
      .ToArray();
    _map.Clear();
    var sw = Stopwatch.StartNew();
    foreach (var thread in threads)
      thread.Start();

    foreach (var thread in threads)
       thread.Join();

     sw.Stop();
    return sw.ElapsedMilliseconds;
  }</pre></div><p>Then we use simple<a id="id21" class="indexterm"></a> lock to synchronize concurrent access to the dictionary:</p><div class="informalexample"><pre class="programlisting">  private static readonly object _simpleLockLock = new object();

  private static void SimpleLockReader()
  {
    lock (_simpleLockLock)
      ReaderProc();
  }

  private static void SimpleLockWriter()
  {
    lock (_simpleLockLock)
      WriterProc();
  }</pre></div><p>The second test is<a id="id22" class="indexterm"></a> using an older <code class="literal">ReaderWriterLock</code> class as follows:</p><div class="informalexample"><pre class="programlisting">  private static readonly ReaderWriterLock _rwLock = new ReaderWriterLock();

  private static void RWLockReader() 
{
    _rwLock.AcquireReaderLock(-1);
    try
    {
      ReaderProc();
    }
    finally
    {
      _rwLock.ReleaseReaderLock();
    }
  }

  private static void RWLockWriter()
  {
    _rwLock.AcquireWriterLock(-1);
    try
    {
      WriterProc();
    }
    finally
    {
      _rwLock.ReleaseWriterLock();
     }
  }</pre></div><p>Finally, we'll demonstrate the usage of <code class="literal">ReaderWriterLockSlim</code>:</p><div class="informalexample"><pre class="programlisting">  private static readonly ReaderWriterLockSlim _rwLockSlim = new ReaderWriterLockSlim();

  private static void RWLockSlimReader()
  {
    _rwLockSlim.EnterReadLock();
    try
    {
      ReaderProc();
    }
    finally 
    {
      _rwLockSlim.ExitReadLock();
    }
  }

  private static void RWLockSlimWriter()
  {
    _rwLockSlim.EnterWriteLock();
    try 
    {
      WriterProc();
    }
    finally 
    {
      _rwLockSlim.ExitWriteLock();
    }
  }</pre></div><p>Now we run all of these<a id="id23" class="indexterm"></a> tests, using one iteration as a warm up to exclude any first run issues that could affect the overall performance:</p><div class="informalexample"><pre class="programlisting">static void Main()
{
  // Warm up
    Measure(SimpleLockReader, SimpleLockWriter);

    // Measure
    var simpleLockTime = Measure(SimpleLockReader, SimpleLockWriter);
    Console.WriteLine("Simple lock: {0}ms", simpleLockTime);

    // Warm up
    Measure(RWLockReader, RWLockWriter);

    // Measure
    var rwLockTime = Measure(RWLockReader, RWLockWriter);
    Console.WriteLine("ReaderWriterLock: {0}ms", rwLockTime);

    // Warm up
    Measure(RWLockSlimReader, RWLockSlimWriter);

     // Measure
    var rwLockSlimTime = Measure(RWLockSlimReader, RWLockSlimWriter);
    Console.WriteLine("ReaderWriterLockSlim: {0}ms", rwLockSlimTime);
  }
}</pre></div><p>Executing this code on Core i7 2600K and x64 OS in the Release configuration gives the following results:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Simple lock: 367ms</strong></span>
<span class="strong"><strong>ReaderWriterLock: 246ms</strong></span>
<span class="strong"><strong>ReaderWriterLockSlim: 183ms</strong></span>
</pre></div><p>It shows that <code class="literal">ReaderWriterLockSlim</code> is about 2 times faster than the usual lock statement.</p><p>You can change the <a id="id24" class="indexterm"></a>number of reader and writer threads, tweak the lock time, and see how the performance changes in each case.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note06"></a>Note</h3><p>Note that using a reader writer lock on the collection is not enough to provide a possibility to iterate over this collection. While the collection itself will be in the correct state, while iterating, if any of the collection items were removed or added, an exception will be thrown. This means, that you need to put all the iteration process inside a lock, or produce a new immutable copy of the collection and iterate over this copy.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec11"></a>Spin lock</h2></div></div><hr /></div><p>Using operating system <a id="id25" class="indexterm"></a>level synchronization primitives requires quite a noticeable amount of resources, because of the context switching and all the entire corresponding overhead. Besides this, there is such thing as lock latency; that is, the time required for a lock to be notified about the state change of another lock. This means that when the current lock is being released, it takes some additional time for another lock to be signaled. This is the reason why when we need short time locks, it could be significantly faster to use a single thread without any locks than to parallelize these operations using OS level locking mechanics.</p><p>To avoid unnecessary context switches in such a situation, we can use a loop, which checks the other locks in each iteration. Since the locks should be very short, we would not use too much CPU, and we have a significant performance boost by not using the operating system resources and by lowering lock latency to the lowest amount.</p><p>This pattern is not so easy to implement, and, to be effective, you would need to use specific CPU instructions. Fortunately, there is a standard implementation of this pattern in the .NET Framework starting with version 3.5. The implementation contains the following methods and classes:</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec10"></a>Thread.SpinWait</h3></div></div></div><p><code class="literal">Thread.SpinWait</code> <a id="id26" class="indexterm"></a>just spins<a id="id27" class="indexterm"></a> an infinite loop. It's like <code class="literal">Thread.Sleep</code>, only without context switching and using CPU time. It is used rarely in common scenarios, but could be useful in some specific cases, such as simulating real CPU work.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec11"></a>System.Threading.SpinWait</h3></div></div></div><p><code class="literal">System.Threading.SpinWait</code> is <a id="id28" class="indexterm"></a>a structure <a id="id29" class="indexterm"></a>implementing a loop with a condition check. It is used internally in spinlock implementation.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec12"></a>System.Threading.SpinLock</h3></div></div></div><p>Here we will be<a id="id30" class="indexterm"></a> discussing <a id="id31" class="indexterm"></a>about the spinlock implementation itself.</p><p>Note that it is a structure which allows to save on class instance allocation and reduces GC overhead.</p><p>The spinlock can optionally use a<a id="id32" class="indexterm"></a> <span class="strong"><strong>memory barrier</strong></span> (or a memory fencing instruction) to notify other threads that the lock has been released. The default behavior is to use a memory barrier, which prevents memory access operation reordering by compiler or hardware, and improves the fairness of the lock at the expense of performance. The other case is faster, but could lead to incorrect behavior in some situations.</p><p>Usually, it's not encouraged to use a spinlock directly unless you are 100% sure what you're doing. Make sure that you have confirmed the performance bottleneck with tests and you know that your locks are really short.</p><p>The code inside a spin lock <span class="strong"><strong>should not</strong></span> do the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Use regular locks, or a code that uses locks</p></li><li style="list-style-type: disc"><p>Acquire more than one spinlock at a time</p></li><li style="list-style-type: disc"><p>Perform dynamic dispatched calls (virtual methods, interface methods, or delegate calls)</p></li><li style="list-style-type: disc"><p>Call any third-party code, which is not controlled by you</p></li><li style="list-style-type: disc"><p>Perform memory allocation, including new operator usage</p></li></ul></div><p>The following is a sample test for a spinlock:</p><div class="informalexample"><pre class="programlisting">static class Program
{
  private const int _count = 10000000;

  static void Main()
  {
    // Warm up
    var map = new Dictionary&lt;double, double&gt;();
    var r = Math.Sin(0.01);

    // lock
    map.Clear();
    var prm = 0d;
    var lockFlag = new object();
    var sw = Stopwatch.StartNew();
    for (int i = 0; i &lt; _count; i++)
      lock (lockFlag)
      {
        map.Add(prm, Math.Sin(prm));
        prm += 0.01;
      }
    sw.Stop();
    Console.WriteLine("Lock: {0}ms", sw.ElapsedMilliseconds);

    // spinlock with memory barrier
    map.Clear();
    var spinLock = new SpinLock();
    prm = 0;
    sw = Stopwatch.StartNew();
    for (int i = 0; i &lt; _count; i++)
    {
      var gotLock = false;
      try
      {
        spinLock.Enter(ref gotLock);
        map.Add(prm, Math.Sin(prm));
        prm += 0.01;
      }
      finally
      {
        if (gotLock)
          spinLock.Exit(true);
      }
    }
    sw.Stop();
    Console.WriteLine("Spinlock with memory barrier: {0}ms", sw.ElapsedMilliseconds);

    // spinlock without memory barrier
    map.Clear();
    prm = 0;
    sw = Stopwatch.StartNew();
    for (int i = 0; i &lt; _count; i++)
    {
      var gotLock = false;
      try
      {
        spinLock.Enter(ref gotLock);
        map.Add(prm, Math.Sin(prm));
        prm += 0.01;
      }
      finally
      {
        if (gotLock)
          spinLock.Exit(false);
      }
    }
    sw.Stop();
    Console.WriteLine("Spinlock without memory barrier: {0}ms", sw.ElapsedMilliseconds);
  }
}</pre></div><p>Executing this <a id="id33" class="indexterm"></a>code on Core i7 2600K and x64 OS in Release <a id="id34" class="indexterm"></a>configuration gives the following results:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Lock: 1906ms</strong></span>
<span class="strong"><strong>Spinlock with memory barrier: 1761ms</strong></span>
<span class="strong"><strong>Spinlock without memory barrier: 1731ms</strong></span>
</pre></div><p>Note that the performance boost is very small even with short duration locks. Also note that starting from .NET Framework 3.5, the <code class="literal">Monitor</code>, <code class="literal">ReaderWriterLock,</code> and <code class="literal">ReaderWriterLockSlim</code> classes are implemented with spinlock.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note07"></a>Note</h3><p>The main disadvantage of spinlocks is intensive CPU usage. The endless loop consumes energy, while the blocked thread does not. However, now the standard <code class="literal">Monitor</code> class can use spinlock for a short time lock and then turn to usual lock, so in real world scenarios the difference would be even less noticeable than in this test.</p></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec12"></a>Optimization strategy</h2></div></div><hr /></div><p>Creating parallel algorithms is <a id="id35" class="indexterm"></a>not a simple task: there is no universal solution to it. In every case, you have to use a specific approach to write effective code. However, there are several simple rules that work for most of the parallel programs.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec13"></a>Lock localization</h3></div></div></div><p>The first thing to take into <a id="id36" class="indexterm"></a>account when writing parallel code is to lock as<a id="id37" class="indexterm"></a> little code as possible, and ensure that the code inside the lock runs as fast as possible. This makes it less deadlock-prone and scale better with the number of CPU cores. To sum up, acquire the lock as late as possible and release it as soon as possible.</p><p>Let us consider the following situation: for example, we have some calculation performed by method <code class="literal">Calc</code> without any side effects. We would like to call it with several different arguments and store the results in a list. The first intention is to write the code as follows:</p><div class="informalexample"><pre class="programlisting">for (var i = from; i &lt; from + count; i++)
  lock (_result)
    _result.Add(Calc(i));</pre></div><p>This code works, but we call the <code class="literal">Calc</code> method and perform the calculation inside our lock. This calculation does not have any side effects, and thus requires no locking, so it would be much more efficient to rewrite the code as shown next:</p><div class="informalexample"><pre class="programlisting">for (var i = from; i &lt; from + count; i++)
{
  var calc = Calc(i);
  lock (_result)
    _result.Add(calc);
}</pre></div><p>If the calculation takes a significant amount of time, then this improvement could make the code run several times faster.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec14"></a>Shared data minimization</h3></div></div></div><p>Another way of improving <a id="id38" class="indexterm"></a>parallel code performance is by <a id="id39" class="indexterm"></a>minimizing the shared data, which is being written in parallel. It is a common situation when we lock over the whole collection every time we write into it, instead of thinking and lowering the amount of locks and the data being locked. Organizing concurrent access and data storage in a way that it minimizes the number of locks can lead to a significant performance increase.</p><p>In the previous example, we locked the entire collection each time, as described in the previous paragraph. However, we really don't care about which worker thread processes exactly what piece of information, so we could rewrite the previous code like the following:</p><div class="informalexample"><pre class="programlisting">var tempRes = new List&lt;string&gt;(count);
for (var i = from; i &lt; from + count; i++)
{
  var calc = Calc(i);
  tempRes.Add(calc);
}
lock (_result)
  _result.AddRange(tempRes);</pre></div><p>The following is <a id="id40" class="indexterm"></a>the<a id="id41" class="indexterm"></a> complete comparison:</p><div class="informalexample"><pre class="programlisting">static class Program
{
  private const int _count = 1000000;
  private const int _threadCount = 8;

  private static readonly List&lt;string&gt; _result = new List&lt;string&gt;();

  private static string Calc(int prm) 
  {
    Thread.SpinWait(100);
    return prm.ToString();
  }

  private static void SimpleLock(int from, int count) 
  {
    for (var i = from; i &lt; from + count; i++)
      lock (_result)
    _result.Add(Calc(i));
  }

  private static void MinimizedLock(int from, int count) 
  {
    for (var i = from; i &lt; from + count; i++) 
    {
      var calc = Calc(i);
      lock (_result)
      _result.Add(calc);
    }
  }

  private static void MinimizedSharedData(int from, int count) 
  {
    var tempRes = new List&lt;string&gt;(count);
    for (var i = from; i &lt; from + count; i++)
    {
      var calc = Calc(i);
      tempRes.Add(calc);
    }
    lock (_result)
      _result.AddRange(tempRes);
  }

  private static long Measure(Func&lt;int, ThreadStart&gt; actionCreator)
  {
    _result.Clear();
    var threads =
      Enumerable
        .Range(0, _threadCount)
        .Select(n =&gt; new Thread(actionCreator(n)))
        .ToArray();
    var sw = Stopwatch.StartNew();
    foreach (var thread in threads)
      thread.Start();
    foreach (var thread in threads)
      thread.Join();
    sw.Stop();
    return sw.ElapsedMilliseconds;
  }

  static void Main()
  {
    // Warm up
    SimpleLock(1, 1);
    MinimizedLock(1, 1);
    MinimizedSharedData(1, 1);

    const int part = _count / _threadCount;

    var time = Measure(n =&gt; () =&gt; SimpleLock(n*part, part));
    Console.WriteLine("Simple lock: {0}ms", time);

    time = Measure(n =&gt; () =&gt; MinimizedLock(n * part, part));
    Console.WriteLine("Minimized lock: {0}ms", time);

    time = Measure(n =&gt; () =&gt; MinimizedSharedData(n * part, part));
    Console.WriteLine("Minimized shared data: {0}ms", time);
  }
}</pre></div><p>Executing this code<a id="id42" class="indexterm"></a> on Core i7 2600K and x64 OS in <a id="id43" class="indexterm"></a>Release configuration gives the following results:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Simple lock: 806ms</strong></span>
<span class="strong"><strong>Minimized lock: 321ms</strong></span>
<span class="strong"><strong>Minimized shared data: 165ms</strong></span>
</pre></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec13"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we learned about the issues with using shared data from multiple threads. We looked through the different techniques allowing us to organize concurrent access to shared state more efficiently in different scenarios. We also established an understanding about the performance issues of using locks, thread blocking, and context switching.</p><p>In the next chapter, we will continue to explore concurrent access to shared data. However, this time we will try to avoid locks and make our parallel program more robust and efficient.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch02"></a>Chapter 2. Lock-Free Concurrency</h2></div></div></div><p>In <a class="link" href="#" linkend="ch01">Chapter 1</a>, <span class="emphasis"><em>Traditional Concurrency</em></span>, we reviewed thread synchronization with locking and how to use locks effectively. However, there will be still performance overhead related to locking. The best way to avoid such issues is by not using locks at all whenever possible. Algorithms that do not use locking are referred to as<a id="id44" class="indexterm"></a> <span class="strong"><strong>lock-free</strong></span> algorithms.</p><p>Lock-free algorithms in turn are of different types. One of the most important types is <a id="id45" class="indexterm"></a>
<span class="strong"><strong>wait-free</strong></span> algorithms. These algorithms not only evade the use of locks, but also are guaranteed to not wait for any events from other threads. This is a best-case scenario but unfortunately, it is a rare situation when we can avoid waiting for the other threads at all. Usually, a real concurrent program tries to be as close as possible to wait-free, and this is what every developer should try to achieve.</p><p>There is one more category of algorithms that do not use OS-level thread blocking but use spin locks. This allows the creation of quite efficient code in situations when the code inside the lock has to run very fast. Such algorithms can be called lock-free in various sources, but strictly speaking they are not as they do not guarantee that the algorithm will be progressing, since it is possible it gets blocked in various situations. We will discuss such situations later in <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Troubleshooting Parallel Programs</em></span>.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note08"></a>Note</h3><p>Please notice that a multithreaded program can be targeted in different scenarios, and thus the metrics could be different. For example, if our goal is to save the battery charge of a laptop or to save the CPU workload, locking techniques are preferred (until some point when there will be too many blocked threads). However, if we need overall performance, then lock-free algorithms are usually better.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec14"></a>Memory model and compiler optimizations</h2></div></div><hr /></div><p>Memory model<a id="id46" class="indexterm"></a> and compiler optimizations<a id="id47" class="indexterm"></a> are not directly related to concurrency, but they are very important concepts for anyone who creates concurrent code, shown as follows:</p><div class="informalexample"><pre class="programlisting">class Program
{
  bool _loop = true;

  static void Main(string[] args)
  {
    var p = new Program();

    Task.Run(() =&gt;
    {
      Thread.Sleep(100);
      p._loop = false;
    });

    while (p._loop);
    //while (p._loop) { Console.Write(".");};

    Console.WriteLine("Exited the loop");
  }
}</pre></div><p>If you compile this with the Release build configuration and JIT compiler optimizations enabled, the loop will usually hang on the x86 and x64 architectures. This happens because JIT optimizes the p._loop read and does something like this:</p><div class="informalexample"><pre class="programlisting">if(p._loop)
{
  while(true);
}</pre></div><p>If there is something inside the while loop, JIT will probably not optimize this code in this way. Also, we may use the <span class="strong"><strong>volatile</strong></span> keyword<a id="id48" class="indexterm"></a> with the Boolean flag like this:</p><div class="informalexample"><pre class="programlisting">volatile bool _loop;</pre></div><p>In this case, JIT will turn off this optimization as well. This is where we use a memory model, and it gets complicated here. Here is a quote from the C# language specification:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>For non-volatile fields, optimization techniques that reorder instructions can lead to unexpected and unpredictable results in multi-threaded programs that access fields without synchronization such as that provided by the lock-statement. These optimizations can be performed by the compiler, by the run-time system, or by hardware. For volatile fields, such reordering optimizations are restricted:</em></span></p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="emphasis"><em>A read of a volatile field is called a</em></span> <a id="id49" class="indexterm"></a><span class="emphasis"><em>volatile read. A volatile read has "acquire semantics"; that is, it is guaranteed to occur prior to any references to memory that occur after it in the instruction sequence.</em></span></p></li><li style="list-style-type: disc"><p><span class="emphasis"><em>A write of a volatile field is called a</em></span><a id="id50" class="indexterm"></a> <span class="emphasis"><em>volatile write. A volatile write has "release semantics"; that is, it is guaranteed to happen after any memory references prior to the write instruction in the instruction sequence.</em></span></p></li></ul></div></blockquote></div><p>As we can see, there is<a id="id51" class="indexterm"></a> nothing specifically stated here about compiler optimizations, but<a id="id52" class="indexterm"></a> in fact JIT does not optimize volatile field read in this case.</p><p>So we can see a description in a specification, but how does this really work? Let's look at a volatile read example:</p><div class="informalexample"><pre class="programlisting">class VolatileRead
{
  int _x;
  volatile int _y;
  int _z;

  void Read()
  {
    int x = _x; // 1
    int y = _y; // 2 (volatile)
    int z = _z; // 3
  }
}</pre></div><p>The possible reordering options would be 1, 2, 3 (original); 2, 1, 3; and 2, 3, 1. This can be imagined as a one-way fence that allows the preceding operation to pass through, but does not allow subsequent operations. So this is called the <a id="id53" class="indexterm"></a>
<span class="strong"><strong>acquire fence</strong></span>.</p><p>Volatile writes look pretty similar. Consider the following code snippet:</p><div class="informalexample"><pre class="programlisting">class VolatileWrite
{
  int _x;
  volatile int _y;
  int _z;

  void Read()
  {
    _x = 1; // 1
    _y = 2; // 2 (volatile)
    _z = 3; // 3
  }
}</pre></div><p>Possible options here are 1, 2, 3 (original); 1, 3, 2; and 3, 1, 2. This is the<a id="id54" class="indexterm"></a> <span class="strong"><strong>release fence</strong></span>, which allows the reordering of only subsequent read or write operations but does not allow the preceding write operation. We have the <code class="literal">Thread.VolatileRead</code> and <code class="literal">Thread.VolatileWrite</code> methods that do the same thing explicitly. There is the <code class="literal">Thread.MemoryBarrier</code> (<span class="strong"><strong>memory barrier</strong></span>) method as well, which allows us to use a full fence when we do not<a id="id55" class="indexterm"></a> let through any operations.</p><p>I would like to mention <a id="id56" class="indexterm"></a>that we are now on less certain ground. Different memory models on different architectures can be confusing, and code without <span class="strong"><strong>volatile</strong></span><a id="id57" class="indexterm"></a> can <a id="id58" class="indexterm"></a>perfectly work on x86 and amd64. However, if you are using shared data, please be aware of possible reordering and non-reordering optimizations and choose the appropriate behavior.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note09"></a>Note</h3><p>Please be aware that making a field volatile means that all the read and write operations will have slightly lower performance and they will have the code in common, since some possible optimizations will be ignored.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec15"></a>The System.Threading.Interlocked class</h2></div></div><hr /></div><p>When we reviewed <a id="id59" class="indexterm"></a>race conditions in the previous chapter, we learned that even a simple increment operation consists of three separate actions. Although modern CPUs can perform such operations at once, it is necessary to make them safe to be used in concurrent programs.</p><p>The .NET Framework contains the <code class="literal">System.Threading.Interlocked</code> class that provides access to several operations that are<a id="id60" class="indexterm"></a> <span class="strong"><strong>atomic</strong></span>, which means that they are uninterruptible and appear to occur instantaneously to the rest of the system. These are the operations that the lock-free algorithms are based on.</p><p>Let's revise a race condition example and compare the locking and <code class="literal">Interlocked</code> class operations. First, we will use the traditional locking approach:</p><div class="informalexample"><pre class="programlisting">var counterLock = new object();
var counter = 0;
ThreadStart proc =
  () =&gt;
  {
    for (int i = 0; i &lt; count; i++)
    {
      lock (counterLock)
        counter++;
      Thread.SpinWait(100);
      lock (counterLock)
        counter--;
    }
  };
var threads =
  Enumerable
    .Range(0, 8)
    .Select(n =&gt; new Thread(proc))
    .ToArray();
var sw = Stopwatch.StartNew();
foreach (var thread in threads)
  thread.Start();
foreach (var thread in threads)
  thread.Join();
sw.Stop();
Console.WriteLine("Locks: counter={0}, time = {1}ms", counter, sw.ElapsedMilliseconds);</pre></div><p>Now, let's replace <a id="id61" class="indexterm"></a>locking with the <code class="literal">Interlocked</code> class method calls:</p><div class="informalexample"><pre class="programlisting">counter = 0;
ThreadStart proc2 =
  () =&gt;
  {
    for (int i = 0; i &lt; count; i++)
    {
      Interlocked.Increment(ref counter);
      Thread.SpinWait(100);
      Interlocked.Decrement(ref counter);
    }
  };
threads =
  Enumerable
    .Range(0, 8)
    .Select(n =&gt; new Thread(proc2))
    .ToArray();
sw = Stopwatch.StartNew();
foreach (var thread in threads)
  thread.Start();
foreach (var thread in threads)
  thread.Join();
sw.Stop();
Console.WriteLine("Lock free: counter={0}, time = {1}ms", counter, sw.ElapsedMilliseconds);</pre></div><p>As a result, we got this on a reference computer:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Locks: counter=0, time = 1892ms</strong></span>
<span class="strong"><strong>Locks: counter=0, time = 800ms</strong></span>
</pre></div><p>Just using atomic operations performed more than twice as well and kept the program logic correct.</p><p>Another tricky part is 64-bit integer calculations. When the program runs in the 64-bit mode, the read and write operations for 64-bit integer numbers are atomic. However, when running in the 32-bit mode, these operations become nonatomic and consist of two parts—reading/writing high 32 bits and low 32 bits of the number.</p><p>The <code class="literal">Interlocked</code> class contains the <code class="literal">Read</code> method that can read a 64-bit integer in the 32-bit mode as an atomic operation. This is not required in 64-bit mode, but if you compile your program in any CPU mode then you should use this method to guarantee atomicity of reads. There are the <code class="literal">Increment</code> and <code class="literal">Decrement</code> method overloads for 64-bit integers as well, and there is the <code class="literal">Add</code> method that allows us to have atomic addition of 32-bit and 64-bit integers.</p><p>Another very <a id="id62" class="indexterm"></a>important operation is the value exchange. Looking at the following code it is obvious that this operation is not atomic, and thus we must put this code inside some kind of lock to keep this operation correct in a concurrent program:</p><div class="informalexample"><pre class="programlisting">var tmp = a;
a = b;
b = tmp;</pre></div><p>The <code class="literal">Interlocked</code> class allows us to perform this operation as atomic with the <code class="literal">Exchange </code>method:</p><div class="informalexample"><pre class="programlisting">b = Interlocked.Exchange(ref a, b)</pre></div><p>There are several overloads for this method that allow us to exchange the numeric values of different types including 32-bit and 64-bit integers, the <code class="literal">float</code> and <code class="literal">double</code> values, object references (there is a generic version of this method with the <code class="literal">type</code> parameter), and the <code class="literal">IntPtr</code> structures.</p><p>The most complicated atomic operation provided by the <code class="literal">Interlocked</code> class is the <code class="literal">CompareExchange</code> method. It accepts three arguments, then it compares the first argument with the third; if they are equal, it assigns the second argument value to the first argument. This is performed by special instruction on hardware too. We will see an example of this later in this chapter when we try to implement a lock-free queue.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note10"></a>Note</h3><p>All the <code class="literal">Interlocked</code> class method calls implicitly generate full fences.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec16"></a>Interlocked internals</h2></div></div><hr /></div><p>To understand how interlocked internals<a id="id63" class="indexterm"></a> work under the hood, we're going to see what machine code is being generated when compiling the <code class="literal">Interlocked.Increment</code> method. If we just run the program in debug mode and look at the disassembly window, we will see the usual method call.</p><p>To see what is really going on, we have to enable all optimizations:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>First, we need to build the code in the Release mode in Visual Studio.</p></li><li><p>Then, we have to go to <span class="strong"><strong>Tools</strong></span> | <span class="strong"><strong>Options</strong></span> | <span class="strong"><strong>Debugging</strong></span> | <span class="strong"><strong>General</strong></span> and uncheck the <span class="strong"><strong>Suppress JIT optimization on module load</strong></span> option.</p></li><li><p>Finally, add a <code class="literal">System.Diagnostics.Debugger.Break()</code> method call to pause the code in debugger.</p></li></ol></div><p>If everything is set, you will see the following code in the disassembly window:</p><div class="informalexample"><pre class="programlisting">Interlocked.Increment(ref counter);

00007FFEF22B49AE  lea         rcx,[rsi+20h]
00007FFEF22B49B2  lock add    dword ptr [rcx],1</pre></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note11"></a>Note</h3><p>Please notice the <span class="strong"><strong>lock</strong></span> prefix in the last line of the code. This prefix is an instruction to the CPU to perform an atomic increment operation. This means that the <code class="literal">Interlocked</code> class is not a usual class, but a hint to the JIT compiler to generate a special code.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec17"></a>Writing lock-free code</h2></div></div><hr /></div><p>Since we have a very <a id="id64" class="indexterm"></a>limited number of atomic operations, it is very hard to write lock-free code. For some common data structures, such as a double linked list, there is no lock-free implementation. Besides, it is very easy to make a mistake, and the main problem is that such code could work fine 99.9 percent of the time, which makes debugging enormously confusing.</p><p>Therefore, the best practice is to use standard implementations of such algorithms. A good place to start is by using concurrent collections from the <code class="literal">System.Collections.Concurrent</code> namespace that was introduced in the .NET Framework 4.0. We will review them in detail in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Using Concurrent Data Structures</em></span>. However, now we will try to do not as advised and implement a lock-free stack and a lock-free queue from scratch.</p><p>The cornerstone of the lock-free code is the following pattern: read some data from the shared state, calculate a new value, and then write the new value back, but only if the shared state wasn't mutated by any other thread by that time. The last check and write operation must be atomic, and this is what we use <code class="literal">Interlocked.CompareExchange</code> for. This description looks a bit confusing, but it can be illustrated with quite an easy example. Imagine multiple threads calculating an integer sum in parallel. Consider the following line of code, for example:</p><div class="informalexample"><pre class="programlisting">_total += current;</pre></div><p>If we use this simple code, we would get race condition here since this operation is not atomic. The easiest way to fix this is by using atomic addition with the <code class="literal">Interlocked.Add</code> method, but to illustrate the <code class="literal">CompareExchange</code> method logic, let's implement the addition like this:</p><div class="informalexample"><pre class="programlisting">int beforeValue, newValue;
do
{
  beforeValue = _total;
  newValue = beforeValue + current;
}
while (beforeValue != Interlocked.CompareExchange(ref _total, newValue, beforeValue))</pre></div><p>First, we save the <code class="literal">_total</code> value in the <code class="literal">beforeValue</code> temporary variable. Then, we calculate a new value and store it in <code class="literal">newValue</code>. Finally, we're trying to save <code class="literal">newValue</code> in <code class="literal">_total</code>, but <a id="id65" class="indexterm"></a>only if <code class="literal">_total</code> remains the same when we started the operation. If not, it means that the <code class="literal">_total</code> value has been changed by another thread and we have to repeat the operation with the new value of <code class="literal">_total</code>.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec15"></a>The ABA problem</h3></div></div></div><p>Remember when we <a id="id66" class="indexterm"></a>mentioned that lock-free programming is very complicated? Now, it's time to prove it. Here is another case when a seemingly right concurrent code works absolutely wrong.</p><p>Imagine that we have a lock-free stack implementation with the <code class="literal">Interlocked.CompareExchange</code> atomic <span class="strong"><strong>compare-and-swap</strong></span> (<span class="strong"><strong>CAS</strong></span>)<a id="id67" class="indexterm"></a> operation. Let's assume that it contains three items: A on top, B, and C. Thread 1 calls the <code class="literal">Pop</code> method; it sets the old head value as A and the new head value as B. However for some reason, thread 1 gets suspended by the operating system. Meanwhile, thread 2 pops item A from the stack and saves it for later use. Then, it pushes item D on the stack. After doing this, it finally pushes item A back on top of the stack, but this time A's next item is D and our stack contains four items: A on top, D, B, and C.</p><p>Now the first thread continues to run. It compares whether the old head value and the current head value are the same, and they are! Therefore, the thread writes value B to the head of the stack. Now, the stack is corrupted and contains two items: B on the top and C.</p><p>The described process can be illustrated by the following schema:</p><div class="mediaobject"><img src="graphics/4202_02_01.jpg" /></div><p>So, just having atomic <a id="id68" class="indexterm"></a>CAS operations is not enough. To make this code work right, it's very important to make sure that we do not reuse references in our code or allow them to escape to our consumers. Thus, when we push item A twice, it should be different from the existing items from the stack perspective. To achieve this, it's enough to allocate a new wrapper object each time something is being pushed onto the stack.</p><p>Here is a quote from Wikipedia that describes the ABA problem very well:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>Natalie is waiting in her car at a red traffic light with her children. Her children start fighting with each other while waiting, and she leans back to scold them. Once their fighting stops, Natalie checks the light again and notices that it's still red. However, while she was focusing on her children, the light had changed to green, and then back again. Natalie doesn't think the light ever changed, but the people waiting behind her are very mad and honking their horns now.</em></span></p></blockquote></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec16"></a>The lock-free stack</h3></div></div></div><p>Now, we are ready to implement a <a id="id69" class="indexterm"></a>lock-free stack data structure. First, we define a base abstract class for our stack implementation:</p><div class="informalexample"><pre class="programlisting">public abstract class StackBase&lt;T&gt;</pre></div><p>Then we have an inner class to define an item on the stack:</p><div class="informalexample"><pre class="programlisting">private class Item
{
  private readonly T _data;
  private readonly Item _next;

  public Item(T data, Item next)
  {
    _data = data;
    _next = next;
  }

  public T Data
  {
    get { return _data; }
  }

  public Item Next
  {
    get { return _next; }
  }
}</pre></div><p>The item class contains user data and a reference to the next element on the stack. Now, we're adding a stack top item:</p><div class="informalexample"><pre class="programlisting">private Item _head;</pre></div><p>A property that indicates whether the stack is empty is as follows:</p><div class="informalexample"><pre class="programlisting">public bool IsEmpty
{
  get { return _head == null; }
}</pre></div><p>Two abstract methods that store and retrieve an item from the stack:</p><div class="informalexample"><pre class="programlisting">public abstract void Push(T data);

public abstract bool TryPop(out T data);</pre></div><p>Now we have a base for different stack implementations to compare how they perform. We start with a lock-based stack:</p><div class="informalexample"><pre class="programlisting">public class LockStack&lt;T&gt; : StackBase&lt;T&gt;</pre></div><p>As we remember, the lock statement is translated to the <code class="literal">Monitor</code> class method calls by the C# compiler. The monitor class tries to avoid using OS-level locks and uses spin locks to achieve a performance boost when a lock takes a little time. We're going to illustrate this and create a stack that uses only OS-level locks with the help of the <code class="literal">System.Threading.Mutex</code> class, which uses the <span class="strong"><strong>mutex</strong></span> synchronization primitive<a id="id70" class="indexterm"></a> from the <a id="id71" class="indexterm"></a>OS. We create a mutex instance:</p><div class="informalexample"><pre class="programlisting">private readonly Mutex _lock = new Mutex();</pre></div><p>Then, implement the <code class="literal">Push</code> and <code class="literal">Pop</code> methods as follows:</p><div class="informalexample"><pre class="programlisting">public override void Push(T data)
{
  _lock.WaitOne();
  try
  {
    _head = new Item(data, _head);
  }
  finally
  {
    _lock.ReleaseMutex();
  }
}

public override bool TryPop(out T data)
{
  _lock.WaitOne();
  try
  {
    if (IsEmpty)
    {
      data = null;
      return false;
    }
    data = _head.Data;
    _head = _head.Next;
    return true;
  }
  finally
  {
    _lock.ReleaseMutex();
  }
}</pre></div><p>This implementation puts a thread in a blocked state every time it has to wait for the lock to be released. This is the worst-case scenario, and we're going to see the test results that prove this.</p><p>Now we will implement a concurrent stack with a monitor and lock statement:</p><div class="informalexample"><pre class="programlisting">public class MonitorStack&lt;T&gt; : StackBase&lt;T&gt; where T: class
{
  private readonly object _lock = new object();

  public override void Push(T data)
  {
    lock (_lock)
      _head = new Item(data, _head);
  }

  public override bool TryPop(out T data)
  {
    lock (_lock)
    {
      if (IsEmpty)
      {
        data = null;
        return false;
      }
      data = _head.Data;
      _head = _head.Next;
      return true;
    }
  }
}</pre></div><p>Then it's the lock-free stack implementation's turn:</p><div class="informalexample"><pre class="programlisting">public class LockFreeStack&lt;T&gt; where T: class</pre></div><p>Notice that we had to add <span class="strong"><strong>class constraint</strong></span><a id="id72" class="indexterm"></a> to the generic type parameter. We do this because we cannot atomically exchange values that are more than 8 bytes in size. If we look at the generic<a id="id73" class="indexterm"></a> version of the <code class="literal">Interlocked.CompareExchange</code> method, we can make sure that its <code class="literal">type</code> parameter has the same class constraint.</p><p>Let's get to implementation:</p><div class="informalexample"><pre class="programlisting">public void Push(T data)
{
  Item item, oldHead;
  do
  {
    oldHead = _head;
    item = new Item(data, oldHead);
  } while (oldHead != Interlocked.CompareExchange(ref _head, item, oldHead));
}</pre></div><p>This implementation is quite similar to a lock-free addition example. We basically do the same thing, only instead of addition, we're storing a new reference to the stack's head.</p><p>The <code class="literal">TryPop</code> method code is slightly more complicated:</p><div class="informalexample"><pre class="programlisting">public bool TryPop(out T data)
{
  var oldHead = _head;
  while (!IsEmpty)
  {
    if (oldHead == Interlocked.CompareExchange(ref _head, oldHead.Next, oldHead))
    {
      data = oldHead.Data;
      return true;
    }
    oldHead = _head;
  }
  data = null;
  return false;
}</pre></div><p>Here we have to notice that the stack can be empty; in this case, we return <code class="literal">false</code> to indicate that we failed to retrieve a value from the stack.</p><p>Also, we would like to compare our code to the standard <code class="literal">ConcurrentStack</code> implementation from <code class="literal">System.Collections.Concurrent</code>. It is possible to use an interface to work with all collections in the same way, but in this case, it is easier to create a wrapper class that contains the source collection:</p><div class="informalexample"><pre class="programlisting">public class ConcurrentStackWrapper&lt;T&gt; : StackBase&lt;T&gt;
{
  private readonly ConcurrentStack&lt;T&gt; _stack;
  public ConcurrentStackWrapper()
  {
    _stack = new ConcurrentStack&lt;T&gt;();
  }

  public override void Push(T data)
  {
    _stack.Push(data);
  }

  public override bool TryPop(out T data)
  {
    return _stack.TryPop(out data);
  }
}</pre></div><p>The only operation left is to<a id="id74" class="indexterm"></a> compare the performances of our stack implementations:</p><div class="informalexample"><pre class="programlisting">private static long Measure(StackBase&lt;string&gt; stack)
{
  var threads = Enumerable
    .Range(0, _threadCount)
    .Select(
      n =&gt; new Thread(
        () =&gt;
        {
          for (var j = 0; j &lt; _iterations; j++)
          {
            for (var i = 0; i &lt; _iterationDepth; i++)
            {
              stack.Push(i.ToString());
            }

            string res;

            for (var i = 0; i &lt; _iterationDepth; i++)
            {
              stack.TryPop(out res);
            }
          }
        }))
    .ToArray();
  var sw = Stopwatch.StartNew();
  foreach (var thread in threads)
    thread.Start();
  foreach (var thread in threads)
    thread.Join();
  sw.Stop();
  if (!stack.IsEmpty)
    throw new ApplicationException("Stack must be empty!");
  return sw.ElapsedMilliseconds;
}</pre></div><p>We run several threads and each of <a id="id75" class="indexterm"></a>these threads pushes and pops items to the stack in parallel. We wait for all the threads to complete, and check whether the stack is empty, which means that the program is correct. Finally, we measure the time required for all the operations to complete.</p><p>The results can be different and greatly depend on the CPU. This one is from a 3.4 GHz quad core Intel i7-3770 CPU:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>LockStack: 6718ms</strong></span>
<span class="strong"><strong>LockFreeStack: 209ms</strong></span>
<span class="strong"><strong>MonitorStack: 154ms</strong></span>
<span class="strong"><strong>ConcurrentStack: 121ms</strong></span>
</pre></div><p>This one is from a hyper-v virtual machine with two CPU cores running on a 2.2 GHz quad core Intel i7-4702HQ CPU laptop with power saving mode enabled:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>LockStack: 39497ms</strong></span>
<span class="strong"><strong>LockFreeStack: 388ms</strong></span>
<span class="strong"><strong>MonitorStack: 691ms</strong></span>
<span class="strong"><strong>ConcurrentStack: 419ms</strong></span>
</pre></div><p>The typical results are as follows: <code class="literal">LockStack</code> is the slowest, the <code class="literal">LockFreeStack</code> and <code class="literal">MonitorStak</code> implementations perform about the same, and the standard <code class="literal">ConcurrentStack</code> shows the best results. The <code class="literal">MonitorStack</code> implementation works well because, in this case, operations under lock are very fast, that is, about two processor cycles, and in this situation, spin wait works very well. We'll get back to explaining these results in detail later in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Using Concurrent Data Structures</em></span>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec17"></a>The lock-free queue</h3></div></div></div><p>Stack and queue are the simplest of<a id="id76" class="indexterm"></a> basic data structures. We have implemented a lock-free stack, and we encountered several tricky problems that we had to resolve. Implementing a lock-free concurrent queue is a more sophisticated task, since we now have to perform several operations at once. For example, when we queue a new item, we must simultaneously set the old tail's next item reference to a new item and then change a tail reference that the new item is now a new tail. Unfortunately, we cannot change two objects as an atomic operation. So, we must find a way to properly synchronize access to the head and tail without locks:</p><div class="informalexample"><pre class="programlisting">public class LockFreeQueue&lt;T&gt;
{</pre></div><p>We define a simple class that is going to contain data in the queue:</p><div class="informalexample"><pre class="programlisting">protected class Item
{
  public T Data;
  public Item Next;
}</pre></div><p>We will store references to the queue's tail and head and initialize them by default:</p><div class="informalexample"><pre class="programlisting">private Item _head;
private Item _tail;

public LockFreeQueue()
{
  _head = new Item();
  _tail = _head;
}</pre></div><p>The first challenge is to implement an <code class="literal">Enqueue</code> method. What we can do is set <code class="literal">tail.Next</code> in the CAS operation, but let the tail reference advance later, maybe by other threads. This guarantees that the linked list of queue items will always be valid, and if we see that we failed to set a new tail, just let this operation start in another thread:</p><div class="informalexample"><pre class="programlisting">public void Enqueue(T data)
{</pre></div><p>Create a new queue item and reserve space for the local copies of the <code class="literal">_tail</code> and <code class="literal">_tail.Next</code> references:</p><div class="informalexample"><pre class="programlisting">Item item = new Item();
item.Data = data;

Item oldTail = null;
Item oldNext = null;</pre></div><p>We repeat the queueing operation until it succeeds:</p><div class="informalexample"><pre class="programlisting">bool update = false;
while (!update) {</pre></div><p>Copy references to local variables and acquire a full fence so that the read and write operations will not be reordered. We have to use the <code class="literal">Next</code> field from the local copy, because the actual <code class="literal">_tail</code> item may have already been changed between both the read operations:</p><div class="informalexample"><pre class="programlisting">oldTail = _tail;
oldNext = oldTail.Next;

Thread.MemoryBarrier();</pre></div><p>The tail may remain the same as it was in the beginning of the operation:</p><div class="informalexample"><pre class="programlisting">if (_tail == oldTail)
{</pre></div><p>In this case, the next reference was null, which means that no one changed the tail since we copied it to <code class="literal">oldNext</code>:</p><div class="informalexample"><pre class="programlisting">if (oldNext == null)
{</pre></div><p>Here we can try queueing an item, and this will be the success of the whole operation:</p><div class="informalexample"><pre class="programlisting">  update = Interlocked.CompareExchange(ref _tail.Next, item, null) == null;
}
else
{</pre></div><p>If not, it means that another <a id="id77" class="indexterm"></a>thread is queueing a new item right now, so we should try to set the tail reference to point to its next node:</p><div class="informalexample"><pre class="programlisting">      Interlocked.CompareExchange(ref _tail, oldNext, oldTail);
    }
  }
}</pre></div><p>Here we have successfully inserted a new item to the end of the queue, and now we're trying to update the tail reference. However, if we fail it is okay, since another thread will eventually do this in its <code class="literal">Enqueue</code> method call:</p><div class="informalexample"><pre class="programlisting">  Interlocked.CompareExchange(ref _tail, item, oldTail);
}</pre></div><p>The main goal of dequeueing properly is to correctly work in situations when we have not yet updated the tail reference:</p><div class="informalexample"><pre class="programlisting">public bool TryDequeue(out T result)
{</pre></div><p>We will create a loop that finishes if there is nothing to dequeue or if we have dequeued an item successfully:</p><div class="informalexample"><pre class="programlisting">result = default(T);
Item oldNext = null;
bool advanced = false;
while (!advanced)
{</pre></div><p>We will make local copies of variables that are needed:</p><div class="informalexample"><pre class="programlisting">Item oldHead = _head;
Item oldTail = _tail;
oldNext = oldHead.Next;</pre></div><p>Then, we will acquire a full fence to prevent read and write reordering:</p><div class="informalexample"><pre class="programlisting">Thread.MemoryBarrier();</pre></div><p>There might be a case when the head item has not been changed yet:</p><div class="informalexample"><pre class="programlisting">if (oldHead == _head)
{</pre></div><p>Then, we will check whether the queue is empty:</p><div class="informalexample"><pre class="programlisting">if (oldHead == oldTail)
{</pre></div><p>In this case, this should <a id="id78" class="indexterm"></a>be <code class="literal">false</code>. If not, it means that we have a lagging tail and we need to update it:</p><div class="informalexample"><pre class="programlisting">if (oldNext != null)

{
  Interlocked.CompareExchange(ref _tail, oldNext, oldTail);
  continue;
}</pre></div><p>If we are here, we have an empty queue:</p><div class="informalexample"><pre class="programlisting">  result = default(T);
  return false;
}</pre></div><p>Now we will get the dequeueing item and try to advance the head reference:</p><div class="informalexample"><pre class="programlisting">    result = oldNext.Data;
    advanced = Interlocked.CompareExchange(
    ref _head, oldNext, oldHead) == oldHead;
  }
}</pre></div><p>We will remove any references that can prevent the garbage collector from doing its job, and then we will exit:</p><div class="informalexample"><pre class="programlisting">    oldNext.Data = default(T);
    return true;
  }

  public bool IsEmpty
  {
    get
    {
      return _head == _tail;
    }
  }
}</pre></div><p>Then we will write the following code to unify access to queues and compare different ways to synchronize access to the queue. To write general performance measurement code, we need to write an interface:</p><div class="informalexample"><pre class="programlisting">public interface IConcurrentQueue&lt;T&gt;
{
  void Enqueue(T data);
  bool TryDequeue(out T data);
  bool IsEmpty { get; }
}</pre></div><p>Both <code class="literal">LockFreeQueue</code> and the standard <code class="literal">ConcurrentQueue</code> are already implementing this interface, and all we need to do is to create a wrapper class like this:</p><div class="informalexample"><pre class="programlisting">class LockFreeQueueWrapper&lt;T&gt; : LockFreeQueue&lt;T&gt;, IConcurrentQueue&lt;T&gt; {}

class ConcurrentQueueWrapper&lt;T&gt; : ConcurrentQueue&lt;T&gt;, IConcurrentQueue&lt;T&gt; {}</pre></div><p>We need a more advanced <a id="id79" class="indexterm"></a>wrapper in the case of a non-thread-safe Queue collection:</p><div class="informalexample"><pre class="programlisting">class QueueWrapper&lt;T&gt; : IConcurrentQueue&lt;T&gt;
{
  private readonly object _syncRoot = new object();
  private readonly Queue&lt;T&gt; _queue = new Queue&lt;T&gt;();

  public void Enqueue(T data)
  {
    lock(_syncRoot)
    _queue.Enqueue(data);
  }

  public bool TryDequeue(out T data)
  {
    if (_queue.Count &gt; 0)
    {
      lock (_syncRoot)
      {
        if (_queue.Count &gt; 0)
        {
          data = _queue.Dequeue();
          return true;
        }
      }
    }
    data = default(T);
    return false;
  }

  public bool IsEmpty
  {
    get { return _queue.Count == 0; }
  }
}</pre></div><p>We have used a <span class="strong"><strong>double checked locking</strong></span> pattern<a id="id80" class="indexterm"></a> inside the <code class="literal">TryDequeue</code> method. At first glance, it seems that the first <code class="literal">if</code> statement is not doing anything useful, and we can just remove it. If you do an experiment and run the program without the first check, it will run about 50 times slower. The goal of the first check is to see whether the queue is empty so that a lock is not acquired; the lock and other threads are allowed to access the queue. Making a lock code minimal is very important, and it is illustrated here very well.</p><p>Now we need performance <a id="id81" class="indexterm"></a>measurement. We can write a generalized code and provide our different queues in a similar way:</p><div class="informalexample"><pre class="programlisting">private static long Measure(IConcurrentQueue&lt;string&gt; queue)
{
  var threads = Enumerable
  .Range(0, _writeThreads)
  .Select(n =&gt; new Thread(() =&gt;
  {
    for (int i = 0; i &lt; _iterations; i++)
    {
      queue.Enqueue(i.ToString());
      Thread.SpinWait(100);
    }
  }))
  .Concat(new[]{new Thread(() =&gt;
  {
    var left = _iterations*_writeThreads;
    while (left &gt; 0)
    {
      string res;
      if (queue.TryDequeue(out res))
        left--;
    }
  })
  })
  .ToArray();
  var sw = Stopwatch.StartNew();
  foreach (var thread in threads)
    thread.Start();
  foreach (var thread in threads)
    thread.Join();
  sw.Stop();
  if (!queue.IsEmpty)
    throw new ApplicationException("Queue is not empty!");
  return sw.ElapsedMilliseconds;
}</pre></div><p>The last thing that we need is just run the program and the results are going to be like this:</p><div class="informalexample"><pre class="programlisting">private const int _iterations = 1000000;
private const int _writeThreads = 8;

public static void Main()
{
  Console.WriteLine("Queue: {0}ms", Measure(new QueueWrapper&lt;string&gt;()));
  Console.WriteLine("LockFreeQueue: {0}ms", Measure(new LockFreeQueueWrapper&lt;string&gt;()));
  Console.WriteLine("ConcurrentQueue: {0}ms", Measure(new ConcurrentQueueWrapper&lt;string&gt;()));
}</pre></div><p>The output is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Queue: 3453ms</strong></span>
<span class="strong"><strong>LockFreeQueue: 1868ms</strong></span>
<span class="strong"><strong>ConcurrentQueue: 1162ms</strong></span>
</pre></div><p>These results show that<a id="id82" class="indexterm"></a> our lock-free queue has an advantage over straightforward locking, but the standard <code class="literal">ConcurrentQueue</code> performs better. It uses complicated ways of storing data—a linked list of array segments, which allows us to organize a more optimal process of storing and reading data.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec18"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we have learned how we can synchronize concurrent access to shared data without locking. We found out what a memory model and atomic operation are and how the .NET Framework allows programmers to use them in code. We have discussed the major problems related to lock-free programming and made sure that atomicity is necessary, but not enough to make the concurrent code work right. Also, we have implemented a lock-free stack and queue and illustrated the lock-free approach with concrete examples.</p><p>In the next chapter, we will combine approaches that we have learned so far and see how we can structure a concurrent program to lower the performance overhead and optimize it, depending on what exactly the program does.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch03"></a>Chapter 3. Understanding Parallelism Granularity</h2></div></div></div><p>One of the most essential tasks when writing parallel code is to divide your program into subsets that will run in parallel and communicate between each other. Sometimes the task naturally divides into separate pieces, but usually it is up to you to choose which parts to make parallel. Should we use a small number of large tasks, many small tasks, or maybe large and small tasks at the same time?</p><p>Theoretically speaking, it does not matter. In case of an ideal computational device, it would have no overhead for creating a worker thread and distributing work between any numbers of threads. However, on a real CPU, this performance overhead is significant and it is very important to take this into account. The right way to split your program into parallel parts is the key to writing effective and fast programs. In this chapter, we are going to review this problem in detail.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec20"></a>The number of threads</h2></div></div><hr /></div><p>One of the easiest ways to split your <a id="id83" class="indexterm"></a>program into a parallel executing part is using threads. However, what is a thread's cost for the operating system and CPU? What number of threads is optimal?</p><p>In Windows and in the 32-bit mode, the maximum number of threads in your process is restricted by the virtual address space available, which is two gigabytes. A thread stack's size is one megabyte, so we can have maximum 2,048 threads. In a 64-bit OS for a 32-bit process, it should be 4,096. However in practice, the address space will be fragmented and occupied by some other data, and there are other reasons why the maximum number of threads can be significantly different.</p><p>The best way to find out what's going on is to write a code that checks our assumptions. Here we will print the current size of a handle, giving us a way to detect whether we are in 32-bit or 64-bit mode. Then the code will start new threads until we get any exception, and it will print out the number of threads that we were able to start:</p><div class="informalexample"><pre class="programlisting">Console.WriteLine(IntPtr.Size);
var cnt = 0;

try
{
  for (var i = 0; i &lt; int.MaxValue; i++)
  {
    new Thread(() =&gt; Thread.Sleep(Timeout.Infinite)).Start();
    cnt++;
  }
}
Catch
{
  Console.WriteLine(cnt);
}</pre></div><p>In 32-bit mode on 64-bit Windows, results could be like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>4</strong></span>
<span class="strong"><strong>1522</strong></span>
</pre></div><p>When we switch to 64-bit mode, we will get the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>8</strong></span>
<span class="strong"><strong>71926</strong></span>
</pre></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note12"></a>Note</h3><p>Please be aware that if we run this in 64-bit mode, the program will exhaust system resources and might cause the OS to hang!</p></div><p>In 64-bit mode, we have no <a id="id84" class="indexterm"></a>tight address space restrictions anymore, but there are other limited resources such as operating system handles, kernel memory space, and more. So, we do not know exactly how many threads we should be able to run. However, why are we getting 1,522 threads while we expected to get about 4,000 when we compiled our program in 32-bit mode?</p><p>There are two reasons behind this:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The first reason is that when we run a 32-bit process on 64-bit Windows, a thread will have a 64-bit stack as well, and the actual stack allocation will be 1 MB + 256 KB of the 64-bit stack (or even 1 MB on the Windows versions prior to Windows Vista).</p></li><li style="list-style-type: disc"><p>The second reason is that our process is limited to 2 GB of the address space. If we want to use more, we have to specify a special flag, <span class="strong"><strong>IMAGE_FILE_LARGE_ADDRESS_AWARE,</strong></span> for our program, which is set using the <span class="strong"><strong>/LARGEADDRESSAWARE</strong></span> linker option. We cannot set this flag directly in Visual Studio, but we are able to use a tool<a id="id85" class="indexterm"></a> called <span class="strong"><strong>EditBin.exe</strong></span>, which is included in Visual Studio installation.</p></li></ul></div><p>To use this tool, just open Visual Studio Developer Command Prompt and run the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>editbin /LARGEADDRESSAWARE path\to\your\program.exe</strong></span>
</pre></div><p>To switch off this flag, use this syntax:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>editbin /LARGEADDRESSAWARE:NO path\to\your\program.exe</strong></span>
</pre></div><p>If you set this flag for the preceding program, you will see that we are able to create about 3,200 threads. Notice that we can use the so-called <span class="strong"><strong>4-gigabyte tuning</strong></span><a id="id86" class="indexterm"></a> on 32-bit Windows, and using this along with the preceding option, we can get 3GB of memory for our 32-bit process, which should give us about 3,000 threads.</p><p>However, do we need to create that many threads? A thread is a quite expensive resource, and if more threads are created, more corresponding work has to be performed by the CPU. Besides this, modern desktop CPUs support only a few parallel threads—from 2 to 12 at the moment. CPUs on servers have more cores and can run more threads, but server-side concurrency is quite different and will be reviewed later in detail in <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Server-Side Asynchrony</em></span>. Therefore, creating more threads will not make a program effective, but instead it will make the program slower.</p><p>To prove this, we need to <a id="id87" class="indexterm"></a>explore a more complicated program than just using <code class="literal">Thread.SpinWait</code> to simulate CPU load. We would like to see a real computational task that will involve every CPU's block working under heavy load. A task like this can be an implementation of a ray tracing algorithm to render several spheres. Here is a quote from Wikipedia:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>In computer graphics, ray tracing is a technique for generating an image by tracing the path of light through pixels in an image plane and simulating the effects of its encounters with virtual objects.</em></span></p></blockquote></div><p>It is relatively easy to implement, and it can be easily scaled because the different parts of a scene have no shared data and can be rendered independently. The full code can be found in the code samples of this chapter. The actual rendering code is placed inside the <code class="literal">RenderScene</code> method. It accepts start and end column numbers and an array of pixel colors, which will contain the results of a rendering process.</p><p>In the beginning, we defined the algorithm parameters. In the sample code, we will use the image dimensions of 1920x1920 pixels:</p><div class="informalexample"><pre class="programlisting">private const int _width = 1920;
private const int _height = 1920;</pre></div><p>This may not fit into your screen, and to avoid complexity, scrolling was not implemented here. So, if the resultant image is too large, you can simply lower its size. However, the measurements were taken for the initial image size.</p><p>To display the rendering results, we will call the <code class="literal">ShowResult</code> method. It creates <code class="literal">System.Drawing.Bitmap</code> with rendering results, creates the <code class="literal">PictureBox</code> control with this bitmap data, and shows it in Windows Forms Application:</p><div class="informalexample"><pre class="programlisting">private static void ShowResult(Color[,] data)
{
  var bitmap = new Bitmap(_width, _height, PixelFormat.Format32bppArgb);
  for (var i = 0; i &lt; _width; i++)
    for (var j = 0; j &lt; _height; j++)
      bitmap.SetPixel(i, j, data[i, j]);
  var pic = new PictureBox {
    Image = bitmap,
    Dock = DockStyle.Fill
  };

  var form = new Form {
    ClientSize = new Size(_width, _height)
  };

  form.KeyDown += (s, a) =&gt; form.Close();
  form.Controls.Add(pic);
  Application.Run(form);
}</pre></div><p>Then, we can run this code like this:</p><div class="informalexample"><pre class="programlisting">var data = new Color[_width, _height];
RenderScene(data, 0, _width);
ShowResult(data);</pre></div><p>To render the scene, there <a id="id88" class="indexterm"></a>are two loops going through the X and Y coordinates. To make the rendering process parallel, we can use the X coordinate to split the calculations between worker threads, so each thread will render its own columns set. Then we will increase the worker threads number and repeat the process to measure performance:</p><div class="informalexample"><pre class="programlisting">for (var threadCnt = 1; threadCnt &lt;= 32; threadCnt++)
{
  var part = _width/threadCnt;
  var threads = Enumerable.Range(0, threadCnt)  .Select(
    n =&gt; {
      var startCol = n*part;
      var endCol = n == threadCnt - 1
        ? _width - (threadCnt - 1) * part - 1
        : (n + 1) * part;

        return new Thread(() =&gt; RenderScene(data, startCol, endCol));
    }).ToArray();

  var sw = Stopwatch.StartNew();

  foreach (var thread in threads)
    thread.Start();
  foreach (var thread in threads)
    thread.Join();

  sw.Stop();

  Console.WriteLine("{0} threads. Render time {1}ms", threadCnt, sw.ElapsedMilliseconds);
}</pre></div><p>This is the<a id="id89" class="indexterm"></a> rendering result:</p><div class="mediaobject"><img src="graphics/4208_03_01.jpg" /></div><p>This is the <a id="id90" class="indexterm"></a>dependency between the number of worker threads and the overall performance on a  Core i7 2600K CPU and a 64-bit OS:</p><div class="mediaobject"><img src="graphics/4208_03_02.jpg" /></div><p>This chart shows <a id="id91" class="indexterm"></a>three main stages. The first stage is a significant performance improvement when we increase the thread number up to four. An Intel Core i7 2600K CPU has four physical cores, and loading all the cores gives us almost linear scalability. Then we can have a smoother performance change while going from four to eight threads. This is due to the fact that this CPU supports <a id="id92" class="indexterm"></a>
<span class="strong"><strong>hyperthreading</strong></span> technology. The hyper-threaded cores are implemented with a second set of hardware registers in the same core, but they use the same compute pipeline. Without going into too much detail, we can say that this often can be very efficient and can perform almost like two physical CPU cores. In this example, we can see that the hyperthreading technology allows the program to run faster.</p><p>The last stage is when we increase the threads number from 8 to 32. The line goes slightly up and this means that we do not gain any advantage and only lose performance. The CPU cannot perform faster because we have already put the maximum workload on it and creating more threads only leads to creating more work for running the threads and not calculations.</p><p>Thus, the most effective option is using as many threads as cores your CPU has and as many logical cores your operating system supports. 16 threads is a common number that will be enough for most of the present and near future desktop CPUs. The other option is to use the <code class="literal">Environment.ProcessorCount</code> variable to know during runtime how many cores the concrete CPU has.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note13"></a>Note</h3><p>Please notice that in general you should not use threads directly. There are other possibilities of running tasks in parallel, and you should use threads only when you are 100% aware of the advantages and disadvantages of other approaches. We'll review some of them later in this book.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec21"></a>Using the thread pool</h2></div></div><hr /></div><p>As already mentioned, creating a<a id="id93" class="indexterm"></a> thread is quite an expensive operation. In addition to this, creating more and more threads is not efficient. To make asynchronous operations easier, in Common Language Runtime there is a thread pool, which is represented by the <code class="literal">System.Threading.Threadpool</code> class. Instead of creating a thread every time we need one, we ask the thread pool for a worker thread. If it has a thread available, a thread pool returns it to us. When its job is done, it goes back into the thread pool in a suspended state until it is needed again.</p><p>There are two types of threads inside the thread pool: <span class="strong"><strong>worker threads</strong></span> <a id="id94" class="indexterm"></a>and <a id="id95" class="indexterm"></a>
<span class="strong"><strong>input/output threads</strong></span>. I/O threads are used for asynchronous I/O processing and we are not going to review them here. Let's concentrate on worker threads instead. This is what MSDN states about thread pool and its limits:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>There is one thread pool per process.</em></span></p><p><span class="emphasis"><em>Beginning with the .NET Framework 4, the default size of the thread pool for a process depends on several factors, such as the size of the virtual address space. A process can call the GetMaxThreads method to determine the number of threads.</em></span></p><p><span class="emphasis"><em>The number of threads in the thread pool can be changed by using the SetMaxThreads method.</em></span></p><p><span class="emphasis"><em>Each thread uses the default stack size and runs at the default priority.</em></span></p></blockquote></div><p>If we try to acquire more worker threads than the thread pool's limit, the subsequent requests will be queued and will wait until a worker thread becomes available. So, we cannot have more thread pool worker threads than its limit at a time.</p><p>In practice, the thread pool implementation is very complicated and relies on empiric assumptions. Also, it has been changed with new .NET Framework versions, and it is possible that it will be changed in future, so we should not rely on specific implementation details.</p><p>However, the common logic is simple; the thread pool maintains a small number of worker threads and creates more threads when needed until the limit is reached. To see how this works, we can write a code that will create thread pool worker threads and see how many threads are being allocated at a time:</p><div class="informalexample"><pre class="programlisting">for (var i = 0; i &lt; _threadCount; i++)
  ThreadPool.QueueUserWorkItem(
   s =&gt;
    {
      Interlocked.Increment(ref _runCount);
      Thread.Sleep(5000);
      Interlocked.Decrement(ref _runCount);
    });
Thread.Sleep(1000);
while (_runCount &gt; 0)
{
  Console.WriteLine(_runCount);
  Thread.Sleep(100);
}</pre></div><p>We enqueue a number of worker threads, and each of them increments a thread counter, then waits for 5 seconds, and then decrements the counter, signaling that its work is finished. In the main thread, we print out this counter to see how the worker threads are being allocated.</p><p>For the .NET Framework 4.5 and a specific hardware, this code shows that at first we almost immediately have nine worker threads, then the counter grows slowly until 35-40, and then it goes back to 0. Thus, using the thread pool with a large number of tasks allows us to effectively load the CPU and abstract from the actual threads usage specifics.</p><p>There is one more<a id="id96" class="indexterm"></a> worthwhile thing to mention about the thread pool that can be good or bad in different scenarios. There is one thread pool per process, and every library and framework that you use can potentially work with the thread pool, so some of the worker threads can be already busy with third-party code tasks. So, if some library is not well written and occupies many worker threads or blocks them with long-running operations, then your program will not be able to effectively load the CPU. Also, this can be caused by a third- party code that works with input/output operation incorrectly, which leads to performance degradation as well.</p><p>So if your program uses the thread pool for computation tasks and the CPU is not fully loaded, it is worth checking how many worker threads are there and what exactly they are doing. Specifically, this is extremely important for server-side concurrency, where server frameworks usually share the thread pool with your code.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec22"></a>Understanding granularity</h2></div></div><hr /></div><p>When there is one common <a id="id97" class="indexterm"></a>computational task inside your application, it is quite obvious how to make it run in parallel. The most effective solution would be to divide the tasks in parts and run these parts on each available CPU core. Since the number of parts will not be large, there will not be any significant performance overhead. This way of dividing your code into parallel running tasks<a id="id98" class="indexterm"></a> is called <span class="strong"><strong>coarse-grained</strong></span>:</p><div class="mediaobject"><img src="graphics/4208_03_03.jpg" /></div><p>There is one problem <a id="id99" class="indexterm"></a>with the coarse-grained approach. The large tasks can run at significantly different times, and then at these times, some of the CPU cores will not be used to help compute the other tasks. One more possibility is that these tasks can block the CPU cores while waiting for some signals from other threads or input/output operation to complete. In this case, the CPU time would be wasted.</p><p>To be more effective, we will have to split these tasks into more parts. If the number of parts will be less, then we will still have the problem of some tasks running much faster than others do and some of CPU cores will be unavailable for further computations. So, we have to split the tasks into many small pieces until we can say that blocking one task is not important because the CPU can switch to another task at once. This approach is called<a id="id100" class="indexterm"></a> <span class="strong"><strong>fine-grained</strong></span>:</p><div class="mediaobject"><img src="graphics/4208_03_04.jpg" /></div><p>How can we implement such a program? We have to divide our computation into very small tasks and minimize the overhead for each task since there will be many of them, and we do not want to waste CPU time to support these tasks' infrastructure instead of doing computation. Then we have to find a way to run these tasks effectively.</p><p>It is very complicated to write a general algorithm to divide many different computation tasks into several worker threads. Fortunately, such frameworks already exist and one of them is included in the .NET Framework. It is called <a id="id101" class="indexterm"></a>
<span class="strong"><strong>Task Parallel Library</strong></span> (TPL). We will discuss TPL in detail in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Task Parallel Library in Depth</em></span>.</p><p>Now, we will use TPL to write a fine-grained parallel program. We simulate that the tasks are different by running <code class="literal">SpinWait</code> with different number of cycles. Then we split our tasks into differently-sized pieces and calculate the number of iterations per millisecond that we were able to run.</p><p>The sample code will be as follows:</p><div class="informalexample"><pre class="programlisting">  var random = new Random();
  var taskSizes =
    Enumerable
      .Range(0, _totalSize)
      .Select(n =&gt; random.NextDouble())
      .ToArray();
  for (var workSize = 256; workSize &gt; 0; workSize -= 4)
  {
    var total = 0;
    var tasks = new List&lt;Task&gt;();
    var i = 0;
    while (total &lt; _totalSize)
    {
      var currentSize = (int)(taskSizes[i]*workSize) + 1;
      tasks.Add(
        new Task(
          () =&gt;
          {
            Thread.SpinWait(currentSize*_sizeElementaryDelay);
          }));
      i++;
      total += currentSize;
    }
    var sw = Stopwatch.StartNew();
    foreach (var task in tasks)
      task.Start();
    Task.WaitAll(tasks.ToArray());
    sw.Stop();
    Console.WriteLine(
      "Work size {0},
      Task count {1}, Effectiveness {2:####} works/ms",
      workSize, tasks.Count,
      ((double)total * _sizeElementaryDelay)/sw.ElapsedMilliseconds);
  }
}</pre></div><p>The fundamental entity in TPL is the <code class="literal">System.Threading.Task</code> class<a id="id102" class="indexterm"></a>, which represents a basic task that has to be run. To compare the performance of large tasks versus small tasks, we will go through the following process:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>We prepare an array of random task sizes to create a unique set of tasks for each time we run the program.</p></li><li style="list-style-type: disc"><p>Then we split the total work into a small number of large tasks, run the measurement, and then repeat the whole process once again by splitting the work into smaller tasks and making the total number of tasks larger.</p></li><li style="list-style-type: disc"><p>Each measurement involves starting <code class="literal">Stopwatch</code>, running all tasks, waiting for all the tasks to complete with the <code class="literal">Task.WaitAll</code> method, and then measuring how much time it took to complete all the tasks.</p></li></ul></div><p>Here is sample chart illustrating the results of running this code:</p><div class="mediaobject"><img src="graphics/4208_03_05.jpg" /></div><p>This chart shows that when we reduce task size, we increase performance until some point. Then the task size becomes small enough to achieve full CPU workload. Making tasks smaller becomes ineffective due to an overall task overhead increase.</p><p>This was a synthetic test. In practice, everything will depend on a program's nature. If it is possible to vary the task size for your program, and if performance is crucial, you can run several tests and find out the best parameters experimentally.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec23"></a>Choosing the coarse-grained or fine-grained approach</h2></div></div><hr /></div><p>Fine-grained parallelism <a id="id103" class="indexterm"></a>granularity allows us to run heterogeneous <a id="id104" class="indexterm"></a>computational tasks effectively. Besides this, the fine-grained approach makes the splitting of your program into tasks easier, especially if these tasks are related to each other and, for example, latter tasks use some computation results of former tasks. However, we will have to trade off some performance, since the CPU has to be used to manage all these tasks as well.</p><p>To find out how fine-grained granularity can affect performance for a real task, let's implement a ray tracing algorithm using TPL and compare it to the results that we got in the beginning using an optimal number of threads. To implement the fine-grained program version, we will just create a task for each image column and start it immediately. The implementation code is as follows:</p><div class="informalexample"><pre class="programlisting">var tasks = new List&lt;Task&gt;();
var fineSw = Stopwatch.StartNew();
for (var i = 0; i &lt; _width; i++)
{
  var col = i; // Create separate variable for closure
  tasks.Add(Task.Factory.StartNew(() =&gt; RenderScene(data, col, col)));
}
Task.WaitAll(tasks.ToArray());
fineSw.Stop();
Console.WriteLine("Fine grained {0}ms", fineSw.ElapsedMilliseconds);</pre></div><p>Executing this code in coarse-grained mode takes about 150 milliseconds on the specific hardware. A fine-grained mode takes about 160 milliseconds. At first glance, the difference is insignificant. However, it is still noticeable, even after knowing that the TPL code is very well optimized. So, if performance is very important, it is possible to try implementing parallelism granularity by yourself. However before this, you must be absolutely sure that the bottleneck is granularity and the results of the tests conducted approve this.</p><p>If not, just use<a id="id105" class="indexterm"></a> TPL and fine-grained approach, which is easy to <a id="id106" class="indexterm"></a>code and still provides good performance.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec24"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we have reviewed a problem of parallel computations granularity. We have tried different ways to split our program into concurrently executing pieces and saw the performance impact in each case. Also, we've implemented a real computation task of rendering spheres with a ray tracing algorithm and learned to parallelize it with threads and Task Parallel Library.</p><p>In the next chapter, we will continue to learn Task Parallel Library. We shall review this framework in detail and clarify every aspect of using it including how the tasks are being run, how we combine tasks together, and how to handle exceptions and timeouts.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch04"></a>Chapter 4. Task Parallel Library in Depth</h2></div></div></div><p>In the previous chapter, we have already used TPL to simplify the writing of some fine-grained parallel code. The code looked quite clear; however, TPL is a quite complicated framework with a high level of abstraction, and it deserves a detailed review.</p><p>Most code samples that we have seen so far were quite simple in terms of composition. We took a computational problem, split it into several independent parts, and ran these parts on different worker threads. When all the parts are completed, we get their results and combine them into a final calculation result. However, most real-world programs usually have a complex structure. We need to get input data, and then there are program stages that depend on each other; to continue the calculations, we have to get results from previous stages. These stages can take different durations to complete and require different approaches for parallelization.</p><p>It is possible to write this logic based on worker threads and synchronization primitives. However, with many parts and dependencies, such code will become too large and verbose. To make the programming easier, we can take advantage of different <span class="strong"><strong>parallel programming model</strong></span><a id="id107" class="indexterm"></a> implementations that abstract threads and synchronization mechanics and offer some kind of a higher-level API that is much easier to use. This is the parallel programming model definition from Wikipedia:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>In computer software, a parallel programming model is a model for writing parallel programs which can be compiled and executed. The value of a programming model can be judged on its generality: how well a range of different problems can be expressed for a variety of different architectures, and its performance: how efficiently they execute. The implementation of a programming model can take several forms such as libraries invoked from traditional sequential languages, language extensions, or complete new execution models.</em></span></p></blockquote></div><p>One such model is<a id="id108" class="indexterm"></a> <span class="strong"><strong>task-based parallelism</strong></span>. Its main concept is a task, which is just a piece of synchronously executing code. If one task depends on another task's result, we can provide such information to the framework. The final part is the<a id="id109" class="indexterm"></a> <span class="strong"><strong>task scheduler</strong></span>. It knows about the current environment and can execute tasks on an optimal number of threads, taking into account the information about dependencies between the tasks. The program code transforms into defining tasks and their dependencies, which is much cleaner than raw threads or thread pool usage.</p><p>Let us reconsider a code sample from the previous chapter:</p><div class="informalexample"><pre class="programlisting">for (var i = 0; i &lt; _width; i++)
{
  var col = i; // Create separate variable for closure
  tasks.Add(Task.Factory.StartNew(() =&gt; RenderScene(data, col, col)));
}
Task.WaitAll(tasks.ToArray());</pre></div><p>Here, we have used a loop to iterate through all the columns of our scene, and then we split calculations to create a separate task for each column. To create such tasks, we use the <code class="literal">System.Threading.Task</code> class. The <code class="literal">StartNew</code> method creates a new <code class="literal">Task</code> instance and starts the task at once. When we have completed creating all the tasks, we will use the <code class="literal">Task.WaitAll</code> static method to wait until all the tasks complete their jobs.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec25"></a>Task composition</h2></div></div><hr /></div><p>Let's consider a situation where, before running a task (let's call the task, task B), we will need a result from the calculation of a previous task, task A. Such dependency between tasks is usually called <span class="strong"><strong>future</strong></span><a id="id110" class="indexterm"></a> or <a id="id111" class="indexterm"></a>
<span class="strong"><strong>promise</strong></span>. This means that, when we run task A, we do not know its result before the calculations are complete. So we state (make a promise) that, at some point in the future, we will run task B as soon as we get the result from task A.</p><p>Why do we need to declare dependencies in a specific way? We can always create dependent tasks as follows:</p><div class="informalexample"><pre class="programlisting">var taskA = new Task&lt;string&gt;(
  () =&gt;
  {
    Console.WriteLine("Task A started");
    Thread.Sleep(1000);
    Console.WriteLine("Task A complete");
    return "A";
  });
taskA.Start();
var taskB = new Task(
  () =&gt;
  {
    Console.WriteLine("Task B started");
    Console.WriteLine("Task A result is {0}", taskA.Result);
  });
taskB.Start();
taskB.Wait();</pre></div><p>The result is this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Task A started</strong></span>
<span class="strong"><strong>Task B started</strong></span>
<span class="strong"><strong>Task A complete</strong></span>
<span class="strong"><strong>Task A result is A</strong></span>
</pre></div><p>First, we create a new <a id="id112" class="indexterm"></a>task A instance and use a thread pool worker thread to execute the code inside this task.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note14"></a>Note</h3><p>By default, Task Parallel Library uses .NET as the thread pool to run task code. However, it is possible to use other ways to run tasks, and the part of TPL that is responsible for running tasks is called the<a id="id113" class="indexterm"></a> <span class="strong"><strong>task scheduler</strong></span>. We will review task schedulers later in this chapter.</p></div><p>The output displays <span class="strong"><strong>Task A started</strong></span> and simulates some calculations using the <code class="literal">Thread.Sleep</code> method. At the same time, we will create a new task B instance, which uses another thread pool worker thread to run. It outputs <span class="strong"><strong>Task B started</strong></span> to the console and then blocks until task A completes. Then, task A signals its completion by printing <span class="strong"><strong>Task A complete</strong></span> and returns the "A" string as a result. Task B gets a signal that task A is completed and prints the result as <span class="strong"><strong>Task A result is A</strong></span>.</p><p>So, it seems that we have successfully created two dependent tasks. Unfortunately, this code will be quite ineffective and hard to maintain. Imagine that we need more dependencies. This code will in turn create many tasks that will use other tasks' results, and to understand dependencies, a reader will have to analyze each task's code. Besides this, when task A runs, task B blocks the thread pool thread. It means that we have just wasted one worker thread that is doing nothing and cannot be used to serve some other job. If we create many tasks, we will soon take over all the worker threads from a thread pool, and this is a very bad practice that leads to scalability and performance problems.</p><p>Nevertheless, it is obvious that there is no sense in running tasks A and B in parallel, since B needs A to complete. To run this code synchronously, we can merge the code from A and B, but this would break up program logic and lead us back to the coarse-grained approach.</p><p>Another way is to analyze dependencies between tasks and use thread pool worker threads more efficiently. For example, do not schedule task B code execution until task A code finishes and returns its result. All we need to do is to declare a dependency between tasks explicitly, so TPL will know what tasks to run first and what to delay. This is exactly what the <code class="literal">Task.ContiueWith</code> method does. We use this method on an initial task, and this returns another task (usually called a <a id="id114" class="indexterm"></a>
<span class="strong"><strong>continuation task</strong></span>) that will be executed after the former task completes:</p><div class="informalexample"><pre class="programlisting">var taskA = new Task&lt;string&gt;(
  () =&gt;
  {
    Console.WriteLine("Task A started");
    Thread.Sleep(1000);
    Console.WriteLine("Task A complete");
    return "A";
  });
taskA
  .ContinueWith(
    task =&gt;
    {
      Console.WriteLine("Task B started");
      Console.WriteLine("Task A result is {0}", task.Result);
    });
taskA.Start();
taskA.Wait();</pre></div><p>We created a task <a id="id115" class="indexterm"></a>A instance similar to the previous example. However, instead of creating a new task, we used the <code class="literal">ContinueWith</code> method on the task A instance that allows us to provide a code that will be run when task A completes. We have access to the task A instance via the <code class="literal">task</code> parameter of the lambda expression. Now the TPL task scheduler will place a continuation task code on a thread pool only after task A runs to completion.</p><p>The result of this code will be as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Task A started</strong></span>
<span class="strong"><strong>Task A complete</strong></span>
<span class="strong"><strong>Task B started</strong></span>
<span class="strong"><strong>Task A result is A</strong></span>
</pre></div><p>Notice that the order of messages is different than the previous result. Now task B is started after task A completes.</p><p>This can be a disadvantage if the latter task performs some work that can be run in parallel. In this case, running task B after A will be inefficient, since it is actually a synchronous code execution. However, TPL is about task composition and it simply means that we can split task B into two tasks; one will run in parallel with task A and the other will be placed in a continuation task:</p><div class="informalexample"><pre class="programlisting">var taskA = new Task&lt;string&gt;(
  () =&gt;
  {
    Console.WriteLine("Task A started");
    Thread.Sleep(1000);
    Console.WriteLine("Task A complete");
    return "A";
  });
taskA.Start();

var taskB1 = new Task(() =&gt; Console.WriteLine("Task B1 started"));
taskB1.Start();

taskA.ContinueWith(tsk =&gt; Console.WriteLine("Task A result is {0}", tsk.Result));

taskA.Wait();</pre></div><p>If we run this code, the <a id="id116" class="indexterm"></a>results will show that task A and B1 run in parallel; B1 can even be run before A, since it does not really matter in terms of program logic in what order independent tasks are scheduled to run.</p><p>There are more complicated ways of composing tasks. For example, when a task needs results from multiple tasks, the <code class="literal">ContinueWith</code> method allows us to follow only one task, and we need task B2 to get the results from A and B1:</p><div class="mediaobject"><img src="graphics/4202_04_01.jpg" /></div><p>However, there is a <code class="literal">TaskFactory</code> class that can be accessed through the <code class="literal">Task.Factory</code> static property. It contains many useful things to create and schedule tasks, but what we need now is its <code class="literal">ContinueWhenAll </code>method.</p><p>The implementation of the multiple dependency schema is as follows:</p><div class="informalexample"><pre class="programlisting">var taskA = new Task&lt;string&gt;(
  () =&gt;
  {
    Console.WriteLine("Task A started");
    Thread.Sleep(1000);
    Console.WriteLine("Task A complete");
    return "A";
  });
taskA.Start();

var taskB1 = new Task&lt;string&gt;(
  () =&gt;
  {
    Console.WriteLine("Task B1 started");
    Thread.Sleep(500);
    Console.WriteLine("Task B1 complete");
    return "B";
  });
taskB1.Start();

Task
  .Factory
  .ContinueWhenAll(
    new []{taskA, taskB1},
    tasks =&gt; Console.WriteLine("Task A result is {0}, Task B result is {1}", tasks[0].Result, tasks[1].Result));

taskA.Wait();</pre></div><p>The <code class="literal">ContinueWhenAll</code> method<a id="id117" class="indexterm"></a> accepts an array of tasks as its first parameter and a lambda expression as the second. The lambda expression <code class="literal">tasks</code> parameter is the tasks array that we have just provided. Instead of using this, it is possible to create a closure and access the <code class="literal">taskB1</code> and <code class="literal">taskA</code> variables in the lambda body, but this would create unnecessary dependencies in the code, which is generally a bad practice.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note15"></a>Note</h3><p>This is often referred to as <a id="id118" class="indexterm"></a>
<span class="strong"><strong>code coupling</strong></span>. When the code has many dependencies, it is called <a id="id119" class="indexterm"></a>
<span class="strong"><strong>high coupling</strong></span>; in this case, the code is hard to maintain, since <a id="id120" class="indexterm"></a>any change can affect the other parts. <span class="strong"><strong>Low coupling</strong></span> means that this part of the code does not depend on other parts, so it can be changed and maintained easily without breaking the other code, and other changes will most likely not break this part of the program.</p></div><p>The results will be as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Task A started</strong></span>
<span class="strong"><strong>Task B1 started</strong></span>
<span class="strong"><strong>Task B1 complete</strong></span>
<span class="strong"><strong>Task A complete</strong></span>
<span class="strong"><strong>Task A result is A, Task B result is B</strong></span>
</pre></div><p>This shows that tasks A and B1 run independently in parallel, and the final code gets the results from both the tasks. We successfully described dependencies in a declarative way, and the TPL infrastructure ensured the correctness of the execution order and program logic.</p><p>It is worth mentioning another <code class="literal">TaskFactory</code> class method, the <code class="literal">ContinueWhenAny </code>method, which is quite similar to <code class="literal">ContinueWhenAll</code>. It creates a task that starts when any of the provided tasks in the array complete. This is useful for having several alternative ways to achieve the result, and we use the one that completes faster than the others.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec26"></a>Tasks hierarchy</h2></div></div><hr /></div><p>We mentioned before that the task <a id="id121" class="indexterm"></a>scheduler needs explicitly defined dependencies between tasks to run them effectively and in the correct order. However, besides this, there is a way to achieve implicit dependency definition; when we create one task inside another, a special parent-child dependency is created for these tasks. By default, this does not affect how these tasks will be executed, but there is a way to make this dependency really important.</p><p>We can create a task with the <code class="literal">TaskFactory.CreateNew</code> method by providing a special <code class="literal">TaskCreationOptions.AttachedToParent</code> parameter. This changes the usual task behavior, and the important differences are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The parent task will not complete until every child task completes.</p></li><li style="list-style-type: disc"><p>If the case child tasks cause any exceptions, they will be translated to the parent task.</p></li><li style="list-style-type: disc"><p>The parent task status depends on its child tasks. If any child task fails, the parent task will have the <code class="literal">TaskStatus.Faulted</code> status as well.</p></li></ul></div><p>To illustrate this, we can compare the behavior of the default task and the task attached to the parent. Here, we will create a child task without specifying the task creation options:</p><div class="informalexample"><pre class="programlisting">Task
  .Factory
  .StartNew(
    () =&gt;
    {
      Console.WriteLine("Parent started");
      Task
        .Factory
        .StartNew(
          () =&gt;
          {
            Console.WriteLine("Child started");
            Thread.Sleep(100);
            Console.WriteLine("Child complete");
          });
    })
  .Wait();
Console.WriteLine("Parent complete");</pre></div><p>As a result we get the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Parent started</strong></span>
<span class="strong"><strong>Child started</strong></span>
<span class="strong"><strong>Parent complete</strong></span>
</pre></div><p>It is important that the parent task has completed before the child task, and since we waited only for the parent task, the main thread exited and the child task did not complete at all.</p><p>Now we add the <code class="literal">AttachedToParent</code> option in the same code, changing only the child task as follows:</p><div class="informalexample"><pre class="programlisting">Task
  .Factory
  .StartNew(
    () =&gt;
    {
      Console.WriteLine("Child started");
      Thread.Sleep(100);
      Console.WriteLine("Child complete");
    },
    <span class="strong"><strong>TaskCreationOptions.AttachedToParent</strong></span>);</pre></div><p>Run this again to<a id="id122" class="indexterm"></a> get the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Parent started</strong></span>
<span class="strong"><strong>Child started</strong></span>
<span class="strong"><strong>Child complete</strong></span>
<span class="strong"><strong>Parent complete</strong></span>
</pre></div><p>Here, we can see that the parent task waits until the child task finishes and only then changes its status to <code class="literal">TaskStatus.RanToCompletion</code>.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec27"></a>Awaiting task completion</h2></div></div><hr /></div><p>There are different ways to wait <a id="id123" class="indexterm"></a>until the TPL task completes. In the previous code, we used the <code class="literal">Task.Wait</code> method. This method blocks the current thread until this task completes. If the task gives a result, the same effect can be achieved when the <code class="literal">Task.Result</code> instance property is queried. This is a basic way to coordinate tasks in the program.</p><p>When we needed to wait for multiple tasks, we used the <code class="literal">Task.WaitAll</code> static method. If we keep aside the optimization and exception handling code, this method will be implemented using the following logic:</p><div class="informalexample"><pre class="programlisting">var waitedOnTaskList = new List&lt;Task&gt;(tasks.Length);
for (int i = tasks.Length - 1; i &gt;= 0; i--)
{
  Task task = tasks[i];
  if (!taskIsCompleted)
    waitedOnTaskList.Add(task);
}

if (waitedOnTaskList != null)
{
  WaitHandle[] waitHandles = new WaitHandle[waitedOnTaskList.Count];
  for (var i = 0; i &lt; waitHandles.Length; i++)
    waitHandles[i] = waitedOnTaskList[i].CompletedEvent.WaitHandle;
  WaitAll(waitHandles);
}</pre></div><p>We have defined a list <a id="id124" class="indexterm"></a>of tasks that are not completed yet and then attached an array of handles to the OS-specific objects that can be used to wait for each task to be completed. Then we wait on these objects until all underlying tasks are completed.</p><p>As in the previous case, along with <code class="literal">WaitAll</code>, the <code class="literal">Task</code> type defines the <code class="literal">WaitAny</code> static method. It waits until any task in the array is completed. It can be used to track the progress of task completion or to choose the fastest way to get results from the several alternatives.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec28"></a>Task cancellation</h2></div></div><hr /></div><p>A task represents a common<a id="id125" class="indexterm"></a> asynchronous operation. This means that we don't know when it completes. Sometimes, it is clear that we do not need this task anymore. For example, if the operation takes too long to complete, or the user clicks on the <span class="strong"><strong>Cancel</strong></span> button. In this case, we need to stop the task.</p><p>One of the lower-level ways to stop a thread is by calling its <code class="literal">Abort</code> method. Before going on, I would like to emphasize the importance of not using this.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note16"></a>Note</h3><p>Never ever use <code class="literal">Thread.Abort</code>!</p></div><p><code class="literal">Thread.Abort</code> raises a very special exception called <code class="literal">ThreadAbortException</code> on a thread that is being aborted. This exception can happen at more or less any point in your program and cannot be stopped by the usual exception handling. We can write a code with catch block and the code inside this block will work, but as soon as the catch block ends, the same exception will be raised again. But—surprise—if we call the <code class="literal">Thread.CurrentThread.ResetAbort</code> method inside the catch block, the thread abort request will be canceled. This means that calling <code class="literal">Thread.Abort</code> does not guarantee that the thread will be actually aborted.</p><p>Another aspect of using this method is that it affects only the managed code. If your thread is waiting for unmanaged code to complete, which is almost every I/O operation, the thread will not be aborted until this operation ends. If the operation never completes, the code will never return and your program will hang.</p><p>Also, due to the .NET CLR constructing type algorithm specifics, this exception can break your program. If there is an exception inside a static constructor of some type, this exception gets cached, and all further attempts to use this type will lead to throwing this exception. So if we call <code class="literal">Thread.Abort</code> and raise this exception while the target thread was executing any static constructor, we will get <code class="literal">ThreadAbortException</code> when any thread tries to access the type that failed to be created on the previous thread.</p><p>If this is not enough, there is one more illustration of how evil this exception is. Imagine the code that is usually written for working with files:</p><div class="informalexample"><pre class="programlisting">using (FileStream fs = File.Open(fileName, ...))
{
  ...do stuff with data file...
}</pre></div><p>The preceding code<a id="id126" class="indexterm"></a> is the shorter version of the following code:</p><div class="informalexample"><pre class="programlisting">FileStream fs = File.Open(fileName, ...);
try
{
  ...do stuff with data file...
}
finally
{
  IDisposable disposable = fs;
  disposable.Dispose();
}</pre></div><p>Since <code class="literal">ThreadAbortException</code> can emerge at any point, it can happen inside the finally block. If it happens there, the code in this block will not run to completion and the file will remain opened. In this case, the <code class="literal">FileStream</code> class implements a disposable pattern and is likely to be closed while its finalizer method is called when garbage collection occurs. However, it is clear that leaving the file open for an undefined time is not a good thing and other code is not always correctly written.</p><p>Therefore, <code class="literal">Thread.Abort</code> must be avoided in all circumstances. Instead of using this, we should write the code while being aware of the cancellation possibility. It is important that this cancellation must not depend on any concrete ways of running the operation itself, since TPL abstracts away task execution mechanics, allowing us to write custom task schedulers and use them with standard TPL code.</p><p>Fortunately, the .NET Framework contains a Cancellation API, and this is what we should use to implement cancellation in our code. TPL uses this API as well, which makes it easier to write cancellation code for TPL-based programs.</p><p>The Cancellation API is based on two main types—the <code class="literal">System.Threading.CancellationToken </code>structure and the <code class="literal">System.Threading.CancellationTokenSource</code> class. The cancellation token contains methods and properties that we can use to handle the cancellation request, and the cancellation token source allows us to create cancellation tokens and initiate cancellation requests.</p><p>A typical<a id="id127" class="indexterm"></a> situation is when we have two parts of a code. The first part is the code that creates, combines, and runs tasks. This code can interact with the program UI and handles situations when we need to cancel some of the running tasks. Usually, this part is responsible for creating <code class="literal">CancellationTokenSource</code>, constructing cancellation token instances, and providing them to each task that can be cancelled. Then, when the cancellation process is being initiated, we call the <code class="literal">Cancel</code> or <code class="literal">CancelAfter</code> methods on each cancellation token needed.</p><p>The second part of code lives inside tasks and uses cancellation token instances to get cancellation signals. There are several common approaches to implementing the cancellation itself. They are covered in the following sections.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec18"></a>Checking a flag</h3></div></div></div><p>If the code inside a task is quite<a id="id128" class="indexterm"></a> easy, for example, it is a loop with short iterations, then the easiest way to stop the operation is to check some flag variable inside this loop and exit if the flag is set.</p><p>The first part of the code creates a task, provides it with a cancellation token, and then initiates a cancellation process. Finally, we measure the time of the task cancellation process as follows:</p><div class="informalexample"><pre class="programlisting">private static void RunTest(Action&lt;CancellationToken&gt; action, string name)
{
  var cancelSource = new CancellationTokenSource();
  var cancelToken = cancelSource.Token;
  var task = Task
      .Factory
      .StartNew(() =&gt; action(cancelToken), cancelToken);

  // Wait for starting task
  while (task.Status != TaskStatus.Running) { }

  var sw = Stopwatch.StartNew();
  cancelSource.Cancel();
  while (!task.IsCompleted) {}
  sw.Stop();
  Console.WriteLine("{0} task cancelled in {1} ms", name, sw.ElapsedMilliseconds);
}</pre></div><p>Notice that we are providing a cancellation token not only to our task, but also to the <code class="literal">StartNew</code> method as well. The reason for this is that TPL is aware of cancellation tokens as well and can cancel the task even if it has not started yet and our code is not able to handle cancellation.</p><p>Also, we use a loop instead of calling the <code class="literal">Wait</code> method. The <code class="literal">Wait</code> method has an overload accepting the cancellation token instance. If we call the <code class="literal">Cancel</code> method from the token, the <code class="literal">Wait</code> method will return the execution at once. This is a built-in cancellation mechanism in TPL, but we need custom cancellation now, so we emulate waiting with task status checking inside the loop. First, we wait until the task actually starts, and then we initiate cancellation and wait until the task completes.</p><p>Finally, we stop the timer <a id="id129" class="indexterm"></a>and print out the results.</p><p>The code for the task runs an infinite loop, waits, and checks whether a cancellation is requested:</p><div class="informalexample"><pre class="programlisting">RunTest(tok =&gt;
{
  while (true)
  {
    Thread.Sleep(100);
    if (tok.IsCancellationRequested)
      break;
  }
}, "CheckFlag");</pre></div><p>The result can be like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>CheckFlag task got cancelled in 103 ms</strong></span>
</pre></div><p>This means that the cancellation happened in the first loop iteration as soon as the task code checked the flag.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec19"></a>Throwing an exception</h3></div></div></div><p>If the code inside the <a id="id130" class="indexterm"></a>task is complicated, it is difficult to check the flag in every part of the code. There can be many loops inside many methods, and if we get results from a method that can be cancelled, we need to provide additional information to distinguish whether this method was cancelled or successfully ran to completion. In this case, it is much easier to use another cancellation technique—throwing a special cancellation exception.</p><p>If we use the <code class="literal">CancellationToken.ThrowIfCancellationRequested</code> method on our token, then it will throw <code class="literal">OperationCanceledException</code> when cancellation is requested. This exception will stop code execution inside the task, bubble up to the TPL infrastructure that will handle it, and set task status to <code class="literal">TaskState.Canceled</code>.</p><p>Instead of checking the flag, we instruct the token to raise <code class="literal">OperationCanceledException</code> when receiving a cancellation request:</p><div class="informalexample"><pre class="programlisting">RunTest( tok =&gt;
{
  while (true)
  {
    Thread.Sleep(100);
    tok.ThrowIfCancellationRequested();
  }
}, "ThrowException");</pre></div><p>The changes are minimal, and the result should be the same:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>ThrowException task got cancelled in 109 ms</strong></span>
</pre></div><p>As soon as we <a id="id131" class="indexterm"></a>get to the <code class="literal">ThrowIfCancellationRequested</code> method, the call operation gets cancelled with an exception.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec20"></a>Using OS wait objects with WaitHandle</h3></div></div></div><p>The next option is<a id="id132" class="indexterm"></a> useful when the code inside<a id="id133" class="indexterm"></a> a task is waiting on an OS synchronization <a id="id134" class="indexterm"></a>primitive for a significant time. Here, we can use <code class="literal">CancellationToken.WaitHandle</code> to include in the waiting process and react immediately when cancellation is requested.</p><p>This is usually combined with one of the previously described techniques—we just stop waiting and proceed with the cancellation.</p><p>This is how it looks:</p><div class="informalexample"><pre class="programlisting">RunTest(tok =&gt;
{
  var evt = new ManualResetEvent(false);
  while (true)
  {
    WaitHandle.WaitAny(new[] { evt, tok.WaitHandle }, 100);
    tok.ThrowIfCancellationRequested();
  }
}, "WaitHandle");</pre></div><p>In this example, we have created a <code class="literal">ManualResetEvent</code> instance to wait on it instead of using <code class="literal">Thread.Sleep</code>. However, we have used <code class="literal">WaitHandle.WaitAny</code> to include the cancellation token in the waiting process. So, here we wait for the event or token to be signaled using the 100 ms timeout value and then continue running the loop.</p><p>Now the result should be different as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>WaitHandle task got cancelled in 0 ms</strong></span>
</pre></div><p>Since we are able to proceed with the cancellation as soon as the token gets signaled, it happens almost immediately.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec21"></a>Cancellation using callbacks</h3></div></div></div><p>It is good when <a id="id135" class="indexterm"></a>you control all the code, and it is possible to change <a id="id136" class="indexterm"></a>every piece of the code to implement cancellation properly. However, the most common situation is when you use some external code inside your task and you do not control this code. Imagine if this is connected via a slow network to some server and this fetches data. You press the <span class="strong"><strong>Cancel</strong></span> button, but the operation will not complete until it finishes the I/O operation. This is not a very good user experience and can be a key reason for the user to choose a different software.</p><p>Of course, we can write similar code from scratch. However, usually we do not need to, since almost every third-party code such as this provides something, such as the <code class="literal">Close</code> or <code class="literal">Dispose</code> methods, allowing us to interrupt communication and release allocated resources. The problem is that these methods can be very different in every third-party framework.</p><p>Fortunately, the cancellation API provides us with a possibility to register any cancellation code as a callback and run this callback as soon as a cancellation is requested. To illustrate this approach, we can write a client/server application and implement a callback cancellation.</p><p>The server part is relatively simple. We just need to allow inbound connection and simulate a slow response:</p><div class="informalexample"><pre class="programlisting">const int port = 8083;
new Thread(() =&gt;
{
  var listener = new TcpListener(IPAddress.Any, port);
  listener.Start();
  while (true)
    using (var client = listener.AcceptTcpClient())
    using (var stream = client.GetStream())
    using (var writer = new StreamWriter(stream))
    {
      Thread.Sleep(100);
      writer.WriteLine("OK");
    }
  }) {IsBackground = true}
  .Start();</pre></div><p>This server will listen for incoming connections on port 8083; when the connection is established, it waits for 100ms and responds with an <span class="strong"><strong>OK</strong></span> string.</p><p>Inside our task, we are going to connect to this server via the <code class="literal">TcpClient</code> class and then cancel the connection as soon as possible:</p><div class="informalexample"><pre class="programlisting">RunTest(tok =&gt;
{
  while (true)
  {
    using (var client = new TcpClient())
    {
      client.Connect("localhost", port);
      using (var stream = client.GetStream())
      using (var reader = new StreamReader(stream))
      Console.WriteLine(reader.ReadLine());
    }
    tok.ThrowIfCancellationRequested();
  }
}, "Callback");</pre></div><p>This sample prints the following result:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>OK</strong></span>
<span class="strong"><strong>Callback task got cancelled in 109 ms</strong></span>
</pre></div><p>This code connects to the server and waits for the server to respond; only after getting the response do we proceed with the cancellation.</p><p>According to the documentation, the <code class="literal">TcpClient</code> class includes the <code class="literal">Close</code> method. This method interrupts work and closes the TCP connection if it has been already opened. All we need to do is to call this method when a cancellation is requested:</p><div class="informalexample"><pre class="programlisting">RunTest(tok =&gt;
{
  while (true)
  {
    using (var client = new TcpClient())
    <span class="strong"><strong>using (tok.Register(client.Close))</strong></span>
    {
      client.Connect("localhost", port);
      using (var stream = client.GetStream())
      using (var reader = new StreamReader(stream))
      Console.WriteLine(reader.ReadLine());
    }
    tok.ThrowIfCancellationRequested();
  }
}, "Callback");</pre></div><p>The difference is just<a id="id137" class="indexterm"></a> adding a single line of code. We call <a id="id138" class="indexterm"></a>the <code class="literal">CancellationToken.Register</code> method that accepts the callback that will be called in the case of cancellation and returns the <code class="literal">CancellationTokenRegistration</code> structure. It implements <code class="literal">IDisposable</code> and calling the <code class="literal">Dispose</code> method on it will deregister the callback, so it will not be called if the cancellation happens afterwards.</p><p>So in the sample code, we would like to run <code class="literal">client.Close</code> when the cancellation happens but only inside the inner <code class="literal">using</code> block. If the cancellation happens somewhere else, we do not need to run this callback. As a result, we will get something like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Callback task got cancelled in 3 ms</strong></span>
</pre></div><p>Now it is clear that we do not wait for the server to respond and cancel the operation almost immediately. We managed to make the users happy without rewriting <code class="literal">TcpClient</code> from scratch with the<a id="id139" class="indexterm"></a> help of <a id="id140" class="indexterm"></a>the cancellation API.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec29"></a>Latency and the coarse-grained approach with TPL</h2></div></div><hr /></div><p>Raw performance, or the number<a id="id141" class="indexterm"></a> of calculations per second that our <a id="id142" class="indexterm"></a>program is able to perform, is not always a most important goal to achieve. Sometimes it is even more important to stay responsive and interact with the user as fast as possible. Unfortunately, it is not easy to achieve both these advantages at the same time; there are situations when we need to choose our primary goal.</p><p>To simulate such a situation, let's create a combination of coarse-grained computational tasks that takes a long time to complete and runs in the background, and a number of short-lived tasks representing user interaction. We would like these short tasks to run as fast as possible with low latency. Now we write a code to test how these long-running tasks can affect latency:</p><div class="informalexample"><pre class="programlisting">for (var longThreadCount = 0; longThreadCount &lt; 24; longThreadCount++)
{
  // Create coarse grained tasks
  var longThreads = new List&lt;Task&gt;();
  for (var i = 0; i &lt; longThreadCount; i++)
    longThreads.Add(
      Task.Factory.StartNew(
        () =&gt; Thread.Sleep(1000)));

  // Measure latency
  var sw = Stopwatch.StartNew();
  for (var i = 0; i &lt; _measureCount; i++)
    Task
      .Factory
      .StartNew(() =&gt; Thread.SpinWait(100))
      .Wait();
  sw.Stop();
  Console.WriteLine("Long running threads {0}. Average latency {1:0.###} ms", longThreadCount, (double)sw.ElapsedMilliseconds / _measureCount);

  Task.WaitAll(longThreads.ToArray());
}</pre></div><p>We have created up to 24 long running threads inside the loop, and in each iteration, we measured up an average latency of running a short task. Finally, we wait for all tasks to complete and print out results. This is how the result data looks on a chart:</p><div class="mediaobject"><img src="graphics/4202_04_02.jpg" /></div><p>We can see that we <a id="id143" class="indexterm"></a>have a very low latency until eight long <a id="id144" class="indexterm"></a>running tasks, and then it dramatically increases up to 4-5 times. The reason is, as usual, complex, but the main reason is that the CPU in this case supports up to eight simultaneously running threads. While long-running tasks occupied fewer threads than this limit, the remaining threads can be used to execute short-lived tasks. As soon as there are no free threads remaining, short tasks have to compete for thread pool worker threads and share CPU time with the long-running tasks, and thus the short tasks become much slower.</p><p>To make short tasks faster again, we can isolate long tasks from the thread pool that runs the short tasks. If the short tasks have priority in getting resources, then they will run faster, and the long-running tasks will run a bit slower, but the short-task latency will be much better.</p><p>TPL has an option to specify that a task is long-running and should be treated in a special way:</p><div class="informalexample"><pre class="programlisting">Task.Factory.StartNew(
  () =&gt; Thread.Sleep(1000),
  <span class="strong"><strong>TaskCreationOptions.LongRunning</strong></span>)</pre></div><p>In .NET 4.5, the <a id="id145" class="indexterm"></a>default task scheduler runs such tasks on <a id="id146" class="indexterm"></a>separate threads that are not thread pool threads. This is what the reference implementation of the <code class="literal">ThreadPoolTaskScheduler</code> method of <code class="literal">QueueTask</code> looks like:</p><div class="informalexample"><pre class="programlisting">protected internal override void QueueTask(Task task)
{
  if ((task.Options &amp; TaskCreationOptions.LongRunning) != TaskCreationOptions.None)
  {
    new Thread(s_longRunningThreadWork) { IsBackground = true }.Start(task);
  }
  else
  {
    bool forceGlobal = (task.Options &amp; TaskCreationOptions.PreferFairness) != TaskCreationOptions.None;
    ThreadPool.UnsafeQueueCustomWorkItem(task, forceGlobal);
  }
}</pre></div><p>However, in general, we do not know how such tasks will be treated, and the way of running such tasks is totally up to the current task scheduler implementation.</p><p>Adding new results to the chart gives us this:</p><div class="mediaobject"><img src="graphics/4202_04_03.jpg" /></div><p>It seems that we <a id="id147" class="indexterm"></a>successfully resolved latency issue. Of <a id="id148" class="indexterm"></a>course, the long-running tasks will be slightly slower, but this is what we wanted to achieve.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec30"></a>Exception handling</h2></div></div><hr /></div><p>Another important aspect of TPL <a id="id149" class="indexterm"></a>is working with exceptions. Just as the normal code that we write can generate an exception, so can the code inside a TPL task. Since every task has its own stack, we cannot work with exceptions in the usual way. TPL has several options that allow us to work with exceptions in a parallel program.</p><p>The easiest option is to check the task status. If an exception has been raised inside the task, it will have the <code class="literal">Status</code> property set to <code class="literal">TaskStatus.Faulted</code>. The exception will be available through the <code class="literal">Task.Exception</code> property:</p><div class="informalexample"><pre class="programlisting">var task = Task.Factory.StartNew(() =&gt;
{
  throw new ApplicationException("Test exception");
});

while (!task.IsCompleted) {}

Console.WriteLine("Status = {0}", task.Status);
Console.WriteLine(task.Exception);</pre></div><p>This code prints the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Status = Faulted</strong></span>

<span class="strong"><strong>System.AggregateException: One or more errors occurred. ---&gt; System.ApplicationException: Test exception</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>The original exception that has been thrown in the code became wrapped in an <code class="literal">AggregateException</code> instance. The reason is that there can be many exceptions from child tasks that run in parallel. In the aggregate exception instance, there is the <code class="literal">InnerExceptions</code> property that will contain all the wrapped exceptions.</p><p>To wait for the task <a id="id150" class="indexterm"></a>completion, we have used a loop instead of the <code class="literal">Task.Wait</code> method. When a task completes with an exception, this method will rethrow the exception on the thread that has called <code class="literal">Wait</code>. If we replace the <code class="literal">while</code> loop with the <code class="literal">task.Wait()</code> method call and run the code again, we will see an unhandled exception:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Unhandled Exception: System.AggregateException: One or more errors occurred. ---&gt; System.ApplicationException: Test exception</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>The same behavior will happen when we use the <code class="literal">Task.Result</code> property or the <code class="literal">Task.WaitAll/WaitAny</code> static methods.</p><p>When reviewing parent-child relations between tasks, we have stated that, if we create a child task with <code class="literal">TaskCreationOptions.AttachedToParent,</code> then its exceptions will automatically be propagated to the parent task. To check the exception behavior, we can quickly create two nested tasks and throw an exception from the child task:</p><div class="informalexample"><pre class="programlisting">Task.Factory.StartNew(() =&gt;
{
  Task.Factory.StartNew(() =&gt;
  {
    throw new ApplicationException("Test exception");
  }, TaskCreationOptions.AttachedToParent);
})
.Wait();</pre></div><p>This will print the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Unhandled Exception: System.AggregateException: One or more errors occurred. ---&gt; System.AggregateException: One or more errors occurred. ---&gt; System.ApplicationException: Test exception</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>As we expected, the parent task completed with the exception that bubbled from its child task. However, now we have an aggregate exception that contains another aggregate exception, which in turn contains the initial exception from the child task. The exception hierarchy repeats the task relationship, which is not always a good thing.</p><p>We may put the previous code in a try block and write a catch block to print the inner exceptions as follows:</p><div class="informalexample"><pre class="programlisting">catch (AggregateException ae)
{
  foreach (Exception e in ae.InnerExceptions)
  {
    Console.WriteLine("{0}: {1}", e.GetType(), e.Message);
  }
}</pre></div><p>The results of the <a id="id151" class="indexterm"></a>preceding code can be surprising:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>System.AggregateException: One or more errors occurred.</strong></span>
</pre></div><p>Since it is a hierarchy, we need to check inner exceptions inside each aggregate exception that we get. Since the aggregate exception is only a container for a real exception, we actually need to collect only the other exceptions. Fortunately, there is a way to flatten the exception hierarchy into a simple collection of initial exceptions. To check this, let's create a complex task structure and see what is inside the top-level exception:</p><div class="informalexample"><pre class="programlisting">var t = Task.Factory.StartNew(() =&gt;
{
  Task.Factory.StartNew(
  () =&gt;
  {
    Task.Factory.StartNew(
    () =&gt;
    {
      throw new ApplicationException("And we need to go deeper");
    }, TaskCreationOptions.AttachedToParent);

    throw new ApplicationException("Test exception");
  }, TaskCreationOptions.AttachedToParent);</pre></div><div class="informalexample"><pre class="programlisting">  Task.Factory.StartNew(() =&gt;
  {
    throw new ApplicationException("Test sibling exception");
  },
  TaskCreationOptions.AttachedToParent);
});
try
{
  t.Wait();
}
catch (AggregateException ae)
{
  foreach (<span class="strong"><strong>Exception e in ae.Flatten().InnerExceptions</strong></span>)
  {
    Console.WriteLine("{0}: {1}", e.GetType(), e.Message);
  }
}</pre></div><p>As a result, we will get a list of all the initial exceptions:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>System.ApplicationException: Test sibling exception</strong></span>
<span class="strong"><strong>System.ApplicationException: Test exception</strong></span>
<span class="strong"><strong>System.ApplicationException: And we need to go deeper</strong></span>
</pre></div><p>One of the <a id="id152" class="indexterm"></a>cancellation options that we have reviewed so far was throwing a special kind of exception, <code class="literal">OperationCanceledException</code>. TPL treats this exception in a special way. The task status will be <code class="literal">TaskStatus.Canceled</code> instead of <code class="literal">Faulted</code>, and the <code class="literal">Exception</code> property will be empty:</p><div class="informalexample"><pre class="programlisting">var cancelSource = new CancellationTokenSource();
var token = cancelSource.Token;
var task =
  Task
    .Factory
    .StartNew(
      () =&gt;
      {
        while (true)
          token.ThrowIfCancellationRequested();
      },
      token);
while (task.Status != TaskStatus.Running) {}
cancelSource.Cancel();
while (!task.IsCompleted) {}
Console.WriteLine("Status = {0}, IsCanceled = {1}", task.Status, task.IsCanceled);
Console.WriteLine(task.Exception);</pre></div><p>The result shows that a cancellation exception in this case is being treated differently:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Status = Canceled, IsCanceled = True</strong></span>
</pre></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note17"></a>Note</h3><p>Please notice that if we do not pass a token instance as the last parameter of the StartNew method, the cancellation exception will be treated like a regular exception.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec31"></a>Using the Parallel class</h2></div></div><hr /></div><p>TPL provides a reach<a id="id153" class="indexterm"></a> API to compose a parallel program. However, it is quite verbose, and if we write a simple code, there are easier way to parallelize it. For common tasks such as running some code in parallel and parallelizing the <code class="literal">for</code> and <code class="literal">foreach</code> loops, there is a Parallel class that provides a simple and easy to use API.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec22"></a>Parallel.Invoke</h3></div></div></div><p>This method executes <a id="id154" class="indexterm"></a>actions in parallel if the CPU has multiple cores and supports multiple threads. If the CPU has only one core, actions will be executed synchronously. This method blocks the calling thread until all the actions are completed:</p><div class="informalexample"><pre class="programlisting">Parallel.Invoke(
  () =&gt; Console.WriteLine("Action 1"),
  () =&gt;
  {
    Thread.SpinWait(10000);
    Console.WriteLine("Action 2");
  },
  () =&gt; Console.WriteLine("Action 3"));
Console.WriteLine("End");</pre></div><p>After running the preceding lines of code, we get the following output:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Action 1</strong></span>
<span class="strong"><strong>Action 3</strong></span>
<span class="strong"><strong>Action 2</strong></span>
<span class="strong"><strong>End</strong></span>
</pre></div><p>We can provide the <code class="literal">ParallelOptions</code> class instance to this method to configure additional options such as limiting the parallelism degree, specifying a cancellation token, and using a specific implementation of the task scheduler to run tasks on it.</p><p>The straightforward implementation of this method will be as follows:</p><div class="informalexample"><pre class="programlisting">var tasks = new List&lt;Task&gt;();

foreach (var action in actions)
{
  tasks.Add(Task.Factory.StartNew(action));
}

Task.WaitAll(tasks.ToArray());</pre></div><p>However, the real implementation, besides cancellation, correctness checks, and exception handling, is still very different. This is due to code performance optimization. The usual task scheduler is written assuming that we do not know how many tasks we are going to run. In this specific case, this is a defined value. If it is less than or equal to <code class="literal">SMALL_ACTIONCOUNT_LIMIT</code> (that is 10 in the current .NET Framework version 4.5), then the algorithm is similar to our implementation.</p><p>In the case of more tasks, it becomes more complicated. First, we create an empty special task called<a id="id155" class="indexterm"></a> <span class="strong"><strong>replicable task</strong></span>. This task is treated in a special way by a task scheduler. The implementation code is as follows:</p><div class="informalexample"><pre class="programlisting">var actionIndex = 0;
var rootTask =
  new ReplicableTask(
    () =&gt;
    {
      int myIndex;
      while ((myIndex = InterLocked.Increment(ref actionIndex)) &lt;= actions.Length)
        body(myIndex-1);
    });
rootTask.RunSynchronously();
rootTask.Wait();</pre></div><p>Here, we have the <code class="literal">actionIndex</code> local variable that is used by the task code inside the lambda expression. This creates a closure, and the C# compiler generates a helper class instance and puts the <code class="literal">actionIndex</code> variable inside this class as a field. Thus, if we create more copies of this task, they all will share a single <code class="literal">actionIndex</code> variable. At the same time, the <code class="literal">myIndex</code> variable will be different for each copy of this task.</p><p>So a scheduling <a id="id156" class="indexterm"></a>algorithm can create as many copies of this task as needed, and still it is guaranteed that every action will be executed at least once or only one time. This allows scheduling mechanisms to work efficiently. First, we create as many copies of the threads as the CPU support. Then, if tasks run longer than a certain amount of time, the scheduler will create more copies to prevent CPU cores from idling. This makes the tasks run slightly slower, but we know that our tasks are long-running and this will not be important for overall performance.</p><p>This algorithm also ensures that, even when we have many actions to be run, the real number of tasks that are to be executed in parallel will be low and close to the number of threads that the CPU supports.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec23"></a>Parallel.For and Parallel.Foreach</h3></div></div></div><p>These methods are <a id="id157" class="indexterm"></a>useful to create parallel loops. They use the same<a id="id158" class="indexterm"></a> strategy as <code class="literal">Parallel.Invoke</code>, since it is very effective when having a large number of iterations to run in parallel. <code class="literal">Parallel.Foreach</code> offers even more control, allowing us to use a custom task partitioning algorithm with the <code class="literal">Partitioner&lt;T&gt;</code> and <code class="literal">OrderablePartitioner&lt;T&gt;</code> abstract class implementations.</p><p>To see the default parallelization strategy, let's run this code:</p><div class="informalexample"><pre class="programlisting">private static void Calc(int iterations)
{
  var taskIds = new HashSet&lt;int&gt;();
  var sum = 0;
  Parallel.For(
    0,
    iterations,
    i =&gt;
    {
      Thread.SpinWait(1000000);
      lock (taskIds)
        taskIds.Add(Task.CurrentId.Value);
    });
  Console.WriteLine("{0} iterations, {1} tasks", iterations, taskIds.Count);
}</pre></div><p>We simply call the <code class="literal">Parallel.For</code> method with a different number of iterations and count how many unique task ids we've got.</p><p>On a machine with Core i7-2600K CPU, we will get these values:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>1 iteration, 1 tasks</strong></span>
<span class="strong"><strong>4 iterations, 4 tasks</strong></span>
<span class="strong"><strong>8 iterations, 8 tasks</strong></span>
<span class="strong"><strong>12 iterations, 8 tasks</strong></span>
<span class="strong"><strong>16 iterations, 8 tasks</strong></span>
<span class="strong"><strong>32 iterations, 9 tasks</strong></span>
<span class="strong"><strong>64 iterations, 9 tasks</strong></span>
</pre></div><p>The CPU supports<a id="id159" class="indexterm"></a> eight concurrent threads, and the algorithm <a id="id160" class="indexterm"></a>chose eight tasks to run in parallel until 32 iterations, when one additional task is added to prevent possible CPU idling; this makes the code more efficient.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec24"></a>Understanding the task scheduler</h3></div></div></div><p>The task scheduler <a id="id161" class="indexterm"></a>manages and executes TPL tasks. First, we will review a default task scheduler algorithm, and then we will learn how to create a custom task scheduler and use it with TPL to run tasks on it.</p><p>The default task scheduler is based on the .NET thread pool and uses its global queue to run top-level tasks that are not created in the context of another task. However, if we create a nested or child task, it is put on a local queue that is created on a worker thread that runs the parent task. When this worker thread gets ready to run a task, it first looks for work items on the local queue that is accessed in LIFO order. Using local queue reduces contention since we do not access any shared data; thus, there is no need for any synchronization.</p><p>If the local queue is empty, the worker thread looks into a global queue. If this queue is empty, then to prevent idling the thread is going to look at other threads' local queues. If the thread finds a work item here after running some heuristics to decide if taking this work item will be efficient, the thread steals this work item from another thread's local queue. The stealing happens in FIFO order for efficiency reasons.</p><p>This way TPL tries to improve performance by lowering contention and using CPU cache more effectively, and at the same time, by load balancing between worker threads with a work-stealing algorithm.</p><p>The default scheduler works well, but in some cases, we need to replace it with another. Imagine a WPF application that has a button clicked event handler with the following code:</p><div class="informalexample"><pre class="programlisting">var t = Task.Factory.StartNew(() =&gt;
{
  Console.WriteLine("Id: {0}, Is threadpool thread: {1}",
    Thread.CurrentThread.ManagedThreadId,
    Thread.CurrentThread.IsThreadPoolThread);

  Thread.Sleep(TimeSpan.FromSeconds(1));
  _label.Content = new TextBlock {Text = "Hello from TPL task"};
},
CancellationToken.None,
TaskCreationOptions.None,
TaskScheduler.Default);

while (t.Status != TaskStatus.RanToCompletion &amp;&amp; t.Status != TaskStatus.Faulted)
{
  // run message loop
  Application.Current.Dispatcher.Invoke(
    DispatcherPriority.Background, new Action(delegate { }));
}

if (null != t.Exception)
{
  var innerException = t.Exception.Flatten().InnerException;
  Console.WriteLine("{0}: {1}", innerException.GetType(), innerException.Message);
}</pre></div><p>If we run this <a id="id162" class="indexterm"></a>code, we will see the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Id: 4, Is threadpool thread: True</strong></span>
<span class="strong"><strong>System.InvalidOperationException: The calling thread must be STA, because many UI components require this.</strong></span>
</pre></div><p>The reason is that we tried to access the UI control from a thread pool worker thread, which is forbidden. To make this code work, we have to use a task scheduler that will put this task on a UI thread:</p><div class="informalexample"><pre class="programlisting">var t = Task.Factory.StartNew(() =&gt;
{
    Console.WriteLine("Id: {0}, Is threadpool thread: {1}",
      Thread.CurrentThread.ManagedThreadId,
      Thread.CurrentThread.IsThreadPoolThread);

    Thread.Sleep(TimeSpan.FromSeconds(1));
    _label.Content = new TextBlock {Text = "Hello from TPL task"};
  },
  CancellationToken.None,
  TaskCreationOptions.None,
TaskScheduler.FromCurrentSynchronizationContext());</pre></div><p>The output will be different, and the program will run successfully, changing the label value:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Id: 1, Is threadpool thread: False</strong></span>
</pre></div><p>The UI and asynchrony is a very large and complicated topic. We will get back to this later in this book.</p><p>Last but not<a id="id163" class="indexterm"></a> the least is implementing a custom task scheduler. We need to inherit this from the TaskScheduler class and implement several abstract members:</p><div class="informalexample"><pre class="programlisting">public class SynchronousTaskScheduler: TaskScheduler
{
  // we do not schedule tasks, we run them synchronously
  protected override IEnumerable&lt;Task&gt; GetScheduledTasks()
  {
    return Enumerable.Empty&lt;Task&gt;();
  }

  // run the task synchronously on the current thread
  protected override void QueueTask(Task task)
  {
    TryExecuteTask(task);
  }

  // the same thing – just run the task on current thread
  protected override bool TryExecuteTaskInline(
    Task task, bool taskWasPreviouslyQueued)
  {
    return TryExecuteTask(task);
  }

  // maximum concurrency level is 1, because only one task runs at //a time
  public override int MaximumConcurrencyLevel
  {
    get { return 1; }
  }
}</pre></div><p>Of course, real-world task schedulers are much more complicated than this one, but this works too. Let's use this with the previous code:</p><div class="informalexample"><pre class="programlisting">var t = Task.Factory.StartNew(() =&gt;
{
  Console.WriteLine("Id: {0}, Is threadpool thread: {1}",
    Thread.CurrentThread.ManagedThreadId,
    Thread.CurrentThread.IsThreadPoolThread);

  Thread.Sleep(TimeSpan.FromSeconds(1));
  _label.Content = new TextBlock {Text = "Hello from TPL task"};
  },
  CancellationToken.None,
  TaskCreationOptions.None,
  new SynchronousTaskScheduler());</pre></div><p>The code will <a id="id164" class="indexterm"></a>work fine and we will get the same results.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec32"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we have reviewed Task Parallel Library in detail. We have studied its architecture and composition blocks. We have learned about exception handling and task cancellation in detail. We examined performance and latency issues by finding out the best way of writing code to achieve good results. Using the <code class="literal">Parallel</code> class API allowed us to quickly create parallel programs, and deep-diving into TPL task scheduling allowed us to write a custom task scheduler and customize TPL task execution.</p><p>In the next chapter, we will learn how the C# language supports asynchrony. We will understand its new keywords, <code class="literal">async</code> and <code class="literal">await</code>, and understand how we can use Task Parallel Library with the new C# syntax. Also, we will review in detail how exactly new language features work and create our own custom code that will be compatible with the <code class="literal">await</code> statement.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch05"></a>Chapter 5. C# Language Support for Asynchrony</h2></div></div></div><p>The <span class="strong"><strong>Task Parallel Library</strong></span><a id="id165" class="indexterm"></a> makes it possible to combine asynchronous tasks and set dependencies between them. In the previous chapter, we reviewed this topic in detail. However to get a clear understanding in this chapter, we will use this approach to solve a real problem—downloading images from Bing (the search engine). Also, we will do the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Implement standard synchronous approach</p></li><li style="list-style-type: disc"><p>Use Task Parallel Library to create an asynchronous version of the program</p></li><li style="list-style-type: disc"><p>Use C# 5.0 built-in asynchrony support to make the code easier to read and maintain</p></li><li style="list-style-type: disc"><p>Simulate C# asynchronous infrastructure with the help of iterators</p></li><li style="list-style-type: disc"><p>Learn about other useful features of Task Parallel Library</p></li><li style="list-style-type: disc"><p>Make any C# type compatible with built-in asynchronous keywords</p></li></ul></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec33"></a>Implementing the downloading of images from Bing</h2></div></div><hr /></div><p>Everyday <a class="ulink" href="http://Bing.com" target="_blank">Bing.com</a> publishes its background image that can<a id="id166" class="indexterm"></a> be used<a id="id167" class="indexterm"></a> as desktop wallpaper. There is an XML API to get information about these pictures that <a id="id168" class="indexterm"></a>can be found at <a class="ulink" href="http://www.bing.com/hpimagearchive.aspx" target="_blank">http://www.bing.com/hpimagearchive.aspx</a>.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec25"></a>Creating a simple synchronous solution</h3></div></div></div><p>Let's<a id="id169" class="indexterm"></a> try <a id="id170" class="indexterm"></a>to write a program to download the last eight images from this site. We will start by defining objects to store image information. This is where a thumbnail image and its description will be stored:</p><div class="informalexample"><pre class="programlisting">using System.Drawing;

public class WallpaperInfo
{
  private readonly Image _thumbnail;
  private readonly string _description;

  public WallpaperInfo(Image thumbnail, string description)
  {
    _thumbnail = thumbnail;
    _description = description;
  }
 
  public Image Thumbnail
  {
    get { return _thumbnail; }
  }
 
  public string Description
  {
    get { return _description; }
  }
}</pre></div><p>The next <a id="id171" class="indexterm"></a>container <a id="id172" class="indexterm"></a>type is for all the downloaded pictures and the time required to download and make the thumbnail images from the original pictures:</p><div class="informalexample"><pre class="programlisting">public class WallpapersInfo
{
  private readonly long _milliseconds;
  private readonly WallpaperInfo[] _wallpapers;

  public WallpapersInfo(long milliseconds, WallpaperInfo[] wallpapers)
  {
    _milliseconds = milliseconds;
    _wallpapers = wallpapers;
  }

  public long Milliseconds
  {
    get { return _milliseconds; }
  }

  public WallpaperInfo[] Wallpapers
  {
    get { return _wallpapers; }
  }
}</pre></div><p>Now we need to create a loader class to download images from Bing. We need to define a <code class="literal">Loader</code> static class and follow with an implementation. Let's create a method that will make a thumbnail image from the source image stream:</p><div class="informalexample"><pre class="programlisting">private static Image GetThumbnail(Stream imageStream)
{
  using (imageStream)
  {
    var fullBitmap = Image.FromStream(imageStream);
    return new Bitmap(fullBitmap, 192, 108);
  }
}</pre></div><p>To <a id="id173" class="indexterm"></a>communicate <a id="id174" class="indexterm"></a>via the HTTP protocol, it is recommended to use the <code class="literal">System.Net.HttpClient</code> type from the <code class="literal">System.Net.dll</code> assembly. Let's create the following extension methods that will allow us to use the POST HTTP method to download an image and get an opened stream:</p><div class="informalexample"><pre class="programlisting">private static Stream DownloadData(this HttpClient client, string uri)
{
  var response = client.PostAsync(
    uri, new StringContent(string.Empty)).Result;

  return response.Content.ReadAsStreamAsync().Result;
}

private static Task&lt;Stream&gt; DownloadDataAsync(this HttpClient client, string uri){
  Task&lt;HttpResponseMessage&gt; responseTask = client.PostAsync(uri, new StringContent(string.Empty));

  return responseTask.ContinueWith(task =&gt; task.Result.Content.ReadAsStreamAsync()).Unwrap();
}</pre></div><p>To create the easiest implementation possible, we will implement downloading without any asynchrony. Here, we will define HTTP endpoints for the Bing API:</p><div class="informalexample"><pre class="programlisting">private const string _catalogUri = "http://www.bing.com/hpimagearchive.aspx?format=xml&amp;idx=0&amp;n=8&amp;mbl=1&amp;mkt=en-ww";
private const string _imageUri = "http://bing.com{0}_1920x1080.jpg";</pre></div><p>Then, we will start measuring the time required to finish downloading and download an XML catalog that has information about the images that we need:</p><div class="informalexample"><pre class="programlisting">var sw = Stopwatch.StartNew();

var client = new HttpClient();
var catalogXmlString = client.DownloadString(_catalogUri);</pre></div><p>Next, the XML string will be parsed to an XML document:</p><div class="informalexample"><pre class="programlisting">var xDoc = XDocument.Parse(catalogXmlString);</pre></div><p>Now using LINQ to XML, we will query the information needed from the document and run the download process for each image:</p><div class="informalexample"><pre class="programlisting">var wallpapers = xDoc
  .Root
  .Elements("image")
  .Select(e =&gt;
    new
    {
      Desc = e.Element("copyright").Value,
      Url = e.Element("urlBase").Value
    })
  .Select(item =&gt;
    new
    {
      item.Desc,
      FullImageData = client.DownloadData(
        string.Format(_imageUri, item.Url))
    })
  .Select( item =&gt;
    new WallpaperInfo(
      GetThumbnail(item.FullImageData),
      item.Desc))
  .ToArray();

sw.Stop();</pre></div><p>The<a id="id175" class="indexterm"></a> first<a id="id176" class="indexterm"></a> <code class="literal">Select</code> method call extracts the image URL and description from each <code class="literal">image</code> XML element that is a direct child of root element. This information is contained inside the <code class="literal">urlBase</code> and <code class="literal">copyright</code> XML elements inside the <code class="literal">image</code> element. The second one downloads an image from the Bing site. The last <code class="literal">Select</code> method creates a thumbnail image and stores all the information needed inside the <code class="literal">WallPaperInfo</code> class instance.</p><p>To display the results, we need to create a user interface. <span class="strong"><strong>Windows Forms</strong></span><a id="id177" class="indexterm"></a> is a simple and fast way to implement the technology, so we can use it to show the results to the user. There is a button that runs the download, a panel to show the downloaded pictures, and a label that will show the time required to finish downloading.</p><p>Here is the implementation code. This includes a calculation of the top co-ordinate for each element, a code to display the images and start the download process:</p><div class="informalexample"><pre class="programlisting">private int GetItemTop(int height, int index)
{
  return index * (height + 8) + 8;
}
 
private void RefreshContent(WallpapersInfo info)
{
  _resultPanel.Controls.Clear();
  _resultPanel.Controls.AddRange(
  info.Wallpapers.SelectMany((wallpaper, i) =&gt; new Control[]
  {
    new PictureBox
    {
      Left = 4,
      Image = wallpaper.Thumbnail,
      AutoSize = true,
      Top = GetItemTop(wallpaper.Thumbnail.Height, i)
    },
    new Label
    {
      Left = wallpaper.Thumbnail.Width + 8,
      Top = GetItemTop(wallpaper.Thumbnail.Height, i),
      Text = wallpaper.Description,
      AutoSize = true
    }
  }).ToArray());

  _timeLabel.Text = string.Format(
    "Time: {0}ms", info.Milliseconds);
}
private void _loadSyncBtn_Click(object sender, System.EventArgs e)
{
  var info = Loader.SyncLoad();
  RefreshContent(info);
}</pre></div><p>The <a id="id178" class="indexterm"></a>result <a id="id179" class="indexterm"></a>looks as follows:</p><p> </p><div class="mediaobject"><img src="graphics/4202_05_02.jpg" /></div><p>So the<a id="id180" class="indexterm"></a> time to<a id="id181" class="indexterm"></a> download all these images should be about several seconds if the Internet connection is broadband. Can we do this faster? We certainly can! Now we will download and process the images one by one, but we totally can process each image in parallel.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec26"></a>Creating a parallel solution with Task Parallel Library</h3></div></div></div><p>In the previous<a id="id182" class="indexterm"></a> chapter, we reviewed<a id="id183" class="indexterm"></a> Task Parallel Library<a id="id184" class="indexterm"></a> and the relationships between tasks. The code naturally splits into several stages:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Load images catalog XML from Bing</p></li><li style="list-style-type: disc"><p>Parse the XML document and get the information needed about the images</p></li><li style="list-style-type: disc"><p>Load <a id="id185" class="indexterm"></a>each image's<a id="id186" class="indexterm"></a> data from Bing</p></li><li style="list-style-type: disc"><p>Create a <a id="id187" class="indexterm"></a>thumbnail image for each image downloaded</p></li></ul></div><p>The process can be visualized with the dependency chart:</p><div class="mediaobject"><img src="graphics/4208_05_03.jpg" /></div><p><code class="literal">HttpClient</code> has naturally asynchronous API, so we only need to combine everything together with the help of a <code class="literal">Task.ContinueWith</code> method:</p><div class="informalexample"><pre class="programlisting">public static Task&lt;WallpapersInfo&gt; TaskLoad()
{
  var sw = Stopwatch.StartNew();

  var downloadBingXmlTask = new HttpClient().GetStringAsync(
    _catalogUri);

  var parseXmlTask = downloadBingXmlTask.ContinueWith(task =&gt;
  {
    var xmlDocument = XDocument.Parse(task.Result);
    return xmlDocument.Root
      .Elements("image")
      .Select(e =&gt;
        new
        {
          Description = e.Element("copyright").Value,
          Url = e.Element("urlBase").Value
        });
  });

  var downloadImagesTask = parseXmlTask.ContinueWith(
    task =&gt; Task.WhenAll(
      task.Result.Select(item =&gt; new HttpClient()
        .DownloadDataAsync(string.Format(_imageUri, item.Url))
        .ContinueWith(downloadTask =&gt; new WallpaperInfo(
          GetThumbnail(downloadTask.Result), item.Description)))))
        .Unwrap();

  return downloadImagesTask.ContinueWith(task =&gt;
  {
    sw.Stop();

    return new WallpapersInfo(sw.ElapsedMilliseconds, task.Result);
  });
}</pre></div><p>The <a id="id188" class="indexterm"></a>code has some interesting <a id="id189" class="indexterm"></a>moments. The first task is created by the <code class="literal">HttpClient</code> <a id="id190" class="indexterm"></a>instance, and it completes when the download process succeeds. Now we will attach a subsequent task, which will use the XML string downloaded by the previous task, and then we will create an XML document from this string and extract the information needed.</p><p>Now this is becoming more complicated. We want to create a task to download each image and continue until all these tasks complete successfully. So we will use the LINQ Select method to run downloads for each image that was defined in the XML catalog, and after the download process completes, we will create a thumbnail image and store the information in the <code class="literal">WallpaperInfo</code> instance. This creates <code class="literal">IEnumerable&lt;Task&lt;WallpaperInfo&gt;&gt;</code> as a result, and to wait for all these tasks to complete, we will use the <code class="literal">Task.WhenAll</code> method. However, this is a task that is inside a continuation task, and the result is going to be of the <code class="literal">Task&lt;Task&lt;WallpaperInfo[]&gt;&gt;</code> type. To get the inner task, we will use the <code class="literal">Unwrap</code> method, which has the following syntax:</p><div class="informalexample"><pre class="programlisting">public static Task Unwrap(this Task&lt;Task&gt; task)</pre></div><p>This can be used on any <code class="literal">Task&lt;Task&gt;</code> instance and will create a proxy task that represents an entire asynchronous operation properly.</p><p>The last task is to stop the timer and return the downloaded images and is quite straightforward. We have to add another button to the UI to run this implementation. Notice the implementation of the button click handler:</p><div class="informalexample"><pre class="programlisting">private void _loadTaskBtn_Click(object sender, System.EventArgs e)
{
  var info = Loader.TaskLoad();
  info.ContinueWith(task =&gt; RefreshContent(task.Result),
    CancellationToken.None,
    TaskContinuationOptions.None,
    TaskScheduler.FromCurrentSynchronizationContext());
}</pre></div><p>Since the<a id="id191" class="indexterm"></a> <code class="literal">TaskLoad</code> method is<a id="id192" class="indexterm"></a> asynchronous, it returns immediately. To display the results, we <a id="id193" class="indexterm"></a>have to define a continuation task. However, from the previous chapter you already know that the default task scheduler will run a task code on a thread pool worker thread. To work with UI controls, we have to run the code on the UI thread, and we use a task scheduler that captures the current synchronization context and runs the continuation task on this. We will cover synchronization context and the related infrastructure later in <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Server-Side Asynchrony</em></span>, and <a class="link" href="#" linkend="ch09">Chapter 9</a>, <span class="emphasis"><em>Concurrency in the User Interface</em></span>, where server-side and client-side asynchrony will be reviewed in detail.</p><p>Let's name the button as <span class="strong"><strong>Load using TPL</strong></span> and test the results. If your Internet connection is fast, this implementation will download the images in parallel much faster compared to the previous sequential download process.</p><p>If we look back at the code, we will see that it is quite hard to understand what it actually does. We can see how one task depends on the other, but the original goal is unclear despite the code being very compact and easy. Imagine what will happen if we try to add exception handling here. We would have to append an additional continuation task with exception handling to each task. This will be much harder to read and understand. In a real-world program, it will be a challenging task to keep in mind these tasks composition and support a code written in such a paradigm.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec27"></a>Enhancing the code with C# 5.0 built-in support for asynchrony</h3></div></div></div><p>Fortunately, C# 5.0<a id="id194" class="indexterm"></a> introduced<a id="id195" class="indexterm"></a> the <code class="literal">async</code> and <code class="literal">await</code> keywords that are intended to make asynchronous code look synchronous, and thus, makes reading of code and understanding the program flow easier. However, this is another abstraction and it hides many things that happen under the hood from the programmer, which in several situations is not a good thing. The potential pitfalls and solutions will be covered later in this book, but <a id="id196" class="indexterm"></a>now let's<a id="id197" class="indexterm"></a> rewrite the previous code using new C# 5.0 features:</p><div class="informalexample"><pre class="programlisting">public static async Task&lt;WallpapersInfo&gt; AsyncLoad()
{
  var sw = Stopwatch.StartNew();

  var client = new HttpClient();
  var catalogXmlString = await client.GetStringAsync(_catalogUri);
  var xDoc = XDocument.Parse(catalogXmlString);

  var wallpapersTask = xDoc
    .Root
    .Elements("image")
    .Select(e =&gt; 
      new
      {
        Description = e.Element("copyright").Value,
        Url = e.Element("urlBase").Value
      })
    .Select(async item =&gt;
      new
      {
        item.Description,
        FullImageData = await client.DownloadDataAsync(
          string.Format(_imageUri, item.Url))
      });

  var wallpapersItems = await Task.WhenAll(wallpapersTask);

  var wallpapers = wallpapersItems.Select(
    item =&gt; new WallpaperInfo(
      GetThumbnail(item.FullImageData), item.Description));

  sw.Stop();

  return new WallpapersInfo(sw.ElapsedMilliseconds, 
    wallpapers.ToArray());
}</pre></div><p>Now the code looks almost like the first synchronous implementation. The <code class="literal">AsyncLoad</code> method has a <code class="literal">async</code> modifier and a <code class="literal">Task&lt;T&gt;</code> return value, and such methods must always return <code class="literal">Task </code>or be declared as <code class="literal">void</code>—this is enforced by the compiler. However, in the method's code, the type that is returned is just <code class="literal">T</code>. This is strange at first, but the method's return value will be eventually turned into <code class="literal">Task&lt;T&gt;</code> by the C# 5.0 compiler. The <code class="literal">async</code> modifier is necessary to use <code class="literal">await</code> inside the method. In the further code, there is <code class="literal">await</code> inside a lambda expression, and we need to mark this lambda as <code class="literal">async</code> as well.</p><p>So what is going on when we use <code class="literal">await</code> inside our code? It does not always mean that the call is actually asynchronous. It can happen that by the time we call the method, the result is already available, so we just get the result and proceed further. However, the most common case is when we make an asynchronous call. In this case, we start, for example, by<a id="id198" class="indexterm"></a> downloading<a id="id199" class="indexterm"></a> a XML string from Bing via HTTP and immediately return a task that is a continuation task and contains the rest of the code after the line with <code class="literal">await</code>.</p><p>To run this, we need to add another button named <span class="strong"><strong>Load using async</strong></span>. We are going to use <code class="literal">await</code> in the button click event handler as well, so we need to mark it with the <code class="literal">async</code> modifier:</p><div class="informalexample"><pre class="programlisting">private async void _loadAsyncBtn_Click(object sender, System.EventArgs e)
{
  var info = await Loader.AsyncLoad();
  RefreshContent(info);
}</pre></div><p>Now if the code after <code class="literal">await</code> is being run in a continuation task, why is there no multithreaded access exception? The <code class="literal">RefreshContent</code> method runs in another task, but the C# compiler is aware of the synchronization context and generates a code that executes the continuation task on the UI thread. The result should be as fast as a TPL implementation but the code is much cleaner and easy to follow.</p><p>Last but not least, is the possibility to put asynchronous method calls inside a <code class="literal">try</code> block. The C# compiler generates a code that will propagate the exception into the current context and unwrap the <code class="literal">AggregateException</code> instance to get the original exception from it.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note18"></a>Note</h3><p>In C# 5.0, it was impossible to use <code class="literal">await</code> inside catch and finally blocks, but C# 6.0 introduced a new async/await infrastructure and this limitation was removed.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec28"></a>Simulating C# asynchronous infrastructure with iterators</h3></div></div></div><p>To dig into the <a id="id200" class="indexterm"></a>implementation <a id="id201" class="indexterm"></a>details, it makes sense to look at the decompiled code of the <code class="literal">AsyncLoad</code> method:</p><div class="informalexample"><pre class="programlisting">public static Task&lt;WallpapersInfo&gt; AsyncLoad()
{
  Loader.&lt;AsyncLoad&gt;d__21 stateMachine;

  stateMachine.&lt;&gt;t__builder = AsyncTaskMethodBuilder&lt;WallpapersInfo&gt;.Create();

  stateMachine.&lt;&gt;1__state = -1;

  stateMachine
    .&lt;&gt;t__builder
    .Start&lt;Loader.&lt;AsyncLoad&gt;d__21&gt;(ref stateMachine);

  return stateMachine.&lt;&gt;t__builder.Task;
}</pre></div><p>The method body was <a id="id202" class="indexterm"></a>replaced by a compiler-generated code that creates a special kind of state machine. We will not review the further implementation details here, because it is quite complicated and is subject to changes from version to version. However, what's going on is that the code gets divided into separate pieces at each line where <code class="literal">await</code> is present, and each piece becomes a separate state in the generated state machine. Then, a special <code class="literal">System.Runtime.CompilerServices.AsyncTaskMethodBuilder</code> structure creates <code class="literal">Task</code> that represents the generated state machine workflow.</p><p>This state machine is quite similar to the one that is generated for the iterator methods that leverage the <code class="literal">yield</code> keyword. In C# 6.0, the same universal code gets generated for the code containing <code class="literal">yield</code> and <code class="literal">await</code>. To illustrate the general principles behind the generated code, we can use iterator methods to implement another version of asynchronous images download from Bing.</p><p>Therefore, we <a id="id203" class="indexterm"></a>can turn an asynchronous method into an iterator method that returns the <code class="literal">IEnumerable&lt;Task&gt;</code> instance. We replace each <code class="literal">await</code> with <code class="literal">yield return</code> making each iteration to be returned as <code class="literal">Task</code>. To run such a method, we need to execute each task and return the final result. This code can be considered as an analogue of <code class="literal">AsyncTaskMethodBuilder</code>:</p><div class="informalexample"><pre class="programlisting">private static Task&lt;TResult&gt; ExecuteIterator&lt;TResult&gt;(
  Func&lt;Action&lt;TResult&gt;,IEnumerable&lt;Task&gt;&gt; iteratorGetter)
{
  return Task.Run(() =&gt;
  {
    var result = default(TResult);

    foreach (var task in iteratorGetter(res =&gt; result = res))
      task.Wait();

    return result;
  });
}</pre></div><p>We iterate through each task and await its completion. Since we cannot use the <code class="literal">out</code> and <code class="literal">ref</code> parameters in iterator methods, we use a lambda expression to return the result from each task. To make the code easier to understand, we have created a new container task and used the <code class="literal">foreach</code> loop; however, to be closer to the original implementation, we should get the first task and use the <code class="literal">ContinueWith</code> method providing the next task to it and continue until the last task. In this case, we will end up having one final task representing an entire sequence of asynchronous operations, but the code will become more complicated as well.</p><p>Since it is not possible to use the yield keyword inside a lambda expressions in the current C# versions, we will implement image download and thumbnail generation as a separate method:</p><div class="informalexample"><pre class="programlisting">private static IEnumerable&lt;Task&gt; GetImageIterator(
  string url,
  string desc,
  Action&lt;WallpaperInfo&gt; resultSetter)
{
  var loadTask = new HttpClient().DownloadDataAsync(
    string.Format(_imageUri, url));

  yield return loadTask;

  var thumbTask = Task.FromResult(GetThumbnail(loadTask.Result));
  yield return thumbTask;

  resultSetter(new WallpaperInfo(thumbTask.Result, desc));
}</pre></div><p>It looks like<a id="id204" class="indexterm"></a> a common C# async code with <code class="literal">yield return</code> used instead of the <code class="literal">await</code> keyword <a id="id205" class="indexterm"></a>and <code class="literal">resultSetter</code> used instead of <code class="literal">return</code>. Notice the <code class="literal">Task.FromResult</code> method that we used to get <code class="literal">Task</code> from the synchronous <code class="literal">GetThumbnail</code> method. We can use <code class="literal">Task.Run </code>and put this operation on a separate worker thread, but it will be an ineffective solution. <code class="literal">Task.FromResult</code> allows us to get <code class="literal">Task</code> that is already completed and has a result. If you use <code class="literal">await</code> with such task, it will be translated into a synchronous call.</p><p>The main code can be rewritten in the same way:</p><div class="informalexample"><pre class="programlisting">private static IEnumerable&lt;Task&gt; GetWallpapersIterator(
  Action&lt;WallpaperInfo[]&gt; resultSetter)
{
  var catalogTask = new HttpClient().GetStringAsync(_catalogUri);
  yield return catalogTask;

  var xDoc = XDocument.Parse(catalogTask.Result);

  var imagesTask = Task.WhenAll(xDoc
    .Root
    .Elements("image")
    .Select(e =&gt; new 
    {
      Description = e.Element("copyright").Value,
      Url = e.Element("urlBase").Value
    })
    .Select(item =&gt; ExecuteIterator&lt;WallpaperInfo&gt;(
      resSetter =&gt; GetImageIterator(
        item.Url, item.Description, resSetter))));

yield return imagesTask;

  resultSetter(imagesTask.Result);
}</pre></div><p>This combines everything together:</p><div class="informalexample"><pre class="programlisting">public static WallpapersInfo IteratorLoad()
{
  var sw = Stopwatch.StartNew();

  var wallpapers = ExecuteIterator&lt;WallpaperInfo[]&gt;(GetWallpapersIterator)
      .Result;

  sw.Stop();

  return new WallpapersInfo(sw.ElapsedMilliseconds, wallpapers);
}</pre></div><p>To run this, we <a id="id206" class="indexterm"></a>will create one more button called <span class="strong"><strong>Load using iterator</strong></span>. The button <a id="id207" class="indexterm"></a>click handler just runs the <code class="literal">IteratorLoad</code> method and then refreshes the UI. This also works with about the same speed as other asynchronous implementations.</p><p>This example can help us to understand the logic behind the C# code generation for asynchronous methods used with <code class="literal">await</code>. Of course, the real code is much more complicated, but the principles behind it remain the same.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec34"></a>Is the async keyword really needed?</h2></div></div><hr /></div><p>It is a common<a id="id208" class="indexterm"></a> question about why do we need to mark methods as <code class="literal">async</code>. We have already mentioned iterator methods in C# and the <code class="literal">yield</code> keyword. This is very similar to <code class="literal">async</code>/<code class="literal">await</code>, and yet we do not need to mark iterator methods with any modifier. The C# compiler is able to determine that it is an iterator method when it meets the <code class="literal">yield return</code> or <code class="literal">yield break</code> operators inside such a method. So the question is, why is it not the same with <code class="literal">await</code> and the asynchronous methods?</p><p>The reason is that asynchrony support was introduced in the latest C# version, and it is very important not to break any legacy code while changing the language. Imagine if any code used <code class="literal">await</code> as a name for a field or variable. If C# developers make <code class="literal">await</code> a keyword without any conditions, this old code will break and stop compiling. The current approach guarantees that if we do not mark a method with <code class="literal">async</code>, the old code will continue to work.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec35"></a>Fire-and-forget tasks</h2></div></div><hr /></div><p>Besides <code class="literal">Task</code> and <code class="literal">Task&lt;T&gt;,</code> we can declare an<a id="id209" class="indexterm"></a> asynchronous method as void. It is useful in the case of top-level event handlers, for example, the button click or text changed handlers in the UI. An event handler that returns a value is possible, but is very inconvenient to use and does not make much sense.</p><p>So allowing <code class="literal">async void</code> methods makes it possible to use <code class="literal">await</code> inside such event handlers:</p><div class="informalexample"><pre class="programlisting">private async void button1_Click(object sender, EventArgs e)
{
  await SomeAsyncStuff();
}</pre></div><p>It seems that nothing bad is happening, and the C# compiler generates almost the same code as for the <code class="literal">Task</code> returning method, but there is an important catch related to exceptions handling.</p><p>When an asynchronous method returns <code class="literal">Task</code>, exceptions are connected to this task and can be handled both by TPL and the <code class="literal">try</code>/<code class="literal">catch</code> block in case <code class="literal">await</code> is used. However, if we have a <code class="literal">async void</code> method, we have no <code class="literal">Task</code> to attach the exceptions to and those exceptions just get posted to the current synchronization context. These exceptions can be observed using <code class="literal">AppDomain.UnhandledException</code> or similar events in a GUI application, but this is very easy to miss and not a good practice.</p><p>The other problem is that we cannot use a <code class="literal">void</code> returning asynchronous method with <code class="literal">await</code>, since there is no return value that can be used to await on it. We cannot compose such a method with other asynchronous tasks and participate in the program workflow. It is basically a fire-and-forget operation that we start, and then we have no way to control how it will proceed (if we did not write the code for this explicitly).</p><p>Another problem is <code class="literal">void</code> returning <code class="literal">async</code> lambda expression. It is very hard to notice that lambda returns void, and all problems related to usual methods are related to lambda expression as well. Imagine that we want to run some operation in parallel. From the previous chapter we learned that to achieve this, we can use the <code class="literal">Parallel.ForEach</code> method. To download some news in parallel, we can write a code like this:</p><div class="informalexample"><pre class="programlisting">Parallel.ForEach(Enumerable.Range(1,10), async i =&gt;
{
  var news = await newsClient.GetTopNews(i);
  newsCollection.Add(news);
});</pre></div><p>However, this<a id="id210" class="indexterm"></a> will not work, because the second parameter of the <code class="literal">ForEach</code> method is <code class="literal">Action&lt;T&gt;</code>, which is a void returning delegate. Thus, we will spawn 10 download processes, but since we cannot wait for completion, we abandon all asynchronous operations that we just started and ignore the results.</p><p>A general rule of thumb is to avoid using <code class="literal">async void</code> methods. If this is inevitable and there is an event handler, then always wrap the inner <code class="literal">await</code> method calls in try/catch blocks and provide exception handling.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec36"></a>Other useful TPL features</h2></div></div><hr /></div><p>Task Parallel Library<a id="id211" class="indexterm"></a> has a large codebase and some useful features such as <code class="literal">Task.Unwrap</code> or <code class="literal">Task.FromResult</code> that are not very well known to developers. We have still not mentioned two more extremely useful methods yet. They are covered in the following sections.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec29"></a>Task.Delay</h3></div></div></div><p>Often, it is required to wait for a <a id="id212" class="indexterm"></a>certain amount of time in the code. One of the traditional ways to wait is using the <code class="literal">Thread.Sleep</code> method. The problem is that <code class="literal">Thread.Sleep</code> blocks the current thread, and it is not asynchronous.</p><p>Another disadvantage is that we cannot cancel waiting if something has happened. To implement a solution for this, we will have to use system synchronization primitives such as an event, but this is not very easy to code. To keep the code simple, we can use the <code class="literal">Task.Delay</code> method:</p><div class="informalexample"><pre class="programlisting">// Do something
await Task.Delay(1000);
// Do something</pre></div><p>This method can be canceled with a help of the <code class="literal">CancellationToken</code> infrastructure and uses system timer under the <a id="id213" class="indexterm"></a>hood, so this kind of waiting is truly asynchronous.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec30"></a>Task.Yield</h3></div></div></div><p>Sometimes we need a part of the code<a id="id214" class="indexterm"></a> to be guaranteed to run asynchronously. For example, we need to keep the UI responsive, or maybe we would like to implement a fine-grained scenario. Anyway, as we already know that using <code class="literal">await</code> does not mean that the call will be asynchronous. If we want to return control immediately and run the rest of the code as a continuation task, we can use the <code class="literal">Task.Yield</code> method:</p><div class="informalexample"><pre class="programlisting">// Do something
await Task.Yield();
// Do something</pre></div><p><code class="literal">Task.Yield</code> just causes a continuation to be posted on the current synchronization context, or if the synchronization context is not available, a continuation will be posted on a thread pool worker thread.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec37"></a>Implementing a custom awaitable type</h2></div></div><hr /></div><p>Until now we have only<a id="id215" class="indexterm"></a> used <code class="literal">Task</code> with the <code class="literal">await</code> operator. However, it is not the only type that is compatible with <code class="literal">await</code>. Actually, the <code class="literal">await</code> operator can be used with every type that contains the <code class="literal">GetAwaiter</code> method with no parameters and the return type that does the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Implements the <code class="literal">INotifyCompletion</code> interface</p></li><li style="list-style-type: disc"><p>Contains the <code class="literal">IsCompleted</code> boolean property</p></li><li style="list-style-type: disc"><p>Has the <code class="literal">GetResult</code> method with no parameters</p></li></ul></div><p>This method can even be an extension method, so it is possible to extend the existing types and add the <code class="literal">await</code> compatibility to them. In this example, we will create such a method for the <code class="literal">Uri</code> type. This method will download content as a string via HTTP from the address provided in the <code class="literal">Uri </code>instance:</p><div class="informalexample"><pre class="programlisting">private static TaskAwaiter&lt;string&gt; GetAwaiter(this Uri url)
{
  return new HttpClient().GetStringAsync(url).GetAwaiter();
}

var content = await new Uri("http://google.com");
Console.WriteLine(content.Substring(0, 10));</pre></div><p>If we run this, we will see the first 10 characters of the Google website content.</p><p>As you may notice, here we used the <code class="literal">Task</code> type indirectly, returning the already provided awaiter method for the <code class="literal">Task</code> type. We can implement an awaiter method manually from scratch, but it really does not make any sense. To understand how this works it will be enough to create a <a id="id216" class="indexterm"></a>custom wrapper around an already existing <code class="literal">TaskAwaiter:</code></p><div class="informalexample"><pre class="programlisting">struct DownloadAwaiter : INotifyCompletion
{
  private readonly TaskAwaiter&lt;string&gt; _awaiter;

  public DownloadAwaiter(Uri uri)
  {
    Console.WriteLine("Start downloading from {0}", uri);
    var task = new HttpClient().GetStringAsync(uri);
    _awaiter = task.GetAwaiter();
    Task.GetAwaiter().OnCompleted(() =&gt; Console.WriteLine("download completed"));
  }

  public bool IsCompleted
  {
    get { return _awaiter.IsCompleted; }
  }
 
  public void OnCompleted(Action continuation)
  {
    _awaiter.OnCompleted(continuation);
  }
 
  public string GetResult()
  {
    return _awaiter.GetResult();
  }
}</pre></div><p>With this code, we have customized asynchronous execution that provides diagnostic information to the console. To get rid of <code class="literal">TaskAwaiter</code>, it will be enough to change the <code class="literal">OnCompleted</code> method with custom code that will execute some operation and then a continuation provided in this method.</p><p>To use this custom awaiter, we need to change <code class="literal">GetAwaiter</code> accordingly:</p><div class="informalexample"><pre class="programlisting">private static DownloadAwaiter GetAwaiter(this Uri uri)
{
  return new DownloadAwaiter(uri);
}</pre></div><p>If we run this, we will see additional information on the console. This can be useful for diagnostics and debugging.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec38"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we looked at the C# language infrastructure that supports asynchronous calls. We covered the new C# keywords, <code class="literal">async</code> and <code class="literal">await</code>, and how we can use Task Parallel Library with the new C# syntax. We learned how C# generates code and creates a state machine that represents an asynchronous operation, and we implemented an analogue solution with the help of iterator methods and the <code class="literal">yield</code> keyword. Besides this, we studied additional Task Parallel Library features and looked at how we can use <code class="literal">await</code> with any custom type.</p><p>In the next chapter, we will learn about data structures that are built for concurrency and common algorithms that rely on them.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch06"></a>Chapter 6. Using Concurrent Data Structures</h2></div></div></div><p>Choosing an appropriate data structure for your concurrent algorithm is a crucial step. We have already learned from the previous chapters that it is not usually possible to use just any .NET object as a shared data in a multithreaded program. We can assume that most of the common types in .NET are implemented in such a way that their static members are thread-safe, while their instance members are not. However, only those objects that are specifically designed to be thread-safe can be used as they are in a multithreaded environment.</p><p>Therefore, if we need multiple threads to add some item to a collection, we cannot just call the <code class="literal">Add</code> method of a shared instance of the <code class="literal">List&lt;T&gt;</code> type. It will lead to unpredictable results, and most probably the program will end up throwing a weird exception.</p><p>Thus, in this situation, there are two general ways to follow: either we implement synchronized access to the standard collection ourselves with the help of existing synchronization primitives, or we can use existing concurrent collections from the <code class="literal">System.Collections.Concurrent</code> namespace.</p><p>In this chapter, we are going to dig into the details of using data structures in concurrent applications and review advantages and disadvantages of each option.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec39"></a>Standard collections and synchronization primitives</h2></div></div><hr /></div><p>To highlight <a id="id217" class="indexterm"></a>what problems can appear when we use nonthread safe collections in <a id="id218" class="indexterm"></a>a concurrent program, let's write a simple program that will use the <code class="literal">Parallel.Foreach</code> class to copy a collection and double its elements:</p><div class="informalexample"><pre class="programlisting">var source = Enumerable.Range(1, 42000).ToList();
var destination = new List&lt;int&gt;();
            
Parallel.ForEach(source, n =&gt; destination.Add(n * 2));
 
Assert.AreEqual(source.Count, destination.Count);</pre></div><p>If we run this code, we will almost certainly get the <code class="literal">AggregateException</code> exception with the <code class="literal">ArgumentException</code> instance wrapped inside it.</p><p>This happens because the <code class="literal">Add</code> method of the <code class="literal">List&lt;T&gt;</code> class is not thread safe, and the reason for this lies in the implementation details:</p><div class="informalexample"><pre class="programlisting">public void Add(T item)
{
    if (_size == _items.Length) EnsureCapacity(_size + 1);
    _items[_size++] = item;
    _version++;
}</pre></div><p>In case the <a id="id219" class="indexterm"></a>concurrent threads access this method when the <code class="literal">_size == items.Length – 1 </code>condition is true, the <code class="literal">ArgumentException</code> exception will almost certainly occur. The implementation will cause the collection to have an inconsistent <a id="id220" class="indexterm"></a>state; a race condition will lead the inner array new size to be less than needed.</p><p>To avoid a race condition, we can implement some sort of synchronization for shared collection access using the <a id="id221" class="indexterm"></a>
<span class="strong"><strong>lock</strong></span> statement:</p><div class="informalexample"><pre class="programlisting">object syncRoot = new object();
var source = Enumerable.Range(1, 42000).ToList();
var destination = new List&lt;int&gt;();
 
Parallel.ForEach(source,
    n =&gt;
    {
        lock (syncRoot)
        {
            destination.Add(n * 2);
        }
    });
 
Assert.AreEqual(source.Count, destination.Count);</pre></div><p>This code will run without errors. However, its efficiency will be less than doing the same job from a single thread. Instead of doing calculations, a thread will be waiting for a shared resource (in this case, it is the <code class="literal">destination</code> variable) access. This situation is called thread <a id="id222" class="indexterm"></a>
<span class="strong"><strong>contention</strong></span>, and it can significantly decrease your program performance.</p><p>To use all the available CPU cores effectively, we always have to try to reduce contention as much as possible. In some cases, it is possible to use special synchronization primitives or<a id="id223" class="indexterm"></a> lock-free algorithms, or use thread local computations, which<a id="id224" class="indexterm"></a> are merged at the end of parallel calculations to get the final result.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec40"></a>Implementing a cache with ReaderWriterLockSlim</h2></div></div><hr /></div><p>Caching is a<a id="id225" class="indexterm"></a> common technique that is being used in many applications to increase performance and efficiency. Usually, reading from a cache occurs more often than writing operation, and the number of cache readers is higher that the number of writers.</p><p>In this particular<a id="id226" class="indexterm"></a> case, there is no sense in using an exclusive lock preventing other threads from reading another cache value. There is a built-in synchronization object that has exactly this behavior, and it is called <code class="literal">ReaderWriterLockSlim</code>.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note19"></a>Note</h3><p>There are several classes in the .NET Framework inside the <code class="literal">System.Threading</code> namespace, whose names end with <code class="literal">Slim</code>. It is usually more efficient and lightweight to implement the corresponding classes without <code class="literal">Slim</code> at the end of their names. In most cases, you should prefer the <code class="literal">Slim</code> versions over original ones, unless you are 100% sure why you need non-slim objects. This rule works with the <code class="literal">ReaderWriterLock</code> and <code class="literal">ReaderWriterLockSlim</code> classes as well—always prefer a <code class="literal">Slim</code> object, because it has major efficiency and corrective improvements.</p></div><p>Cache can be used differently in the application, but the most common approach is using <span class="strong"><strong>cache aside</strong></span> pattern. The client is <a id="id227" class="indexterm"></a>unaware of caching; if there is a long-running operation and no result of this operation can be found in the cache, we perform the operation and save the result into the cache. If there is a result in the cache, we do not start a long-running operation but use the cached value instead.</p><p>A simple code of a cache provider that contains one long-running operation and implements cache aside pattern will look as follows:</p><div class="informalexample"><pre class="programlisting">public class CustomProvider
{
    private readonly Diction­­ary&lt;string, OperationResult&gt; _cache = 
        new Dictionary&lt;string, OperationResult&gt;();

    private readonly ReaderWriterLockSlim _rwLockSlim = 
        new ReaderWriterLockSlim();
 
    public OperationResult RunOperationOrGetFromCache(
        string operationId)
    {
        _rwLockSlim.EnterReadLock();
        try
        {
            OperationResult result;
            if (_cache.TryGetValue(operationId, out result))
                return result;
        }
        finally
        {
            _rwLockSlim.ExitReadLock();
        }
 
        _rwLockSlim.EnterWriteLock();
 
        try
        {
            OperationResult result;
            if (_cache.TryGetValue(operationId, out result))
                return result;
 
            result = RunLongRunningOperation(operationId);
            _cache.Add(operationId, result);
            return result;
        }
        finally
        {
            _rwLockSlim.ExitReadLock();
        }
    }
 
    private OperationResult RunLongRunningOperation(
        string operationId)
    {
        // Running real long-running operation
        // ...
    }
}</pre></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note20"></a>Note</h3><p>It is very<a id="id228" class="indexterm"></a> important to<a id="id229" class="indexterm"></a> always implement a cache invalidation strategy, which is missing in this demo code as it is not relevant to the topic of the chapter. However, in real-world scenarios, you have to pay attention to this to avoid memory leaks. The simple invalidation strategy can be setting a cache item lifetime explicitly or using weak references so that garbage collection will invalidate the cache.</p></div><p>This sample <a id="id230" class="indexterm"></a>demonstrates a <code class="literal">CustomProvider</code> class, which contains only one <code class="literal">RunOperationOrGetFromCache</code> public method. This method accepts an operation identifier and returns the operation result as an <code class="literal">OperationResult</code> object. To implement correct cache parallel reading, in the beginning we acquire a reader lock and then check that there is a result in the cache. If not, we acquire a writer lock and then check that there is an operation value inside the cache, which can appear while we are acquiring the lock. If there is still <a id="id231" class="indexterm"></a>nothing in the cache, we will run the long-running operation, put its result into the cache, and return it to the client.</p><p>If we don't perform this check, we can get <code class="literal">ArgumentException</code> when trying to add an item with the same<a id="id232" class="indexterm"></a> key to the dictionary twice, and as a result we do unnecessary work.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip03"></a>Tip</h3><p>However, as it usually happens in concurrent programming, this approach can be non-effective in different situations. Using <code class="literal">ReaderWriterLockSlim </code>for implementing dictionary-based caching almost always lead to worse performance than simply using a common statement, <code class="literal">lock (syncRoot)</code>. The problem is that acquiring reader lock is not a very fast operation. A <code class="literal">ReaderWriterLockSlim</code> object has to ensure that acquiring a writer lock is not possible while being inside a reader block, and this requires the use of some synchronization logic, which is costly. If a long running operation is really long running, this overhead is not significant. However, in our case, reading a value from <code class="literal">Dictionary</code> is a very fast operation, and in this situation, locking the overhead becomes noticeable. Since a lock statement uses spin-wait optimization for short running operations, it will be more effective in this particular case.</p></div><p>The previous tip works for choosing a data structure as well. In simple cases, implementing general locking over nonthread safe object could work better than a specialized universal thread safe data structure. However, when concurrent program logic becomes more complicated, it is a good idea to go for standard concurrent data structures.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec41"></a>Concurrent collections in .NET</h2></div></div><hr /></div><p>Since the first .NET <a id="id233" class="indexterm"></a>Framework version, most of the collections in the <code class="literal">System.Collections</code> namespace contained the <code class="literal">Synchronized</code> factory method that creates a thread safe wrapper over the collection instance, which ensures thread safety:</p><div class="informalexample"><pre class="programlisting">var source = Enumerable.Range(1, 42000).ToList();
var destination = ArrayList.Synchronized(new List&lt;int&gt;());
 
Parallel.ForEach(source,
    n =&gt;
    {
        destination.Add(n);
    });
 
Assert.AreEqual(source.Count, destination.Count);</pre></div><p>The synchronized collection wrapper can be used in a concurrent environment, but its efficiency is low, since it uses simple locking ensuring exclusive collection access for every operation. This approach is called <a id="id234" class="indexterm"></a>
<a id="id235" class="indexterm"></a>
<span class="strong"><strong>coarse-grained</strong></span> locking and it is described in <a class="link" href="#" linkend="ch03">Chapter 3</a>, <span class="emphasis"><em>Understanding Parallelism Granularity</em></span>. It does not scale well with an increase in the number of clients and the amount of data inside the collection.</p><p>A complicated, but an efficient, approach is to use <span class="strong"><strong>fine-grained</strong></span> locking, so we can provide an exclusive access only to the parts of the collection that are in use. For example, if the<a id="id236" class="indexterm"></a> underlying data storage is an array, we can create multiple locks that will cover the corresponding array parts. This approach requires determining the required lock first, but it will also allow a non-blocking access to the different parts of the array. This will use locks only when there is a concurrent access to the same data. In certain scenarios, the performance difference will be huge.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note21"></a>Note</h3><p>PLINQ uses exactly the<a id="id237" class="indexterm"></a> same approach for parallel collections processing. There is a special mechanism called partitioning, which splits a collection in multiple segments. Each segment gets processed on a separate thread. A standard partitioner implementation resides inside the <code class="literal">System.Collections.Concurrent.Partitioner</code> type.</p></div><p>With the .NET Framework 4.0 release, a new set of concurrent collections are available for .NET developers. These collections are specifically designed for high load concurrent access and use lock-free and fine-grained approaches internally. These collections are available in the <code class="literal">System.Collections.Concurrent</code> namespace:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><thead><tr><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Concurrent Collection</p>
</th><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>System.Collections.Generic analogue</p>
</th></tr></thead><tbody><tr><td style="" align="left" valign="top">
<p><code class="literal">ConcurrentDictionary&lt;TKey, TValue&gt;</code></p>
</td><td style="" align="left" valign="top">
<p><code class="literal">Dictionary&lt;TKey, TValue&gt;</code></p>
</td></tr><tr><td style="" align="left" valign="top">
<p><code class="literal">ConcurrentBag&lt;T&gt;</code></p>
</td><td style="" align="left" valign="top">
<p><code class="literal">None</code></p>
</td></tr><tr><td style="" align="left" valign="top">
<p><code class="literal">ConcurrentQueue&lt;T&gt;</code></p>
</td><td style="" align="left" valign="top">
<p><code class="literal">Queue&lt;T&gt;</code></p>
</td></tr><tr><td style="" align="left" valign="top">
<p><code class="literal">ConcurrentStack&lt;T&gt;</code></p>
</td><td style="" align="left" valign="top">
<p><code class="literal">Stack&lt;T&gt;</code></p>
</td></tr></tbody></table></div><p>Each of these concurrent collections are suitable for different work scenarios. Further, we will go through all <a id="id238" class="indexterm"></a>of these data structures and review the implementation details and the best-suited work scenario.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec42"></a>ConcurrentDictionary</h2></div></div><hr /></div><p>We can<a id="id239" class="indexterm"></a> improve the implementation of <code class="literal">CustomProvider</code> using <code class="literal">ConcurrentDictionary&lt;TKey, TValue&gt;</code> to handle the synchronization:</p><div class="informalexample"><pre class="programlisting">public class CustomProvider
{
    private readonly 
        ConcurrentDictionary&lt;string, OperationResult&gt; _cache = 
            new ConcurrentDictionary&lt;string, OperationResult&gt;();
 
    public OperationResult RunOperationOrGetFromCache(
        string operationId)
    {
        return _cache.GetOrAdd(operationId, 
            id =&gt; RunLongRunningOperation(id));
    }
 
    private OperationResult RunLongRunningOperation(
        string operationId)
    {
        // Running real long-running operation
        // ...
        Console.WriteLine("Running long-running operation");
        return OperationResult.Create(operationId);
    }
}</pre></div><p>The code became much simpler. We just used the <code class="literal">GetOrAdd</code> method and it does exactly what we need; if there is an element in the dictionary, it just returns its value or runs a provided delegate, gets the result value, and stores it in the dictionary.</p><p>Every concurrent collection implements a corresponding generic interface. For example, <code class="literal">ConcurrentDictionary&lt;TKey, TValue&gt; </code>implements the standard <code class="literal">IDictionary&lt;TKey, TValue&gt; </code>interface. However besides this, it introduces new methods because it is not enough to introduce the thread safe version of each method. Consider this example:</p><div class="informalexample"><pre class="programlisting">private readonly IDictionary&lt;string, OperationResult&gt; _cache =
    new ConcurrentDictionary&lt;string, OperationResult&gt;();
 
public OperationResult RunOperationOrGetFromCache(
    string operationId)
{
    OperationResult result;
    
    if (_cache.TryGetValue(operationId, out result))
    {
        return result;
    }
            
    result = RunLongRunningOperation(operationId);
    _cache.Add(operationId, result);
    return result;
}</pre></div><p>This code will not work correctly in a multithreaded environment. Both the <code class="literal">TryGetValue</code> and <code class="literal">Add</code> operations are thread safe, but a sequence of two operations without additional synchronization can cause a race condition, and in this example, it is possible to get<a id="id240" class="indexterm"></a> an exception thrown from the <code class="literal">Add</code> method while trying to add an element when it has already been added to the dictionary by another thread.</p><p>It is clear that in this situation, just having the <code class="literal">IDictionary&lt;TKey, TValue&gt; </code>implementation is not enough. One of the possible solutions is to replace <code class="literal">_cache.Add</code> with the <code class="literal">_cache.TryAdd</code> method, but this will require us to get back to using a concrete class:</p><div class="informalexample"><pre class="programlisting">private readonly
    ConcurrentDictionary&lt;string, OperationResult&gt; _cache =
        new ConcurrentDictionary&lt;string, OperationResult&gt;();
 
public OperationResult RunOperationOrGetFromCache(
    string operationId)
{
    OperationResult result;
    if (_cache.TryGetValue(operationId, out result))
    {
        return result;
    }
            
    result = RunLongRunningOperation(operationId);
    _cache.TryAdd(operationId, result);
    return result;
}</pre></div><p>While this solution is also far from perfect, we can already see why concurrent collections changed the common API and introduced a set of new methods. Usually, these new methods represent atomic operations that consist of several steps and each step performs a specific action internally: <code class="literal">GetOrAdd</code>, <code class="literal">AddOrUpdate</code>, and so on.</p><p>Now let's review one more important aspect of this implementation. If we look at the code thoroughly, we can see that despite there being no errors in the concurrent environment it is possible<a id="id241" class="indexterm"></a> that the <code class="literal">RunLongRunningOperation</code> method can be called twice. Thus, only the first result will be stored in the dictionary and the latter method call result will be wasted. This is also important because the <code class="literal">GetOrAdd </code>method of the <code class="literal">ConcurrentDictionary&lt;TKey, TValue&gt;</code> class is implemented in a very similar way.</p><p>This means that <a id="id242" class="indexterm"></a>using <code class="literal">RunOperationOrGetFromCache</code> in a concurrent environment will result in calling a long running operation multiple times per one value. If this turns out to be costly, similar to transmitting a large volume of data via the network or performing CPU intensive long time calculations, this is definitely not a good approach.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec31"></a>Using Lazy&lt;T&gt;</h3></div></div></div><p>Since <code class="literal">AddOrGet</code> is<a id="id243" class="indexterm"></a> implemented in a way that every call to this method with the same key will result in getting the same value, we can use a little trick to prevent the long running operation from running multiple times:</p><div class="informalexample"><pre class="programlisting">private readonly 
    ConcurrentDictionary&lt;string, Lazy&lt;OperationResult&gt;&gt; _cache =
        new ConcurrentDictionary&lt;string, Lazy&lt;OperationResult&gt;&gt;();
 
public OperationResult RunOperationOrGetFromCache(
    string operationId)
{
    return _cache.GetOrAdd(operationId, 
        id =&gt; new Lazy&lt;OperationResult&gt;(
          () =&gt; RunLongRunningOperation(id))).Value;
}</pre></div><p>In this example, we wrap the <code class="literal">RunLongRunningOperation</code> method call into a special object—<code class="literal">Lazy&lt;OperationResult&gt;</code>. This class is a part of the .NET Framework Base Class Library (BCL) that ensures that the provided delegate will be executed only once and only when its <code class="literal">Value</code> property is accessed by an external code.</p><p>We can look at the <code class="literal">GetOrAdd</code> method implementation details to fully understand what is happening under the hood:</p><div class="informalexample"><pre class="programlisting">// ConcurrentDictionary&lt;TKey, TValue&gt; implementation
public TValue GetOrAdd(TKey key, Func&lt;TKey, TValue&gt; valueFactory)
{
    TValue resultingValue;
    if (TryGetValue(key, out resultingValue))
    {
        return resultingValue;
    }
            
    TryAddInternal(key, valueFactory(key), false, true, 
        out resultingValue);

    return resultingValue;
}
 
/// &lt;summary&gt;
/// Shared internal implementation for inserts and updates.
/// If key exists, we always return false;
/// and if updateIfExists == true we 
/// force update with value;
/// If key doesn't exist, we always add value and return true;
/// &lt;/summary&gt;
private bool TryAddInternal(TKey key, TValue value, 
    bool updateIfExists, bool acquireLock,
    out TValue resultingValue)
{
    // ... The implementation details
}</pre></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note22"></a>Note</h3><p>.NET Framework Core is now open source and can be found on GitHub in the Microsoft/dotnet repository. However, there is a more convenient way to learn the .NET source code—a referencesource.microsoft.com web site. This resource was specifically created for learning the internals of .NET and provides a comfortable search and navigation using the code semantics, not just a simple text search. For example, if you are looking for all the cases of the <code class="literal">System.String.Substring(System.Int32)</code> method usage, you will not get any other <code class="literal">Substring</code> method overloads.</p></div><p>We can see<a id="id244" class="indexterm"></a> that if there is no cached operation result in the dictionary, we immediately call <code class="literal">valueFactory(key)</code> (this is where multiple <code class="literal">RunLongRunningOperation</code> calls happen), and the returned result goes to the <code class="literal">TryAddInternal</code> method. Even the comments to this method state that if a key exists and the <code class="literal">updateIfExists</code> parameter equals to <code class="literal">false,</code> we will use the old value that has been already stored in the dictionary.</p><p>Using <code class="literal">Lazy&lt;OperationResult&gt; </code>instead of <code class="literal">OperationResult</code> leads to a situation where we call only the <code class="literal">Lazy&lt;T&gt; </code>object constructor multiple times, while a long running operation will be executed only once when the first <code class="literal">GetOrAdd</code> method call completes.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec32"></a>Implementation details</h3></div></div></div><p><code class="literal">ConcurrentDictionary</code> is in fact a usual hash table that contains an array of buckets protected by an<a id="id245" class="indexterm"></a> array of locks. The number of locks can be defined by the user and theoretically, allows many threads to access the dictionary without any contention if they all use different locks and thus, the different parts of data in the dictionary.</p><p>A <code class="literal">ConcurrentDictionary</code> inner structure scheme looks like this:</p><div class="mediaobject"><img src="graphics/B04208_06_01.jpg" /></div><p>The entire <code class="literal">ConcurrentDictionary</code> state is placed in a separate <code class="literal">Tables</code> class instance in the <code class="literal">m_tables</code> field. This makes it possible to have an atomic state change operation for the dictionary with the help of the <a id="id246" class="indexterm"></a>
<span class="strong"><strong>compare-and-swap</strong></span> (CAS) operations.</p><p>The <code class="literal">Tables</code> class contains the following most important fields:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><code class="literal">m_buckets</code>: This is an<a id="id247" class="indexterm"></a> array of buckets; each of the buckets contains a singly-linked list of nodes with dictionary data.</p></li><li style="list-style-type: disc"><p><code class="literal">m_locks</code>: This is an <a id="id248" class="indexterm"></a>array of locks; each lock provides synchronized access to one or more buckets.</p></li><li style="list-style-type: disc"><p><code class="literal">m_countPerLock</code>: This is <a id="id249" class="indexterm"></a>an array of counters; each counter contains a total number of nodes that are protected by the corresponding lock. For example, if we look at the previous scheme, where the first lock protects the first two buckets, the <code class="literal">m_countPerLock[0]</code> element will contain the value of 5.</p></li><li style="list-style-type: disc"><p><code class="literal">m_comparer</code>: This is <a id="id250" class="indexterm"></a>an <code class="literal">IEqualityComparer&lt;TKey&gt;</code> object that contains the logic for calculating the hash value of a key object.</p></li></ul></div><p>The<code class="literal"> ConcurrentDictionary</code> class in turn contains three large operations groups:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>Lock-free</strong></span> operations: This kind<a id="id251" class="indexterm"></a> of operation can be run in parallel from multiple threads without any contention</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Fine-grained lock</strong></span> operations: As it has<a id="id252" class="indexterm"></a> been already explained, these operations can be concurrently executed without any contention if they manipulate the different parts of data inside the dictionary</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Exclusive lock</strong></span> operations: These <a id="id253" class="indexterm"></a>operations<a id="id254" class="indexterm"></a> can run only on a single thread and require a full collection lock to ensure thread safety</p></li></ul></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec01"></a>Lock-free operations</h4></div></div></div><p>These operations do<a id="id255" class="indexterm"></a> not require any lock and can be used safely from multiple threads. This is the list of the corresponding <a id="id256" class="indexterm"></a>methods:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><code class="literal">ContainsKey</code></p></li><li style="list-style-type: disc"><p><code class="literal">TryGetValue</code></p></li><li style="list-style-type: disc"><p>Read access by dictionary indexer</p></li><li style="list-style-type: disc"><p><code class="literal">GetEnumerator</code></p></li></ul></div><p>The first three operations are based on the <code class="literal">TryGetValue</code> method. This contains the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>Get the key object hash code using current comparer.</p></li><li><p>Get the bucket number by the key hash with the help of the <code class="literal">GetBucketAndLockNo</code> method. The lock number is not used at the moment.</p></li><li><p>Iterate over the current bucket node list to find the corresponding value:</p><div class="informalexample"><pre class="programlisting">public bool TryGetValue(TKey key, out TValue value)
{
    int bucketNo, lockNoUnused;

    Tables tables = m_tables;
    GetBucketAndLockNo(
        tables.m_comparer.GetHashCode(key), out bucketNo, out lockNoUnused, 
        tables.m_buckets.Length, tables.m_locks.Length);

    // The Volatile.Read ensures that the load of the 
    // fields of 'n' doesn't move before the load from buckets[i].
    Node n = Volatile.Read&lt;Node&gt;(ref tables.m_buckets[bucketNo]);

    // Iterate over Nodes to find entry with a corresponding key
    ...
}</pre></div></li></ol></div><p>The <code class="literal">GetEnumerator</code> method<a id="id257" class="indexterm"></a> implementation is <a id="id258" class="indexterm"></a>quite straightforward:</p><div class="informalexample"><pre class="programlisting">public IEnumerator&lt;KeyValuePair&lt;TKey, TValue&gt;&gt; GetEnumerator()
{
    Node[] buckets = m_tables.m_buckets;

    for (int i = 0; i &lt; buckets.Length; i++)
    {
        // The Volatile.Read ensures that 
        // the load of the fields of 'current' 
        // doesn't move before the load from buckets[i].
        Node current = Volatile.Read&lt;Node&gt;(ref buckets[i]);

        while (current != null)
        {
            yield return new KeyValuePair&lt;TKey, TValue&gt;(
               current.m_key, current.m_value);

            current = current.m_next;
        }
    }
}</pre></div><p>As we can see, the <code class="literal">GetEnumerator</code> method does not create a copy of buckets contents, and this allows multiple threads to change the dictionary data while another thread iterates over these elements. Notice the <code class="literal">Volatile.Read</code> construct that creates an acquire-fence and ensures that no reads or writes can be reordered before the load from <code class="literal">buckets[i]</code>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec02"></a>Fine-grained lock operations</h4></div></div></div><p>These operations<a id="id259" class="indexterm"></a> usually<a id="id260" class="indexterm"></a> work with a single element inside the dictionary. These methods use the fine-grained locking approach:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><code class="literal">TryAdd</code></p></li><li style="list-style-type: disc"><p><code class="literal">TryRemove</code></p></li><li style="list-style-type: disc"><p><code class="literal">TryUpdate</code></p></li><li style="list-style-type: disc"><p>write access by a dictionary indexer</p></li><li style="list-style-type: disc"><p><code class="literal">GetOrAdd</code></p></li><li style="list-style-type: disc"><p><code class="literal">AddOrUpdate</code></p></li></ul></div><p>These operations internally use the <code class="literal">GetBucketAndLockNo</code> method, which returns the bucket and the<a id="id261" class="indexterm"></a> lock numbers. The<a id="id262" class="indexterm"></a> implementation usually contains the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>Get the key object hash code.</p></li><li><p>Get the bucket and the lock numbers.</p></li><li><p>Acquire the lock.</p></li><li><p>Change the current bucket—delete or change some element inside.</p></li><li><p>Release the acquired lock.</p></li></ol></div><p>Most of the operations in the preceding list use the <code class="literal">TryAddInternal</code> method internally. Let's review the simplified code of this method:</p><div class="informalexample"><pre class="programlisting">private bool TryAddInternal(TKey key, TValue value, 
    out TValue resultingValue)
{
    while (true)
    {
        bool resizeDesired = false;
        var tables = m_tables;
        int bucketNo, lockNo;
        int hashcode = tables.m_comparer.GetHashCode(key);
 
        GetBucketAndLockNo(hashcode, out bucketNo, out lockNo);
 
        try
        {
            Monitor.Enter(tables.m_locks[lockNo]);
 
            // If the table just got resized, we may not be holding 
            // the right lock, and must retry.
            // This should be a rare occurence.
            if (tables != m_tables)
            {
                continue;
            }
 
            // Looping through Nodes in the bucket.
            // If existing Node was found
            // the method returns false, otherwise 
            // new Node would be added
            for (Node node = tables.m_buckets[bucketNo]; 
                     node != null; node = node.m_next)
            {
                // ...
            }
 
            // If the number of elements guarded by this lock has 
            // exceeded the budget, resize the bucket table.
            // It is also possible that GrowTable will increase 
            // the budget but won't resize the bucket table.
            // That happens if the bucket table is found to be 
            // poorly utilized due to a bad hash function.
            if (tables.m_countPerLock[lockNo] &gt; m_budget)
            {
                resizeDesired = true;
            }
        }
        finally
        {
            Monitor.Exit(tables.m_locks[lockNo]);
        }
 
        // Resize table if needed.
        // This method should be called outside the lock
        // to prevent a deadlocks.
        if (resizeDesired)
        {
            GrowTable(tables, tables.m_comparer);
        }
 
        resultingValue = value;
        return true;
    }
}</pre></div><p>It is clear that this <a id="id263" class="indexterm"></a>code implements all the<a id="id264" class="indexterm"></a> preceding steps—we get the key hash, the bucket, and the lock number and proceed to the element needed. However, there are a couple of important points to pay attention to:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Using the <a id="id265" class="indexterm"></a>
<span class="strong"><strong>while</strong></span> loop to work around the situation where another thread has changed the collection and its <code class="literal">m_tables</code> field. In this case, we just retry until we succeed and the old and new <code class="literal">m_tables</code> values remain equal.</p></li><li style="list-style-type: disc"><p>When node <a id="id266" class="indexterm"></a>count per one lock exceeds some threshold value (<code class="literal">m_budget</code>), the hash table rebalancing <a id="id267" class="indexterm"></a>occurs inside the <code class="literal">GrowTable</code> method. This requires an exclusive lock for the dictionary to be acquired.</p></li></ul></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec03"></a>Exclusive lock operations</h4></div></div></div><p>There are more<a id="id268" class="indexterm"></a> operations that are required to get an <a id="id269" class="indexterm"></a>exclusive lock as the <code class="literal">GrowTable</code> does. It is very important to know these operations and avoid using them in a multithreaded environment if possible. Here is the operations list:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><code class="literal">Clear</code></p></li><li style="list-style-type: disc"><p><code class="literal">ToArray</code></p></li><li style="list-style-type: disc"><p><code class="literal">CopyTo</code></p></li><li style="list-style-type: disc"><p><code class="literal">Count</code></p></li><li style="list-style-type: disc"><p><code class="literal">IsEmpty</code></p></li><li style="list-style-type: disc"><p><code class="literal">GetKeys</code></p></li><li style="list-style-type: disc"><p><code class="literal">GetValues</code></p></li></ul></div><p>We remember that trying to work with multiple locks can easily lead to deadlocks in a concurrent program. Fortunately, the concurrent dictionary contains the <code class="literal">AcquireLocks</code> method that can safely acquire multiple locks always in the same order that prevents deadlocks. This method is used internally from the <code class="literal">AcquireAllLocks</code> method, which safely acquires all the locks in the dictionary.</p><p>Every operation listed previously uses the same algorithm; first, it calls <code class="literal">AcquireAllLocks</code> to prevent concurrent changes to the dictionary, then it modifies the <code class="literal">m_table</code> instance and changes the dictionary state. For example, here is how the <code class="literal">Count</code> property is implemented:</p><div class="informalexample"><pre class="programlisting">public int Count
{
    get
    {
        int count = 0;
 
        try
        {
            // Acquire all locks
            AcquireAllLocks();
 
            // Compute the count, we allow overflow
            for (int i = 0; i &lt; m_tables.m_countPerLock.Length; i++)
            {
                count += m_tables.m_countPerLock[i];
            }
 
        }
        finally
        {
            // Release locks that have been acquired earlier
            ReleaseLocks();
        }
 
        return count;
    }
}</pre></div></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec33"></a>Using the implementation details in practice</h3></div></div></div><p>Knowing the<a id="id270" class="indexterm"></a> principles of how the concurrent dictionary is implemented can help you in some practical situations.</p><p>A better understanding of concurrent dictionary constructor parameters, for example, <code class="literal">concurrencyLevel</code>, will help to tune up your data structure for the concrete task. On one hand, the more locks we create, the more threads can potentially work with the dictionary without locking, which is a good thing. On the other hand, creating more locks creates more performance overhead, and we cannot explicitly set a lock control or a bucket, so this can lead to decline of performance. Knowing these details will help us to study the program under a profiler to find the best solution for our concrete case.</p><p>Another important implementation aspect is the dictionary buckets containing singly-linked lists. Adding an element to such a list is an O(N) operation and this can be a problem when storing hundreds of thousands of small items in the dictionary.</p><p>Since the <code class="literal">Count</code>, <code class="literal">ToArray,</code> and <code class="literal">IsEmpty</code> operations require exclusive locking, in some cases using corresponding LINQ alternatives such as <code class="literal">Enumerable.Count()</code>, <code class="literal">Enumerable.ToArray(),</code> and <code class="literal">Enumerable.Any()</code> will be much more efficient in situations where the dictionary often gets concurrently updated.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec43"></a>ConcurrentBag&lt;T&gt;</h2></div></div><hr /></div><p><code class="literal">ConcurrentBag&lt;T&gt;</code> is one of the<a id="id271" class="indexterm"></a> simplest concurrent collections. It is intended to store any general-purpose data. The main feature of this collection is how it stores the data; the <code class="literal">Add</code> method appends an item to a doubly-linked list that is stored in the current thread's local storage. This makes the appending operation very efficient, since there is no contention. Getting an item from the collection with the <code class="literal">TryTake</code> or <code class="literal">TryPeek</code> methods is also quite efficient. First, we look for the item in the local list, but if it is empty, we look for items in other threads' local lists.</p><p>This approach is called <a id="id272" class="indexterm"></a>
<span class="strong"><strong>work stealing</strong></span> and works well when each thread contains more or less the same number of data and uses the same number of append and take operations.</p><p>Let's review an example of using the <code class="literal">ConcurrentBag&lt;T&gt; </code>data structure:</p><div class="informalexample"><pre class="programlisting">var bag = new ConcurrentBag&lt;string&gt;();
 
var task1 = Run(() =&gt;
{
    AddAndPrint(bag, "[T1]: Item 1");
    AddAndPrint(bag, "[T1]: Item 2");
    AddAndPrint(bag, "[T1]: Item 3");
 
    Thread.Sleep(2000);
    TakeAndPrint(bag);
    TakeAndPrint(bag);
}, threadName: "T1");
 
var task2 = Run(() =&gt;
{
    AddAndPrint(bag, "[T2]: Item 1");
    AddAndPrint(bag, "[T2]: Item 2");
    AddAndPrint(bag, "[T2]: Item 3");
 
    Thread.Sleep(1000);
    TakeAndPrint(bag);
    TakeAndPrint(bag);
    TakeAndPrint(bag);
    TakeAndPrint(bag);
}, threadName: "T2");
 
Task.WaitAll(task1, task2);</pre></div><p>The <code class="literal">AddAndPrint</code>, <code class="literal">TakeAndPrint</code> and <code class="literal">Run</code> methods help to create a thread with a given name and allows us to append and remove elements from the <code class="literal">ConcurrentBag&lt;T&gt;</code> object, while printing the element value to the console:</p><div class="informalexample"><pre class="programlisting">private static Task Run(Action action, string threadName)
{
    var tcs = new TaskCompletionSource&lt;object&gt;();
    var thread = new Thread(() =&gt;
    {
        action();
        tcs.SetResult(null);
    });
    thread.Name = threadName;
    thread.Start();
 
    return tcs.Task;
}
 
private static void AddAndPrint(ConcurrentBag&lt;string&gt; bag, 
    string value)
{
    Console.WriteLine("{0}: Add - {1}", 
        Thread.CurrentThread.Name, value);

    bag.Add(value);
}
 
private static void TakeAndPrint(ConcurrentBag&lt;string&gt; bag)
{
    string value;
    if (bag.TryTake(out value))
    {
        Console.WriteLine("{0}: Take - {1}", 
            Thread.CurrentThread.Name, value);
    }
}</pre></div><p>Here we created two tasks, and each task sets two elements to the queue. Then it waits for some time and<a id="id273" class="indexterm"></a> starts to process the appended elements. The inner storage structure of the <code class="literal">ConcurrentBag</code> object will look like this when the appending of the elements is finished:</p><div class="mediaobject"><img src="graphics/B04208_06_02.jpg" /></div><p><code class="literal">ConcurentBag&lt;T&gt;,</code> as we have already mentioned, contains several doubly-linked lists, one list for each thread. Adding an item leads to appending it to the end of the local list, but getting items<a id="id274" class="indexterm"></a>  from the concurrent bag is slightly more complicated:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>T2: Add - [T2]: Item 1</strong></span>
<span class="strong"><strong>T1: Add - [T1]: Item 1</strong></span>
<span class="strong"><strong>T2: Add - [T2]: Item 2</strong></span>
<span class="strong"><strong>T2: Add - [T2]: Item 3</strong></span>
<span class="strong"><strong>T1: Add - [T1]: Item 2</strong></span>
<span class="strong"><strong>T1: Add - [T1]: Item 3</strong></span>
<span class="strong"><strong>T2: Take - [T2]: Item 3</strong></span>
<span class="strong"><strong>T2: Take - [T2]: Item 2</strong></span>
<span class="strong"><strong>T2: Take - [T2]: Item 1</strong></span>
<span class="strong"><strong>T2: Take - [T1]: Item 1</strong></span>
<span class="strong"><strong>T1: Take - [T1]: Item 3</strong></span>
<span class="strong"><strong>T1: Take - [T1]: Item 2</strong></span>
</pre></div><p>We append items to the collection from two threads, and this explains an addition order that was demonstrated previously. The most interesting thing is how items are removed from <code class="literal">ConcurrentBag</code>. In our case, the second thread starts getting the items from the collection. First, it gets the elements that were added by this thread, but in the reverse order (from the end of the doubly-linked list). When the local list becomes empty, it tries to "steal" work from another thread, but this time it gets items from the beginning of the underlying list.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec34"></a>ConcurrentBag in practice</h3></div></div></div><p>The<a id="id275" class="indexterm"></a> implementation details of the <code class="literal">ConcurentBag&lt;T&gt; </code>data structure makes it useful only in very specific scenarios. Reading and writing objects has to happen on the same thread to minimize contention. It makes this collection not very useful in most common situations, since usually different threads append and read data from a collection.</p><p>A good practical scenario for <code class="literal">ConcurentBag&lt;T&gt; </code>is an object pool. It is usually implemented in a way that when some object, which is significantly expensive to create, does not get cleaned up by the garbage collector, it goes to some object storage and is easily accessed when needed. Since usually such operations happen on a single thread, this will make a perfect condition to use this kind of concurrent collection.</p><p>Another similar example is a thread pool implementation. If we look closely at the <code class="literal">DefaultTaskScheduler</code> implementation from Task Parallel Library, we can see that it has the same behavior as the concurrent bag. This task scheduler does not use a global task list; instead, it creates a number of local task lists for each worker thread. If some task creates a child task (without providing the <code class="literal">PreferFairness</code> option), it will be appended to the local task list. This helps to reduce contention and has a higher probability of finding the required data in the CPU cache. Also it uses work stealing in case the local task list is empty.</p><p>However, even if the concurrent bag perfectly fits in your scenario, it is a good idea to try to use other data structures and measure and compare the performance of each implementation. The synthetic tests (they can be found in the code samples of this chapter) show that the <code class="literal">ConcurrentBag&lt;T&gt;</code> performance is not impressive, and maybe choosing <code class="literal">ConcurrentQueue&lt;T&gt; </code>or <code class="literal">ConcurrentStack&lt;T&gt;</code> will be a better solution. Even in perfect conditions when the same thread appends and retrieves data, a concurrent bag is about three times slower than a concurrent queue.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec44"></a>ConcurrentQueue&lt;T&gt;</h2></div></div><hr /></div><p><code class="literal">ConcurrentQueue&lt;T&gt;</code> is a <a id="id276" class="indexterm"></a>concurrent version of the <code class="literal">Queue&lt;T&gt; </code>class. It contains three basic methods: <code class="literal">Enqueue</code> appends an item to the queue, <code class="literal">TryDequeue</code> retrieves an item from the queue if it is possible, and <code class="literal">TryPeek</code> gets the first element in the queue without removing it from the queue. The last two methods return false if the queue is empty.</p><p>Now let's see a sample code for <code class="literal">ConcurrentQueue&lt;T&gt;</code>:</p><div class="informalexample"><pre class="programlisting">var queue = new ConcurrentQueue&lt;string&gt;();
 
var task1 = Run(() =&gt;
{
    AddAndPrint(queue, "[T1]: Item 1");
    AddAndPrint(queue, "[T1]: Item 2");
    AddAndPrint(queue, "[T1]: Item 3");
 
    Thread.Sleep(2000);
    TakeAndPrint(queue);
    TakeAndPrint(queue);
}, threadName: "T1");
 
var task2 = Run(() =&gt;
{
    AddAndPrint(queue, "[T2]: Item 1");
    AddAndPrint(queue, "[T2]: Item 2");
    AddAndPrint(queue, "[T2]: Item 3");
 
    Thread.Sleep(1000);
    TakeAndPrint(queue);
    TakeAndPrint(queue);
    TakeAndPrint(queue);
    TakeAndPrint(queue);
}, threadName: "T2");
 
Task.WaitAll(task1, task2);</pre></div><p>In this example, we do the same with the <code class="literal">ConcurrentBag&lt;T&gt;</code> code. We create two named threads; each thread appends three items to the queue. Then after some pause, threads start to retrieve the elements from the queue:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>T1: Add - [T1]: Item 1</strong></span>
<span class="strong"><strong>T2: Add - [T2]: Item 1</strong></span>
<span class="strong"><strong>T2: Add - [T2]: Item 2</strong></span>
<span class="strong"><strong>T2: Add - [T2]: Item 3</strong></span>
<span class="strong"><strong>T1: Add - [T1]: Item 2</strong></span>
<span class="strong"><strong>T1: Add - [T1]: Item 3</strong></span>
<span class="strong"><strong>T2: Dequeue - [T1]: Item 1</strong></span>
<span class="strong"><strong>T2: Dequeue - [T2]: Item 1</strong></span>
<span class="strong"><strong>T2: Dequeue - [T2]: Item 2</strong></span>
<span class="strong"><strong>T2: Dequeue - [T2]: Item 3</strong></span>
<span class="strong"><strong>T1: Dequeue - [T1]: Item 2</strong></span>
<span class="strong"><strong>T1: Dequeue - [T1]: Item 3</strong></span>
</pre></div><p>Concurrent queue is a FIFO (First In, First Out) collection, but since this is a multithreaded environment, the order of appending and removing elements is not strictly sequential.</p><p>The <code class="literal">ConcurrentQueue&lt;T&gt;</code> class is implemented on a singly-linked list of ring buffers (or segments). This allows this collection to be lock-free that makes it very attractive to use this in high load concurrent applications.</p><p>In the beginning, a<a id="id277" class="indexterm"></a> concurrent queue creates one segment that is referenced by two inner fields: <code class="literal">m_head</code> and <code class="literal">m_tail</code> (the first and the last segments reference correspondingly). The segment size is 32 bytes, and each segment contains two references: <code class="literal">Low</code> and <code class="literal">High</code>. <code class="literal">Low</code> references an element position in the buffer that can be removed by calling the <code class="literal">Dequeue</code> method, and <code class="literal">High</code> references the last item in the buffer that has been added by<a id="id278" class="indexterm"></a> using the <code class="literal">Enqueue</code> method.</p><p>Here is how the queue will look internally after appending six elements and then removing two of them:</p><div class="mediaobject"><img src="graphics/B04208_06_03.jpg" /></div><p>If we find out during the process of appending an element to the queue that the segment is full, then one more segment is created and attached to the end of the segment list. Only the first and the last<a id="id279" class="indexterm"></a> segments can be partially full, every other segment must be completely full.</p><p>If we append 80 elements and then remove four, we will see something like this:</p><div class="mediaobject"><img src="graphics/B04208_06_04.jpg" /></div><p>The overall queue size will be <span class="emphasis"><em>32 – 4 + 32 + 16 = 76</em></span>. The queue will contain three segments, and the first and the last segments will be partially filled.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec45"></a>ConcurrentStack&lt;T&gt;</h2></div></div><hr /></div><p>The <code class="literal">ConcurrentStack&lt;T&gt;</code> data structure is <a id="id280" class="indexterm"></a>a concurrent version of a standard <code class="literal">Stack&lt;T&gt;</code> collection. It contains three main methods: <code class="literal">Push</code>, <code class="literal">TryPop,</code> and <code class="literal">TryPeek</code>, to append, retrieve and get the item from the collection by FILO (First In, Last Out) principle.</p><p><code class="literal">ConcurrentStack&lt;T&gt;</code> is implemented as a singly-linked lock-free list, which makes it less interesting in terms of reviewing the implementation details. Nevertheless, it is still useful to know, and if we have to choose a concurrent data structure for a scenario where elements processing order is not important, it is preferable to use a concurrent queue since it has less performance overhead. Appending elements to the concurrent stack always leads to additional memory allocation, which can be a significant drawback in certain scenarios.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec46"></a>The Producer/Consumer pattern</h2></div></div><hr /></div><p>The Producer/Consumer<a id="id281" class="indexterm"></a> pattern is one of the most widely used parallel programming patterns. The most natural approach is to organize your application for processing work items on another thread. In this case, we get two application parts—one puts new work to be processed and the other checks for new work and performs element processing. The standard .NET Framework thread pool is a good example; one thread puts a work item in a processing queue by calling the <code class="literal">Task.Run</code> function of the <code class="literal">ThreadPool.QueueUserWorkItem</code> methods, and the infrastructure finds other threads to process these tasks.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note23"></a>Note</h3><p>The other parallel programming patterns will be reviewed in the next chapter. The Producer/Consumer pattern is very tightly related to concurrent data structures, and it is more naturally described along with them.</p></div><p>Another classic example is a user interface programming. To create responsive and fast UI, a UI thread<a id="id282" class="indexterm"></a>  has to offload as much work as possible to other threads. Therefore, it posts tasks to a queue, and some background threads process these tasks and provide the result back to UI.</p><p>The same approach is used in server-side programming. To effectively process client requests, they are queued first, and only then does the server infrastructure assign a worker thread to process the user request.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec35"></a>Custom Producer/Consumer pattern implementation</h3></div></div></div><p>Let's try to<a id="id283" class="indexterm"></a> implement the Producer/Consumer pattern with the help of the standard <code class="literal">Queue&lt;T&gt;</code> class. Before we can get to the programming, we have to think about the requirements:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>What should a consumer do when calling the <code class="literal">Take </code>method while the current queue does not contain any elements?</p></li><li style="list-style-type: disc"><p>What should a producer do when calling the <code class="literal">Add</code> method as the collection size has reached some threshold value?</p></li></ul></div><p>If we look at the standard concurrent collections implementation, it makes sense to replace the <code class="literal">Take</code> method with <code class="literal">TryTake</code>, and this will return <span class="strong"><strong>false</strong></span> if the queue is empty. Instead of the <code class="literal">Add </code>method, we can implement <code class="literal">TryAdd</code> that will return <span class="strong"><strong>false</strong></span> when the queue is full. Unfortunately, it is not the best design for a Producer/Consumer queue.</p><p>A more natural approach would be to make the <code class="literal">Take</code> method block the current thread when the underlying queue is empty and return the result as soon as any producer thread adds an item to the queue; such a queue is called a<a id="id284" class="indexterm"></a> <span class="strong"><strong>blocking queue</strong></span>. The same with the <code class="literal">Add</code> method—just block when the queue is full and put an item as soon as there is a place for an item in the queue. This approach helps us to handle a situation when there are too many producers or they just create more items that consumers can handle. This kind of queue is called a <a id="id285" class="indexterm"></a>
<span class="strong"><strong>bounded queue</strong></span>.</p><p>A simple <code class="literal">BoundedBlockingQueue</code> implementation will look like this:</p><div class="informalexample"><pre class="programlisting">public class BoundedBlockingQueue&lt;T&gt;
{
    private readonly Queue&lt;T&gt; _queue = new Queue&lt;T&gt;(); 
        
    private readonly SemaphoreSlim _nonEmptyQueueSemaphore = 
        new SemaphoreSlim(0, int.MaxValue);
 
 
    private readonly SemaphoreSlim _nonFullQueueSemaphore;
 
    public BoundedBlockingQueue(int boundedCapacity)
    {
        _nonFullQueueSemaphore = new SemaphoreSlim(
            boundedCapacity);
    }
 
    public void Add(T value)
    {
        _nonFullQueueSemaphore.Wait();
 
        lock (_queue) _queue.Enqueue(value);
        _nonEmptyQueueSemaphore.Release();
    }
 
    public T Take()
    {
        _nonEmptyQueueSemaphore.Wait();
        T result;
        lock (_queue)
        {
            Debug.Assert(_queue.Count != 0);
            result = _queue.Dequeue();
        }
 
        _nonFullQueueSemaphore.Release();
        return result;
    }
}</pre></div><p>This implementation uses a simple queue and two semaphores—<code class="literal">_nonFullQueueSemaphore</code> and <code class="literal">_nonEmptyQueueSemaphore</code>. We use the first one to block producers when the queue is full; the second blocks consumers when the queue is empty. When<a id="id286" class="indexterm"></a>  the <code class="literal">Add</code> method is called; we call <code class="literal">Wait</code> on <code class="literal">_nonFullQueueSemaphore</code>. It will return control when the queue is not full, and then we can add another semaphore counter to unblock consumer threads. The <code class="literal">Take</code> method works exactly like this, but in a reverse order—we wait on the <code class="literal">_nonEmptyQueueSemaphore</code> semaphore until we have anything in the queue, and then we remove the appeared element from the queue and increase the other semaphore counter.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip04"></a>Tip</h3><p>In the production code, we will have to implement <code class="literal">IDisposable</code> to support deterministic resources releasing, proper exception handling, and cancellation policy by providing the <code class="literal">CancellationToken</code> instance to the <code class="literal">Add</code> and <code class="literal">Take</code> methods. However, in this example, it is not relevant to the topic and this logic is omitted to keep the remaining code clean and simple.</p></div><p>In some cases, the Producer/Consumer queue can be used to process a fixed (or at least a finite) number <a id="id287" class="indexterm"></a> of elements. In this case, we need to be able to notify the consumers that items appending is over:</p><div class="informalexample"><pre class="programlisting">public class BoundedBlockingQueue&lt;T&gt;
{
    private readonly Queue&lt;T&gt; _queue = new Queue&lt;T&gt;(); 
        
    private readonly SemaphoreSlim _nonEmptyQueueSemaphore = 
        new SemaphoreSlim(0, int.MaxValue);
 
    private readonly 
        CancellationTokenSource _consumersCancellationTokenSource =
            new CancellationTokenSource();
 
    private readonly SemaphoreSlim _nonFullQueueSemaphore;
 
    public BoundedBlockingQueue(int boundedCapacity)
    {
        _nonFullQueueSemaphore = new SemaphoreSlim(boundedCapacity);
    }
 
    public void CompleteAdding()
    {
        // Notify all the consumers that completion is finished
        _consumersCancellationTokenSource.Cancel();
    }
 
    public void Add(T value)
    {
        _nonFullQueueSemaphore.Wait();
 
        lock (_queue) _queue.Enqueue(value);
        _nonEmptyQueueSemaphore.Release();
    }
 
    public T Take()
    {
        T item;
        if (!TryTake(out item))
        {
            throw new InvalidOperationException();
        }
 
        return item;
    }
 
    public IEnumerable&lt;T&gt; Consume()
    {
        T element;
        
        while(TryTake(out element))
        {
            yield return element;
        }
    }
 
    private bool TryTake(out T result)
    {
        result = default(T);
 
        if (!_nonEmptyQueueSemaphore.Wait(0))
        {
            try
            {
                _nonEmptyQueueSemaphore.Wait(
                   _consumersCancellationTokenSource.Token);
            }
            catch (OperationCanceledException e)
            {
                // Breaking the loop only when cancellation 
                // was requested by CompleteAdding
                if (e.CancellationToken == 
                        _consumersCancellationTokenSource.Token)
                {
                    return false;
                }
 
                // Propagate original exception
                throw;
            }
        }
        
        lock (_queue)
        {
            result = _queue.Dequeue();
        }
 
        _nonFullQueueSemaphore.Release();
        return true;
    }
}</pre></div><p>Here we see new <code class="literal">CompleteAdding</code> and <code class="literal">Consume</code> methods. The first one is intended to be used from producer's code to signal that we have finished appending items to the queue. The <code class="literal">Consume</code> method can be used by consumers to process all the items until the queue is empty and item appending is complete.</p><p>We have also<a id="id288" class="indexterm"></a>  implemented a cooperative cancellation here with the help of the <code class="literal">CancellationTokenSource</code> and <code class="literal">CancellationToken</code> objects. The <code class="literal">CompleteAdding</code> method sets the flag that indicates that no additional elements will be added to the collection. The <code class="literal">TryTake</code> method uses this flag and standard semaphore cancellation logic to break the loop when cancellation is requested.</p><p>We can use our brand new collection in the following way:</p><div class="informalexample"><pre class="programlisting">var queue = new BoundedBlockingQueue&lt;string&gt;(3);
 
var t1 = Task.Run(() =&gt;
{
    AddAndPrint(queue, "1");
    AddAndPrint(queue, "2");
    AddAndPrint(queue, "3");
    AddAndPrint(queue, "4");
    AddAndPrint(queue, "5");
 
    queue.CompleteAdding();
    Console.WriteLine("[{0}]: finished producing elements",
        Thread.CurrentThread.ManagedThreadId);
 
});
 
var t2 = Task.Run(() =&gt;
{
    foreach (var element in queue.Consume())
    {
        Print(element);
    }
                
    Console.WriteLine("[{0}]: Processing finished.",
        Thread.CurrentThread.ManagedThreadId);
});
 
var t3 = Task.Run(() =&gt;
{
    foreach (var element in queue.Consume())
    {
        Print(element);
    }
                
    Console.WriteLine("[{0}]: Processing finished.",
        Thread.CurrentThread.ManagedThreadId);
});
 
Task.WaitAll(t1, t2, t3);</pre></div><p>In this code, we used <a id="id289" class="indexterm"></a> one producer thread that appends items to the queue, and two consumer threads. The result will be the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[4]: Added 1</strong></span>
<span class="strong"><strong>[9]: Took 1</strong></span>
<span class="strong"><strong>[8]: Took 2</strong></span>
<span class="strong"><strong>[4]: Added 2</strong></span>
<span class="strong"><strong>[4]: Added 3</strong></span>
<span class="strong"><strong>[4]: Added 4</strong></span>
<span class="strong"><strong>[4]: Added 5</strong></span>
<span class="strong"><strong>[9]: Took 3</strong></span>
<span class="strong"><strong>[9]: Took 5</strong></span>
<span class="strong"><strong>[4]: finished producing elements</strong></span>
<span class="strong"><strong>[8]: Took 4</strong></span>
<span class="strong"><strong>[9]: Processing finished.</strong></span>
<span class="strong"><strong>[8]: Processing finished.</strong></span>
</pre></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec47"></a>The Producer/Consumer pattern in .NET 4.0+</h2></div></div><hr /></div><p>Since .NET <a id="id290" class="indexterm"></a>Framework 4.0, there has been a<a id="id291" class="indexterm"></a> standard <code class="literal">BlockingCollection&lt;T&gt;</code> class, so we should prefer using this to create our own implementations such as <code class="literal">BoundedBlockingQueue&lt;T&gt;</code>. It contains all the required operations and allows us to choose different element storage strategies using different concurrent collections.</p><p>In spite of <code class="literal">BlockingCollection&lt;T&gt;</code> implementing the <code class="literal">ICollection&lt;T&gt;</code> interface, it is just a wrapper over any general concurrent collection that implements <code class="literal">IProducerConsumerCollection&lt;T&gt;</code>. The <code class="literal">Blocking</code> part of the collection name means that the <code class="literal">Take</code> method blocks until new elements appear in the collection. A more accurate name for this collection would be <code class="literal">BoundedBlockingProducerConsumer&lt;T&gt;</code>, since it also blocks the <a id="id292" class="indexterm"></a>
<code class="literal">Add</code> method when the maximum<a id="id293" class="indexterm"></a> underlying collection capacity is reached.</p><p>Let's use <code class="literal">BlockingCollection&lt;T&gt;</code> to create a custom Producer/Consumer implementation that allows us to create a specific number of consumer threads:</p><div class="informalexample"><pre class="programlisting">public class CustomProducerConsumer&lt;T&gt; : IDisposable
{
    private readonly Action&lt;T&gt; _consumeItem;
    private readonly BlockingCollection&lt;T&gt; _blockingCollection;
    private readonly Task[] _workers;
 
    public CustomProducerConsumer(Action&lt;T&gt; consumeItem, 
        int degreeOfParallelism, 
        int capacity = 1024)
    {
        _consumeItem = consumeItem;
            
        _blockingCollection = new BlockingCollection&lt;T&gt;(capacity);
            
        _workers = Enumerable.Range(1, degreeOfParallelism)
            .Select(_ =&gt; Task.Factory.StartNew(Worker, 
                 TaskCreationOptions.LongRunning))
            .ToArray();
    }
 
    public void Process(T item)
    {
        _blockingCollection.Add(item);
    }
 
    public void CompleteProcessing()
    {
        _blockingCollection.CompleteAdding();
    }
 
    public void Dispose()
    {
        // Unblock all workers even if the client
        // didn't call CompleteProcessing
        if (!_blockingCollection.IsAddingCompleted)
        {
            _blockingCollection.CompleteAdding();
        }
 
        Task.WaitAll(_workers);
 
        _blockingCollection.Dispose();
    }

    private void Worker()
    {
        foreach (var item in 
            _blockingCollection.GetConsumingEnumerable())
        {
            _consumeItem(item);
        }
    }</pre></div><p>The constructor of <code class="literal">CustomProducerConsumer&lt;T&gt;</code> accepts as a parameter an <code class="literal">Action&lt;T&gt;</code> delegate that represents the consumer, queue size, and required parallelism degree. Then, we create the<a id="id294" class="indexterm"></a> required number of worker threads by creating the <code class="literal">Task</code> objects with the <code class="literal">TaskCreationOptions.LongRunning</code> option. The process method is intended to append new elements, and the <code class="literal">CompleteProcessing</code> method signals that there will be no more elements<a id="id295" class="indexterm"></a> appended to the queue:</p><div class="informalexample"><pre class="programlisting">Action&lt;string&gt; processor = element =&gt;
{
    Console.WriteLine("[{0}]: Processing element '{1}'",
        Thread.CurrentThread.ManagedThreadId, element);
};
 
var producerConcumer = new CustomProducerConsumer&lt;string&gt;(
   processor, Environment.ProcessorCount);

for (int i = 0; i &lt; 5; i++)
{
    string item = "Item " + (i + 1);
    Console.WriteLine("[{0}]: Adding element '{1}'",
        Thread.CurrentThread.ManagedThreadId, item);
 
    producerConcumer.Process("Item " + (i + 1));
}
 
Console.WriteLine("[{0}]: Complete adding new elements",
    Thread.CurrentThread.ManagedThreadId);
 
producerConcumer.CompleteProcessing();

// Dispose will block till all operations gets completed
producerConcumer.Dispose();</pre></div><p>If we run this code, we will get the following result:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[5]: Adding element 'Item 1'</strong></span>
<span class="strong"><strong>[5]: Adding element 'Item 2'</strong></span>
<span class="strong"><strong>[5]: Adding element 'Item 3'</strong></span>
<span class="strong"><strong>[9]: Processing element 'Item 1'</strong></span>
<span class="strong"><strong>[8]: Processing element 'Item 2'</strong></span>
<span class="strong"><strong>[5]: Adding element 'Item 4'</strong></span>
<span class="strong"><strong>[5]: Adding element 'Item 5'</strong></span>
<span class="strong"><strong>[5]: Complete adding new elements</strong></span>
<span class="strong"><strong>[9]: Processing element 'Item 5'</strong></span>
<span class="strong"><strong>[10]: Processing element 'Item 3'</strong></span>
<span class="strong"><strong>[11]: Processing element 'Item 4'</strong></span>
</pre></div><p>The result shows<a id="id296" class="indexterm"></a> that there is one producer thread that appends elements to the collection, and four different<a id="id297" class="indexterm"></a> consumer threads that process these elements until the producer thread stops appending items.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec48"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we have learned about different concurrent data structures, their advantages and disadvantages, and we have understood that choosing an appropriate concurrent data structure is a complicated and responsible task. The right choice is defined by many criteria such as availability, complexity, resource consumption, versatility, performance, and many others.</p><p>Similar to software development, in general there is no single and proper universal solution appropriate for all usage scenarios. In some cases, it is better to use regular collections with exclusive locking. Some other cases will require developing our own specific concurrent data structures from scratch, since a universal standard collection will not fit in the high performance requirements. A rule of thumb is to try to implement the easiest solution and then measure the performance and check where the performance bottleneck of your application is.</p><p>In the next chapter, we will consider different concurrent and asynchronous programming patterns that can help in structuring your parallel program for simplicity and efficiency and allow you to quickly implement well-known concurrent algorithms.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch07"></a>Chapter 7. Leveraging Parallel Patterns</h2></div></div></div><p>There are many programming rules, tricks, and typical patterns related to concurrent programming that have been developed to address concrete problems that often happen in practice. In this chapter, we will go through several kinds of concurrent programming patterns—low-level patterns (concurrent idioms), .NET-specific patterns for asynchronous programming (Asynchronous Programming Patterns), and high-level concurrent application building blocks (Concurrent Design Patterns). Let's review them one by one.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec49"></a>Concurrent idioms</h2></div></div><hr /></div><p>The .NET Framework <a id="id298" class="indexterm"></a>platform contains some high-level components that make concurrent applications programming much easier. In <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Using Concurrent Data Structures</em></span>, we reviewed concurrent collections and data structures, and in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Task Parallel Library in Depth</em></span>, and <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>C# Language Support for Asynchrony</em></span>, we looked at Task Parallel Library and the C# language<a id="id299" class="indexterm"></a> <code class="literal">async/await</code> infrastructure.</p><p>Here, we will see how TPL and C# can improve your programming experience.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec36"></a>Process Tasks in Completion Order</h3></div></div></div><p>As an example task, let's consider <a id="id300" class="indexterm"></a>leveraging a weather information from a service for each provided city, processing the information, and printing it to the console. The simple implementation will be like this:</p><div class="informalexample"><pre class="programlisting">public async Task UpdateWeather()
{
  var cities = new List&lt;string&gt; { "Los Angeles", "Seattle", "New York" };

  var tasks =
    from city in cities
    select new { City = city, WeatherTask = GetWeatherForAsync(city) };

  foreach (var entry in tasks)
  {
    var weather = await entry.WeatherTask;

    ProcessWeather(entry.City, weather);
  }
}

private Task&lt;Weather&gt; GetWeatherForAsync(string city)
{
  Console.WriteLine("Getting the weather for '{0}'", city);

  return WeatherService.GetWeatherAsync(city);
}

private void ProcessWeather(string city, Weather weather)
{
  Console.WriteLine("[{2}]: Processing weather for '{0}': '{1}'",
    city, weather, DateTime.Now.ToLongTimeString());
}</pre></div><p>In this code, we used a <a id="id301" class="indexterm"></a>LINQ query to get the weather data for each city. The program will work well, but there is a problem in this code; we call the weather info service one by one and a new request gets issued only after the preceding request has been completed. We can use a workaround by calling the <code class="literal">ToList</code> method on the query, but we will get the results in their starting order and not by task completion.</p><p>The solution is to use the Process Tasks in Completion Order idiom. The implementation is based on the <code class="literal">Task.WhenAny</code> method:</p><div class="informalexample"><pre class="programlisting">var cities = new List&lt;string&gt; { "Los Angeles", "Seattle", "New York" };
var tasks = cities.Select(async city =&gt;
{
  return new {City = city, Weather = await GetWeatherForAsync(city)};
}).ToList();

while (tasks.Count != 0)
{
  var completedTask = await Task.WhenAny(tasks);

  tasks.Remove(completedTask);

  var result = completedTask.Result;

  ProcessWeather(result.City, result.Weather);
}</pre></div><p>Here, we called the <a id="id302" class="indexterm"></a>weather information service for all the cities in parallel, and then inside the <a id="id303" class="indexterm"></a>
<span class="strong"><strong>while</strong></span> loop we used the <code class="literal">Task.WhenAny</code> method to get the first completed task. The task gets processed and removed from the running task list. As required in this example, tasks are being processed in completion order.</p><p>However, the code looks more complicated than the first sample. To get the code structured, we can create a generic <code class="literal">OrderByCompletion</code> implementation for the tasks collection:</p><div class="informalexample"><pre class="programlisting">public static IEnumerable&lt;Task&lt;T&gt;&gt; OrderByCompletion&lt;T&gt;(
  this IEnumerable&lt;Task&lt;T&gt;&gt; taskSequence)
{
    var tasks = taskSequence.ToList();

    while (tasks.Count != 0)
    {
      var tcs = new TaskCompletionSource&lt;T&gt;();

      // Getting the first finished task
      Task.WhenAny(tasks).ContinueWith((Task&lt;Task&lt;T&gt;&gt; tsk) =&gt; {
        tasks.Remove(tsk.Result);

        tcs.FromTask(tsk.Result);
      });

      yield return tcs.Task;
  }
}</pre></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note24"></a>Note</h3><p>Nevertheless, this implementation has a serious pitfall. Since the <code class="literal">Task.WhenAny</code> method creates a continuation task for each running task and we are calling it inside the loop, we can conclude that this <code class="literal">OrderByCompletion</code> method implementation has a time complexity of <span class="emphasis"><em>O(n2)</em></span>. To improve the performance, we can register a continuation for each task that will use the <code class="literal">TaskCompletionSource</code> array to store each task's result.</p></div><p>It is very comfortable to use the newly implemented <code class="literal">OrderByCompletion</code> method:</p><div class="informalexample"><pre class="programlisting">var cities = new List&lt;string&gt; { "Los Angeles", "Seattle", "New York" };

var tasks = cities.Select(async city =&gt;
{
  return new {City = city, Weather = await GetWeatherForAsync(city)};
});

foreach (var task in tasks.OrderByCompletion())
{
  var taskResult = await task;

  // taskResult is an object of anonymous type with City and
  // WeatherTask
    ProcessWeather(taskResult.City, taskResult.Weather);
}</pre></div><p>Now it is <a id="id304" class="indexterm"></a>possible to use the plain old <code class="literal">foreach</code> loop<a id="id305" class="indexterm"></a> similarly to the first implementation, but the task processing happens by completion and not by start order. The results will demonstrate this processing behavior:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[12:54:35 PM]: Getting the weather for 'Los Angeles'</strong></span>
<span class="strong"><strong>[12:54:35 PM]: Getting the weather for 'Seattle'</strong></span>
<span class="strong"><strong>[12:54:35 PM]: Getting the weather for 'New York'</strong></span>
<span class="strong"><strong>[12:54:36 PM]: Processing weather for 'Seattle': 'Temp: 7C'</strong></span>
<span class="strong"><strong>Got the weather for 'Los Angeles'</strong></span>
<span class="strong"><strong>[12:54:39 PM]: Processing weather for 'Los Angeles': 'Temp: 6C'</strong></span>
<span class="strong"><strong>Got the weather for 'New York'</strong></span>
<span class="strong"><strong>[12:54:40 PM]: Processing weather for 'New York': 'Temp: 8C'</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec37"></a>Limiting the parallelism degree</h3></div></div></div><p>To use computer <a id="id306" class="indexterm"></a>resources effectively, we need to be able to specify the number of simultaneously running operations. Besides this, the optimal parallel operations number is related to their nature. If these operations are long-running and CPU-bound, it makes sense to use the number of hardware-supported threads to limit the parallelism degree.</p><p>However, if they are IO-bound, there is no clear limit. It depends on many factors related to the kind of IO that is happening and the corresponding hardware characteristics. It may be HDD random read speed, or network throughput and latency, or in the case of remote service calls, the performance of this service, and so on. Creating a general solution in this case is very hard and can be more complicated than creating our own implementation of a thread pool, which does the same for CPU-bound tasks.</p><p>However, for starters, we can just run multiple parallel operations and limit the parallelism degree with a certain number. Let's pretend that we did experiments with our weather info service and found out by measurements that the most effective option is to run only two simultaneous requests to this service.</p><p>One of the ways of implementing such a limit is by creating a <code class="literal">ForEachAsync</code> extension method that accept a <code class="literal">degreeOfParallelism</code> parameter:</p><div class="informalexample"><pre class="programlisting">public static IEnumerable&lt;Task&lt;TTask&gt;&gt;
  ForEachAsync&lt;TItem, TTask&gt;(
    this IEnumerable&lt;TItem&gt; source,
    Func&lt;TItem, Task&lt;TTask&gt;&gt; selector,
    int degreeOfParallelism)
    {

    // We need to know all the items in the source
    // before starting tasks
    var tasks = source.ToList();

    int completedTask = -1;

    // Creating an array of TaskCompletionSource that would hold
    // the results for each operations
    var taskCompletions = new TaskCompletionSource&lt;TTask&gt;[tasks.Count];

    for(int n = 0; n &lt; taskCompletions.Length; n++)
        taskCompletions[n] = new TaskCompletionSource&lt;TTask&gt;();

    // Partitioner would do all grunt work for us and split
    // the source into appropriate number of chunks
    // for parallel processing
    foreach (var partition in Partitioner.Create(tasks).
        GetPartitions(degreeOfParallelism)) {
        var p = partition;

        // Loosing sync context and starting asynchronous
        // computation for each partition
    Task.Run(async () =&gt;
    {
      while (p.MoveNext())
      {
            var task = selector(p.Current);

            // Don't want to use empty catch .
            // This trick just swallows an exception
            await task.ContinueWith(_ =&gt; { });

            int finishedTaskIndex = Interlocked.Increment(
              ref completedTask);

              taskCompletions[finishedTaskIndex]
             .FromTask(task);
      }
    });
  }

  return taskCompletions.Select(tcs =&gt; tcs.Task);
}</pre></div><p>There are <a id="id307" class="indexterm"></a>several options that we can choose to implement a limit on the degree of parallelism. For example, we can use semaphores or other synchronization primitives. However, we can choose more comfortable options to use Task Parallel Library and its <code class="literal">Partitioner</code> type to get a set of partitions with the <code class="literal">Partitioner.CreatePartitioner</code> method call. Each of these partitions represents something like an iterator that can be used in parallel with other partitions. To store the completed tasks, we will use an array of <code class="literal">TaskCompletionSource</code> objects, which will hold the results in completion order.</p><p>The way of using this method is shown in the following example:</p><div class="informalexample"><pre class="programlisting">var cities = new List&lt;string&gt; { "Los Angeles", "Seattle", "New York", "San Francisco" };

var tasks = cities.ForEachAsync(async city =&gt;
{
  return new { City = city, Weather = await GetWeatherForAsync(city) };
}, 2);

foreach (var task in tasks)
{
  var taskResult = await task;

  ProcessWeather(taskResult.City, taskResult.Weather);
}</pre></div><p>These are the results:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[1:22:09 PM]: Getting the weather for 'Los Angeles'</strong></span>
<span class="strong"><strong>[1:22:09 PM]: Getting the weather for 'Seattle'</strong></span>
</pre></div><p>Here the parallelism limit started to work. We will not run more tasks until one of them is completed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[1:22:10 PM]: Processing weather for 'Los Angeles': 'Temp: 6C'</strong></span>
</pre></div><p>The first task has finished; now we can run one more task:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[1:22:10 PM]: Getting the weather for 'New York'</strong></span>
</pre></div><p>This task is completed at once:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[1:22:15 PM]: Processing weather for 'New York': 'Temp: 8C'</strong></span>
</pre></div><p>Here, we run one more task:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[1:22:15 PM]: Getting the weather for 'San Francisco'</strong></span>
</pre></div><p>Now the second task is completed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[1:22:16 PM]: Processing weather for 'Seattle': 'Temp: 7C'</strong></span>
</pre></div><p>Here goes the last task:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[1:22:20 PM]: Processing weather for 'San Francisco': 'Temp: 4C'</strong></span>
</pre></div><p>This is the illustration of the previous process:</p><div class="mediaobject"><img src="graphics/4208_07_01.jpg" /></div><p>Here we have <a id="id308" class="indexterm"></a>two partitions; each of these runs a set of tasks. The second partition is able to run only one task, because it runs for a long time. The first partition managed to run three tasks. The number of partitions limits the degree of parallelism.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec38"></a>Setting a task timeout</h3></div></div></div><p>Operation cancellation <a id="id309" class="indexterm"></a>support is built into the Task Parallel Library; many .NET Framework classes, as well as third-party code, support it and allow us to provide a cancellation mechanism in case an operation timeout happens. Some of these classes make programming easier and allow you to provide just a timeout value for the operation.</p><p>However, not all code has this potential. Besides this, we often operate with a task that has been already started and we cannot configure the timeout value in the operation. It is a very common problem and there is a solution for this:</p><div class="informalexample"><pre class="programlisting">public static async Task&lt;T&gt; WithTimeout&lt;T&gt;(this Task&lt;T&gt; task,
  TimeSpan timeout)
  {
  // Cover two corner cases: when task is completed and when
  // timeout is infinite
if (task.IsCompleted || timeout == Timeout.InfiniteTimeSpan)
{
    return await task;
  }

  var cts = new CancellationTokenSource();

  if (await Task.WhenAny(task, Task.Delay(timeout, cts.Token)) == task)
  {
    cts.Cancel();
    return await task;
  }

  // Observe potential exception from the original task
  task.ContinueWith(_ =&gt; { }, TaskContinuationOptions.ExecuteSynchronously);

  throw new TimeoutException();
}</pre></div><p>Now we can use the <code class="literal">WithTimeout</code> method on any task to set the timeout value for the operation. We can use this method like this:</p><div class="informalexample"><pre class="programlisting">try
{
  Weather weather = await
    WeatherService.GetWeatherAsync("New York").
    WithTimeout(TimeSpan.FromSeconds(2));

  ProcessWeather(weather);
}
catch (TimeoutException)
{
  Console.WriteLine("Task was timed out!");
}</pre></div><p>The <a id="id310" class="indexterm"></a>implementation looks simple, but there are a couple of important nuances:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>In the beginning, we check for situations where the task has been completed already, or we have an infinite timeout value. In this case, it is enough to use the C# <span class="strong"><strong>await</strong></span> statement<a id="id311" class="indexterm"></a> to get the task result in a safe manner.</p></li><li style="list-style-type: disc"><p>If the task completes before the timeout, we cancel the corresponding <code class="literal">Task.Delay</code> timer task. This looks like a slight optimization, but it can have a noticeable impact on the application performance.</p></li><li style="list-style-type: disc"><p>We try to observe the provided task exception, which is a very important thing to do. If we do not do so, we could easily cause <code class="literal">TaskScheduler.TaskUnobservedException</code> to be raised. In .NET 4.5+, it will not ruin your application at once, but it should be avoided anyway.</p></li></ul></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec50"></a>Asynchronous patterns</h2></div></div><hr /></div><p>Since releasing the first<a id="id312" class="indexterm"></a> version of C# and the .NET Framework, there has been built-in support for running asynchronous operations. Unfortunately, this infrastructure was quite complicated and hard to use, and this caused the next platform versions to include new ways (patterns) of writing asynchronous code that enhanced asynchronous programming experience.</p><p>Here, we will review three asynchronous programming patterns starting from the oldest:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>APM</strong></span>: Asynchronous Programming Model (introduced in the .NET Framework 1.0)</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>EAP</strong></span>: Event-Based Asynchronous Pattern (released with the .NET Framework 2.0)</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>TAP</strong></span>: Task-Based Asynchronous Pattern (appeared with the .NET Framework 4.0)</p></li></ul></div><p>The first two patterns are usually considered as legacy code and should be used only in support scenarios where there is no possibility to use the task infrastructure from Task Parallel Library.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec39"></a>Asynchronous Programming Model</h3></div></div></div><p>The <span class="strong"><strong>Asynchronous Programming Model</strong></span> (<span class="strong"><strong>APM</strong></span>)<a id="id313" class="indexterm"></a> structure is <a id="id314" class="indexterm"></a>as follows:</p><div class="informalexample"><pre class="programlisting">// Synchronous operation
public Result Operation(int input, ref int inOut, out int output);

// First method that denotes beginning of the asynchronous
//operation
public IAsyncResult BeginOperation(int input, ref int inOut, out int output, AsyncCallback callback, object state);

// Second method that should be called when the operation is
//completed
public Result EndOperation(ref int inOut, out int output, IAsyncResult asyncResult);</pre></div><p>This pattern is structured in the following way: an asynchronous operation splits into two methods—<code class="literal">BeginOperationName</code>/<code class="literal">EndOperationName</code>, where the <code class="literal">OperationName</code> part is an actual name of this operation. The <code class="literal">BeginOperationName</code> method accepts input parameters, starts an asynchronous operation, and returns some kind of operation state that is represented by an object implementing <code class="literal">IAsyncResult</code> interface. Usually, it also accepts an additional operation context—the <code class="literal">state</code> parameter, and a callback that will be called when the operation completes.</p><p>To get the operation result and operation exception handling, we need to call the <code class="literal">EndOperationName</code> method. If the operation is already complete, this method will immediately return the result or throw an exception. If the operation is still running, this method call will be blocked until the operation completes.</p><p><code class="literal">IAsyncResult</code> provides a <code class="literal">WaitHandle</code> instance that can be used to determine whether the operation has been completed, or whether the operation has completed synchronously.</p><p>As an example of using the APM pattern, let's implement the weather information service call and explain the code step by step:</p><div class="informalexample"><pre class="programlisting">public class WeatherService
{
  private readonly Func&lt;string, Weather&gt; _getWeatherFunc;
  public WeatherService()
  {
    _getWeatherFunc = GetWeather;
   }
  public Weather GetWeather(string city)
  {
    // Original synchronous implementation
  }

  public IAsyncResult BeginGetWeather(string city, AsyncCallback callback, object state) {
    return _getWeatherFunc.BeginInvoke(city, callback, state);
  }

  public Weather EndGetWeather(IAsyncResult asyncResult)
  {
    return _getWeatherFunc.EndInvoke(asyncResult);
  }
}</pre></div><p>Here, in this <a id="id315" class="indexterm"></a>example, we simulated an <a id="id316" class="indexterm"></a>asynchronous operation with an asynchronous delegate invocation. The real APM implementation including remote service call details is too complicated, and it does not make sense to illustrate the APM pattern.</p><p>Then, we will write a client with APM:</p><div class="informalexample"><pre class="programlisting">var weatherServce = new WeatherService();

// Pseudo asynchronous call
string newYork = "New York";
IAsyncResult ar1 = weatherServce.BeginGetWeather(newYork, callback: null, state: null);

ar1.AsyncWaitHandle.WaitOne();
Weather weather1 = weatherServce.EndGetWeather(ar1);
ProcessWeather(newYork, weather1);

// Real asynchronous version
string seattle = "Seattle";
weatherServce.BeginGetWeather(seattle, callback: (IAsyncResult asyncResult) =&gt;
  {
    var context = (Tuple&lt;string, WeatherService&gt;)asyncResult.AsyncState;

    try
    {
      Weather weather = context.Item2.EndGetWeather(asyncResult);
      ProcessWeather(context.Item1, weather);
    }
        catch (Exception e)
    {
      HandleWeatherError(e);
    }
  },
  state: Tuple.Create(seattle, weatherServce));</pre></div><p>The first piece of code shows how we can call an asynchronous operation in the APM paradigm. We started with the <code class="literal">BeginGetWeather</code> method call, then immediately called <code class="literal">ar1.WaitHandle.WaitOne</code>. We can simply call <code class="literal">weatherService.EndGetWeather </code>instead and get the same result.</p><p>Then we used a<a id="id317" class="indexterm"></a> real asynchronous <a id="id318" class="indexterm"></a>operation call. We have used both the last input parameters of the <code class="literal">BeginGetWeather</code> method—<code class="literal">callback</code> and <code class="literal">state</code>. Notice that there is no context capture—the context gets into asynchronous operation through a <code class="literal">state</code> parameter.</p><p>The APM pattern has the following <a id="id319" class="indexterm"></a>features:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>Low-level pattern</strong></span>: This was <a id="id320" class="indexterm"></a>introduced in the first .NET Framework version and is used for many asynchronous operations in the Base Class Library.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Low performance overhead</strong></span>: The <a id="id321" class="indexterm"></a>callback method is called on the same thread where the asynchronous operation completed. No additional operations for synchronization context capturing occurs.</p><p>Besides, it is <a id="id322" class="indexterm"></a>very hard to combine several asynchronous operations, so one depends on another.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Coupling between the asynchronous operation provider and its consumers</strong></span>: Asynchronous <a id="id323" class="indexterm"></a>operation is not a first<a id="id324" class="indexterm"></a>-class object. It is not possible to initiate the operation, then to pass it somehow to the other code and handle it there. A class that provides an asynchronous operation and its client classes have a tight connection. This, as well, makes unit testing for such operations very hard, since it is very hard to create a mock asynchronous operation.</p></li></ul></div><p>The APM can be<a id="id325" class="indexterm"></a> used in the following<a id="id326" class="indexterm"></a> scenario—<span class="strong"><strong>only for legacy code support</strong></span>. Task-based asynchronous patterns can do everything APM can do. Also they have a low performance overhead, but are modern and easy to use—especially with the C# <a id="id327" class="indexterm"></a>
<span class="strong"><strong>async</strong></span>/<span class="strong"><strong>await</strong></span> statements.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec40"></a>Event-based Asynchronous Pattern</h3></div></div></div><p>An <a id="id328" class="indexterm"></a>
<span class="strong"><strong>Event-based Asynchronous Pattern</strong></span> (<span class="strong"><strong>EAP</strong></span>)<a id="id329" class="indexterm"></a> structure is as follows:</p><div class="informalexample"><pre class="programlisting">// Synchronous operation
public Result Operation(int input, ref int inOut, out int output);

// Raised when the Operation finished (successfuly, with exception or was cannelled)
public event EventHandler&lt;OperationCompletedEventArgs&gt; OperationCompleted;

// Report execution progress
public event EventHandler&lt;ProgressChangedEventArgs&gt; OperationProgressChanged;

// Method that starts asynchronous execution
public void OperationAsync(int input, ref int inOut);

// Method that starts asynchronous execution and gets additional user defined state
public void OperationAsync(int input, ref int inOut, object userState);

// Cancel pending operation
public void CancelAsync(object state);

public class OperationCompletedEventArgs: AsyncCompletedEventArgs
{
    public OperationCompletedEventArgs(
        Exception error, bool cancelled, object userState)
        : base(error, cancelled, userState)
    {
    }

    public Result Result { get; internal set; }
    public int InOut { get; internal set; }
    public int Output { get; internal set; }
}</pre></div><p>EAP was implemented in .NET Framework 2.0 and was designed to be used in application UI components. Most of the .NET types that implement this pattern inherit the <code class="literal">System.ComponentModel.Component</code> class as well and can be easily used with Windows Forms or WPF design-time editor.</p><p>The main idea behind EAP is to use events for notification about asynchronous operation completion. We start the operation with the <code class="literal">OperationNameAsync</code> method, and the completion event name is usually <code class="literal">OperationNameCompleted</code>. Besides this, there are other events, for example the <code class="literal">OperationProgressChanged</code> event that allows us to track the operation's execution progress.</p><p>An important feature of this pattern is that these events use the same synchronization context where the asynchronous operation has been started. If we use the UI thread to run this operation, then it is possible to use UI controls from the event handlers method of the component that implements EAP, which makes the code clean and comfortable to write.</p><p>Let's implement a <a id="id330" class="indexterm"></a>weather information <a id="id331" class="indexterm"></a>service with EAP:</p><div class="informalexample"><pre class="programlisting">public class WeatherService
{
  private bool _isOperationRunning = false;
  private readonly SendOrPostCallback _operationFinished;

  public WeatherService()
  {
    // This delegate should be called 
    // in captured sync context
    _operationFinished = ProcessOperationFinished;
  }

  public Weather GetWeather(string city)
  {
    // Original synchronous implementation
  }

  public event EventHandler&lt;GetWeatherCompletedEventArgs&gt; 
    GetWeatherCompleted;

  public void GetWeatherAsync(string city, object userState)
  {
    if (_isOperationRunning)
      throw new InvalidOperationException();

   _isOperationRunning = true;
   AsyncOperation operation = AsyncOperationManager
    .CreateOperation(userState);

    // Running GetWeather asynchronously
    ThreadPool.QueueUserWorkItem(state =&gt;
    {
      GetWeatherCompletedEventArgs args = null;
      try
      {
        var weather = GetWeather(city);
        args = new GetWeatherCompletedEventArgs(weather, state);
      }
      catch (Exception e)
      {
          args = new GetWeatherCompletedEventArgs(e, state);
        }

        // Using AsyncOperation that will marshal control
        // flow to the synchronization context that was
        // captured at the beginning of this method.

        operation.PostOperationCompleted(_operationFinished, args);

      }, userState);
  }

  private void ProcessOperationFinished(object state)
  {
    // Mark that current operation is completed
    _isOperationRunning = false;

    var args = (GetWeatherCompletedEventArgs)state;

    var handler = GetWeatherCompleted;
      if (handler != null)
        handler(this, args);
  }
}</pre></div><p>The<code class="literal"> GetWeatherAsync</code> method contains the main pattern logic. First, we created the <code class="literal">AsyncOperation</code> object, where we captured the current synchronization context with <code class="literal">SynchronizationContext.Current</code>. Then, we used the <code class="literal">ThreadPool.QueueUserWorkItem</code> method to run the <code class="literal">GetWeather</code> operation asynchronously on a<a id="id332" class="indexterm"></a> thread pool. Then we used <code class="literal">operation.PostOperationCompleted</code> to post a notification about operation completion<a id="id333" class="indexterm"></a> on the captured synchronization context. This will allow event subscribers to handle the <code class="literal">GetWeatherCompleted</code> event safely and will make it possible to use UI controls without using the <code class="literal">Control.Invoke</code> and <code class="literal">Dispatcher.BeginInvoke</code> mechanics.</p><p>Now let's look at how to use the service with EAP:</p><div class="informalexample"><pre class="programlisting">var weatherService = new WeatherService();
var city = "New York";

// Start asynchronous operation
weatherService.GetWeatherAsync(city, userState: null);

// If current method is running in UI thread
// following event handler would be executed in the UI thread
weatherService.GetWeatherCompleted += (sender, args) =&gt; {
  Weather result = args.Result;
  ProcessWeather(city, result);
};</pre></div><p>The EAP<a id="id334" class="indexterm"></a> features are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>High-level pattern</strong></span>: EAP<a id="id335" class="indexterm"></a> allows us to consume asynchronous operations with ease as well as start new ones</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>High overhead</strong></span>: Since<a id="id336" class="indexterm"></a> operation completion events always get posted to the captured synchronization context, this pattern is not intended to be used from low-level components that do intensive IO operations</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Intended for UI components</strong></span>: Since <a id="id337" class="indexterm"></a>EAP was designed for a very specific scenario (UI components), it might not be the best choice to program some other features</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Complicated implementation</strong></span>: While this is definitely easier than APM, it is still hard to program <a id="id338" class="indexterm"></a>real-world scenarios with operation progress and cancellation</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Coupling between asynchronous operation provider and its consumers</strong></span>: Similar to the <a id="id339" class="indexterm"></a>previous pattern, this one also creates tight coupling between the operation class and client classes</p></li></ul></div><p>EAP can used in the<a id="id340" class="indexterm"></a> following<a id="id341" class="indexterm"></a> scenario—<span class="strong"><strong>legacy code support</strong></span>. Nevertheless, if you write a new code you should not <a id="id342" class="indexterm"></a>use EAP. Task-based async pattern has everything that EAP has, but it also has language level support, loose coupling, and a lot of other useful features.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec41"></a>Task-based Asynchronous Pattern</h3></div></div></div><p>Task Parallel Library<a id="id343" class="indexterm"></a> has been existing since the .NET <a id="id344" class="indexterm"></a>Framework 4.0 release, and it introduced a new asynchronous programming pattern—<span class="strong"><strong>Task-based Asynchronous Pattern</strong></span> (<span class="strong"><strong>TAP</strong></span>). This pattern consists of the following methods:</p><div class="informalexample"><pre class="programlisting">// Synchronous operation
public Result Operation(int input, ref int inOut, out int output);

// Asynchronous version
public Task&lt;WrappedResult&gt; OperationAsync(int input, int inOut);

// Custom result that wraps in/out and out parameters
public class WrappedResult
{
  public Result Result { get; internal set; }
  public int InOut { get; internal set; }
  public int Output { get; internal set; }
}</pre></div><p>Similar to EAP, TAP uses the same naming scheme. Operations are named <code class="literal">OperationNameAsync</code> by adding the <code class="literal">Async</code> suffix to the synchronous implementation name. However, the main idea behind TAP is to use a special <code class="literal">Task</code> object that represents an asynchronous operation without any return value, and <code class="literal">Task&lt;T&gt;</code> for those that return results of the <code class="literal">T</code> type. Since we can access the result only through the Task.Result property, every input and output parameter must be a part of the return value.</p><p>The following is one more weather information service implementation:</p><div class="informalexample"><pre class="programlisting">public class WeatherService
{
  public Weather GetWeather(string city)
  {
    // Original synchronous implementation
  }
  public Task&lt;Weather&gt; GetWeatherAsync(string city)
  {
    return Task.Run(() =&gt; GetWeather(city));
  }
}</pre></div><p>The easiest implementation that seems to be obvious is to wrap a synchronous method into a task with the help of the <code class="literal">Task.Run </code>method. However, this approach should not be used in real-world applications, unless you are completely sure about what is going on.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note25"></a>Note</h3><p>This antipattern is called "async over sync" and using this will lead to scalability and performance problems in your application. Most of the truly asynchronous operations in the .NET Framework are IO-bound, and thus do not require using additional threads. This topic will be reviewed in detail in <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Server-Side Asynchrony</em></span>.</p></div><p>Let's look at the <a id="id345" class="indexterm"></a>following code:</p><div class="informalexample"><pre class="programlisting">public async Task ProcessWeatherFromWeatherService()
{
  var weatherService = new WeatherService();
  string city = "San Francisco";

  // If this method was called in the UI thread,
  // "awaiter" will capture synchronization context
  // and ProcessWeather method would be called in the UI thread as
  // well

  Weather weather = await weatherService.GetWeatherAsync(city);
  ProcessWeather(city, weather);
}</pre></div><p>Task-based <a id="id346" class="indexterm"></a>Asynchronous Pattern is now the most popular and most convenient way to develop asynchronous applications. It can be characterized by the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>Low overhead</strong></span>: Tasks <a id="id347" class="indexterm"></a>have low overhead and can be used in high-load scenarios.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>High-level</strong></span>: Task is a <a id="id348" class="indexterm"></a>high level abstraction that provides a convenient API to combine asynchronous operations, to capture or not capture the current synchronization context if needed, convert older APM and EAP patterns to TAP, and many other features.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Comfortable to use</strong></span>: This <a id="id349" class="indexterm"></a>pattern is easy to use by developers, but at the same time, it has a rich API and more features than the previous two.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Language support in C#/VB</strong></span>: C#<a id="id350" class="indexterm"></a> and VB.NET has built-in <span class="strong"><strong>async</strong></span>/<span class="strong"><strong>await</strong></span> statements that make asynchronous programming much easier. This infrastructure is based on the <code class="literal">Task</code> and <code class="literal">Task&lt;T&gt;</code> types.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note26"></a>Note</h3><p>As we saw in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>C# Language Support for Asynchrony</em></span>, <span class="strong"><strong>await</strong></span> can be used with any type that has its own method or an extension method called <code class="literal">GetAwaiter</code> without parameters, which returns the object that implements the <code class="literal">INotifyCompletion</code> interface and contains the <code class="literal">IsCompleted</code> Boolean property and the <code class="literal">GetResult</code> method with no parameters.</p></div></li><li style="list-style-type: disc"><p><span class="strong"><strong>Task and Task&lt;T&gt; are first-class objects</strong></span>: Unlike<a id="id351" class="indexterm"></a> previous patterns, a task instance is self-sufficient. It can be passed as a parameter to other methods or can be stored <a id="id352" class="indexterm"></a>in a variable<a id="id353" class="indexterm"></a> or instance field. If you have access to the task instance, you will have full control over the corresponding asynchronous operation. We do not need to use the asynchronous operation class a second time to finish the operation. We can test such operations and return an already completed task from a mock method.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Getting rid of side effects</strong></span>: Using <a id="id354" class="indexterm"></a>the <code class="literal">Task&lt;T&gt;</code> class encourages the avoidance of side effects in the program, which is very important to reduce contention and improve scalability.</p></li></ul></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec51"></a>Concurrent patterns</h2></div></div><hr /></div><p>We have already reviewed <a id="id355" class="indexterm"></a>some of these patterns earlier in this book. For example, in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Task Parallel Library in Depth</em></span>, we studied <code class="literal">Parallel.Invoke</code> and <code class="literal">Parallel.Foreach,</code> which actually is an implementation of the <a id="id356" class="indexterm"></a>
<span class="strong"><strong>fork/join</strong></span> pattern. In <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Using Concurrent Data Structures</em></span>, we reviewed a<a id="id357" class="indexterm"></a> <span class="strong"><strong>Producer/Consumer</strong></span> pattern implementation. However, there is a very important scenario that we have not seen yet. It is called a <a id="id358" class="indexterm"></a>
<span class="strong"><strong>parallel pipeline</strong></span>.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec42"></a>Parallel pipelines</h3></div></div></div><p>Usually a complex parallel computation can be considered as several stages combined into some sort of a pipeline. The latter stage needs the results of the former, and this prevents these stages from running in parallel. However, the calculations inside each stage can be independent, which allows us to parallelize each stage itself. Besides this, we can simultaneously run all the stages, assuming that we can process stage results one by one, so we do not have to wait until each stage computes all the results before proceeding to the next stage. Instead of this, we get an item from a previous stage as soon as it is ready and pass it along to the next stage, and so on and so forth, until the final stage. This way of organizing parallel computations is known as <span class="strong"><strong>parallel pipeline</strong></span>, which is a special case of a Producer/Consumer pattern. It allows us to achieve almost parallel processing of stage computations, shifted by the time that is required to get the first stage result.</p><p>The following code shows how to implement a <span class="strong"><strong>parallel pipeline</strong></span><a id="id359" class="indexterm"></a> using a standard <code class="literal">BlockingCollection</code> data structure:</p><div class="informalexample"><pre class="programlisting">private const int ParallelismDegree = 4;
private const int Count = 1;

static void Main(string[] args){
  var cts = new CancellationTokenSource();

  Task.Run(() =&gt; {
    if (Console.ReadKey().KeyChar == 'c') {
      cts.Cancel();
    }
  });

  var sourceArrays = new BlockingCollection&lt;string&gt;[ParallelismDegree];
  for (int i = 0; i &lt; sourceArrays.Length; i++) {
    sourceArrays[i] = new BlockingCollection&lt;string&gt;(Count);
  }

  var getWeatherStep = new PipelineWorkerAsync&lt;string, Weather&gt; (
    sourceArrays,
    city =&gt; WeatherService.GetWeatherAsync(city),
    cts.Token,
    "Get Weather",
    Count
  );

  var convertTempStep = new PipelineWorkerAsync&lt;Weather, Tuple&lt;string, decimal&gt;&gt; (
    getWeatherStep.Output,
    weather =&gt; Task.FromResult(Tuple.Create(weather.City, weather.TemperatureCelcius * (decimal)9/5 + 32)),
    cts.Token,
    "Convert Temperature",
    Count
  );

  var printInfoStep = new PipelineWorkerAsync&lt;Tuple&lt;string, decimal&gt;, string&gt; (
    convertTempStep.Output,
    t =&gt; Console.WriteLine("The temperature in {0} is {1}F on thread id {2}", t.Item1, t.Item2, Thread.CurrentThread.ManagedThreadId),
        cts.Token,
        "Print Information"
    );

  try {
    Parallel.Invoke(
      () =&gt; {
        Parallel.ForEach(
          new[] {"Seattle", "New York", "Los Angeles", "San Francisco"},
            (city, state) =&gt; {
              if (cts.Token.IsCancellationRequested) {
                state.Stop();
              }

              AddCityToSourceCollection(sourceArrays, city, cts.Token);
            });
            foreach (var arr in sourceArrays) {
              arr.CompleteAdding();
            }
          },
        () =&gt; getWeatherStep.RunAsync().GetAwaiter().GetResult(),
        () =&gt; convertTempStep.RunAsync().GetAwaiter().GetResult(),
        () =&gt; printInfoStep.RunAsync().GetAwaiter().GetResult()
      );
  }
  catch (AggregateException ae) {
    foreach (var ex in ae.InnerExceptions)
      Console.WriteLine(ex.Message + ex.StackTrace);
  }

  if (cts.Token.IsCancellationRequested) {
    Console.WriteLine("Operation has been canceled! Press ENTER to exit.");
  }
  else {
    Console.WriteLine("Press ENTER to exit.");
  }
  Console.ReadLine();
}

static void AddCityToSourceCollection
  BlockingCollection&lt;string&gt;[] cities, string city,
  CancellationToken token) {
    BlockingCollection&lt;string&gt;.TryAddToAny(cities, city, 50, token);
  Console.WriteLine("Added {0} to fetch weather on thread id {1}", city, Thread.CurrentThread.ManagedThreadId);

  Thread.Sleep(TimeSpan.FromMilliseconds(100));
}</pre></div><p>At the beginning of the <a id="id360" class="indexterm"></a>preceding code, we are implementing a cancellation operation for the pipeline by running a separate task that is listening for the <span class="emphasis"><em>C</em></span> key press. When the user presses the <span class="emphasis"><em>C</em></span> button, the task runs <code class="literal">cts.Cancel</code> that signals a cancellation operation to the shared cancellation token. This token goes into all the further operations and is able to cancel the entire parallel pipeline at once.</p><p>Now, we define the pipeline behavior. First, we set the parallelism degree for our parallel pipeline. In the following example, we will create four blocking collections for one element each. It will cause four elements to be processed in parallel. If we need to change this, we can use two collections for two elements, and so on.</p><p>Next, we will define pipeline steps. The first step is responsible for getting weather information for each city that appears in the source collection. Then the next step will convert the temperature from Celsius to Fahrenheit. The final step will print out the weather information to the console.</p><p>All we need to do now is run the entire pipeline. We will use the <code class="literal">Parallel.Invoke</code> statement to run all the pipeline stages in parallel, and in the first stage, we will use <code class="literal">Parallel.Foreach</code> to fill in the <code class="literal">cities</code> collection in <a id="id361" class="indexterm"></a>parallel as well:</p><div class="informalexample"><pre class="programlisting">class PipelineWorkerAsync&lt;TInput, TOutput&gt;
{
  Func&lt;TInput, Task&lt;TOutput&gt;&gt; _processorAsync = null;
  Action&lt;TInput&gt; _outputProcessor = null;
  BlockingCollection&lt;TInput&gt;[] _input;
  CancellationToken _token;
  private int _count;

  public PipelineWorkerAsync(
    BlockingCollection&lt;TInput&gt;[] input,
    Func&lt;TInput, Task&lt;TOutput&gt;&gt; processorAsync,
    CancellationToken token,
    string name,
    int count)
    {
      _input = input;
      _count = count;
      _processorAsync = processorAsync;
      _token = token;

      Output = new BlockingCollection&lt;TOutput&gt;[_input.Length];
      for (int i = 0; i &lt; Output.Length; i++)
        Output[i] = null == input[i] ? null: new BlockingCollection &lt;TOutput&gt;(Count);

      Name = name;
  }

  public PipelineWorkerAsync(
    BlockingCollection&lt;TInput&gt;[] input,
    Action&lt;TInput&gt; renderer,
    CancellationToken token,
    string name) {
      _input = input;
      _outputProcessor = renderer;
      _token = token;
      Name = name;
      Output = null;
    }

    public BlockingCollection&lt;TOutput&gt;[]
        Output { get; private set; }

    public string Name { get; private set; }

    public async Task RunAsync() {
      Console.WriteLine("{0} is running", this.Name);
      List&lt;Task&gt; tasks = new List&lt;Task&gt;();
      foreach (var bc in _input) {
        var local = bc;
        var t = Task.Run(new Func&lt;Task&gt;(async () =&gt; {
          TInput receivedItem;
          while (!local.IsCompleted &amp;&amp; !_token.IsCancellationRequested) {
            var ok = local.TryTake(out receivedItem, 50, _token);

            if (ok) {
              if (Output != null) {
                TOutput outputItem = await _processorAsync(receivedItem);
                BlockingCollection&lt;TOutput&gt;.AddToAny(Output, outputItem);

                Console.WriteLine("{0} sent {1} to next, on thread id {2}",Name, outputItem, Thread.CurrentThread.ManagedThreadId);

                Thread.Sleep(TimeSpan.FromMilliseconds(100));
              }
              else {
                _outputProcessor(receivedItem);
              }
            }
            else {
              Thread.Sleep(TimeSpan.FromMilliseconds(50));
            }
          }
        }),
        _token);

        tasks.Add(t);
      }

      await Task.WhenAll(tasks);

      if (Output != null) {
        foreach (var bc in Output) bc.CompleteAdding();
      }
    }
}</pre></div><p>The pipeline step logic is defined inside the <code class="literal">PipelineWorkerAsync</code> class. We have created the worker instance, providing it with the input collections and a transformation function that gets an initial value and calculates the result. Then we ran collection processing in parallel. While we processed each collection, we passed calculation results to the output collections of the next step in our pipeline. This happens until the final step has been reached, which just <a id="id362" class="indexterm"></a>prints results to the console.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec52"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we have considered the different kinds of asynchronous programming patterns—from the smallest ones such as a task with timeout to the large multipurpose parallel pipeline pattern. We have reviewed the history of asynchronous programming in the .NET Framework and C#, and went step by step through all existing patterns including APM, EAP, and TAP.</p><p>In the next chapter, we will cover a very important topic of server-side asynchronous programming. We will learn about scalability, performance metrics, details of IO-bound and CPU-bound asynchronous operations, and how the slightest mistake can ruin your backend. Also, we will learn a couple of tricks that will allow us to detect possible scalability problems and avoid them.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch08"></a>Chapter 8. Server-side Asynchrony</h2></div></div></div><p>In this chapter, we will show how a server application is different from other applications, what scalability is, and how it is important. We will look at the .NET HTTP API server application framework, learn to use Visual Studio to create load tests, dig into asynchronous I/O details, and review important nuances such as synchronization context. Finally, we will suggest an architectural pattern for a server application to run long operations and remain scalable and performant.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec53"></a>Server applications</h2></div></div><hr /></div><p>A <span class="strong"><strong>server application</strong></span> can be defined as an application that accepts requests, processes them, and sends the corresponding responses to the client. Communication happens via some transport protocols, and usually, but not necessarily, the client and server applications are situated on different physical computers. The computer that runs the server application is usually referred to <a id="id363" class="indexterm"></a>as the server.</p><p>There are many types of server applications. For example, a Remote Desktop Services software that allows us to open remote session to a Windows machine is a server application. Each user connection <a id="id364" class="indexterm"></a>consumes a lot of server resources, but in this particular scenario, this is inevitable. This server application does not need to support hundreds or thousands of simultaneous users and is intended to be like this. However, if we imagine a website that allows only a few users to browse it simultaneously, it would be definitely a failure.</p><p>On the other hand, it is OK when a website user gets notifications from the server with a delay of 2-3 seconds, but if we try to work with a remote desktop connection that shows updates from the server with such a delay, it would be very uncomfortable. There are different metrics that characterize a server application, and in different scenarios different metrics are important. One of the most important server application characteristics is <span class="strong"><strong>scalability</strong></span>. Here is <a id="id365" class="indexterm"></a>how this term is defined in Wikipedia:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>Scalability is the ability of a system, network, or process to handle a growing amount of work in a</em></span> <a id="id366" class="indexterm"></a><span class="emphasis"><em>capable manner or its ability to be enlarged to accommodate that growth.</em></span></p></blockquote></div><p>Imagine that we<a id="id367" class="indexterm"></a> have a website and it handles a certain number of concurrent users. To handle more users, we can try to add more memory and maybe install a new CPU with more cores to the server. If this allows us to achieve this goal, we can say that the application is<a id="id368" class="indexterm"></a> able to <span class="strong"><strong>scale vertically</strong></span>. If we can install more servers and make our application run on multiple machines and handle more users, this kind <a id="id369" class="indexterm"></a>of scalability is called <span class="strong"><strong>horizontal scalability</strong></span>. The following diagram shows the vertical and horizontal scalability:</p><div class="mediaobject"><img src="graphics/4208_08_01.jpg" /></div><p>It may seem that every server application should scale in both ways, but usually this is not what happens. This topic is very interesting and vast, and it is worth writing another book on this. Let's state that most general-purpose server applications nowadays are web applications and services, so later we will review the ASP.NET web platform and specifically the OWIN Web API framework.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec54"></a>The OWIN Web API framework</h2></div></div><hr /></div><p>In this chapter, we will <a id="id370" class="indexterm"></a>concentrate on the ASP.NET platform. At the time of writing this book, ASP.NET 5 was not released. However, the OWIN project existed, and the code looked almost the same as in ASP.NET 5. So this was used to write the sample server applications. When ASP.NET 5 will be released, it will be easy to convert this code to the new platform. We will not go into the details of <span class="strong"><strong>OWIN</strong></span>; it is an acronym for <span class="strong"><strong>Open Web Interface for .NET</strong></span>, and basically, it is a way to compose application components with each other. It is a part of the ASP.NET ecosystem, and all we need to know for now is that with OWIN we can write HTTP services.</p><p>When we use ASP.NET, we see a typical HTTP application platform. First, there is an HTTP host that accepts incoming connections from clients. It can be a full Internet Information Services web server, or it can be a simple HTTP listener hosted in a usual .NET process. After the incoming HTTP request is processed by the HTTP host, it goes to the ASP.NET infrastructure. It gets a worker thread from the .NET thread pool and starts request data processing on this thread.</p><p>First, it tries to define what code will be handling this request by matching the request URL to existing routes. A route describes how URL parts correlate to web application code parts. A logical set of server code is called a controller. In the OWIN Web API framework, a controller contains a number of actions—methods that handle different HTTP requests usually by HTTP verbs (or by other rules that can be set in routes). Before all this becomes too complicated, let's look at the code. In the samples directory, it is located in the <span class="strong"><strong>Chapter 8</strong></span> solution folder in the <span class="strong"><strong>AsyncServer</strong></span> project. To leverage OWIN, we need to install the <code class="literal">Microsoft.AspNet.WebApi.OwinSelfHost</code> NuGet package. The first part is the entry code for the entire OWIN application:</p><div class="informalexample"><pre class="programlisting">public class Startup
{
  public void Configuration(IAppBuilder appBuilder)
  {
    var config = new HttpConfiguration();
    config.Routes.MapHttpRoute(
      "DefaultApi",
      "api/{controller}/{id}",
      new {id = RouteParameter.Optional});

    appBuilder.UseWebApi(config);
  }
}</pre></div><p>Here we have configured our OWIN application by providing a default route. It will match URLs such as <code class="literal">http://hostname/api/somename/5</code> to a class called <code class="literal">SomenameController</code> that contains the <code class="literal">Get</code> method (if the request verb was HTTP GET) and will call this method providing a parameter <code class="literal">id = 5</code> into it. The last line instructs OWIN to use a Web API component in the application.</p><p>Now let's look at the controller:</p><div class="informalexample"><pre class="programlisting">public class BadAsyncController : ApiController
{
  private readonly AsyncLib _client;

  public BadAsyncController()
  {
    _client = new AsyncLib();
  }

  public async Task&lt;HttpResponseMessage&gt; Get()
  {
    var sw = Stopwatch.StartNew();
    string value = await _client.BadMethodAsync();
    sw.Stop();
    var timespan = sw.Elapsed;
    return Request.CreateResponse(HttpStatusCode.OK,
      new
      {
      Message = value,
      Time = timespan
    });
  }
}</pre></div><p>Here, we see the <code class="literal">Get</code><a id="id371" class="indexterm"></a> method code, which calls a library's asynchronous method and measures the time it took to complete. Then it returns an anonymous object containing the response data. It will be serialized to the JSON format by default.</p><p>We will define another controller, which will be different only with respect to an asynchronous library's method name that it calls:</p><div class="informalexample"><pre class="programlisting">public class GoodAsyncController : ApiController
{
  private readonly AsyncLib _client;

  public GoodAsyncController()
  {
    _client = new AsyncLib();
  }

  public async Task&lt;HttpResponseMessage&gt; Get()
  {
    var sw = Stopwatch.StartNew();
    string value = await _client.GoodMethodAsync();
    sw.Stop();
    var timespan = sw.Elapsed;
    return Request.CreateResponse(HttpStatusCode.OK,
    new
    {
      Message = value,
      Time = timespan
    });
  }
}</pre></div><p>Here we have called <code class="literal">GoodMethodAsync</code>. We will describe both controllers later, but now we need to run the <a id="id372" class="indexterm"></a>application. We need to create an application host:</p><div class="informalexample"><pre class="programlisting">class Program
{
  static void Main(string[] args)
  {
    string baseAddress = "http://localhost:9000/";

    using (WebApp.Start&lt;Startup&gt;(url: baseAddress))
    {
      HttpClient client = new HttpClient();

      var response = client.GetAsync(baseAddress + "api/GoodAsync").Result;

      Console.WriteLine(response);
      Console.WriteLine(response.Content.ReadAsStringAsync().Result);
      Console.WriteLine();

      response = client.GetAsync(baseAddress + "api/BadAsync").Result;

      Console.WriteLine(response);
      Console.WriteLine(response.Content.ReadAsStringAsync().Result);

      Console.ReadLine();
    }
  }
}</pre></div><p>This code starts a web application on a localhost on port 9000. If this port is already taken, there will be an exception. In this case, just change the port number. After the application starts, we will issue two HTTP requests and see the results on the console window. Both requests <a id="id373" class="indexterm"></a>should complete without any issues and show that it took two seconds for them to complete. You can use a regular web browser to open <code class="literal">http://localhost:9000</code> and see the results. Internet Explorer is not very good with JSON, but Google Chrome will show you a JSON result with good formatting. Besides this, there is a very useful Google Chrome extension called Postman. This can issue different HTTP requests and is very comfortable to use; it is shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4208_08_02.jpg" /></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec55"></a>Load testing and scalability</h2></div></div><hr /></div><p>We see that both the<a id="id374" class="indexterm"></a> controllers have behaved the same so far. However, what about scalability? To check how well the application scales, we need to have many requests from <a id="id375" class="indexterm"></a>many users. We will be able to do this with the help of different tools. First, we can use Visual Studio, but it requires the Ultimate edition (or the Enterprise edition for Visual Studio 2015) where web test tools are available. If you have it, then you can create a new project and choose the <span class="strong"><strong>Web Performance and Load Test</strong></span> project from the test category. In the samples folder, there is an already created test project that is called <span class="strong"><strong>AsyncServerTests</strong></span>. Now we need to create Web Performance Test. After creating, it will run in the browser and try to record your test. You can record it<a id="id376" class="indexterm"></a>  from the browser or stop the recording and add a new request as shown in the following screenshot; then in <span class="strong"><strong>Properties</strong></span> provide a full URL to see what <a id="id377" class="indexterm"></a>have we tested so far:</p><div class="mediaobject"><img src="graphics/4208_08_03.jpg" /></div><p>Next, we need to create a load test. When we add a new load test, it will show a wizard with different options. We need to choose a constant load pattern and set the number of users to <code class="literal">1000</code>. Then, in the test mix, we have to pick a web test that we have just created. Finally, in the run settings set the warm-up duration to 15 seconds, and set duration time to 2 minutes. Click on <span class="strong"><strong>Finish</strong></span> and repeat all this for another controller. When everything is set, let's run a load test for <code class="literal">GoodAsyncController</code>. The output is as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4208_08_04.jpg" /></div><p>These data show that for 1000 users per second, the average response time was still about two seconds. This is a <a id="id378" class="indexterm"></a>very good result and shows that <code class="literal">GoodAsyncController</code> scales well and is able to handle many concurrent requests. To compare this to <code class="literal">BadAsyncController,</code> we need to create a web and load test for this, and then run the load test.</p><p>Before doing so, if we do not have the Visual Studio Ultimate edition, it is still possible to load test our web<a id="id379" class="indexterm"></a> application. The easiest way is to use the Apache bench command line tool. It is included in the Apache web server installation, but if you do not need it, you can download<a id="id380" class="indexterm"></a> <span class="strong"><strong>xampp</strong></span> (a preconfigured Apache distributive) that has a portable installation option. This means that you can download a zip archive from the xampp site, and then extract it to somewhere in your file system. You will find the <code class="literal">ab.exe</code> tool in the <code class="literal">xampp\apache\bin</code> folder. It has many parameters, but we can use just two of them—the number of concurrent requests and the time for the benchmark. Here we have issued 1,000 concurrent requests for 2 minutes to our <code class="literal">GoodAsyncController</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>ab -c 1000 -t 120 http://localhost:9000/api/GoodAsync</strong></span>
</pre></div><p>The output shown will be the same—the average request time will be around 2 seconds.</p><p>Now let's see the performance test results for <code class="literal">BadAsyncController</code>. The following screenshot shows the performance test results:</p><div class="mediaobject"><img src="graphics/4208_08_05.jpg" /></div><p>Here the picture is different. We see that the average request time is more than ten times higher than in the <a id="id381" class="indexterm"></a> previous test. Obviously, this code does not scale as well as <code class="literal">GoodAsyncController</code> does. Since the codes inside the controllers are identical, and the only<a id="id382" class="indexterm"></a> difference is the asynchronous library method that was called, it makes sense to look into this library and see what is going on:</p><div class="informalexample"><pre class="programlisting">public class AsyncLib
{
  public async Task&lt;string&gt; GoodMethodAsync()
  {
    await Task.Delay(TimeSpan.FromSeconds(2));
    return "Good async library method result";
  }

  public async Task&lt;string&gt; BadMethodAsync()
  {
    Thread.Sleep(TimeSpan.FromSeconds(2));
    return "Bad async library method result";
  }
}</pre></div><p>The code is actually very simple. Both the methods wait for two seconds, and then return string results. However, we <a id="id383" class="indexterm"></a> can see that <code class="literal">Thread.Sleep</code> is obviously the reason behind<a id="id384" class="indexterm"></a> bad scalability. In the diagram, you can see what is going on when we use <code class="literal">BadMethodAsync</code> in our web application:</p><div class="mediaobject"><img src="graphics/4208_08_06.jpg" /></div><p>Each worker thread starts running our code and waits two seconds doing nothing. Then, they return the response. As we may recall from the previous chapters, thread pool worker threads are a limited resource, and when we start issuing 1,000 concurrent requests in a short time, all the worker threads become occupied running <code class="literal">Thread.Sleep</code>. At the same time, <code class="literal">GoodAsyncController</code> behaves differently. This can be seen in the following diagram:</p><div class="mediaobject"><img src="graphics/4208_08_07.jpg" /></div><p><code class="literal">Task.Delay</code> uses a timer object under the hood. This allows an ASP.NET worker thread to start a wait<a id="id385" class="indexterm"></a>  operation, and then to return to the application pool and process some other requests. When two seconds pass, the timer posts a continuation callback to an available ASP.NET thread pool worker thread. This allows the application to process more user<a id="id386" class="indexterm"></a> requests, since worker threads are not blocked. So, this timer object helps our application to remain fast and scalable.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec56"></a>I/O and CPU-bound tasks</h2></div></div><hr /></div><p>If we consider any CPU-intensive<a id="id387" class="indexterm"></a> work that our server application can run instead of <code class="literal">Thread.Sleep</code>, we will find that this application will suffer from the same problem. Worker threads will become busy quite quickly, and there is not much that we can do about this. We can try to change our application logic to work around this problem, and we will get back to this problem at the end of the chapter.</p><p>However, besides CPU-bound operations, there are tasks related to input/output processes, such as reading or writing a file, issuing a network request, or even performing a query against a database. These operations usually take much more time compared to CPU-bound work, and potentially they should be more problematic to our server application. I/O-bound work can take seconds. So does this mean that our worker threads will be locked for a longer time and the application will fail to scale?</p><p>Fortunately, there is one more component of the I/O-bound operation. When we mention a file or network request, we know that there are physical devices such as disks and network cards that actually execute these operations. These devices have controllers, and a controller in this context means a micro-computer with its own CPU. To perform an I/O-bound task, we do not need to waste the main CPU's time, it is enough to give all the required data to the I/O device controller, and it will perform the I/O operation and return the results with the<a id="id388" class="indexterm"></a> help of a device driver.</p><p>To communicate with the I/O devices, Windows uses a special object called <span class="strong"><strong>I/O Completion Port</strong></span> (or <span class="strong"><strong>IOCP</strong></span>). It <a id="id389" class="indexterm"></a>behaves pretty much like a timer, but the signals are coming from the I/O devices and not from the internal clock. This means that, while an I/O operation is in progress, we can reuse the ASP.NET worker thread to serve other requests, and thus achieve good scalability. The following diagram depicts the processes graphically:</p><div class="mediaobject"><img src="graphics/4208_08_08.jpg" /></div><p>Notice a new entity called the I/O thread in the preceding diagram. There is a separate smaller pool of I/O threads inside this .NET thread pool. The I/O threads are not different from the usual worker threads, but they are being used only to execute continuation callbacks for asynchronous I/O operations. If we use general worker threads for this purpose, it can happen that there are no worker threads available and we cannot complete the I/O operation, which in turn will lead to deadlocks. Using a separate thread pool will help to prevent this, but we also need to be very careful not to cause I/O threads starvation. Look at the following example.</p><p>Here we will create an HTTP GET request for the Google site. As we have already learned, when we use <code class="literal">await</code>, all the code following the line with <code class="literal">await</code> gets wrapped in a continuation callback <a id="id390" class="indexterm"></a>and is called when the asynchronous operation completes. Here we will use <code class="literal">Thread.Sleep</code> to see which threads will get busy:</p><div class="informalexample"><pre class="programlisting">private static async Task&lt;string&gt; IssueHttpRequest()
{
  var str = await new HttpClient().GetStringAsync("http://google.com");
  Thread.Sleep(5000);
  return str;
}</pre></div><p>Then, we need to get information about what is happening with thread pool threads. Fortunately, a .NET thread pool has a set of static methods that allow us to get some information about worker and I/O threads in a thread pool:</p><div class="informalexample"><pre class="programlisting">private static void PrintThreadCounts()
{
  int ioThreads;
  int maxIoThreads;
  int workerThreads;
  int maxWorkerThreads;

  ThreadPool.GetMaxThreads(out maxWorkerThreads, out maxIoThreads);
  ThreadPool.GetAvailableThreads(out workerThreads, out ioThreads);

  Console.WriteLine(
    "Worker threads: {0}, I/O threads: {1}, Total threads: {2}",
    maxWorkerThreads - workerThreads,
    maxIoThreads - ioThreads,
    Process.GetCurrentProcess().Threads.Count
  );
}</pre></div><p>In the <code class="literal">Main</code> method, we will run many asynchronous I/O tasks; while iterating through all these tasks to complete in each second, we will print out information about thread pool threads:</p><div class="informalexample"><pre class="programlisting">private static void Main(string[] args)
{
  var tasks = new List&lt;Task&lt;string&gt;&gt;();

  for (var i = 0; i &lt; 100; i++)
  {
    tasks.Add(Task.Run(() =&gt;
    {
      // Thread.Sleep(5000);
      return IssueHttpRequest();
    }));
  }

  var allComplete = Task.WhenAll(tasks);

  while (allComplete.Status != TaskStatus.RanToCompletion)
  {
    Thread.Sleep(1000);
    PrintThreadCounts();
  }

  Console.WriteLine(tasks[0].Result.Substring(0, 160));
}</pre></div><p>If we run this code (among the other samples for <span class="strong"><strong>Chapter 8</strong></span>; this one is called <span class="strong"><strong>IOThreadsTest</strong></span>), it will show that the I/O thread number will slowly increase until some point and go back to zero. To prove that the I/O operation really happens, the last lines will be the <a id="id391" class="indexterm"></a>beginning of the Google web page HTML content. If we now comment out the first <code class="literal">Thread.Sleep</code> call and uncomment it in the <code class="literal">Main</code> method, the situation will be different. We will block worker threads, and the I/O thread number will remain low.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec57"></a>Deep dive into asynchronous I/O</h2></div></div><hr /></div><p>Usually, there is no<a id="id392" class="indexterm"></a> need to use Win32 API to start an asynchronous I/O operation. The .NET base class library has many APIs that are comfortable to use, and leverage asynchronous I/O. The following code is not intended to be used in a production software, it just shows how such an API can be written in case you do not have it in the .NET Framework.</p><p>First, we need to allow an unsafe code in our project. The setting is inside the project properties of the <span class="strong"><strong>Build</strong></span> section as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4208_08_09.jpg" /></div><p>Here, we need to define many data structures for the API function calls. The fully working code can <a id="id393" class="indexterm"></a>be found in the <span class="strong"><strong>BindHandle</strong></span> sample project. In this book, we will skip the unimportant details.</p><p>First, we need to use P/Invoke for two Windows API functions:</p><div class="informalexample"><pre class="programlisting">[DllImport("kernel32.dll", SetLastError = true, CharSet = CharSet.Auto)]
public static extern SafeFileHandle CreateFile(
   string lpFileName,
   EFileAccess dwDesiredAccess,
   EFileShare dwShareMode,
   IntPtr lpSecurityAttributes,
   ECreationDisposition dwCreationDisposition,
   EFileAttributes dwFlagsAndAttributes,
   SafeFileHandle hTemplateFile);

[DllImport("kernel32.dll", SetLastError = true)]
unsafe internal static extern int ReadFile(
  SafeFileHandle handle,
  byte* bytes,
  int numBytesToRead,
  IntPtr numBytesRead_mustBeZero,
  NativeOverlapped* overlapped);</pre></div><p>Then, we create a file and write some text in it in the usual way:</p><div class="informalexample"><pre class="programlisting">using (var sw = File.CreateText("test.txt"))
{
  sw.WriteLine("Test!");
}</pre></div><p>Here, we are opening this file for asynchronous reading. Notice <code class="literal">EFileAttributes.Overlapped</code> in the method parameters. If we want an asynchronous I/O operation, we must specify this flag:</p><div class="informalexample"><pre class="programlisting">SafeFileHandle handle = CreateFile(
  "test.txt",
  EFileAccess.FILE_GENERIC_READ,
  EFileShare.Read | EFileShare.Write | EFileShare.Delete,
  (IntPtr)null,
  ECreationDisposition.OpenExisting,
  EFileAttributes.Overlapped,
  new SafeFileHandle(IntPtr.Zero, false));</pre></div><p>Now we bind the file handle to a .NET thread pool. It maintains an I/O completion port, and this handle will be attached to the port:</p><div class="informalexample"><pre class="programlisting">if (!ThreadPool.BindHandle(handle))
{
  Console.WriteLine("Failed to bind handle to the threadpool.");
  return;
}</pre></div><p>We need to prepare a buffer for the file that is going to be read. The following code checks whether the buffer is empty:</p><div class="informalexample"><pre class="programlisting">byte[] bytes = new byte[0x8000];

Console.WriteLine("First byte in buffer: {0}", bytes[0]);</pre></div><p>Now, we need to<a id="id394" class="indexterm"></a> prepare a callback that will be executed after the asynchronous operation completes. If everything is fine, we will get file content from the buffer and print it to the console. We must clean up the resources after the operation completion:</p><div class="informalexample"><pre class="programlisting">IOCompletionCallback iocomplete = delegate(uint errorCode, uint numBytes, NativeOverlapped* nativeOverlapped)
  {
    try
    {
      if (errorCode != 0 &amp;&amp; numBytes != 0)
      {
        Console.WriteLine("Error {0} when reading file.", errorCode);
      }
      Console.WriteLine("Read {0} bytes.", numBytes);
      Console.WriteLine(
        Encoding.UTF8.GetChars(
          new ArraySegment&lt;byte&gt;(bytes,0, (int)numBytes).ToArray()));
    }
    finally
    {
      Overlapped.Unpack(nativeOverlapped);
      Overlapped.Free(nativeOverlapped);
    }
  };</pre></div><p>Here, we have prepared a data structure to be passed to the asynchronous operation start. We have to pin our<a id="id395" class="indexterm"></a> buffer's address to memory, so the pointer will be valid:</p><div class="informalexample"><pre class="programlisting">Overlapped overlapped = new Overlapped();

NativeOverlapped* pOverlapped = overlapped.Pack(iocomplete, bytes);

pOverlapped-&gt;OffsetLow = 0;

fixed (byte* p = bytes)
{</pre></div><div class="informalexample"><pre class="programlisting">  // Here we start asynchronously reading the file.
  // When the operation will complete, ioComplete
  // callback will be called
  int r = ReadFile(handle, p, bytes.Length, IntPtr.Zero, pOverlapped);

  if (r == 0)
  {
    r = Marshal.GetLastWin32Error();
    if (r != ERROR_IO_PENDING)
    {
      Console.WriteLine("Failed to read file. LastError is {0}", Marshal.GetLastWin32Error());
      Overlapped.Unpack(pOverlapped);
      Overlapped.Free(pOverlapped);
      return;
    }
  }
}</pre></div><p>When we run this code, we will see that the file content has been successfully read.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec58"></a>Real and fake asynchronous I/O operations</h2></div></div><hr /></div><p>So far, an <a id="id396" class="indexterm"></a>asynchronous I/O seems to be a good thing for server applications. Unfortunately, there is quite unexpected underwater stone that is very hard to find. Let's look at the following code. It happens that the <code class="literal">FileStream</code> instance has the <code class="literal">IsAsync</code> property, indicating that the underlying I/O operation is <a id="id397" class="indexterm"></a>asynchronous. We will start a few asynchronous writes and check whether they are really asynchronous:</p><div class="informalexample"><pre class="programlisting">private const int BUFFER_SIZE = 4096;

private static async Task ProcessAsynchronousIO()
{
  using (var stream = new FileStream("test1.txt", FileMode.Create, FileAccess.ReadWrite, FileShare.None, BUFFER_SIZE))
  {
    Console.WriteLine("1. Uses I/O Threads: {0}", stream.IsAsync);

    var buffer = Encoding.UTF8.GetBytes(CreateFileContent());
    var t = stream.WriteAsync(buffer, 0, buffer.Length);
    await t;
  }

  using (var stream = new FileStream("test2.txt", FileMode.Create, FileAccess.ReadWrite, FileShare.None, BUFFER_SIZE, FileOptions.Asynchronous))
  {
    Console.WriteLine("2. Uses I/O Threads: {0}", stream.IsAsync);

    var buffer = Encoding.UTF8.GetBytes(CreateFileContent());
    var t = stream.WriteAsync(buffer, 0, buffer.Length);
    await t;
  }

  using (var stream = File.Create("test3.txt", BUFFER_SIZE, FileOptions.Asynchronous))
  using (var sw = new StreamWriter(stream))
  {
    Console.WriteLine("3. Uses I/O Threads: {0}", stream.IsAsync);

    await sw.WriteAsync(CreateFileContent());
  }

  using (var sw = new StreamWriter("test4.txt", append: true))
  {
    Console.WriteLine("4. Uses I/O Threads: {0}", ((FileStream) sw.BaseStream).IsAsync);

    await sw.WriteAsync(CreateFileContent());
  }

  Console.WriteLine("Deleting files...");

  var deleteTasks = new Task[4];
  for (var i = 0; i &lt; 4; i++)
  {
    var fileName = string.Format("test{0}.txt", i + 1);
    deleteTasks[i] = SimulateAsynchronousDelete(fileName);
  }

  await Task.WhenAll(deleteTasks);

  Console.WriteLine("Deleting complete.");
}

private static string CreateFileContent()
{
  var sb = new StringBuilder();
  for (var i = 0; i &lt; 100000; i++)
  {
    sb.AppendFormat("{0}", new Random(i).Next(0, 99999));
    sb.AppendLine();
  }
  return sb.ToString();
}

private static Task SimulateAsynchronousDelete(string fileName)
{
  // No delete async in API
  return Task.Run(() =&gt; File.Delete(fileName));
}

private static void Main(string[] args)
{
  var t = ProcessAsynchronousIO();
  t.GetAwaiter().GetResult();
}</pre></div><p>When we run the code, we will see that only the numbers two and three writes are asynchronous. However, we have used the <code class="literal">await</code> statement and call <code class="literal">WriteAsync</code> in all cases. What is going on? The answer is that if we do not specify the correct options for the file API we use, the file will provide us with the wrong kind of asynchrony that uses worker threads for the I/O process and thus is not scalable.</p><p>This problem<a id="id398" class="indexterm"></a> can be illustrated by the <code class="literal">SimulateAsynchronousDelete</code> method. There is no asynchronous delete function in the Win32 API, so<a id="id399" class="indexterm"></a> it just starts a new task where the synchronous delete is being performed. This<a id="id400" class="indexterm"></a> practice is called <span class="strong"><strong>async over sync</strong></span> and should be avoided. Do not write your libraries like this. If there is no asynchronous API for some operation, do not make it look asynchronous. In the following diagram, we can see why it is a bad practice for a server application:</p><div class="mediaobject"><img src="graphics/4208_08_10.jpg" /></div><p>This workflow is even worse than the usual synchronous code, because there is an additional performance overhead related to running this part of the operation on a different worker thread. We end up wasting worker thread for the entire time of the I/O operation anyway, and this is fake asynchronous I/O. It is actually a CPU-bound operation that will affect the scalability and performance of your application.</p><p>So if we have the source code of a library, we can make sure that it leverages a truly asynchronous I/O. However, a source code is not always available, and even if it is available, it can often be puzzling and complicated. To make sure that our asynchrony is right, we can use a tool that shows the API calls from the application, and we will be able to see whether an I/O completion port has been used.</p><p>There is a<a id="id401" class="indexterm"></a> program called API Monitor. It can be easily found in any search engine, is free to use, and easy to install. There are two versions <a id="id402" class="indexterm"></a>of this program: 32-bit and 64-bit, so you have to pay attention to which version is appropriate for your application.</p><p>From the start, we will need to set up a filter to see only the required function calls. For our sample code, it is enough to monitor two functions, <code class="literal">CreateFileW</code> and <code class="literal">CreateIoCompletionPort</code>. The filter is shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4208_08_11.jpg" /></div><p>Then we need to<a id="id403" class="indexterm"></a> run our application under API Monitor. To<a id="id404" class="indexterm"></a> start monitoring, press <span class="emphasis"><em>Ctrl</em></span> + <span class="emphasis"><em>M</em></span> or use the <span class="strong"><strong>File</strong></span> | <span class="strong"><strong>Monitor New Process…</strong></span> menu option. The start dialog will appear as follows:</p><div class="mediaobject"><img src="graphics/4208_08_12.jpg" /></div><p>When you<a id="id405" class="indexterm"></a> press <span class="strong"><strong>OK</strong></span>, the application will start and then you <a id="id406" class="indexterm"></a>will see a report as follows:</p><div class="mediaobject"><img src="graphics/4208_08_13.jpg" /></div><p>You can see that to write the <code class="literal">test2.txt</code> file, the <code class="literal">FILE_FLAG_OVERLAPPED</code> flag was provided to the <code class="literal">CreateFileW</code> function, meaning that we are using the I/O completion port. The <code class="literal">CreateFileW</code> function returned the <code class="literal">0x234</code> file handle, which was bound to the I/O completion port<a id="id407" class="indexterm"></a> by calling the <code class="literal">CreateIoCompletionPort</code> function. The first and the last file writes are <a id="id408" class="indexterm"></a>not using the completion port and thus are not really asynchronous.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec59"></a>Synchronization context</h2></div></div><hr /></div><p>Another very<a id="id409" class="indexterm"></a> important concept is synchronization context. We will review synchronization context and other kinds of context in detail in the next chapter, but for now let's start with a demonstration. This sample is called <span class="strong"><strong>IISSynchronizationContext</strong></span>. This time we need to host our application in an IIS web server, so we will use the <span class="strong"><strong>Microsoft.Owin.Host.SystemWeb</strong></span> NuGet package, and create an empty ASP.NET application. First, we will configure our application and define a default route:</p><div class="informalexample"><pre class="programlisting">public class Startup
{
  public void Configuration(IAppBuilder appBuilder)
  {
    var config = new HttpConfiguration();
    config.Routes.MapHttpRoute(
      "DefaultApi", "api/{controller}/{action}/{id}", new { id = RouteParameter.Optional}
      );

    appBuilder.UseWebApi(config);
  }
}</pre></div><p>Then we will create a controller with two methods. One of them tries to get asynchronous operation results synchronously, and the other uses <code class="literal">await</code> and asynchronous execution:</p><div class="informalexample"><pre class="programlisting">public class HomeController : ApiController
{
  [HttpGet]
  public int Sync()
  {
    var lib = new AsyncLib();

    return lib.CountCharactersAsync(new Uri("http://google.com")).Result;
  }

  [HttpGet]
  public async Task&lt;int&gt; Async()
  {
    var lib = new AsyncLib();

    return await lib.CountCharactersAsync(new Uri("http://google.com"));
  }
}</pre></div><p>Here we have defined our asynchronous operation as downloading content from a given URL and returning<a id="id410" class="indexterm"></a> its length in characters:</p><div class="informalexample"><pre class="programlisting">public class AsyncLib
{
  public async Task&lt;int&gt; CountCharactersAsync(Uri uri)
  {
    using (var client = new HttpClient())
    {
      var content = await client.GetStringAsync(uri)
//   .ConfigureAwait(continueOnCapturedContext: false);

      return content.Length;
    }
  }
}</pre></div><p>When we run this code in Visual Studio, a default web browser should start and open the web application URL. In the sample code, both actions can be reached via <code class="literal">http://localhost:5098/api/Home/Async</code> and <code class="literal">http://localhost:5098/api/Home/Sync</code> respectively. The <code class="literal">Async</code> version works fine, while the <code class="literal">Sync</code> code hangs forever.</p><p>This can be fixed if we uncomment the <code class="literal">ConfigureAwait</code> line in the <code class="literal">AsyncLib</code> class. If you run a new code, the <code class="literal">Sync</code> version will also work. To understand the reasons for this, we need to get back to the synchronization context concept. A synchronization context represents an environment that has some data associated to it, and an ability to run a delegate using this environment. In ASP.NET, when using a IIS web server there is a special synchronization context that keeps the current culture and user identity.</p><p>Now when we use <code class="literal">await</code> by default, if we use await with the <code class="literal">Task&lt;T&gt;</code> instance, we will get a special <code class="literal">TaskAwaiter&lt;T&gt;</code> structure that is used by the C# compiler in the generated state machine code. To run a continuation callback, C# ends up calling the <code class="literal">UnsafeOnCompleted</code> method:</p><div class="informalexample"><pre class="programlisting">public struct TaskAwaiter&lt;TResult&gt; : ICriticalNotifyCompletion
{
  private readonly Task&lt;TResult&gt; m_task;

  internal TaskAwaiter(Task&lt;TResult&gt; task)
  {
    Contract.Requires(task != null, "Constructing an awaiter requires a task to await.");
    m_task = task;
  }

  public void UnsafeOnCompleted(Action continuation)
  {
    TaskAwaiter.OnCompletedInternal(m_task, continuation, continueOnCapturedContext:true, flowExecutionContext:false);
  }
}</pre></div><p>So this code tries<a id="id411" class="indexterm"></a> to post a continuation callback to the current synchronization context. However when we run this code synchronously, we will get a classic deadlock situation:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The code blocks the current synchronization context until the operation completes</p></li><li style="list-style-type: disc"><p>The operation completes and posts the continuation callback to the current synchronization context</p></li><li style="list-style-type: disc"><p>However, it is blocked until we get a result and cannot run this continuation callback, and thus cannot get a result</p></li><li style="list-style-type: disc"><p>All this leads to a deadlock</p></li></ul></div><p>To prevent this, we can use the <code class="literal">ConfigureAwait(continueOnCapturedContext: false)</code> method. It returns a special <code class="literal">ConfiguredTaskAwaitable</code> type instance, which in turn returns <code class="literal">ConfiguredTaskAwaiter</code> to the C# compiler-generated code. In this case, we use <code class="literal">UnsafeOnCompleted</code> as well, but this time it is specifically configured not to capture the current synchronization context, and the continuation callback gets posted to a default task scheduler, which is likely to be a thread pool worker thread:</p><div class="informalexample"><pre class="programlisting">public struct ConfiguredTaskAwaiter : ICriticalNotifyCompletion
{
  private readonly Task&lt;TResult&gt; m_task;
  private readonly bool m_continueOnCapturedContext;

  internal ConfiguredTaskAwaiter(Task&lt;TResult&gt; task, bool continueOnCapturedContext)
  {
    Contract.Requires(task != null, "Constructing an awaiter requires a task to await.");
    m_task = task;
    m_continueOnCapturedContext = continueOnCapturedContext;
  }

  public void UnsafeOnCompleted(Action continuation)
  {
    OnCompletedInternal(m_task, continuation, m_continueOnCapturedContext, flowExecutionContext:false);
  }
}</pre></div><p>This means that when you write a library with async methods that have the <code class="literal">await</code> statements inside<a id="id412" class="indexterm"></a> and if you are sure that your continuation code does not need the current synchronization context, always use <code class="literal">.ConfigureAwait(false)</code> to prevent such situations. Also vice versa; if you have to work with asynchronous operations synchronously in ASP.NET, it is very dangerous to use the <code class="literal">Task.Result</code> property and block the current thread. You should use <code class="literal">Task.ContinueWith</code> along with the corresponding options to get the result without <code class="literal">await</code>.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec60"></a>CPU-bound tasks and queues</h2></div></div><hr /></div><p>So far, we have reviewed many special details about I/O-bound tasks, but what about CPU-bound work? Technically, the most efficient way will be to run such work synchronously and scale horizontally by adding more and more servers to be able to handle increasing load. Nevertheless, it can happen that this CPU-bound work is not the only responsibility of a server application. In this case, we can find a way to get this to work out of the web<a id="id413" class="indexterm"></a> application, allowing it to run fast; now the CPU-bound part can be scaled separately and does not affect the rest of this application.</p><p>This is how cloud applications work. Usually, if there is a long running operation, a web application registers it into some data store, returns a unique identifier of this operation to the client, and posts this operation to a special queue. Then there is a separate pool of worker processes that monitor this queue, get tasks from them, process them, and write results to a data store. When the client arrives next time, the web application checks whether the task has been already completed by any worker and if it has, the application returns the result to the client.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec61"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we have learned about server applications and how they are different. We have looked at scalability and understood why it is very important for a server application to be able to scale well. We have created an OWIN Web API application and learned to host it in an IIS web server and in a separate process. We have used Visual Studio to create load tests for our server application, checked what happens when we use good and poorly written asynchronous code, and leveraged the Apache bench command line tool to run benchmarks without Visual Studio.</p><p>We also have reviewed in detail what an I/O thread and an I/O completion port are, and found out reasons why using an asynchronous I/O is the key to building scalable server applications. To check whether a third-party code uses real asynchronous I/O, we have found a tool that shows Win32 API calls. In conclusion, we have learned about synchronization context and how we can configure continuation tasks to be run on a default task scheduler. Finally, we have discussed how to enhance the scalability of a server application that has long-running CPU-bound tasks.</p><p>In the next chapter, we will review client applications, and specifically the user interface part, in detail. We will learn about modern user interface technologies, how to keep the UI fast and responsive, and how to avoid common pitfalls and mistakes with asynchrony on the client side.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch09"></a>Chapter 9. Concurrency in the User Interface</h2></div></div></div><p>In this chapter, we will review the aspects of using asynchrony in client applications. We will learn about how a Windows application works and define what an UI thread and message loop is. While going through the details of execution and synchronization contexts, we will dig into a C# compiler-generated code and see how it is related to the use of the <code class="literal">await</code> keyword in your program.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec62"></a>The importance of asynchrony for UI</h2></div></div><hr /></div><p>While a server application in general has to be scalable before everything else, a client application is different. It is usually intended to run for one user on one computer, and thus the user expects it to run fast and not cause troubles for the other applications running in the system. While the second part is usually handled by the operating system, the application's performance in getting things done and reacting to user input is crucial for a positive user experience. Imagine if you run an application and it hangs for a few minutes after you click on a<a id="id414" class="indexterm"></a> button. A good application remains responsive and indicates that you have just started a long-running operation that is still running and is going to complete soon. Meanwhile, you can do something else—click on other buttons and perform some other tasks. When the task is completed, you can get back to it and see the result.</p><p>However, achieving just this is often not enough. If you use some application and it reacts to your input even with a slight delay, it will be still very annoying. It is human nature to expect an immediate reaction, and even small delays can cause irritation and anger. This requires a program to offload work from the UI as much as possible, and for this we have to learn how the UI works and the UI threading architecture. Later in this chapter, we will go deeper into the details.</p><p>The last aspect is not relevant to this chapter, but is still very important. While a server application has to consume as few resources per user as possible, if your program needs computational power then it has to be able to use the necessary resources. For instance, if a user's computer has four core <a id="id415" class="indexterm"></a>CPUs with <span class="strong"><strong>hyperthreading</strong></span> technology, then the application has to be able to use all the logical cores to get the result as soon as possible. This is where this<a id="id416" class="indexterm"></a> book's content will be very useful, especially <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Leveraging Parallel Patterns</em></span>, which provides you with concurrent programming patterns.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec63"></a>UI threads and message loops</h2></div></div><hr /></div><p>Modern <a id="id417" class="indexterm"></a>UI framework and programming languages not only make client application development much easier than before, but they also raise a level of abstraction and hide important implementation details. To understand how the UI works, we should look at the lower-level code.</p><p>The following is the code <a id="id418" class="indexterm"></a>of a simple win32 program, which is written in C. If your Visual Studio does not have C/C++ project support installed, it is not a problem. This code is needed just to illustrate how a Windows application works, and we'll break it into parts and examine each part in detail. First, let's look at the full program code listing:</p><div class="informalexample"><pre class="programlisting">#include &lt;windows.h&gt;

const char _szClassName[] = "ConcurrencyInUIWindowClass";

LRESULT CALLBACK WndProc(HWND hwnd, UINT msg, WPARAM wParam, LPARAM lParam)
{
  switch (msg)
  {
  case WM_CLOSE:
    DestroyWindow(hwnd);
    break;
  case WM_DESTROY:
    PostQuitMessage(0);
    break;
  default:
    return DefWindowProc(hwnd, msg, wParam, lParam);
  }
  return 0;
}

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int nCmdShow)
{
  WNDCLASSEX wc;
  HWND hwnd;
  MSG msg;

  // Creating the Window class
  wc.cbSize = sizeof(WNDCLASSEX);// size of the instance
  wc.style = 0;                // class styles, not important here
  wc.lpfnWndProc = WndProc;    // the pointer to Window procedure
  wc.cbClsExtra = 0;           // extra data for this class
  wc.cbWndExtra = 0;           // extra data for this Window
  wc.hInstance = hInstance;    // application instance handle

  wc.hIcon = LoadIcon(NULL, IDI_APPLICATION);// standard large// icon
  wc.hCursor = LoadCursor(NULL, IDC_ARROW);  // standard arrow// cursor
  wc.hbrBackground = (HBRUSH)(COLOR_WINDOW + 1);// background// brush
  wc.lpszMenuName = NULL;          // name of menu resource
  wc.lpszClassName = _szClassName; // Window class name
  wc.hIconSm = LoadIcon(NULL, IDI_APPLICATION); // standard small//icon

  if (!RegisterClassEx(&amp;wc))
  {
    MessageBox(NULL, "Window class registration failed!",
 "Error!", MB_ICONEXCLAMATION | MB_OK);

    return 0;
  }

  hwnd = CreateWindowEx(
    WS_EX_CLIENTEDGE,
    _szClassName,
    "UI Concurrency",
    WS_OVERLAPPEDWINDOW,
    CW_USEDEFAULT, CW_USEDEFAULT, 480, 240,
    NULL, NULL, hInstance, NULL);

  if (hwnd == NULL)
  {
    MessageBox(NULL, "Window creation failed!",
    "Error!", MB_ICONEXCLAMATION | MB_OK);

    return 0;
  }
  ShowWindow(hwnd, nCmdShow);
  UpdateWindow(hwnd);

  <span class="strong"><strong>while (GetMessage(&amp;msg, NULL, 0, 0) &gt; 0)</strong></span>
<span class="strong"><strong>  {</strong></span>
<span class="strong"><strong>    TranslateMessage(&amp;msg);</strong></span>
<span class="strong"><strong>    DispatchMessage(&amp;msg);</strong></span>
<span class="strong"><strong>  }</strong></span>

  return msg.wParam;
}</pre></div><p>The entry point is the <code class="literal">WinMain</code> method, which is a general entrance point for all Windows applications. This is what will be called when the application starts. This method is quite big, but basically it consists of four main steps.</p><p>The first step is to create the Window class instance, and provide it with the data required. The <a id="id419" class="indexterm"></a>most important part here is the pointer to the Window procedure. In our case, it is the <code class="literal">WndProc</code> method, and it will be used later to process messages from the operating system. Also, we need a unique string name for our Window class to use it to <a id="id420" class="indexterm"></a>create a window in our application.</p><p>The second step begins where the <code class="literal">RegisterClassEx</code> method is called. We register the Window class and immediately use its name to create the main application window using the <code class="literal">CreateWindowEx</code> function call. This call returns a handle that is needed for almost every operation related to this window. Then we display the application window on the screen using the <code class="literal">ShowWindow</code> and <code class="literal">UpdateWindow</code> methods.</p><p>The third step is very important and even highlighted in the code listing. This is what is usually called <span class="strong"><strong>the message loop</strong></span> or <span class="strong"><strong>the</strong></span><a id="id421" class="indexterm"></a>
<span class="strong"><strong> message pump</strong></span>. This cycle calls the <code class="literal">GetMessage</code> method that gets the first message from the message queue. This queue is created when a thread creates at least one window and thus becomes <span class="strong"><strong>the UI thread</strong></span>. If the message queue is empty, the <code class="literal">GetMessage</code> method call gets blocked until any messages appear and it dequeues the first message. The operating system puts messages such as a key press or a mouse click on this queue, and then this message gets some preprocessing by the <code class="literal">TranslateMessage</code> function. Then <code class="literal">DispatchMessage</code> sends this message to the Window procedure that is appointed to the Window class that we have used to create the main application window. In our case it is the <code class="literal">WndProc</code> method, and it is responsible for reacting to the operating system and the application events. When the <code class="literal">GetMessage</code> method returns a result that is less than zero, the message loop stops and the application exits.</p><p>So the final step, that is step four, is the message processing inside <code class="literal">WndProc</code>. This has four parameters: <code class="literal">hwnd</code> is the Window handle and allows you to interact with the window, <code class="literal">msg</code> is the message id, and <code class="literal">wParam</code> and <code class="literal">lParam</code> contain specific data for each system message. In our Window procedure, we handle the <code class="literal">WM_CLOSE</code> and <code class="literal">WM_DESTROY</code> messages explicitly to show an example of message handling, and by default, we pass all messages to a standard message handler. If we run the application, we will see that it shows the empty application window with the custom title.</p><p>Now let's add the code to<a id="id422" class="indexterm"></a> show a simple button click handler that will start an asynchronous<a id="id423" class="indexterm"></a> operation. This code replaces the WndProc definition from the preceding code listing:</p><div class="informalexample"><pre class="programlisting">const UINT IDC_START_BUTTON = 101;
const UINT WM_ASYNC_TASK_COMPLETED = WM_USER + 0;

DWORD WINAPI SimulateAsyncOperation(LPVOID lpHwnd)
{
  // pretending that this is an async operation
  // posts the message to the UI message loop
  // from other thread
  HWND hwnd = *((HWND *)lpHwnd);
  Sleep(10000);
  SendMessage(hwnd, WM_ASYNC_TASK_COMPLETED, NULL, NULL);
  return 0;
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT msg, WPARAM wParam, LPARAM lParam)
{
  switch (msg)
  {
  case WM_CREATE:
    {
      HGDIOBJ hfDefault = GetStockObject(DEFAULT_GUI_FONT);
      HWND hWndButton = CreateWindowEx(NULL,
        "BUTTON",
        "OK",
        WS_TABSTOP | WS_VISIBLE |
        WS_CHILD | BS_DEFPUSHBUTTON,
        50,
        80,
        100,
        24,
        hwnd,
        (HMENU)IDC_START_BUTTON,
        GetModuleHandle(NULL),
        NULL);
      SendMessage(hWndButton,
        WM_SETFONT,
        (WPARAM)hfDefault,
        MAKELPARAM(FALSE, 0));
    }
    break;
  case WM_COMMAND:
    switch (LOWORD(wParam))
    {
      case IDC_START_BUTTON:
        {
          HANDLE threadHandle = CreateThread(NULL, 0,
            SimulateAsyncOperation,
            &amp;hwnd, 0, NULL);
          // we do not need the handle, so just close it
          CloseHandle(threadHandle);

          MessageBox(hwnd,
            "Start button pressed",
            "Information",
            MB_ICONINFORMATION);
        }
        break;
    }
    break;
  case WM_ASYNC_TASK_COMPLETED:
    MessageBox(hwnd,
      "Operation completed",
      "Information",
      MB_ICONINFORMATION);
    break;

  case WM_CLOSE:
    // sends WM_DESTROY
    DestroyWindow(hwnd);
    break;
  case WM_DESTROY:
// Window cleanup here
    PostQuitMessage(0);
    break;
  default:
    return DefWindowProc(hwnd, msg, wParam, lParam);
  }
  return 0;
}</pre></div><p>In the beginning, we <a id="id424" class="indexterm"></a>have created identifiers for a button and a custom message. The details are <a id="id425" class="indexterm"></a>not relevant here; they are just some numeric identifiers. The next part is an asynchronous operation code inside the <code class="literal">SimulateAsyncOperation</code> method. It just blocks the current thread for 5 seconds and then sends a custom message to the Window handle that it gets through the input parameter.</p><p>The remaining code is placed inside message handlers in the <code class="literal">WndProc</code> Window procedure. The first important place is the <code class="literal">WM_CREATE</code> message handler. Here we created a button, and set the button text font to a default system font. The other details are not important here; just<a id="id426" class="indexterm"></a> notice the use of <code class="literal">IDC_START_BUTTON</code> inside the <code class="literal">CreateWindowEx</code> method call. This identifier will be used later in the message that the operating system will send when this button is clicked. This message will be processed by the <code class="literal">WM_COMMAND</code> message handler. The sending element identifier is passed in a low-order word of the <code class="literal">wParam</code> value. In the case of our button click, this value will be <code class="literal">IDC_START_BUTTON</code>. We can think of this like the common <code class="literal">Button_Click</code> handler in higher-level frameworks<a id="id427" class="indexterm"></a> such as Windows Forms or WPF. Inside this button click handler, we have created a separate thread that will run the <code class="literal">SimulateAsyncOperation</code> method. Then the simplest solution is to show a modal message box showing that the operation has been started.</p><p>The last, but not the least, step is how we run continuation code after the asynchronous operation completes. The operation sends a custom message, and we handle it with the <code class="literal">WM_ASYNC_TASK_COMPLETED</code> message handler. It simply shows a message box informing about that the operation has been completed. The operation takes 10 seconds to complete, so you can close the first message box and drag around the application window to make sure that it stays responsive.</p><p>Of course, if we run <code class="literal">SimulateAsyncOperation</code> on the UI thread, it will freeze. Simply replace the button click handler code with this to make sure this really happens:</p><div class="informalexample"><pre class="programlisting">case IDC_START_BUTTON:
{
    MessageBox(hwnd,
      "Start button pressed",
      "Information",
      MB_ICONINFORMATION);

    SimulateAsyncOperation(&amp;hwnd);
  }
  break;</pre></div><p>Now if we run the code with these changes, the application window will stop responding for 10 seconds after we press the button and close the modal dialog. This perfectly illustrates what we are trying to achieve; do all the work on the other threads, leave the UI thread just to handle messages as fast as possible, and you will get a great and responsive UI in your application.</p><p>However, in modern UI programming, the abstraction level is very high, and usually you cannot be sure if some code runs on the UI thread or not just by looking at it. Consider this C# code that can be a part of any WPF application:</p><div class="informalexample"><pre class="programlisting">private static async void Click(object sender, EventArgs e)
{
  MessageBox.Show("Starting asynchronous operation....");

  await SomeOperationAsync();

  MessageBox.Show("Asynchronous operation complete!");
}</pre></div><p>This is a button click <a id="id428" class="indexterm"></a>handler that logically does the same thing as the previous code—shows a dialog, runs an asynchronous operation, and notifies us with message boxes about<a id="id429" class="indexterm"></a> the start and end of the operation. It is much simpler than the native Win32 application window procedure message handling code. However, we pay the price by not knowing the details, and by just looking at this piece of code, we cannot say anything about what thread will run which part of this code.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec64"></a>Common problems and solutions</h2></div></div><hr /></div><p>To see what can happen if we do not control how exactly the code correlates to threads, let's start with a simple WPF application that has three different buttons. In this particular case, it is not relevant how the WPF application gets created and how we compose UI controls, so<a id="id430" class="indexterm"></a> we are going to concentrate on the code inside the button click handlers. All the code for this sample is located in the <span class="strong"><strong>AsyncInUI </strong></span>project in the samples for <span class="strong"><strong>Chapter 9</strong></span>. Besides this, we will not use <code class="literal">async</code> and <code class="literal">await</code> yet, because they will create <a id="id431" class="indexterm"></a>one more abstraction level and thus make the code harder to understand.</p><p>The first button tries to call a <code class="literal">Task</code> returning method synchronously:</p><div class="informalexample"><pre class="programlisting">private static void SyncClick(object sender, EventArgs e)
{
    _label.Content = string.Empty;
    try
    {
        string result = TaskMethod().Result;

        _label.Content = result;
    }
    catch (Exception ex)
    {
        _label.Content = ex.Message;
    }
}</pre></div><p>Without knowing exactly what <code class="literal">TaskMethod</code> is, it is impossible to predict how this program will behave. For now, we will experiment and only then look at its code and see what happened. If we run the application and click on the <span class="strong"><strong>Start synchronous operation</strong></span> button, besides an unresponsive UI, we will get a weird error message:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>One or more errors occurred</strong></span>
</pre></div><p>From <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>C# Language Support for Asynchrony</em></span>, we already know that this is a message from the <code class="literal">AggregateException</code> instance. The easiest way to get the real exception message is by getting the <code class="literal">Task</code> result through the <code class="literal">GetAwaiter</code> method call. The new line of code will be:</p><div class="informalexample"><pre class="programlisting">string result = TaskMethod().GetAwaiter().GetResult();</pre></div><p>This time the UI gets blocked again, but we get the actual error message:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>The calling thread cannot access this object because a different thread owns it.</strong></span>
</pre></div><p>This message<a id="id432" class="indexterm"></a>  tells us that we are trying to access a UI control from a non-UI thread, which is <a id="id433" class="indexterm"></a>not allowed. Now is the time to dig into the <code class="literal">TaskMethod</code> code:</p><div class="informalexample"><pre class="programlisting">private static Task&lt;string&gt; TaskMethod()
{
    return TaskMethod(TaskScheduler.Default);
}

private static Task&lt;string&gt; TaskMethod(TaskScheduler scheduler)
{
  Task delay = Task.Delay(TimeSpan.FromSeconds(5));

  return delay.ContinueWith(t =&gt;
  {
    string str = string.Format(
      "Task is running on a thread id {0}. Is thread pool thread: {1}", Thread.CurrentThread.ManagedThreadId, Thread.CurrentThread.IsThreadPoolThread);
    _label.Content = str;
    return str;
  },
  scheduler);
}</pre></div><p>So we can see that we have created a timer task and then set up a continuation task using the default task scheduler, which tries to set the label text. Since the default task scheduler posts the task code to the thread pool, we get a multithreaded access error.</p><p>We have already covered task schedulers earlier in the book, and we know that we can get one for the current synchronization context. For now, let's say that this will allow us to post the code to the UI thread, and this would resolve the issue that we have. It seems that if we modify the code to use a proper task scheduler, we will get the required result:</p><div class="informalexample"><pre class="programlisting">string result = TaskMethod(
TaskScheduler.FromCurrentSynchronizationContext()).Result;</pre></div><p>Unfortunately, if we run the modified program and press the button, the application will hang. The reason for this will become clear when we get back to the <code class="literal">WndProc</code> Window procedure source code. We will make a blocking call to <code class="literal">TaskMethod</code> from the button click handler, waiting for the asynchronous operation to complete. However, the button click handler runs on the UI thread, so this stops the message loop from spinning and therefore, we will<a id="id434" class="indexterm"></a>  never get a message from the asynchronous operation because the message loop cannot process the message as it is stopped. It is a classic<a id="id435" class="indexterm"></a> deadlock situation and shows that using synchronous calls on tasks on the UI thread is quite dangerous.</p><p>Nevertheless, we can make this code work. WPF allows us to run the message loop manually:</p><div class="informalexample"><pre class="programlisting">public static class TaskExtensions
{
  public static T WaitWithNestedMessageLoop&lt;T&gt;(this Task&lt;T&gt; task)
  {
    var nested = new DispatcherFrame();
    task.ContinueWith(_ =&gt; nested.Continue = false, TaskScheduler.Default);

    Dispatcher.PushFrame(nested);
    return task.Result;
  }
}</pre></div><p>This code creates a nested message loop. This means that the main message loop pauses, this one starts to process messages until we stop it, and then the main loop gets back in control. So first, we created the nested message loop. Then we set up a continuation task that is going to run on a thread pool worker thread. This task will stop the nested message loop when the initial task completes.</p><p>Finally, we started the nested message loop. The <code class="literal">PushFrame</code> method call is blocked until someone sets the <code class="literal">Continue</code> property on the message loop to false. The nested message loop will process system events and allow the UI to stay responsive while we wait for the initial task to complete. When this completes, the continuation task stops the nested message loop by setting its <code class="literal">Continue</code> property to <code class="literal">false</code>, and then we will get the task result (which will not block now, because the task has been completed) and return it.</p><p>Now, let's change the code and run it:</p><div class="informalexample"><pre class="programlisting">string result = TaskMethod(
TaskScheduler.FromCurrentSynchronizationContext())
.WaitWithNestedMessageLoop();</pre></div><p>The UI stays responsive, and we get a message about the code that works while a label control runs on the UI thread, which is exactly what we wanted to achieve.</p><p>An asynchronous code, however, will <a id="id436" class="indexterm"></a> work fine, because it does not block the UI thread and the message loop. To prove this, let's try to run asynchronous operations<a id="id437" class="indexterm"></a> on the thread pool and on the UI thread:</p><div class="informalexample"><pre class="programlisting">private static void AsyncClick(object sender, EventArgs e)
{
  _label.Content = string.Empty;
  Mouse.OverrideCursor = Cursors.Wait;
  Task&lt;string&gt; task = TaskMethod();

  task.ContinueWith(t =&gt;
    {
       _label.Content = t.Exception.InnerException.Message;
       Mouse.OverrideCursor = null;
    },
    CancellationToken.None,
    TaskContinuationOptions.OnlyOnFaulted,
    TaskScheduler.FromCurrentSynchronizationContext()
  );
}

private static void AsyncOkClick(object sender, EventArgs e)
{
  _label.Content = string.Empty;
  Mouse.OverrideCursor = Cursors.Wait;
  Task&lt;string&gt; task = TaskMethod(
    TaskScheduler.FromCurrentSynchronizationContext());

  task.ContinueWith(t =&gt; Mouse.OverrideCursor = null,
    CancellationToken.None,
    TaskContinuationOptions.None,
    TaskScheduler.FromCurrentSynchronizationContext());
}</pre></div><p>Since we did not want to use <code class="literal">await</code> here, we have to set up continuation tasks to output the result. In the <code class="literal">AsyncClick</code> method, we know that the asynchronous call is going to fail, so we set up an error handling continuation task using the UI thread task scheduler. In the second case, everything is going to be fine, so the continuation task will show a success message. Running <a id="id438" class="indexterm"></a> the program and clicking on the second and <a id="id439" class="indexterm"></a>third buttons proves our assumptions.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec65"></a>How the await keyword works</h2></div></div><hr /></div><p>Now let's write a button click <a id="id440" class="indexterm"></a>handler using <code class="literal">await</code> and see what has changed:</p><div class="informalexample"><pre class="programlisting">private static async void Click(object sender, EventArgs e)
{
  _label.Content = "Starting asynchronous operation....";

  await SomeOperationAsync();

  _label.Content = "Asynchronous operation complete!";
}</pre></div><p>Once again, without knowing exactly what <code class="literal">SomeOperationAsync</code> is, it is still impossible to know how this code is going to behave. Imagine the simplest asynchronous method implementation:</p><div class="informalexample"><pre class="programlisting">static Task SomeOperationAsync()
{
  return Task.Delay(TimeSpan.FromSeconds(5));
}</pre></div><p>In this case, the program will run successfully, which means that the continuation code runs on the UI thread. To find out how this happens, we need to review two important abstractions: execution and synchronization contexts.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl2sec43"></a>Execution and synchronization contexts</h3></div></div></div><p>An <span class="strong"><strong>execution context</strong></span> contains all the data<a id="id441" class="indexterm"></a> related to the current environment in which a thread is running. Usually, there is no need to use this directly; it is used by the<a id="id442" class="indexterm"></a> framework to contain the thread's local information such as security information. When needed, it is possible to restore this information to another thread. the C# infrastructure captures the execution context and flows it into a continuation code by default.</p><p>Here is an example of the code generated by the C# compiler to perform an asynchronous method call with <code class="literal">await</code>:</p><div class="informalexample"><pre class="programlisting">public AsyncVoidMethodBuilder &lt;&gt;t__builder;
...
TaskAwaiter awaiter = Program.SomeOperationAsync().GetAwaiter();
...
// in case the operation is not completed yet
this.&lt;&gt;__builder.AwaitUnsafeOnCompleted(ref awaiter, ref this);</pre></div><p>So if we look at the <code class="literal">AsyncVoidMethodBuilder.AwaitUnsafeOnCompleted </code>method, it will contain the following code:</p><div class="informalexample"><pre class="programlisting">[SecuritySafeCritical]
public void AwaitUnsafeOnCompleted&lt;TAwaiter, TStateMachine&gt;(
  ref TAwaiter awaiter, ref TStateMachine stateMachine)
where TAwaiter : ICriticalNotifyCompletion
where TStateMachine : IAsyncStateMachine
{
  try
  {
    var continuation = m_coreState
    .GetCompletionAction(ref this, ref stateMachine);

    Contract.Assert(continuation != null,
    "GetCompletionAction should always return a valid action.");

    awaiter.UnsafeOnCompleted(continuation);
  }
  catch (Exception e)
  {
    AsyncMethodBuilderCore.ThrowAsync(e, targetContext: null);
  }
}</pre></div><p>Now, we get a continuation <a id="id443" class="indexterm"></a>delegate by calling the <code class="literal">GetCompletionAction</code> <a id="id444" class="indexterm"></a> method:</p><div class="informalexample"><pre class="programlisting">internal Action GetCompletionAction&lt;TMethodBuilder, TStateMachine&gt;(
  ref TMethodBuilder builder, ref TStateMachine stateMachine)
  where TMethodBuilder : IAsyncMethodBuilder
  where TStateMachine : IAsyncStateMachine
  {
  ...

    // The builder needs to flow ExecutionContext, so capture it.
    var capturedContext = ExecutionContext.FastCapture();

  ...
}</pre></div><p>So, we capture the current synchronization context and use it to run a continuation code.</p><p><span class="strong"><strong>Synchronization context</strong></span> is another concept that abstracts away the implementation details of some environment that is able to run the code. It can be a Windows Forms environment that runs a <a id="id445" class="indexterm"></a>delegate with the help of the <code class="literal">Control.BeginInvoke</code> method, a WPF environment that can run the code using the <code class="literal">Dispatcher</code> object, or just any <a id="id446" class="indexterm"></a> other framework that needs such an environment to run the code.</p><p>Let's look at the preceding code, specifically at the <code class="literal">awaiter.UnsafeOnCompleted(continuation)</code> part. The C# async infrastructure uses the <code class="literal">TaskAwaiter</code> type for the <code class="literal">awaiter</code> variable, which has the following <code class="literal">UnsafeOnCompleted</code> method:</p><div class="informalexample"><pre class="programlisting">[SecurityCritical]
public void UnsafeOnCompleted(Action continuation)
{
  TaskAwaiter.OnCompletedInternal(m_task,
    continuation,
    continueOnCapturedContext:true,
    flowExecutionContext:false);
}</pre></div><p>You can see that we captured the current synchronization context. However, notice that the <code class="literal">flowExecutionContext</code> parameter is set to <span class="strong"><strong>false</strong></span>. This only means that the execution context flow happens in another place in the code; here we are only capturing the current synchronization context.</p><p>Well, now we understand how the C# asynchronous infrastructure makes the current execution and synchronization contexts run a continuation code. Is it possible to change this behavior? The answer is yes, it is possible. To stop capturing the current synchronization context, we can use the special <code class="literal">ConfigureAwait</code> method on the <code class="literal">Task</code> instance:</p><div class="informalexample"><pre class="programlisting">private static async void Click(object sender, EventArgs e)
{
  _label.Content = "Starting asynchronous operation....";

  await SomeOperationAsync()
<span class="strong"><strong>  .ConfigureAwait(continueOnCapturedContext: false);</strong></span>

  _label.Content = "Asynchronous operation complete!";
}</pre></div><p>Using the <code class="literal">ConfigureAwait</code> method will lead to another awaiter type, <code class="literal">ConfiguredTaskAwaiter</code>. This will be used by the C# asynchronous infrastructure. It implements <code class="literal">UnsafeOnCompleted</code> slightly differently:</p><div class="informalexample"><pre class="programlisting">[SecurityCritical]
public void UnsafeOnCompleted(Action continuation)
{
  TaskAwaiter.OnCompletedInternal(m_task,
    continuation,
    m_continueOnCapturedContext,
    flowExecutionContext: false);
}</pre></div><p>We can see that providing <span class="strong"><strong>false</strong></span> to the <code class="literal">ConfigureAwait</code> method will cause the synchronization<a id="id447" class="indexterm"></a> context to not be captured. If we run the modified application<a id="id448" class="indexterm"></a>  and press the button, we will get a multithreaded UI control access exception.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec66"></a>Performance issues</h2></div></div><hr /></div><p>So far, we have only<a id="id449" class="indexterm"></a> observed problems related to multithreaded access to the UI controls. By default, the C# <code class="literal">await</code> statement will use the current synchronization and execution contexts and post the continuation code to the appropriate environment. Is there any use for the <code class="literal">ConfigureAwait</code> method? Why should we ever try to change the default behavior? To answer this question, consider the following application. This time we will review the whole code including the one that assembles the application:</p><div class="informalexample"><pre class="programlisting">private static Label _label;

[STAThread]
static void Main(string[] args)
{
  var app = new Application();
  var win = new Window();
  var panel = new StackPanel();
  var button = new Button();
  _label = new Label();
  _label.FontSize = 32;
  _label.Height = 200;
  button.Height = 100;
  button.FontSize = 32;
  button.Content = "Start asynchronous operations";
  button.Click += Click;
  panel.Children.Add(_label);
  panel.Children.Add(button);
  win.Content = panel;
  app.Run(win);

  Console.ReadLine();
}</pre></div><p>A thread where we create the UI controls must be a <span class="strong"><strong>Single-Threaded Apartment</strong></span> thread, or <span class="strong"><strong>STA</strong></span>. This term comes<a id="id450" class="indexterm"></a> from Component Object Model (<span class="strong"><strong>COM</strong></span>) and is basically required for <a id="id451" class="indexterm"></a>the UI message loop to be able to interact with COM components. Many OS components, such as system dialogs, use this technology. To make things easier, just remember that the UI thread in .NET and Windows must be marked by the <code class="literal">STAThread</code> attribute.</p><p>Then, we create several UI controls, compose them in the object model, and finally <code class="literal">app.Run(win)</code> shows the application window and starts its message loop:</p><div class="informalexample"><pre class="programlisting">async static void Click(object sender, EventArgs e)
{
  _label.Content = "Calculating...";
  TimeSpan resultWithContext = await Test();
  TimeSpan resultNoContext = await TestNoContext();
  var sb = new StringBuilder();
  sb.AppendLine(string.Format("With the context: {0}", resultWithContext));
  sb.AppendLine(string.Format("Without the context: {0}", resultNoContext));
  sb.AppendLine(string.Format("Ratio: {0:0.00}",
    resultWithContext.TotalMilliseconds / resultNoContext.TotalMilliseconds));

  _label.Content = sb.ToString();
}</pre></div><p>The button click handler <a id="id452" class="indexterm"></a>does a very simple job. It runs two asynchronous operations, gets their results, and then outputs these results to the label control on the main application window. Since we use the <code class="literal">await</code> statement, we can work with the UI controls from the latter code.</p><p>Now to the most important part of this sample—asynchronous performance tests:</p><div class="informalexample"><pre class="programlisting">async static Task&lt;TimeSpan&gt; Test()
{
  const int iterationsNumber = 100000;
  var sw = new Stopwatch();
  sw.Start();
  for (int i = 0; i &lt; iterationsNumber; i++)
  {
    var t = Task.Run(() =&gt; { });
    await t;
  }
  sw.Stop();
  return sw.Elapsed;
}

async static Task&lt;TimeSpan&gt; TestNoContext()
{
  const int iterationsNumber = 100000;
  var sw = new Stopwatch();
  sw.Start();
  for (int i = 0; i &lt; iterationsNumber; i++)
  {
    var t = Task.Run(() =&gt; { });
    <span class="strong"><strong>await t.ConfigureAwait(continueOnCapturedContext: false);</strong></span>
  }
  sw.Stop();
  return sw.Elapsed;
}</pre></div><p>Both tests do almost the same thing. For a large number of iterations, they create a task, wait for its completion, and finally return the whole amount of time taken by the test to run. These two test codes are different only with respect to the <code class="literal">ConfigureAwait</code> method usage in the second test code. However, this subtle difference produces a huge performance effect.</p><p>If we run the program and press the button, we will see quite a noticeable difference between test performances. On a reference machine, the first test is about ten times slower than the<a id="id453" class="indexterm"></a> second one. However, if you run the application again and then, after pressing the button, you start resizing or dragging the application window, you will notice that the first test becomes even slower. I managed to make it twelve times slower than the second test.</p><p>The answer is simple: the first test uses the UI thread to run a continuation code for each of the one hundred thousand iterations, thus posting the same number of messages on the UI message loop. When we resize or drag the main application window, we produce other messages in the UI that make the message loop run slower, and the test becomes slower as well. This is definitely not a good practice and should be controlled using the <code class="literal">ConfigureAwait</code> method call.</p><p>The second test uses the thread pool worker threads to post its continuation code. Since the thread pool is very well optimized for small, short-running tasks, we get good performance here.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note27"></a>Note</h3><p>If you write a library code, always be careful to avoid the synchronization context. If your continuation code does not require this, always use <code class="literal">ConfigureAwait</code> to turn off the synchronization context flow.</p></div><p>After running the preceding code snippet, we get the following output:</p><div class="mediaobject"><img src="graphics/4208_09_01.jpg" /></div><p>Imagine that the first<a id="id454" class="indexterm"></a> test is a third-party code and cannot be modified. Can we do anything about this? People often try to use <code class="literal">ConfigureAwait</code> as in the following example:</p><div class="informalexample"><pre class="programlisting">async static void Click(object sender, EventArgs e)
{
  _label.Content = "Calculating...";

  var dispatcher = Dispatcher.CurrentDispatcher;

  TimeSpan resultWithContext = await Test().ConfigureAwait(false);

  <span class="strong"><strong>TimeSpan resultNoContext = await TestNoContext();</strong></span>
<span class="strong"><strong>  var sb = new StringBuilder();</strong></span>
<span class="strong"><strong>  sb.AppendLine(string.Format("With the context: {0}", resultWithContext));</strong></span>
<span class="strong"><strong>  sb.AppendLine(string.Format("Without the context: {0}", resultNoContext));</strong></span>
<span class="strong"><strong>  sb.AppendLine(string.Format("Ratio: {0:0.00}",</strong></span>
<span class="strong"><strong>    resultWithContext.TotalMilliseconds / resultNoContext.TotalMilliseconds));</strong></span>

<span class="strong"><strong>  dispatcher.Invoke( () =&gt;</strong></span>
<span class="strong"><strong>  {</strong></span>
<span class="strong"><strong>    _label.Content = sb.ToString();</strong></span>
<span class="strong"><strong>  });</strong></span>
}</pre></div><p>Here we had to slightly modify the code to be able to work with the UI control from the thread pool worker thread. Be aware that if we use the <code class="literal">Dispatcher.CurrentDispatcher.Invoke</code> method to set the label text, the code will fail because all the highlighted code runs in a continuation of the first <code class="literal">await</code> statement, and thus runs on the thread pool. So, here we have to get a dispatcher reference before running the asynchronous code.</p><p>However, nothing has<a id="id455" class="indexterm"></a> changed for the <code class="literal">Test</code> method itself. It still captures the current context and uses the UI thread to run all the iterations. To be able to fix the first test, we have to switch the synchronization context to the thread pool before we run this test. A simple workaround will look like this:</p><div class="informalexample"><pre class="programlisting">async static void Click(object sender, EventArgs e)
{
  _label.Content = "Calculating...";

  var dispatcher = Dispatcher.CurrentDispatcher;

  await Task.Delay(1).ConfigureAwait(false);

  <span class="strong"><strong>TimeSpan resultWithContext = await Test();</strong></span>
<span class="strong"><strong>  TimeSpan resultNoContext = await TestNoContext();</strong></span>
<span class="strong"><strong>  var sb = new StringBuilder();</strong></span>
<span class="strong"><strong>  sb.AppendLine(string.Format("With the context: {0}", resultWithContext));</strong></span>
<span class="strong"><strong>  sb.AppendLine(string.Format("Without the context: {0}", resultNoContext));</strong></span>
<span class="strong"><strong>  sb.AppendLine(string.Format("Ratio: {0:0.00}",</strong></span>
<span class="strong"><strong>    resultWithContext.TotalMilliseconds / resultNoContext.TotalMilliseconds));</strong></span>

<span class="strong"><strong>  dispatcher.Invoke( () =&gt;</strong></span>
<span class="strong"><strong>  {</strong></span>
<span class="strong"><strong>    _label.Content = sb.ToString();</strong></span>
<span class="strong"><strong>  });</strong></span>
}</pre></div><p>Now the first test is inside the continuation code, which runs on the thread pool worker thread, and it uses the thread pool synchronization context. If we run the application, we will see that both tests perform more or less equally.</p><p>This trick can be very useful when dealing with poorly written third-party libraries. Unfortunately, usually such problems are very hard to notice at first glance, and you find them accidentally in the profiler while looking for the roots of some other problems.</p><p>After running the preceding code snippet, we get the following output:</p><div class="mediaobject"><img src="graphics/4208_09_02.jpg" /></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec67"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we have seen the implementation details of traditional Windows application UIs that are usually hidden by the programming platform and high-level UI frameworks. We have learned about what the UI thread and message loop are, and why they are very important to keep the UI thread running and not blocking it with long-running code. Then we learned about the common problems of asynchrony in the UI, and how to avoid deadlocks and multithreaded access to the UI controls' exceptions.</p><p>One of the most important topics covered in this chapter was the C# asynchronous infrastructure internals, showing how the <code class="literal">await</code> statement works, and how we can improve application performance by choosing not to keep the current synchronization context.</p><p>In the next chapter, we will look at troubleshooting concurrent programs in greater detail. We will know about many exciting features of Visual Studio for profiling and debugging parallel programs and find out how to catch more errors in the development stage with the help of unit and functional tests.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch10"></a>Chapter 10. Troubleshooting Parallel Programs</h2></div></div></div><p>This chapter is dedicated to parallel program debugging specifics. We will review how concurrent code is different, what additional problems we usually get, and what can be done to find and fix bugs effectively in multithreaded applications.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec68"></a>How troubleshooting parallel programs is different</h2></div></div><hr /></div><p>A concurrent <a id="id456" class="indexterm"></a>program like any usual program can contain programming errors that could lead to incorrect results. However, concurrency usually leads programs to become more complicated, causing errors to be trickier and harder to find. As mentioned in <a class="link" href="#" linkend="ch01">Chapter 1</a>, <span class="emphasis"><em>Traditional Concurrency</em></span>, there are typical problems related to concurrent shared state access—race conditions and deadlocks, but there are many other kinds of problems specific to concurrent programs. While we will not try to describe every kind of problem in detail, since it will take another book to do that, we will instead describe several techniques that allow us to detect and fix problems over the different stages of working with concurrent programs.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec44"></a>Heisenbugs</h3></div></div></div><p>This is one more problem type, not <a id="id457" class="indexterm"></a>strictly related to concurrent programming, but much more common with it, usually referred to as <span class="strong"><strong>heisenbug</strong></span>. This term is <a id="id458" class="indexterm"></a>defined in Wikipedia as follows:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>In computer programming jargon, a heisenbug is a software bug that seems to disappear or alter its behaviour when one attempts to study it. The term is a pun on the name of Werner Heisenberg, the physicist who first asserted the observer effect of quantum mechanics, which states that the act of observing a system inevitably alters its state.</em></span></p></blockquote></div><p>These problems are usually extremely hard to reproduce and debug, since they usually appear in some special conditions such as high user load, or some specific events timing, and more. This is the kind of bug which you will inevitably meet while developing concurrent applications.</p><p>Besides what we have mentioned so far, concurrent programs can have problems related to infrastructure, such as synchronization contexts and UI, performance problems, or any other kind of problems, which are not related to concurrency and multithreading at all.</p><p>To make your <a id="id459" class="indexterm"></a>program less error-prone, you have to use a combined approach that allows the finding and elimination of bugs in the different stages of developing your application from writing code to analyzing logs of production deployment. There<a id="id460" class="indexterm"></a> are three main stages that are crucial to create robust and performant applications:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>Writing tests</strong></span>: This is a <a id="id461" class="indexterm"></a>very important step that can dramatically reduce bugs in your code. With these tests, it is possible to detect problems right after writing the code, or after deploying your application into a test environment.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Debugging</strong></span>: Visual Studio has specific features and tools to make debugging concurrent applications easier.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Performance measurement and profiling</strong></span>: This is one more very important step that can help to detect whether your program spends too much time switching between threads or blocking them instead of doing its job.</p></li></ul></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec69"></a>Writing tests</h2></div></div><hr /></div><p>Tests allow us to detect <a id="id462" class="indexterm"></a>errors at the very early stages of development. They require significant investment in terms of time and effort, but in return they save a lot of time that could be later spent in debugging the application, which is always much harder. There are different kinds of tests that can help to detect different problems in the application.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec45"></a>Load tests</h3></div></div></div><p>If your application has to deal with multiple concurrent users, it is likely that with the increase in the number of users, you will <a id="id463" class="indexterm"></a>experience problems that cannot be revealed in normal conditions. Simulating a large user load and further log analysis, or studying profiling results is always a good idea and a powerful tool to detect potential pitfalls.</p><p>In <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Server-Side Asynchrony</em></span>, we reviewed a couple of ways to organize a load test. To simulate really large user activity, it could be not enough to use a single machine. It is possible to use Visual Studio Online to run a load test using the power of Microsoft Azure to run several virtual machines and use them all to create a test load for your application. You will need a Visual Studio Online account, and you will need to set a special flag in your test <a id="id464" class="indexterm"></a>settings file:</p><div class="mediaobject"><img src="graphics/4208_10_01.jpg" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec46"></a>Unit tests</h3></div></div></div><p>With unit tests, we <a id="id465" class="indexterm"></a>can perform tests on small isolated parts of our code. For example, if we have an <code class="literal">AsyncCounter</code> class that contains some concurrent counter calculations. The first method<a id="id466" class="indexterm"></a> contains a <span class="strong"><strong>race condition</strong></span>, which leads to incorrect counter value calculation:</p><div class="informalexample"><pre class="programlisting">public async Task&lt;int&gt; CountWithRaceConditionAsync()
{
  const int iterations = 10000;
  var counter = 0;
  Action count =
    () =&gt;
    {
      for (int i = 0; i &lt; iterations; i++)
      {
        counter++;
        Thread.SpinWait(100);
        counter--;
      }
    };
  var tasks =
    Enumerable
      .Range(0, 8)
      .Select(n =&gt; Task.Run(count))
      .ToArray();

  await Task.WhenAll(tasks);

  return counter;
}</pre></div><p>The second method is implemented using the <code class="literal">Interlocked</code> operations, and thus does not have problems with <a id="id467" class="indexterm"></a>race conditions:</p><div class="informalexample"><pre class="programlisting">public async Task&lt;int&gt; CountWithInterlockedAsync()
{
  const int iterations = 10000;
  var counter = 0;
  Action count =
    () =&gt;
    {
      for (int i = 0; i &lt; iterations; i++)
      {
        Interlocked.Increment(ref counter);
        Thread.SpinWait(100);
        Interlocked.Decrement(ref counter);
      }
    };
  var tasks =
    Enumerable
      .Range(0, 8)
      .Select(n =&gt; Task.Run(count))
      .ToArray();

  await Task.WhenAll(tasks);

  return counter;
}</pre></div><p>However, the first method can sometimes produce correct results, so an incorrect implementation can make its way into a production code. To prevent this from happening, let's write a test that runs calculations and checks their results. To write tests, we will use the standard Visual Studio unit test project and the Visual Studio Unit Testing Framework. The test to check these counters looks like this:</p><div class="informalexample"><pre class="programlisting">[TestClass]
public class CounterTests
{
  [TestMethod]
  public async Task TestCounterWithRaceCondition()
  {
    var counter = new AsyncCounter();
    int count = await counter.CountWithRaceConditionAsync();
    Assert.AreEqual(0, count);
  }

  [TestMethod]
  public async Task TestCounterWitInterlocked()
  {
    var counter = new AsyncCounter();
    int count = await counter.CountWithInterlockedAsync();
    Assert.AreEqual(0, count);
  }
}</pre></div><p>Notice that the test methods are marked <a id="id468" class="indexterm"></a>as <span class="strong"><strong>async</strong></span> and returned as <code class="literal">Task</code>. This allows us to use <span class="strong"><strong>await</strong></span> inside tests, and<a id="id469" class="indexterm"></a> this is supported in all the major modern unit testing<a id="id470" class="indexterm"></a> frameworks. The <code class="literal">TestClass</code> attribute informs the unit testing framework that this class contains unit tests, and <code class="literal">TestMethod</code> marks a single test.</p><p>To run tests, we navigate to the <span class="strong"><strong>Test</strong></span> | <span class="strong"><strong>Run</strong></span> | <span class="strong"><strong>All Tests…</strong></span> menu option. Then you will see the Test Explorer window that shows the unit test results. The race condition unit test will fail, because we expect it to return 0, but due to the race condition it usually returns some other number. The other test will succeed:</p><div class="mediaobject"><img src="graphics/4208_10_02.jpg" /></div><p>Now let's try to write a test that will detect deadlocks.</p><p>First, we will prepare another asynchronous library, <code class="literal">AsyncLib</code>, that contains two methods. The first method just waits for one second and completes successfully. The second one contains a <a id="id471" class="indexterm"></a>code that intentionally simulates deadlock:</p><div class="informalexample"><pre class="programlisting">public class AsyncLib
{
  public async Task GoodMethodAsync()
  {
    await Task.Delay(TimeSpan.FromSeconds(1));
  }

  public async Task DeadlockMethodAsync()
  {
    var lock1 = new object();
    var lock2 = new object();

    Task task1 = Task.Run(() =&gt;
    {
      lock (lock1)
      {
        Thread.Sleep(200);
        lock (lock2)
        {
        }
      }
    });

    Task task2 = Task.Run(() =&gt;
    {
      lock (lock2)
      {
        Thread.Sleep(200);
        lock (lock1)
        {
        }
      }
    });

    await Task.WhenAll(task1, task2);
  }
}</pre></div><p>To detect a deadlock, we can only check whether an asynchronous method call completes before a certain timeout. We can add an extension method to <code class="literal">Task</code> that will help us to set the expected execution timeout value in milliseconds. After the timeout expires, we will get <code class="literal">TimeoutException</code> if the task is not completed:</p><div class="informalexample"><pre class="programlisting">public static class TaskExtensions
{
  public static async Task TimeoutAfter(this Task task,
    int millisecondsTimeout)
  {
    if (task == await Task.WhenAny(task,
      Task.Delay(millisecondsTimeout)))
    {
      await task;
    }
    else
    {
      throw new TimeoutException();
    }
  }
}</pre></div><p>The unit test code will be very easy—we'll just add a <code class="literal">TimeoutAfter</code> method call to each asynchronous <a id="id472" class="indexterm"></a>function:</p><div class="informalexample"><pre class="programlisting">[TestClass]
public class LockTests
{
  [TestMethod]
  public async Task TestGoodAsync()
  {
    var lib = new AsyncLib();
    await lib.GoodMethodAsync().TimeoutAfter(2000);
  }


  [TestMethod]
  public async Task TestDeadlockAsync()
  {
    var lib = new AsyncLib();
    await lib.DeadlockMethodAsync().TimeoutAfter(2000);
  }
}</pre></div><p>As a result of running this test, we will see that we have detected a deadlock:</p><div class="mediaobject"><img src="graphics/4208_10_03.jpg" /></div><p>Visual Studio has an option to run unit tests after each build. This will make the build process slightly longer, but we will see that unit test fails are similar to compilation errors. This is very<a id="id473" class="indexterm"></a> comfortable and helps to identify a problem as soon as we write the code. The Visual Studio 2013 Ultimate edition has a feature called <span class="strong"><strong>CodeLens</strong></span> that will show unit test errors right beside the code related to the test:</p><div class="mediaobject"><img src="graphics/4208_10_04.jpg" /></div></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec70"></a>Integration tests</h2></div></div><hr /></div><p>A unit test is a very powerful concept that can increase product quality and can be used to find many bugs as soon <a id="id474" class="indexterm"></a>as they appear in the code. However, when your application becomes more and more complicated, testing separate small components is not enough. Many problems appear when we use these components together, and while two asynchronous methods can run well separately, they can cause a deadlock while running simultaneously. This is why it is very important to write higher-level tests for your application that run the application's business logic altogether. Such tests are called integration tests because we check how the application components work together.</p><p>To illustrate this approach, we will take a slightly changed code from <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Server-Side Asynchrony</em></span>. This is an OWIN Web API application, and we will test this with an HTTP API controller:</p><div class="informalexample"><pre class="programlisting">public class HomeController : ApiController
{
  [HttpGet]
  public int Sync()
  {
    var lib = new AsyncHttp();

    return lib.CountCharactersAsync(new Uri("http://google.com")).Result;
  }

  [HttpGet]
  public async Task&lt;int&gt; Async()
  {
    var lib = new AsyncHttp();

    return await lib.CountCharactersAsync(new Uri("http://google.com"));
  }
}</pre></div><p>This controller looks very simple. However, in a real application, controllers are usually the places that contain application logic, and controller actions call several application components and use the results to provide the client with the data needed. Here it is shown how to write an integration test for such a controller, so you can use this approach with your code.</p><p>Referring to <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Server-Side Asynchrony</em></span>, we remember that this controller has a problem. A synchronous call to an asynchronous method could result in a deadlock. So let's write a test that will look for a deadlock here. First, we will need to modify the <code class="literal">TimeoutAfter</code> extension method to deal with the parameterized <code class="literal">Task&lt;T&gt;</code> type. The easiest approach is to use the reactive extensions NuGet package. We will need to reference the <span class="strong"><strong>Reactive Extensions – Core Library</strong></span> package. Then, we can write the following code:</p><div class="informalexample"><pre class="programlisting">public static Task&lt;T&gt; TimeoutAfter&lt;T&gt;(this Task&lt;T&gt; task,
  int millisecondsTimeout)
{
  return task.ToObservable().Timeout(
    TimeSpan.FromMilliseconds(millisecondsTimeout)).ToTask();
}</pre></div><p>Then, we're going to<a id="id475" class="indexterm"></a> write the test. First of all, we need to reference the OWIN Web API NuGet package. Then we need to add one more package, <span class="strong"><strong>Microsoft.Owin.Testing</strong></span>, that hosts the whole OWIN application in memory. Then we will use the new <code class="literal">ClassInitialize</code> and <code class="literal">ClassCleanup</code> attributes to create a test server and get rid of it when the tests complete:</p><div class="informalexample"><pre class="programlisting">[TestClass]
public class ServerInMemoryTests
{
  private static TestServer _server;
  private static HttpClient _client;

  [ClassInitialize]
  public static void ClassInit(TestContext context)
  {
    _server = TestServer.Create&lt;Startup&gt;();
    _client = _server.HttpClient;
  }

  [TestMethod]
  public async Task TestSyncAction()
  {
    var response = await _client.GetAsync("/api/Home/Sync")
.TimeoutAfter(2000);

    var result = await response.Content.ReadAsAsync&lt;int&gt;();

    Assert.IsTrue(result &gt; 0);
  }

  [TestMethod]
  public async Task TestAsyncAction()
  {
    var response = await _client.GetAsync("/api/Home/Async")
.TimeoutAfter(2000);

    var result = await response.Content.ReadAsAsync&lt;int&gt;();

    Assert.IsTrue(result &gt; 0);
  }

  [ClassCleanup]
  public static void ClassCleanup()
  {
    _server.Dispose();
  }
}</pre></div><p>This test establishes the OWIN pipeline in memory and uses a regular <code class="literal">HttpClient</code> class to simulate http calls to <code class="literal">HomeController</code> by expecting to get a greater than zero number.</p><p>However, when we<a id="id476" class="indexterm"></a> run this test, we are going to find out that everything is fine and no deadlock will be found:</p><div class="mediaobject"><img src="graphics/4208_10_05.jpg" /></div><p>The reason why there is no deadlock here is that the deadlock was related to the synchronization context in the ASP.NET environment, and this test used in-memory hosting. However, we can detect here any application component's interaction issues, and this kind of test is also good to run after each build in Visual Studio.</p><p>To detect infrastructure issues, we have to test the application by running it in the same environment that will be used in production. Fortunately, this is quite easy to do. Instead of creating an in-memory host, we just need to run our application and slightly modify the test code to use a real http interaction:</p><div class="informalexample"><pre class="programlisting">[TestClass]public class ServerHttpTests
{
  private static HttpClient _client;

  [ClassInitialize]
  public static void ClassInit(TestContext context)
  {
    _client = new HttpClient();
    _client.BaseAddress = new Uri("http://localhost:1845/");
  }

  [TestMethod]
  public async Task TestSyncAction()
  {
    var response = await _client.GetAsync("/api/Home/Sync")
.TimeoutAfter(2000);

    var result = await response.Content.ReadAsAsync&lt;int&gt;();

    Assert.IsTrue(result &gt; 0);
  }

  [TestMethod]
  public async Task TestAsyncAction()
  {
    var response = await _client.GetAsync("/api/Home/Async")
.TimeoutAfter(2000);
    var result = await response.Content.ReadAsAsync&lt;int&gt;();

    Assert.IsTrue(result &gt; 0);
  }

  [ClassCleanup]
  public static void ClassCleanup()
  {
    _client.Dispose();
  }
}</pre></div><p>Notice that the test <a id="id477" class="indexterm"></a>code remains the same. We have only changed the <code class="literal">HttpClient</code> instance. Here we just point it to our application URL, and this is all that we have changed. Now the test detects a deadlock where we expected it to occur:</p><div class="mediaobject"><img src="graphics/4208_10_06.jpg" /></div><p>This kind of test is<a id="id478" class="indexterm"></a> not intended to be run along with the built-in Visual Studio. The proper place to run these tests is your continuous integration process, when you create a new build on your build server, deploy the application into a test environment, configure it and pre-populate data storage with some test data, and then run a test suite on this application instance.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip05"></a>Tip</h3><p>The testing stage is very important, because it is much harder to find problems in the debugging or profiling stage. Investing in tests can help to save a lot of further efforts to find out what is wrong with the application, and greatly reduce the number of problems that get into the production environment.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec71"></a>Debugging</h2></div></div><hr /></div><p>Debugging as a very<a id="id479" class="indexterm"></a> extensive topic and there are several books about debugging .NET applications techniques. Here we will review how we can start debugging with Visual Studio, and what tools can help us to debug concurrent applications.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec47"></a>Just my code setting</h3></div></div></div><p>There is a very<a id="id480" class="indexterm"></a> important setting located in the <span class="strong"><strong>Debug, Options and Settings…</strong></span> menu called <span class="strong"><strong>Enable Just My Code</strong></span>:</p><div class="mediaobject"><img src="graphics/4208_10_07.jpg" /></div><p>When this setting is enabled, Visual Studio tries to hide additional information such as compiler-generated code and does not show this in debugging windows, concentrating only on the information related to your code. This seems comfortable, but do not forget that you can always turn it off and study the whole picture in case you need to dig into the infrastructure code.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec48"></a>Call stack window</h3></div></div></div><p>One of the easiest<a id="id481" class="indexterm"></a> debugging tools in Visual Studio is the <span class="strong"><strong>call stack</strong></span> window. An asynchronous method call usually consists of two parts—begin and end operation. If you have a breakpoint inside an asynchronous method body, it is not easy to find out where this operation has been initiated. Fortunately, if you have the latest Visual Studio 2013 installed at least on Windows 8.1 or Windows 2012R2, the call stack window will show you a full call stack including the asynchronous operation starting point.</p><p>We may run this code under the debugger, as follows:</p><div class="informalexample"><pre class="programlisting">class Program
{
  static void Main(string[] args)
  {
    StartAsyncOperation().GetAwaiter().GetResult();
  }

  public static async Task StartAsyncOperation()
  {
    Console.WriteLine("Starting async operation");
    await AsyncOperation();
    Console.WriteLine("After finishing async operation");
  }

  public static async Task AsyncOperation()
  {
    Console.WriteLine("Inside async operation");
    await Task.Delay(TimeSpan.FromSeconds(1));

    Console.WriteLine("Async operation complete!");
  }
}</pre></div><p>In this case, we will see<a id="id482" class="indexterm"></a> in the call stack window that the operation has been initiated in the <code class="literal">StartAsyncOperation</code> method:</p><div class="mediaobject"><img src="graphics/4208_10_08.jpg" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec49"></a>Threads window</h3></div></div></div><p>Another useful Visual Studio <a id="id483" class="indexterm"></a>debugging feature is the <span class="strong"><strong>Threads</strong></span> window. It shows the current threads in the application and allows us to suspend and resume any thread with corresponding buttons and filter threads by marking them with flags and pressing the double flag button:</p><div class="mediaobject"><img src="graphics/4208_10_09.jpg" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec50"></a>Tasks window</h3></div></div></div><p>With the <span class="strong"><strong>Tasks</strong></span> window, it is <a id="id484" class="indexterm"></a>possible to review incomplete TPL tasks and see the different information about them:</p><div class="mediaobject"><img src="graphics/4208_10_10.jpg" /></div><p>The <span class="strong"><strong>Tasks</strong></span> window has<a id="id485" class="indexterm"></a> deadlock diagnostics that inform us about tasks that are deadlocked. To see it in action, we have to run the following code until a deadlock occurs and then press the break button on the debugger toolbar:</p><div class="informalexample"><pre class="programlisting">class Program
{
  static void Main(string[] args)
  {
    DeadlockMethodAsync().GetAwaiter().GetResult();
  }

  public static async Task DeadlockMethodAsync()
  {
    var lock1 = new object();
    var lock2 = new object();

    Task task1 = Task.Run(() =&gt;
    {
      lock (lock1)
      {
        Thread.Sleep(200);
        lock (lock2)
        {
        }
      }
    });

    Task task2 = Task.Run(() =&gt;
    {
      lock (lock2)
      {
        Thread.Sleep(200);
        Debugger.Break();
        lock (lock1)
        {
        }
      }
    });

    Debugger.Break();
    // here you can open Tasks window in Visual Studio
    await Task.WhenAll(task1, task2);
  }
}</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec51"></a>Parallel stacks window</h3></div></div></div><p>To visualize an <a id="id486" class="indexterm"></a>asynchronous program flow, we can use the <span class="strong"><strong>Parallel Stacks</strong></span> window. Let's run a simple parallel <code class="literal">foreach</code> loop:</p><div class="informalexample"><pre class="programlisting">class Program
{
  static void Main(string[] args)
  {
    ParallelForEach().GetAwaiter().GetResult();
  }

  public static async Task ParallelForEach()
  {
    Parallel.ForEach(Enumerable.Range(0, 32), i =&gt;
    {
      Console.WriteLine(i);
      if (i == 24)
      {
        Debugger.Break();
      }
      Thread.Sleep(new Random(i).Next(100, 500));
    });
  }
}</pre></div><p>This screenshot has been made <a id="id487" class="indexterm"></a>on a virtual machine with six core CPUs. We see that one of the tasks was scheduled to run on the main thread:</p><div class="mediaobject"><img src="graphics/4208_10_11.jpg" /></div><p>If we turn off the <span class="strong"><strong>Enable Just My Code</strong></span> setting, we will see more details about how the concurrent program is organized.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec72"></a>Performance measurement and profiling</h2></div></div><hr /></div><p>There is a profiler in <a id="id488" class="indexterm"></a>Visual Studio that can be used to visualize concurrency in your application and see what is going on. Depending on the Visual Studio version, its behavior is different. In Visual Studio 2010, you would just run a profiler session collecting concurrency data and get the required result. In Visual Studio 2012, there was a separate menu option called <span class="strong"><strong>Concurrency Visualizer</strong></span> and this is the most comfortable way<a id="id489" class="indexterm"></a> to look at concurrency processes in your application.</p><p>In Visual Studio 2013, there is no Concurrency Visualizer option by default, and you can still use the regular profiler to collect the basic concurrency information. However, you can install Concurrency Visualizer separately.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec52"></a>The Concurrency Visualizer</h3></div></div></div><p>The Concurrency Visualizer is<a id="id490" class="indexterm"></a> available for Visual Studio 2013 as a separate extension. You can install it in Visual Studio:</p><div class="mediaobject"><img src="graphics/4208_10_12.jpg" /></div><p>After the installation, you will get a <span class="strong"><strong>Concurrency Visualizer</strong></span> menu option under the <span class="strong"><strong>Analyze</strong></span> menu in Visual Studio:</p><div class="mediaobject"><img src="graphics/4208_10_13.jpg" /></div><p>Concurrency Visualizer<a id="id491" class="indexterm"></a> provides a lot of useful information. To illustrate this, let's compare the parallelism granularity test from <a class="link" href="#" linkend="ch03">Chapter 3</a>, <span class="emphasis"><em>Understanding Parallelism Granularity</em></span>, and I/O threads from <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Server-Side Asynchrony</em></span>. The first program under Concurrency Visualizer will look like this:</p><div class="mediaobject"><img src="graphics/4208_10_14.jpg" /></div><p>It can be clearly seen that the program consumes a lot of CPU resources. Now if we visualize I/O threads, we <a id="id492" class="indexterm"></a>will see that it consumes almost no CPU resources:</p><div class="mediaobject"><img src="graphics/4208_10_15.jpg" /></div><p>We can see more details if we go to the <span class="strong"><strong>Threads</strong></span> tab inside the report. The granularity program shows a significant CPU load, as shown here:</p><div class="mediaobject"><img src="graphics/4208_10_16.jpg" /></div><p>However, the I/O threads report indicates that about half of the program time threads are in the blocked state:</p><div class="mediaobject"><img src="graphics/4208_10_17.jpg" /></div><p>There is a lot of data in this report, and if you run a profiler session to collect concurrency information, you can get even more details. But this is just the starting point where you can see what is going<a id="id493" class="indexterm"></a> on in the program, and depending on the information received in the report, you can further investigate why the program does not use all the CPU computational power, or why it spends a lot of time in synchronization process.</p></div></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec73"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we learned about the different stages of application development where we can detect and fix problems in concurrent applications. We reviewed different testing techniques that help to prevent bugs from getting into the application code. We learned to use asynchronous unit tests, host an OWIN Web API application in memory, test HTTP API controllers, and also adapt these tests to run on the real http application hosted on a web server in a test environment.</p><p>We have reviewed different debugging tools included in Visual Studio. These tools help us to visualize the concurrent program workflow, show information about currently running TPL tasks, detect deadlocks, allow us to pause and resume threads, see the details of each thread, and help us to use asynchronous call stacks in a comfortable way, so it is clear where the current asynchronous operation has been started.</p><p>We also installed a Concurrency Visualizer extension in Visual Studio 2013 and used it to find out what is going on in the concurrent application, how much time the application spends synchronizing, blocking threads, and doing CPU-bound work.</p></div></div></div></div>
﻿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">

    <div id="backindex">
      <h1 class="title">Index</h1>
      <h2>A</h2>
      <ul>
        <li>ABA problem<ul><li>about / <a href="#ch02lvl1sec17" title="The ABA problem" class="link">The ABA problem</a></li></ul></li>
        <li>acquire fence<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>async / <a href="#ch10lvl1sec69" title="Unit tests" class="link">Unit tests</a></li>
        <li>async/await infrastructure<ul><li>about / <a href="#ch07lvl1sec49" title="Concurrent idioms" class="link">Concurrent idioms</a></li></ul></li>
        <li>async/await statements / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li>
        <li>asynchronous I/O<ul><li>about / <a href="#ch08lvl1sec57" title="Deep dive into asynchronous I/O" class="link">Deep dive into asynchronous I/O</a></li></ul></li>
        <li>asynchronous patterns<ul><li>about / <a href="#ch07lvl1sec50" title="Asynchronous patterns" class="link">Asynchronous patterns</a></li><li>Asynchronous Programming Model (APM) / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li><li>Event-based Asynchronous Pattern (EAP) / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li><li>Task-based Asynchronous Pattern (TAP) / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li></ul></li>
        <li>Asynchronous Programming Model (APM)<ul><li>about / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li><li>features / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li></ul></li>
        <li>asynchrony, for UI<ul><li>importance / <a href="#ch09lvl1sec62" title="The importance of asynchrony for UI" class="link">The importance of asynchrony for UI</a></li></ul></li>
        <li>async keyword<ul><li>about / <a href="#ch05lvl1sec34" title="Is the async keyword really needed?" class="link">Is the async keyword really needed?</a></li></ul></li>
        <li>async over sync / <a href="#ch08lvl1sec58" title="Real and fake asynchronous I/O operations" class="link">Real and fake asynchronous I/O operations</a></li>
        <li>atomic<ul><li>about / <a href="#ch02lvl1sec15" title="The System.Threading.Interlocked class" class="link">The System.Threading.Interlocked class</a></li></ul></li>
        <li>await / <a href="#ch10lvl1sec69" title="Unit tests" class="link">Unit tests</a></li>
        <li>awaiting task completion<ul><li>about / <a href="#ch04lvl1sec27" title="Awaiting task completion" class="link">Awaiting task completion</a></li></ul></li>
        <li>await keyword<ul><li>working / <a href="#ch09lvl1sec65" title="How the await keyword works" class="link">How the await keyword works</a></li></ul></li>
        <li>await statement / <a href="#ch07lvl1sec49" title="Setting a task timeout" class="link">Setting a task timeout</a></li>
      </ul>
      <h2>B</h2>
      <ul>
        <li>Bing<ul><li>downloading of images, implementing from / <a href="#ch05lvl1sec33" title="Implementing the downloading of images from Bing" class="link">Implementing the downloading of images from Bing</a></li><li>URL / <a href="#ch05lvl1sec33" title="Implementing the downloading of images from Bing" class="link">Implementing the downloading of images from Bing</a></li></ul></li>
        <li>blocking queue / <a href="#ch06lvl1sec46" title="Custom Producer/Consumer pattern implementation" class="link">Custom Producer/Consumer pattern implementation</a></li>
        <li>bounded queue / <a href="#ch06lvl1sec46" title="Custom Producer/Consumer pattern implementation" class="link">Custom Producer/Consumer pattern implementation</a></li>
      </ul>
      <h2>C</h2>
      <ul>
        <li>C# 5.0 built-in support, for asynchrony<ul><li>code, enhancing with / <a href="#ch05lvl1sec33" title="Enhancing the code with C# 5.0 built-in support for asynchrony" class="link">Enhancing the code with C# 5.0 built-in support for asynchrony</a></li></ul></li>
        <li>C# asynchronous infrastructure<ul><li>simulating, with iterators / <a href="#ch05lvl1sec33" title="Simulating C# asynchronous infrastructure with iterators" class="link">Simulating C# asynchronous infrastructure with iterators</a></li></ul></li>
        <li>cache<ul><li>implementing, with ReaderWriterLockSlim / <a href="#ch06lvl1sec40" title="Implementing a cache with ReaderWriterLockSlim" class="link">Implementing a cache with ReaderWriterLockSlim</a></li></ul></li>
        <li>cache aside pattern / <a href="#ch06lvl1sec40" title="Implementing a cache with ReaderWriterLockSlim" class="link">Implementing a cache with ReaderWriterLockSlim</a></li>
        <li>callbacks<ul><li>used, for task cancellation / <a href="#ch04lvl1sec28" title="Cancellation using callbacks" class="link">Cancellation using callbacks</a></li></ul></li>
        <li>class constraint<ul><li>about / <a href="#ch02lvl1sec17" title="The lock-free stack" class="link">The lock-free stack</a></li></ul></li>
        <li>coarse-grained approach<ul><li>about / <a href="#ch03lvl1sec22" title="Understanding granularity" class="link">Understanding granularity</a></li><li>selecting / <a href="#ch03lvl1sec23" title="Choosing the coarse-grained or fine-grained approach" class="link">Choosing the coarse-grained or fine-grained approach</a></li></ul></li>
        <li>coarse-grained approach, with TPL<ul><li>about / <a href="#ch04lvl1sec29" title="Latency and the coarse-grained approach with TPL" class="link">Latency and the coarse-grained approach with TPL</a></li></ul></li>
        <li>coarse-grained locking / <a href="#ch06lvl1sec41" title="Concurrent collections in .NET" class="link">Concurrent collections in .NET</a></li>
        <li>code coupling<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a></li></ul></li>
        <li>common problems<ul><li>about / <a href="#ch09lvl1sec64" title="Common problems and solutions" class="link">Common problems and solutions</a></li><li>solutions / <a href="#ch09lvl1sec64" title="Common problems and solutions" class="link">Common problems and solutions</a></li></ul></li>
        <li>compare-and-swap (CAS) / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a></li>
        <li>compare and swap (CAS)<ul><li>about / <a href="#ch02lvl1sec17" title="The ABA problem" class="link">The ABA problem</a></li></ul></li>
        <li>compiler optimizations<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>Component Object Model (COM) / <a href="#ch09lvl1sec66" title="Performance issues" class="link">Performance issues</a></li>
        <li>Concurrency Visualizer<ul><li>about / <a href="#ch10lvl1sec72" title="The Concurrency Visualizer" class="link">The Concurrency Visualizer</a></li></ul></li>
        <li>ConcurrentBag&lt;T&gt;<ul><li>about / <a href="#ch06lvl1sec43" title="ConcurrentBag&lt;T&gt;" class="link">ConcurrentBag&lt;T&gt;</a></li><li>using / <a href="#ch06lvl1sec43" title="ConcurrentBag in practice" class="link">ConcurrentBag in practice</a></li></ul></li>
        <li>ConcurrentDictionary<ul><li>about / <a href="#ch06lvl1sec42" title="ConcurrentDictionary" class="link">ConcurrentDictionary</a></li><li>Lazy&lt;T&gt; / <a href="#ch06lvl1sec42" title="Using Lazy&lt;T&gt;" class="link">Using Lazy&lt;T&gt;</a></li><li>details, implementing / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a></li><li>implementation details, using / <a href="#ch06lvl1sec42" title="Using the implementation details in practice" class="link">Using the implementation details in practice</a></li></ul></li>
        <li>ConcurrentDictionary class<ul><li>lock-free operations / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a>, <a href="#ch06lvl1sec42" title="Lock-free operations" class="link">Lock-free operations</a></li><li>fine-grained lock operations / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a>, <a href="#ch06lvl1sec42" title="Fine-grained lock operations" class="link">Fine-grained lock operations</a></li><li>exclusive lock operations / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a>, <a href="#ch06lvl1sec42" title="Exclusive lock operations" class="link">Exclusive lock operations</a></li></ul></li>
        <li>concurrent idioms<ul><li>about / <a href="#ch07lvl1sec49" title="Concurrent idioms" class="link">Concurrent idioms</a></li><li>Process Tasks, in Completion Order / <a href="#ch07lvl1sec49" title="Process Tasks in Completion Order" class="link">Process Tasks in Completion Order</a></li><li>parallelism degree, limiting / <a href="#ch07lvl1sec49" title="Limiting the parallelism degree" class="link">Limiting the parallelism degree</a></li><li>task timeout, setting / <a href="#ch07lvl1sec49" title="Setting a task timeout" class="link">Setting a task timeout</a></li></ul></li>
        <li>concurrent patterns<ul><li>about / <a href="#ch07lvl1sec51" title="Concurrent patterns" class="link">Concurrent patterns</a></li></ul></li>
        <li>ConcurrentQueue&lt;T&gt;<ul><li>about / <a href="#ch06lvl1sec44" title="ConcurrentQueue&lt;T&gt;" class="link">ConcurrentQueue&lt;T&gt;</a></li></ul></li>
        <li>ConcurrentStack&lt;T&gt;<ul><li>about / <a href="#ch06lvl1sec45" title="ConcurrentStack&lt;T&gt;" class="link">ConcurrentStack&lt;T&gt;</a></li></ul></li>
        <li>continuation task<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a></li></ul></li>
        <li>CPU-bound tasks and queues<ul><li>about / <a href="#ch08lvl1sec60" title="CPU-bound tasks and queues" class="link">CPU-bound tasks and queues</a></li></ul></li>
        <li>custom awaitable type<ul><li>implementing / <a href="#ch05lvl1sec37" title="Implementing a custom awaitable type" class="link">Implementing a custom awaitable type</a></li></ul></li>
        <li>CustomProvider class / <a href="#ch06lvl1sec40" title="Implementing a cache with ReaderWriterLockSlim" class="link">Implementing a cache with ReaderWriterLockSlim</a></li>
      </ul>
      <h2>D</h2>
      <ul>
        <li>deadlock<ul><li>about / <a href="#ch01lvl1sec08" title="What's the problem?" class="link">What's the problem?</a></li></ul></li>
        <li>debugging<ul><li>about / <a href="#ch10lvl1sec71" title="Debugging" class="link">Debugging</a></li><li>Enable Just My Code setting / <a href="#ch10lvl1sec71" title="Just my code setting" class="link">Just my code setting</a></li><li>call stack window / <a href="#ch10lvl1sec71" title="Call stack window" class="link">Call stack window</a></li><li>threads window / <a href="#ch10lvl1sec71" title="Threads window" class="link">Threads window</a></li><li>Tasks window / <a href="#ch10lvl1sec71" title="Tasks window" class="link">Tasks window</a></li><li>parallel stacks window / <a href="#ch10lvl1sec71" title="Parallel stacks window" class="link">Parallel stacks window</a></li></ul></li>
        <li>double checked locking pattern<ul><li>about / <a href="#ch02lvl1sec17" title="The lock-free queue" class="link">The lock-free queue</a></li></ul></li>
        <li>downloading of images, implementing from Bing<ul><li>about / <a href="#ch05lvl1sec33" title="Implementing the downloading of images from Bing" class="link">Implementing the downloading of images from Bing</a></li><li>simple synchronous solution, creating / <a href="#ch05lvl1sec33" title="Creating a simple synchronous solution" class="link">Creating a simple synchronous solution</a></li><li>parallel solution, creating with Task Parallel Library / <a href="#ch05lvl1sec33" title="Creating a parallel solution with Task Parallel Library" class="link">Creating a parallel solution with Task Parallel Library</a></li><li>code, enhancing with C# 5.0 built-in support / <a href="#ch05lvl1sec33" title="Enhancing the code with C# 5.0 built-in support for asynchrony" class="link">Enhancing the code with C# 5.0 built-in support for asynchrony</a></li><li>C# asynchronous infrastructure, simulating with iterators / <a href="#ch05lvl1sec33" title="Simulating C# asynchronous infrastructure with iterators" class="link">Simulating C# asynchronous infrastructure with iterators</a></li></ul></li>
      </ul>
      <h2>E</h2>
      <ul>
        <li>EditBin.exe tool / <a href="#ch03lvl1sec20" title="The number of threads" class="link">The number of threads</a></li>
        <li>Enqueue method / <a href="#ch06lvl1sec44" title="ConcurrentQueue&lt;T&gt;" class="link">ConcurrentQueue&lt;T&gt;</a></li>
        <li>Event-based Asynchronous Pattern (EAP)<ul><li>about / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li><li>features / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li></ul></li>
        <li>exception handling<ul><li>about / <a href="#ch04lvl1sec30" title="Exception handling" class="link">Exception handling</a></li></ul></li>
        <li>exclusive lock operations / <a href="#ch06lvl1sec42" title="Exclusive lock operations" class="link">Exclusive lock operations</a></li>
        <li>execution context / <a href="#ch09lvl1sec65" title="Execution and synchronization contexts" class="link">Execution and synchronization contexts</a></li>
      </ul>
      <h2>F</h2>
      <ul>
        <li>fake asynchronous I/O operations<ul><li>about / <a href="#ch08lvl1sec58" title="Real and fake asynchronous I/O operations" class="link">Real and fake asynchronous I/O operations</a></li></ul></li>
        <li>features, Asynchronous Programming Model (APM)<ul><li>low-level pattern / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li><li>low performance overhead / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li><li>complicated implementation / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li><li>coupling, between asynchronous operation provider and consumer / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li></ul></li>
        <li>features, Event-based Asynchronous Pattern (EAP)<ul><li>high-level pattern / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li><li>high overhead / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li><li>intended for UI components / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li><li>complicated implementation / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li><li>couping, between asynchronous operation provider and consumers / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li></ul></li>
        <li>features, Task-based Asynchronous Pattern (TAP)<ul><li>low overhead / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li><li>high-level / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li><li>comfortable to use / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li><li>language support, in C#/VB / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li><li>Task and Task&lt;T&gt; are first-class objects / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li><li>avoidance, of side effects / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li></ul></li>
        <li>fine-grained approach<ul><li>about / <a href="#ch03lvl1sec22" title="Understanding granularity" class="link">Understanding granularity</a></li><li>selecting / <a href="#ch03lvl1sec23" title="Choosing the coarse-grained or fine-grained approach" class="link">Choosing the coarse-grained or fine-grained approach</a></li></ul></li>
        <li>fine-grained lock operations / <a href="#ch06lvl1sec42" title="Fine-grained lock operations" class="link">Fine-grained lock operations</a></li>
        <li>fire-and-forget tasks<ul><li>about / <a href="#ch05lvl1sec35" title="Fire-and-forget tasks" class="link">Fire-and-forget tasks</a></li></ul></li>
        <li>foreach loop / <a href="#ch07lvl1sec49" title="Process Tasks in Completion Order" class="link">Process Tasks in Completion Order</a></li>
        <li>fork/join pattern<ul><li>about / <a href="#ch07lvl1sec51" title="Concurrent patterns" class="link">Concurrent patterns</a></li></ul></li>
        <li>future<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a></li></ul></li>
      </ul>
      <h2>G</h2>
      <ul>
        <li>4-gigabyte tuning / <a href="#ch03lvl1sec20" title="The number of threads" class="link">The number of threads</a></li>
        <li>granularity<ul><li>about / <a href="#ch03lvl1sec22" title="Understanding granularity" class="link">Understanding granularity</a></li></ul></li>
      </ul>
      <h2>H</h2>
      <ul>
        <li>heisenbugs<ul><li>about / <a href="#ch10lvl1sec68" title="Heisenbugs" class="link">Heisenbugs</a></li></ul></li>
        <li>high coupling<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a></li></ul></li>
        <li>Hyper-Threading technology / <a href="#ch03lvl1sec20" title="The number of threads" class="link">The number of threads</a></li>
        <li>hyperthreading technology / <a href="#ch09lvl1sec62" title="The importance of asynchrony for UI" class="link">The importance of asynchrony for UI</a></li>
      </ul>
      <h2>I</h2>
      <ul>
        <li>I/O and CPU-bound tasks / <a href="#ch08lvl1sec56" title="I/O and CPU-bound tasks" class="link">I/O and CPU-bound tasks</a></li>
        <li>I/O Completion Port (IOCP) / <a href="#ch08lvl1sec56" title="I/O and CPU-bound tasks" class="link">I/O and CPU-bound tasks</a></li>
        <li>input/output threads / <a href="#ch03lvl1sec21" title="Using the thread pool" class="link">Using the thread pool</a></li>
        <li>integration tests<ul><li>about / <a href="#ch10lvl1sec70" title="Integration tests" class="link">Integration tests</a></li></ul></li>
        <li>interlocked internals<ul><li>working / <a href="#ch02lvl1sec16" title="Interlocked internals" class="link">Interlocked internals</a></li></ul></li>
      </ul>
      <h2>L</h2>
      <ul>
        <li>latency approach, with TPL<ul><li>about / <a href="#ch04lvl1sec29" title="Latency and the coarse-grained approach with TPL" class="link">Latency and the coarse-grained approach with TPL</a></li></ul></li>
        <li>legacy code support scenario / <a href="#ch07lvl1sec50" title="Event-based Asynchronous Pattern" class="link">Event-based Asynchronous Pattern</a></li>
        <li>load testing / <a href="#ch08lvl1sec55" title="Load testing and scalability" class="link">Load testing and scalability</a></li>
        <li>lock-free code<ul><li>writing / <a href="#ch02lvl1sec17" title="Writing lock-free code" class="link">Writing lock-free code</a></li></ul></li>
        <li>lock-free operations / <a href="#ch06lvl1sec42" title="Lock-free operations" class="link">Lock-free operations</a></li>
        <li>lock-free queue<ul><li>about / <a href="#ch02lvl1sec17" title="The lock-free queue" class="link">The lock-free queue</a></li></ul></li>
        <li>lock-free stack<ul><li>about / <a href="#ch02lvl1sec17" title="The lock-free stack" class="link">The lock-free stack</a></li></ul></li>
        <li>lock localization<ul><li>about / <a href="#ch01lvl1sec12" title="Lock localization" class="link">Lock localization</a></li></ul></li>
        <li>locks<ul><li>using / <a href="#ch01lvl1sec09" title="Using locks" class="link">Using locks</a></li></ul></li>
        <li>lock statement<ul><li>about / <a href="#ch01lvl1sec09" title="Lock statement" class="link">Lock statement</a></li></ul> / <a href="#ch06lvl1sec39" title="Standard collections and synchronization primitives" class="link">Standard collections and synchronization primitives</a></li>
        <li>low coupling<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a></li></ul></li>
      </ul>
      <h2>M</h2>
      <ul>
        <li>memory barrier<ul><li>about / <a href="#ch01lvl1sec11" title="System.Threading.SpinLock" class="link">System.Threading.SpinLock</a>, <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>memory model<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>message loop / <a href="#ch09lvl1sec63" title="UI threads and message loops" class="link">UI threads and message loops</a></li>
        <li>message pump / <a href="#ch09lvl1sec63" title="UI threads and message loops" class="link">UI threads and message loops</a></li>
        <li>Monitor class<ul><li>about / <a href="#ch01lvl1sec09" title="Monitor class" class="link">Monitor class</a></li></ul></li>
        <li>mutex synchronization primitive<ul><li>about / <a href="#ch02lvl1sec17" title="The lock-free stack" class="link">The lock-free stack</a></li></ul></li>
      </ul>
      <h2>N</h2>
      <ul>
        <li>.NET<ul><li>concurrent collections / <a href="#ch06lvl1sec41" title="Concurrent collections in .NET" class="link">Concurrent collections in .NET</a></li></ul></li>
        <li>.NET 4.0+<ul><li>Producer/Consumer pattern / <a href="#ch06lvl1sec47" title="The Producer/Consumer pattern in .NET 4.0+" class="link">The Producer/Consumer pattern in .NET 4.0+</a></li></ul></li>
      </ul>
      <h2>O</h2>
      <ul>
        <li>only for legacy code support scenario / <a href="#ch07lvl1sec50" title="Asynchronous Programming Model" class="link">Asynchronous Programming Model</a></li>
        <li>optimization strategy<ul><li>about / <a href="#ch01lvl1sec12" title="Optimization strategy" class="link">Optimization strategy</a></li><li>lock localization / <a href="#ch01lvl1sec12" title="Lock localization" class="link">Lock localization</a></li><li>shared data minimization / <a href="#ch01lvl1sec12" title="Shared data minimization" class="link">Shared data minimization</a></li></ul></li>
        <li>OS wait objects<ul><li>using, with WaitHandle / <a href="#ch04lvl1sec28" title="Using OS wait objects with WaitHandle" class="link">Using OS wait objects with WaitHandle</a></li></ul></li>
        <li>OWIN Web API framework<ul><li>about / <a href="#ch08lvl1sec54" title="The OWIN Web API framework" class="link">The OWIN Web API framework</a></li></ul></li>
      </ul>
      <h2>P</h2>
      <ul>
        <li>Parallel class<ul><li>using / <a href="#ch04lvl1sec31" title="Using the Parallel class" class="link">Using the Parallel class</a></li><li>Parallel.Invoke method / <a href="#ch04lvl1sec31" title="Parallel.Invoke" class="link">Parallel.Invoke</a></li><li>Parallel.For method / <a href="#ch04lvl1sec31" title="Parallel.For and Parallel.Foreach" class="link">Parallel.For and Parallel.Foreach</a></li><li>Parallel.Foreach method / <a href="#ch04lvl1sec31" title="Parallel.For and Parallel.Foreach" class="link">Parallel.For and Parallel.Foreach</a></li></ul></li>
        <li>parallel pipeline<ul><li>about / <a href="#ch07lvl1sec51" title="Concurrent patterns" class="link">Concurrent patterns</a></li><li>implementing / <a href="#ch07lvl1sec51" title="Parallel pipelines" class="link">Parallel pipelines</a></li></ul></li>
        <li>parallel programs<ul><li>troubleshooting / <a href="#ch10lvl1sec68" title="How troubleshooting parallel programs is different" class="link">How troubleshooting parallel programs is different</a></li><li>heisenbugs / <a href="#ch10lvl1sec68" title="Heisenbugs" class="link">Heisenbugs</a></li></ul></li>
        <li>parallel solution<ul><li>creating, with Task Parallel Library / <a href="#ch05lvl1sec33" title="Creating a parallel solution with Task Parallel Library" class="link">Creating a parallel solution with Task Parallel Library</a></li></ul></li>
        <li>performance issues / <a href="#ch09lvl1sec66" title="Performance issues" class="link">Performance issues</a></li>
        <li>performance measurement<ul><li>about / <a href="#ch10lvl1sec72" title="Performance measurement and profiling" class="link">Performance measurement and profiling</a></li></ul></li>
        <li>PLINQ / <a href="#ch06lvl1sec41" title="Concurrent collections in .NET" class="link">Concurrent collections in .NET</a></li>
        <li>producer/consumer pattern<ul><li>about / <a href="#ch07lvl1sec51" title="Concurrent patterns" class="link">Concurrent patterns</a></li></ul></li>
        <li>Producer/Consumer pattern<ul><li>about / <a href="#ch06lvl1sec46" title="The Producer/Consumer pattern" class="link">The Producer/Consumer pattern</a></li><li>implementing / <a href="#ch06lvl1sec46" title="Custom Producer/Consumer pattern implementation" class="link">Custom Producer/Consumer pattern implementation</a></li><li>in .NET 4.0+ / <a href="#ch06lvl1sec47" title="The Producer/Consumer pattern in .NET 4.0+" class="link">The Producer/Consumer pattern in .NET 4.0+</a></li></ul></li>
        <li>profiling<ul><li>about / <a href="#ch10lvl1sec72" title="Performance measurement and profiling" class="link">Performance measurement and profiling</a></li></ul></li>
        <li>promise<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a></li></ul></li>
      </ul>
      <h2>R</h2>
      <ul>
        <li>race condition<ul><li>about / <a href="#ch01lvl1sec08" title="What's the problem?" class="link">What's the problem?</a></li><li>sample / <a href="#ch01lvl1sec08" title="What's the problem?" class="link">What's the problem?</a></li></ul> / <a href="#ch10lvl1sec69" title="Unit tests" class="link">Unit tests</a></li>
        <li>reader writer lock<ul><li>about / <a href="#ch01lvl1sec10" title="Reader-writer lock" class="link">Reader-writer lock</a></li></ul></li>
        <li>ReaderWriterLockSlim<ul><li>used, for implementing cache / <a href="#ch06lvl1sec40" title="Implementing a cache with ReaderWriterLockSlim" class="link">Implementing a cache with ReaderWriterLockSlim</a></li></ul></li>
        <li>ready queue<ul><li>about / <a href="#ch01lvl1sec09" title="Monitor class" class="link">Monitor class</a></li></ul></li>
        <li>real asynchronous I/O operations<ul><li>about / <a href="#ch08lvl1sec58" title="Real and fake asynchronous I/O operations" class="link">Real and fake asynchronous I/O operations</a></li></ul></li>
        <li>release fence<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>replicable task / <a href="#ch04lvl1sec31" title="Parallel.Invoke" class="link">Parallel.Invoke</a></li>
        <li>robust and performant applications<ul><li>creating, stages / <a href="#ch10lvl1sec68" title="Heisenbugs" class="link">Heisenbugs</a></li></ul></li>
        <li>RunLongRunningOperation method / <a href="#ch06lvl1sec42" title="ConcurrentDictionary" class="link">ConcurrentDictionary</a></li>
      </ul>
      <h2>S</h2>
      <ul>
        <li>scalability / <a href="#ch08lvl1sec53" title="Server applications" class="link">Server applications</a>, <a href="#ch08lvl1sec55" title="Load testing and scalability" class="link">Load testing and scalability</a></li>
        <li>server application<ul><li>about / <a href="#ch08lvl1sec53" title="Server applications" class="link">Server applications</a></li><li>types / <a href="#ch08lvl1sec53" title="Server applications" class="link">Server applications</a></li><li>scalability / <a href="#ch08lvl1sec53" title="Server applications" class="link">Server applications</a></li><li>scale vertically / <a href="#ch08lvl1sec53" title="Server applications" class="link">Server applications</a></li><li>horizontal scalability / <a href="#ch08lvl1sec53" title="Server applications" class="link">Server applications</a></li></ul></li>
        <li>shared data minimization<ul><li>about / <a href="#ch01lvl1sec12" title="Shared data minimization" class="link">Shared data minimization</a></li></ul></li>
        <li>simple synchronous solution<ul><li>creating / <a href="#ch05lvl1sec33" title="Creating a simple synchronous solution" class="link">Creating a simple synchronous solution</a></li></ul></li>
        <li>Single-Threaded Apartment (STA) / <a href="#ch09lvl1sec66" title="Performance issues" class="link">Performance issues</a></li>
        <li>spin lock<ul><li>about / <a href="#ch01lvl1sec11" title="Spin lock" class="link">Spin lock</a></li><li>Thread.SpinWait / <a href="#ch01lvl1sec11" title="Thread.SpinWait" class="link">Thread.SpinWait</a></li><li>System.Threading.SpinWait / <a href="#ch01lvl1sec11" title="System.Threading.SpinWait" class="link">System.Threading.SpinWait</a></li><li>System.Threading.SpinLock / <a href="#ch01lvl1sec11" title="System.Threading.SpinLock" class="link">System.Threading.SpinLock</a></li></ul></li>
        <li>standard collections / <a href="#ch06lvl1sec39" title="Standard collections and synchronization primitives" class="link">Standard collections and synchronization primitives</a></li>
        <li>synchronization context<ul><li>about / <a href="#ch08lvl1sec59" title="Synchronization context" class="link">Synchronization context</a></li></ul></li>
        <li>synchronization contexts / <a href="#ch09lvl1sec65" title="Execution and synchronization contexts" class="link">Execution and synchronization contexts</a></li>
        <li>synchronization primitives / <a href="#ch06lvl1sec39" title="Standard collections and synchronization primitives" class="link">Standard collections and synchronization primitives</a></li>
        <li>System.Threading.Interlocked class<ul><li>about / <a href="#ch02lvl1sec15" title="The System.Threading.Interlocked class" class="link">The System.Threading.Interlocked class</a></li></ul></li>
        <li>System.Threading.SpinLock<ul><li>about / <a href="#ch01lvl1sec11" title="System.Threading.SpinLock" class="link">System.Threading.SpinLock</a></li></ul></li>
        <li>System.Threading.SpinWait<ul><li>about / <a href="#ch01lvl1sec11" title="System.Threading.SpinWait" class="link">System.Threading.SpinWait</a></li></ul></li>
        <li>System.Threading.Task class / <a href="#ch03lvl1sec22" title="Understanding granularity" class="link">Understanding granularity</a></li>
      </ul>
      <h2>T</h2>
      <ul>
        <li>Tables class<ul><li>m_buckets / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a></li><li>m_locks / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a></li><li>m_countPerLock / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a></li><li>m_comparer / <a href="#ch06lvl1sec42" title="Implementation details" class="link">Implementation details</a></li></ul></li>
        <li>Task-based Asynchronous Pattern (TAP)<ul><li>about / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li><li>features / <a href="#ch07lvl1sec50" title="Task-based Asynchronous Pattern" class="link">Task-based Asynchronous Pattern</a></li></ul></li>
        <li>task cancellation<ul><li>about / <a href="#ch04lvl1sec28" title="Task cancellation" class="link">Task cancellation</a></li><li>flag, checking / <a href="#ch04lvl1sec28" title="Checking a flag" class="link">Checking a flag</a></li><li>exception, throwing / <a href="#ch04lvl1sec28" title="Throwing an exception" class="link">Throwing an exception</a></li><li>OS wait objects, using with WaitHandle / <a href="#ch04lvl1sec28" title="Using OS wait objects with WaitHandle" class="link">Using OS wait objects with WaitHandle</a></li><li>with callbacks / <a href="#ch04lvl1sec28" title="Cancellation using callbacks" class="link">Cancellation using callbacks</a></li></ul></li>
        <li>task composition<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a></li></ul></li>
        <li>Task Parallel Library<ul><li>parallel solution, creating with / <a href="#ch05lvl1sec33" title="Creating a parallel solution with Task Parallel Library" class="link">Creating a parallel solution with Task Parallel Library</a></li></ul></li>
        <li>Task Parallel Library (TPL)<ul><li>about / <a href="#ch03lvl1sec22" title="Understanding granularity" class="link">Understanding granularity</a></li></ul></li>
        <li>Task Parallel Library, features<ul><li>about / <a href="#ch05lvl1sec36" title="Other useful TPL features" class="link">Other useful TPL features</a></li><li>Task.Delay / <a href="#ch05lvl1sec36" title="Task.Delay" class="link">Task.Delay</a></li><li>Task.Yield / <a href="#ch05lvl1sec36" title="Task.Yield" class="link">Task.Yield</a></li></ul></li>
        <li>task scheduler<ul><li>about / <a href="#ch04lvl1sec25" title="Task composition" class="link">Task composition</a>, <a href="#ch04lvl1sec31" title="Understanding the task scheduler" class="link">Understanding the task scheduler</a></li></ul></li>
        <li>tasks hierarchy<ul><li>about / <a href="#ch04lvl1sec26" title="Tasks hierarchy" class="link">Tasks hierarchy</a></li></ul></li>
        <li>tests<ul><li>writing / <a href="#ch10lvl1sec69" title="Writing tests" class="link">Writing tests</a></li><li>load tests / <a href="#ch10lvl1sec69" title="Load tests" class="link">Load tests</a></li><li>unit tests / <a href="#ch10lvl1sec69" title="Unit tests" class="link">Unit tests</a></li></ul></li>
        <li>Thread.SpinWait<ul><li>about / <a href="#ch01lvl1sec11" title="Thread.SpinWait" class="link">Thread.SpinWait</a></li></ul></li>
        <li>thread contention / <a href="#ch06lvl1sec39" title="Standard collections and synchronization primitives" class="link">Standard collections and synchronization primitives</a></li>
        <li>thread pool<ul><li>using / <a href="#ch03lvl1sec21" title="Using the thread pool" class="link">Using the thread pool</a></li></ul></li>
        <li>threads<ul><li>overview / <a href="#ch03lvl1sec20" title="The number of threads" class="link">The number of threads</a></li></ul></li>
      </ul>
      <h2>U</h2>
      <ul>
        <li>UI thread / <a href="#ch09lvl1sec63" title="UI threads and message loops" class="link">UI threads and message loops</a></li>
      </ul>
      <h2>V</h2>
      <ul>
        <li>volatile<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>volatile keyword<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>volatile read<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
        <li>volatile write<ul><li>about / <a href="#ch02lvl1sec14" title="Memory model and compiler optimizations" class="link">Memory model and compiler optimizations</a></li></ul></li>
      </ul>
      <h2>W</h2>
      <ul>
        <li>WaitHandle<ul><li>OS wait objects, using with / <a href="#ch04lvl1sec28" title="Using OS wait objects with WaitHandle" class="link">Using OS wait objects with WaitHandle</a></li></ul></li>
        <li>waiting queue<ul><li>about / <a href="#ch01lvl1sec09" title="Monitor class" class="link">Monitor class</a></li></ul></li>
        <li>while loop / <a href="#ch06lvl1sec42" title="Fine-grained lock operations" class="link">Fine-grained lock operations</a>, <a href="#ch07lvl1sec49" title="Process Tasks in Completion Order" class="link">Process Tasks in Completion Order</a></li>
        <li>Windows Forms<ul><li>about / <a href="#ch05lvl1sec33" title="Creating a simple synchronous solution" class="link">Creating a simple synchronous solution</a></li></ul></li>
        <li>worker threads / <a href="#ch03lvl1sec21" title="Using the thread pool" class="link">Using the thread pool</a></li>
        <li>work stealing / <a href="#ch06lvl1sec43" title="ConcurrentBag&lt;T&gt;" class="link">ConcurrentBag&lt;T&gt;</a></li>
      </ul>
      <h2>X</h2>
      <ul>
        <li>xampp<ul><li>about / <a href="#ch08lvl1sec55" title="Load testing and scalability" class="link">Load testing and scalability</a></li></ul></li>
      </ul>
    </div>
  </div></div></div>
</div></div></div></body></html>
