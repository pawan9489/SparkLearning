<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="">

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"> <!--320-->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, user-scalable=no">

    <link rel="icon" href="../../mapt/images/favicon.ico">

    <link rel="stylesheet" href="../../mapt/css/font-awesome.css">
    <link rel="stylesheet" href="../../mapt/css/google-fonts.css">
    <link rel="stylesheet" href="../../mapt/css/devicon.css">

    <link rel="stylesheet" href="../../mapt/css/bootstrap.css">
    <link rel="stylesheet" href="../../mapt/css/bootstrap-xl.css">
    <link rel="stylesheet" href="../../mapt/css/magnific-popup.css">
    <link rel="stylesheet" href="../../mapt/css/prism.css">
    <link rel="stylesheet" href="../../mapt/css/hljs-github.css">

    <link rel="stylesheet" href="../../mapt/css/mapt.css">
    <link rel="stylesheet" href="../../mapt/css/custom.css">

    <script src="../../mapt/js/jquery.js"></script>
    <script src="../../mapt/js/bootstrap.js"></script>
    <script src="../../mapt/js/jquery.magnific-popup.js"></script>
    <script src="../../mapt/js/highlight.min.js"></script>

    <script src="../../mapt/js/custom.js"></script>
    
    <title>Scala for Data Science</title>
</head>

<body class="home-body">
    <div id="wrapper">
        <div id="sidebar-wrapper">    
            <ul class="sidebar-nav">
                <div class="list-group" id="sidebar-nav" role="tablist">
                    <li>
                        <a href="../../index.html" class="sidenav-menu-holder back-btn" id="back-link">
                            <span class="sidenav-menu">Book List</span>
                            <span class="pull-left mr5"><i class="fa fa-chevron-left"></i></span>
                        </a>
                    </li>
                    
                    <li class="book-info copyright">
                        <span class="info text-nowrap"><span class="copyleft">&copy;</span><span><strong>RuTracker</strong>.org</span></span>
                    </li>          
                    <li class="book-info copyright">
                        <span class="info text-nowrap">Pub date: <strong>28 Jan 2016</strong></span>
                    </li>         
                    <li class="book-info">
                        <span class="info text-nowrap">Price: â‚¬<strong>39.99</strong></span>
                        <span class="info text-nowrap">ISBN: <strong>9781785281372</strong></span>
                    </li>     
            
                    <li>
                        <a href="graphics/cover.jpg" class="sidenav-menu-holder cover-img">
                            <img src="graphics/cover.jpg" class="cover-image">
                        </a>
                    </li>        
            
                    <div class="book_navigation">
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse1">
                                <div class="section-name">1: Scala and Data Science</div>
                            </a>
                        </li>
                        <div id="collapse1" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="1" class="sub-nav">
                                <a href="#ch01">
                                    <div class="section-name">Chapter 1: Scala and Data Science</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec08" class="sub-nav">
                                <a href="#ch01lvl1sec08">                    
                                    <div class="section-name">Data science</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec09" class="sub-nav">
                                <a href="#ch01lvl1sec09">                    
                                    <div class="section-name">Programming in data science</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec10" class="sub-nav">
                                <a href="#ch01lvl1sec10">                    
                                    <div class="section-name">Why Scala?</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec11" class="sub-nav">
                                <a href="#ch01lvl1sec11">                    
                                    <div class="section-name">When not to use Scala</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec12" class="sub-nav">
                                <a href="#ch01lvl1sec12">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="1" data-section-id="ch01lvl1sec13" class="sub-nav">
                                <a href="#ch01lvl1sec13">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse2">
                                <div class="section-name">2: Manipulating Data with Breeze</div>
                            </a>
                        </li>
                        <div id="collapse2" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="2" class="sub-nav">
                                <a href="#ch02">
                                    <div class="section-name">Chapter 2: Manipulating Data with Breeze</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec14" class="sub-nav">
                                <a href="#ch02lvl1sec14">                    
                                    <div class="section-name">Code examples</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec15" class="sub-nav">
                                <a href="#ch02lvl1sec15">                    
                                    <div class="section-name">Installing Breeze</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec16" class="sub-nav">
                                <a href="#ch02lvl1sec16">                    
                                    <div class="section-name">Getting help on Breeze</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec17" class="sub-nav">
                                <a href="#ch02lvl1sec17">                    
                                    <div class="section-name">Basic Breeze data types</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec18" class="sub-nav">
                                <a href="#ch02lvl1sec18">                    
                                    <div class="section-name">An example logistic regression</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec19" class="sub-nav">
                                <a href="#ch02lvl1sec19">                    
                                    <div class="section-name">Towards re-usable code</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec20" class="sub-nav">
                                <a href="#ch02lvl1sec20">                    
                                    <div class="section-name">Alternatives to Breeze</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec21" class="sub-nav">
                                <a href="#ch02lvl1sec21">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="2" data-section-id="ch02lvl1sec22" class="sub-nav">
                                <a href="#ch02lvl1sec22">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse3">
                                <div class="section-name">3: Plotting with breeze-viz</div>
                            </a>
                        </li>
                        <div id="collapse3" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="3" class="sub-nav">
                                <a href="#ch03">
                                    <div class="section-name">Chapter 3: Plotting with breeze-viz</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec23" class="sub-nav">
                                <a href="#ch03lvl1sec23">                    
                                    <div class="section-name">Diving into Breeze</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec24" class="sub-nav">
                                <a href="#ch03lvl1sec24">                    
                                    <div class="section-name">Customizing plots</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec25" class="sub-nav">
                                <a href="#ch03lvl1sec25">                    
                                    <div class="section-name">Customizing the line type</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec26" class="sub-nav">
                                <a href="#ch03lvl1sec26">                    
                                    <div class="section-name">More advanced scatter plots</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec27" class="sub-nav">
                                <a href="#ch03lvl1sec27">                    
                                    <div class="section-name">Multi-plot example scatterplot matrix plots</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec28" class="sub-nav">
                                <a href="#ch03lvl1sec28">                    
                                    <div class="section-name">Managing without documentation</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec29" class="sub-nav">
                                <a href="#ch03lvl1sec29">                    
                                    <div class="section-name">Breeze-viz reference</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec30" class="sub-nav">
                                <a href="#ch03lvl1sec30">                    
                                    <div class="section-name">Data visualization beyond breeze-viz</div>
                                </a>
                            </li>
                            <li data-chapter="3" data-section-id="ch03lvl1sec31" class="sub-nav">
                                <a href="#ch03lvl1sec31">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse4">
                                <div class="section-name">4: Parallel Collections and Futures</div>
                            </a>
                        </li>
                        <div id="collapse4" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="4" class="sub-nav">
                                <a href="#ch04">
                                    <div class="section-name">Chapter 4: Parallel Collections and Futures</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec32" class="sub-nav">
                                <a href="#ch04lvl1sec32">                    
                                    <div class="section-name">Parallel collections</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec33" class="sub-nav">
                                <a href="#ch04lvl1sec33">                    
                                    <div class="section-name">Futures</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec34" class="sub-nav">
                                <a href="#ch04lvl1sec34">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="4" data-section-id="ch04lvl1sec35" class="sub-nav">
                                <a href="#ch04lvl1sec35">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse5">
                                <div class="section-name">5: Scala and SQL through JDBC</div>
                            </a>
                        </li>
                        <div id="collapse5" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="5" class="sub-nav">
                                <a href="#ch05">
                                    <div class="section-name">Chapter 5: Scala and SQL through JDBC</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec36" class="sub-nav">
                                <a href="#ch05lvl1sec36">                    
                                    <div class="section-name">Interacting with JDBC</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec37" class="sub-nav">
                                <a href="#ch05lvl1sec37">                    
                                    <div class="section-name">First steps with JDBC</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec38" class="sub-nav">
                                <a href="#ch05lvl1sec38">                    
                                    <div class="section-name">JDBC summary</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec39" class="sub-nav">
                                <a href="#ch05lvl1sec39">                    
                                    <div class="section-name">Functional wrappers for JDBC</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec40" class="sub-nav">
                                <a href="#ch05lvl1sec40">                    
                                    <div class="section-name">Safer JDBC connections with the loan pattern</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec41" class="sub-nav">
                                <a href="#ch05lvl1sec41">                    
                                    <div class="section-name">Enriching JDBC statements with the &amp;quot;pimp my library&amp;quot; pattern</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec42" class="sub-nav">
                                <a href="#ch05lvl1sec42">                    
                                    <div class="section-name">Wrapping result sets in a stream</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec43" class="sub-nav">
                                <a href="#ch05lvl1sec43">                    
                                    <div class="section-name">Looser coupling with type classes</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec44" class="sub-nav">
                                <a href="#ch05lvl1sec44">                    
                                    <div class="section-name">Creating a data access layer</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec45" class="sub-nav">
                                <a href="#ch05lvl1sec45">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="5" data-section-id="ch05lvl1sec46" class="sub-nav">
                                <a href="#ch05lvl1sec46">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse6">
                                <div class="section-name">6: Slick â€“ A Functional Interface for SQL</div>
                            </a>
                        </li>
                        <div id="collapse6" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="6" class="sub-nav">
                                <a href="#ch06">
                                    <div class="section-name">Chapter 6: Slick â€“ A Functional Interface for SQL</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec47" class="sub-nav">
                                <a href="#ch06lvl1sec47">                    
                                    <div class="section-name">FEC data</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec48" class="sub-nav">
                                <a href="#ch06lvl1sec48">                    
                                    <div class="section-name">Invokers</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec49" class="sub-nav">
                                <a href="#ch06lvl1sec49">                    
                                    <div class="section-name">Operations on columns</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec50" class="sub-nav">
                                <a href="#ch06lvl1sec50">                    
                                    <div class="section-name">Aggregations with &amp;quot;Group by&amp;quot;</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec51" class="sub-nav">
                                <a href="#ch06lvl1sec51">                    
                                    <div class="section-name">Accessing database metadata</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec52" class="sub-nav">
                                <a href="#ch06lvl1sec52">                    
                                    <div class="section-name">Slick versus JDBC</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec53" class="sub-nav">
                                <a href="#ch06lvl1sec53">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="6" data-section-id="ch06lvl1sec54" class="sub-nav">
                                <a href="#ch06lvl1sec54">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse7">
                                <div class="section-name">7: Web APIs</div>
                            </a>
                        </li>
                        <div id="collapse7" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="7" class="sub-nav">
                                <a href="#ch07">
                                    <div class="section-name">Chapter 7: Web APIs</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec55" class="sub-nav">
                                <a href="#ch07lvl1sec55">                    
                                    <div class="section-name">A whirlwind tour of JSON</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec56" class="sub-nav">
                                <a href="#ch07lvl1sec56">                    
                                    <div class="section-name">Querying web APIs</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec57" class="sub-nav">
                                <a href="#ch07lvl1sec57">                    
                                    <div class="section-name">JSON in Scala an exercise in pattern matching</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec58" class="sub-nav">
                                <a href="#ch07lvl1sec58">                    
                                    <div class="section-name">Extraction using case classes</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec59" class="sub-nav">
                                <a href="#ch07lvl1sec59">                    
                                    <div class="section-name">Concurrency and exception handling with futures</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec60" class="sub-nav">
                                <a href="#ch07lvl1sec60">                    
                                    <div class="section-name">Authentication adding HTTP headers</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec61" class="sub-nav">
                                <a href="#ch07lvl1sec61">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="7" data-section-id="ch07lvl1sec62" class="sub-nav">
                                <a href="#ch07lvl1sec62">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse8">
                                <div class="section-name">8: Scala and MongoDB</div>
                            </a>
                        </li>
                        <div id="collapse8" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="8" class="sub-nav">
                                <a href="#ch08">
                                    <div class="section-name">Chapter 8: Scala and MongoDB</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec63" class="sub-nav">
                                <a href="#ch08lvl1sec63">                    
                                    <div class="section-name">MongoDB</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec64" class="sub-nav">
                                <a href="#ch08lvl1sec64">                    
                                    <div class="section-name">Connecting to MongoDB with Casbah</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec65" class="sub-nav">
                                <a href="#ch08lvl1sec65">                    
                                    <div class="section-name">Inserting documents</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec66" class="sub-nav">
                                <a href="#ch08lvl1sec66">                    
                                    <div class="section-name">Extracting objects from the database</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec67" class="sub-nav">
                                <a href="#ch08lvl1sec67">                    
                                    <div class="section-name">Complex queries</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec68" class="sub-nav">
                                <a href="#ch08lvl1sec68">                    
                                    <div class="section-name">Casbah query DSL</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec69" class="sub-nav">
                                <a href="#ch08lvl1sec69">                    
                                    <div class="section-name">Custom type serialization</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec70" class="sub-nav">
                                <a href="#ch08lvl1sec70">                    
                                    <div class="section-name">Beyond Casbah</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec71" class="sub-nav">
                                <a href="#ch08lvl1sec71">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="8" data-section-id="ch08lvl1sec72" class="sub-nav">
                                <a href="#ch08lvl1sec72">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse9">
                                <div class="section-name">9: Concurrency with Akka</div>
                            </a>
                        </li>
                        <div id="collapse9" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="9" class="sub-nav">
                                <a href="#ch09">
                                    <div class="section-name">Chapter 9: Concurrency with Akka</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec73" class="sub-nav">
                                <a href="#ch09lvl1sec73">                    
                                    <div class="section-name">GitHub follower graph</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec74" class="sub-nav">
                                <a href="#ch09lvl1sec74">                    
                                    <div class="section-name">Actors as people</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec75" class="sub-nav">
                                <a href="#ch09lvl1sec75">                    
                                    <div class="section-name">Hello world with Akka</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec76" class="sub-nav">
                                <a href="#ch09lvl1sec76">                    
                                    <div class="section-name">Case classes as messages</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec77" class="sub-nav">
                                <a href="#ch09lvl1sec77">                    
                                    <div class="section-name">Actor construction</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec78" class="sub-nav">
                                <a href="#ch09lvl1sec78">                    
                                    <div class="section-name">Anatomy of an actor</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec79" class="sub-nav">
                                <a href="#ch09lvl1sec79">                    
                                    <div class="section-name">Follower network crawler</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec80" class="sub-nav">
                                <a href="#ch09lvl1sec80">                    
                                    <div class="section-name">Fetcher actors</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec81" class="sub-nav">
                                <a href="#ch09lvl1sec81">                    
                                    <div class="section-name">Routing</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec82" class="sub-nav">
                                <a href="#ch09lvl1sec82">                    
                                    <div class="section-name">Message passing between actors</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec83" class="sub-nav">
                                <a href="#ch09lvl1sec83">                    
                                    <div class="section-name">Queue control and the pull pattern</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec84" class="sub-nav">
                                <a href="#ch09lvl1sec84">                    
                                    <div class="section-name">Accessing the sender of a message</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec85" class="sub-nav">
                                <a href="#ch09lvl1sec85">                    
                                    <div class="section-name">Stateful actors</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec86" class="sub-nav">
                                <a href="#ch09lvl1sec86">                    
                                    <div class="section-name">Follower network crawler</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec87" class="sub-nav">
                                <a href="#ch09lvl1sec87">                    
                                    <div class="section-name">Fault tolerance</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec88" class="sub-nav">
                                <a href="#ch09lvl1sec88">                    
                                    <div class="section-name">Custom supervisor strategies</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec89" class="sub-nav">
                                <a href="#ch09lvl1sec89">                    
                                    <div class="section-name">Life-cycle hooks</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec90" class="sub-nav">
                                <a href="#ch09lvl1sec90">                    
                                    <div class="section-name">What we have not talked about</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec91" class="sub-nav">
                                <a href="#ch09lvl1sec91">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="9" data-section-id="ch09lvl1sec92" class="sub-nav">
                                <a href="#ch09lvl1sec92">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse10">
                                <div class="section-name">10: Distributed Batch Processing with Spark</div>
                            </a>
                        </li>
                        <div id="collapse10" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="10" class="sub-nav">
                                <a href="#ch10">
                                    <div class="section-name">Chapter 10: Distributed Batch Processing with Spark</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec93" class="sub-nav">
                                <a href="#ch10lvl1sec93">                    
                                    <div class="section-name">Installing Spark</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec94" class="sub-nav">
                                <a href="#ch10lvl1sec94">                    
                                    <div class="section-name">Acquiring the example data</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec95" class="sub-nav">
                                <a href="#ch10lvl1sec95">                    
                                    <div class="section-name">Resilient distributed datasets</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec96" class="sub-nav">
                                <a href="#ch10lvl1sec96">                    
                                    <div class="section-name">Building and running standalone programs</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec97" class="sub-nav">
                                <a href="#ch10lvl1sec97">                    
                                    <div class="section-name">Spam filtering</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec98" class="sub-nav">
                                <a href="#ch10lvl1sec98">                    
                                    <div class="section-name">Lifting the hood</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec99" class="sub-nav">
                                <a href="#ch10lvl1sec99">                    
                                    <div class="section-name">Data shuffling and partitions</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec100" class="sub-nav">
                                <a href="#ch10lvl1sec100">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="10" data-section-id="ch10lvl1sec101" class="sub-nav">
                                <a href="#ch10lvl1sec101">                    
                                    <div class="section-name">Reference</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse11">
                                <div class="section-name">11: Spark SQL and DataFrames</div>
                            </a>
                        </li>
                        <div id="collapse11" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="11" class="sub-nav">
                                <a href="#ch11">
                                    <div class="section-name">Chapter 11: Spark SQL and DataFrames</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec102" class="sub-nav">
                                <a href="#ch11lvl1sec102">                    
                                    <div class="section-name">DataFrames a whirlwind introduction</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec103" class="sub-nav">
                                <a href="#ch11lvl1sec103">                    
                                    <div class="section-name">Aggregation operations</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec104" class="sub-nav">
                                <a href="#ch11lvl1sec104">                    
                                    <div class="section-name">Joining DataFrames together</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec105" class="sub-nav">
                                <a href="#ch11lvl1sec105">                    
                                    <div class="section-name">Custom functions on DataFrames</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec106" class="sub-nav">
                                <a href="#ch11lvl1sec106">                    
                                    <div class="section-name">DataFrame immutability and persistence</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec107" class="sub-nav">
                                <a href="#ch11lvl1sec107">                    
                                    <div class="section-name">SQL statements on DataFrames</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec108" class="sub-nav">
                                <a href="#ch11lvl1sec108">                    
                                    <div class="section-name">Complex data types arrays, maps, and structs</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec109" class="sub-nav">
                                <a href="#ch11lvl1sec109">                    
                                    <div class="section-name">Interacting with data sources</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec110" class="sub-nav">
                                <a href="#ch11lvl1sec110">                    
                                    <div class="section-name">Standalone programs</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec111" class="sub-nav">
                                <a href="#ch11lvl1sec111">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="11" data-section-id="ch11lvl1sec112" class="sub-nav">
                                <a href="#ch11lvl1sec112">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse12">
                                <div class="section-name">12: Distributed Machine Learning with MLlib</div>
                            </a>
                        </li>
                        <div id="collapse12" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="12" class="sub-nav">
                                <a href="#ch12">
                                    <div class="section-name">Chapter 12: Distributed Machine Learning with MLlib</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec113" class="sub-nav">
                                <a href="#ch12lvl1sec113">                    
                                    <div class="section-name">Introducing MLlib Spam classification</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec114" class="sub-nav">
                                <a href="#ch12lvl1sec114">                    
                                    <div class="section-name">Pipeline components</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec115" class="sub-nav">
                                <a href="#ch12lvl1sec115">                    
                                    <div class="section-name">Evaluation</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec116" class="sub-nav">
                                <a href="#ch12lvl1sec116">                    
                                    <div class="section-name">Regularization in logistic regression</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec117" class="sub-nav">
                                <a href="#ch12lvl1sec117">                    
                                    <div class="section-name">Cross-validation and model selection</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec118" class="sub-nav">
                                <a href="#ch12lvl1sec118">                    
                                    <div class="section-name">Beyond logistic regression</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec119" class="sub-nav">
                                <a href="#ch12lvl1sec119">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="12" data-section-id="ch12lvl1sec120" class="sub-nav">
                                <a href="#ch12lvl1sec120">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse13">
                                <div class="section-name">13: Web APIs with Play</div>
                            </a>
                        </li>
                        <div id="collapse13" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="13" class="sub-nav">
                                <a href="#ch13">
                                    <div class="section-name">Chapter 13: Web APIs with Play</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec121" class="sub-nav">
                                <a href="#ch13lvl1sec121">                    
                                    <div class="section-name">Client-server applications</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec122" class="sub-nav">
                                <a href="#ch13lvl1sec122">                    
                                    <div class="section-name">Introduction to web frameworks</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec123" class="sub-nav">
                                <a href="#ch13lvl1sec123">                    
                                    <div class="section-name">Model-View-Controller architecture</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec124" class="sub-nav">
                                <a href="#ch13lvl1sec124">                    
                                    <div class="section-name">Single page applications</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec125" class="sub-nav">
                                <a href="#ch13lvl1sec125">                    
                                    <div class="section-name">Building an application</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec126" class="sub-nav">
                                <a href="#ch13lvl1sec126">                    
                                    <div class="section-name">The Play framework</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec127" class="sub-nav">
                                <a href="#ch13lvl1sec127">                    
                                    <div class="section-name">Dynamic routing</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec128" class="sub-nav">
                                <a href="#ch13lvl1sec128">                    
                                    <div class="section-name">Actions</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec129" class="sub-nav">
                                <a href="#ch13lvl1sec129">                    
                                    <div class="section-name">Interacting with JSON</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec130" class="sub-nav">
                                <a href="#ch13lvl1sec130">                    
                                    <div class="section-name">Querying external APIs and consuming JSON</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec131" class="sub-nav">
                                <a href="#ch13lvl1sec131">                    
                                    <div class="section-name">Creating APIs with Play: a summary</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec132" class="sub-nav">
                                <a href="#ch13lvl1sec132">                    
                                    <div class="section-name">Rest APIs: best practice</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec133" class="sub-nav">
                                <a href="#ch13lvl1sec133">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="13" data-section-id="ch13lvl1sec134" class="sub-nav">
                                <a href="#ch13lvl1sec134">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapse14">
                                <div class="section-name">14: Visualization with D3 and the Play Framework</div>
                            </a>
                        </li>
                        <div id="collapse14" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="14" class="sub-nav">
                                <a href="#ch14">
                                    <div class="section-name">Chapter 14: Visualization with D3 and the Play Framework</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec135" class="sub-nav">
                                <a href="#ch14lvl1sec135">                    
                                    <div class="section-name">GitHub user data</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec136" class="sub-nav">
                                <a href="#ch14lvl1sec136">                    
                                    <div class="section-name">Do I need a backend?</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec137" class="sub-nav">
                                <a href="#ch14lvl1sec137">                    
                                    <div class="section-name">JavaScript dependencies through web-jars</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec138" class="sub-nav">
                                <a href="#ch14lvl1sec138">                    
                                    <div class="section-name">Towards a web application: HTML templates</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec139" class="sub-nav">
                                <a href="#ch14lvl1sec139">                    
                                    <div class="section-name">Modular JavaScript through RequireJS</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec140" class="sub-nav">
                                <a href="#ch14lvl1sec140">                    
                                    <div class="section-name">Bootstrapping the applications</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec141" class="sub-nav">
                                <a href="#ch14lvl1sec141">                    
                                    <div class="section-name">Client-side program architecture</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec142" class="sub-nav">
                                <a href="#ch14lvl1sec142">                    
                                    <div class="section-name">Drawing plots with NVD3</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec143" class="sub-nav">
                                <a href="#ch14lvl1sec143">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="14" data-section-id="ch14lvl1sec144" class="sub-nav">
                                <a href="#ch14lvl1sec144">                    
                                    <div class="section-name">References</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapseappA">
                                <div class="section-name">Appendix A: Pattern Matching and Extractors</div>
                            </a>
                        </li>
                        <div id="collapseappA" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="appA" class="sub-nav">
                                <a href="#appA">
                                    <div class="section-name">Chapter Appendix A: Pattern Matching and Extractors</div>
                                </a>
                            </li>
                            <li data-chapter="appA" data-section-id="ch14lvl1sec145" class="sub-nav">
                                <a href="#ch14lvl1sec145">                    
                                    <div class="section-name">Pattern matching in for comprehensions</div>
                                </a>
                            </li>
                            <li data-chapter="appA" data-section-id="ch14lvl1sec146" class="sub-nav">
                                <a href="#ch14lvl1sec146">                    
                                    <div class="section-name">Pattern matching internals</div>
                                </a>
                            </li>
                            <li data-chapter="appA" data-section-id="ch14lvl1sec147" class="sub-nav">
                                <a href="#ch14lvl1sec147">                    
                                    <div class="section-name">Extracting sequences</div>
                                </a>
                            </li>
                            <li data-chapter="appA" data-section-id="ch14lvl1sec148" class="sub-nav">
                                <a href="#ch14lvl1sec148">                    
                                    <div class="section-name">Summary</div>
                                </a>
                            </li>
                            <li data-chapter="appA" data-section-id="ch14lvl1sec149" class="sub-nav">
                                <a href="#ch14lvl1sec149">                    
                                    <div class="section-name">Reference</div>
                                </a>
                            </li>
                        </div>
                        <li>
                            <a data-toggle="collapse" data-parent="#sidebar-nav" class="sidenav-menu-holder collapsed" href="#collapsebackindex">
                                <div class="section-name">Appendix B: Index</div>
                            </a>
                        </li>
                        <div id="collapsebackindex" class="panel-collapse collapse" role="tabpanel">
                            <li data-chapter="backindex" class="sub-nav">
                                <a href="#backindex">
                                    <div class="section-name">Chapter Appendix B: Index</div>
                                </a>
                            </li>
                        </div>
                    </div>
                </div>
            </ul>
        </div>
        
        <div id="page-content-wrapper" class="book-page">
            <a href="#" id="menu-toggle" class="toggle-nav"><i class="fa fa-bars fa-2x mr5"></i></a>
            
            <a href="#" id="back_to_top" class="back-to-top"><img src="../../mapt/images/kopimi.svg"></a>
            
            <div class="col-sm-12 col-xl-offset-2 col-xl-8 col-lg-offset-1 col-lg-10">
                <div class="btn-group pull-right mt15 mb30" role="group">
                    <a href="#home" class="btn btn-default">
                        <i class="fa fa-share fa-lg no-text-padding"></i>
                        <span class="hidden-xs ml5">Book Home</span>
                    </a>
                    <button class="btn btn-default" data-nid="22180" id="code-download">
                        <i class="fa fa-file fa-lg"></i>
                        <span class="hidden-xs ml5">Download Code Files</span>
                    </button>
                </div>
            </div>
            <div class="clearfix"></div>
            
            <div id="book-wrapper" class="container-fluid">
                <div class="col-sm-12 col-xl-offset-2 col-xl-8 col-lg-offset-1 col-lg-10" id="home">
                    <h2 class="product-title">Scala for Data Science</h2>
                    <hr>
                    <div class="row">
                        <div class="col-sm-12">
                            <h5 class="mt10">By Pascal Bugnion</h5>
                            <div>
                                <p class="mb20"><b>Leverage the power of Scala with different tools to build scalable, robust data science applications</b></p>
                                <a href="#ch01" class="btn btn-info btn-lg pull-right hidden-xs">
                                    Start Reading <i class="fa fa-chevron-right ml5"></i>
                                </a>
                                <a href="#ch01" class="btn btn-info btn-lg btn-block mt20 mb20 visible-xs">
                                    Start Reading <i class="fa fa-chevron-right ml5"></i>
                                </a>
                                <div class="clearfix"></div>
                                <div class="col-sm-12">
                                    <ul id="myTabs" class="nav nav-tabs nav-justified hidden-xs mt20" role="tablist">
                                        <li class="active">
                                            <a href="#info" role="tab" id="info-tab" data-toggle="tab">
                                                <h5>Info</h5>
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#content" role="tab" id="content-tab" data-toggle="tab">
                                                <h5>Contents</h5>
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#author" role="tab" id="author-tab" data-toggle="tab">
                                                <h5>Author</h5>
                                            </a>
                                        </li>
                                    </ul>
                
                                    <ul id="myTabsMobile" class="nav nav-pills text-center nav-stacked visible-xs mb60" role="tablist">
                                        <li class="active">
                                            <a href="#info" role="tab" id="info-tab-responsive" data-toggle="tab">
                                                Info
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#content" role="tab" id="content-tab-responsive" data-toggle="tab">
                                                Contents
                                            </a>
                                        </li>
                                        <li>
                                            <a href="#author" role="tab" id="author-tab-responsive" data-toggle="tab">
                                                Author
                                            </a>
                                        </li>
                                    </ul>
                
                                    <div id="myTabContent" class="tab-content pt30">
                                    
                                        <div role="tabpanel" class="tab-pane active fade in" id="info">
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">Features</h5>
                                            </div>
                                            <div class="hidden-xs">
                                                <h5>Features</h5>
                                            </div>
                                            <hr>
                                            <div>
                                                <ul>
                <li>A complete guide for scalable data science solutions, from data ingestion to data visualization</li>
                <li>Deploy horizontally scalable data processing pipelines and take advantage of web frameworks to build engaging visualizations</li>
                <li>Build functional, type-safe routines to interact with relational and NoSQL databases with the help of tutorials and examples provided</li>
                </ul>
                                            </div>
                                            <br>
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">Learning</h5>
                                            </div>
                                            <div class="hidden-xs">
                                                <h5>Learning</h5>
                                            </div>
                                            <hr>
                                            <div>
                                                <ul>
                <li>Transform and filter tabular data to extract features for machine learning</li>
                <li>Implement your own algorithms or take advantage of MLLibâ€™s extensive suite of models to build distributed machine learning pipelines</li>
                <li>Read, transform, and write data to both SQL and NoSQL databases in a functional manner</li>
                <li>Write robust routines to query web APIs</li>
                <li>Read data from web APIs such as the GitHub or Twitter API</li>
                <li>Use Scala to interact with MongoDB, which offers high performance and helps to store large data sets with uncertain query requirements</li>
                <li>Create Scala web applications that couple with JavaScript libraries such as D3 to create compelling interactive visualizations</li>
                <li>Deploy scalable parallel applications using Apache Spark, loading data from HDFS or Hive</li>
                </ul>
                                            </div>
                                            <br>
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">About</h5>
                                            </div>
                                            <div class="hidden-xs">
                                                <h5>About</h5>
                                            </div>
                                            <hr>
                                            <div>
                                                <p>Scala is a multi-paradigm programming language (it supports both object-oriented and functional programming) and scripting language used to build applications for the JVM. Languages such as R, Python, Java, and so on are mostly used for data science. It is particularly good at analyzing large sets of data without any significant impact on performance and thus Scala is being adopted by many developers and data scientists. Data scientists might be aware that building applications that are truly scalable is hard. Scala, with its powerful functional libraries for interacting with databases and building scalable frameworks will give you the tools to construct robust data pipelines.</p>
                <p>This book will introduce you to the libraries for ingesting, storing, manipulating, processing, and visualizing data in Scala.</p>
                <p>Packed with real-world examples and interesting data sets, this book will teach you to ingest data from flat files and web APIs and store it in a SQL or NoSQL database. It will show you how to design scalable architectures to process and modelling your data, starting from simple concurrency constructs such as parallel collections and futures, through to actor systems and Apache Spark. As well as Scalaâ€™s emphasis on functional structures and immutability, you will learn how to use the right parallel construct for the job at hand, minimizing development time without compromising scalability. Finally, you will learn how to build beautiful interactive visualizations using web frameworks.</p>
                <p>This book gives tutorials on some of the most common Scala libraries for data science, allowing you to quickly get up to speed with building data science and data engineering solutions.</p>
                                            </div>
                                        </div>
                                        
                                        <div role="tabpanel" class="tab-pane fade in" id="content">
                                            <div class="visible-xs">
                                                <h5 class="mobile-title">Contents</h5>
                                                <hr>
                                            </div>
                                            <ul>
                                                <div>
                                                    <li data-chapter="1">
                                                        <div class="section-name">1: Scala and Data Science</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="1" class="chapter-section">
                                                                    <a href="#ch01">        
                                                                        <div class="section-name">Chapter 1: Scala and Data Science</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec08" class="chapter-section">
                                                                    <a href="#ch01lvl1sec08">                    
                                                                        <div class="section-name">Data science</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec09" class="chapter-section">
                                                                    <a href="#ch01lvl1sec09">                    
                                                                        <div class="section-name">Programming in data science</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec10" class="chapter-section">
                                                                    <a href="#ch01lvl1sec10">                    
                                                                        <div class="section-name">Why Scala?</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec11" class="chapter-section">
                                                                    <a href="#ch01lvl1sec11">                    
                                                                        <div class="section-name">When not to use Scala</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec12" class="chapter-section">
                                                                    <a href="#ch01lvl1sec12">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="1" data-section-id="ch01lvl1sec13" class="chapter-section">
                                                                    <a href="#ch01lvl1sec13">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="2">
                                                        <div class="section-name">2: Manipulating Data with Breeze</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="2" class="chapter-section">
                                                                    <a href="#ch02">        
                                                                        <div class="section-name">Chapter 2: Manipulating Data with Breeze</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec14" class="chapter-section">
                                                                    <a href="#ch02lvl1sec14">                    
                                                                        <div class="section-name">Code examples</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec15" class="chapter-section">
                                                                    <a href="#ch02lvl1sec15">                    
                                                                        <div class="section-name">Installing Breeze</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec16" class="chapter-section">
                                                                    <a href="#ch02lvl1sec16">                    
                                                                        <div class="section-name">Getting help on Breeze</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec17" class="chapter-section">
                                                                    <a href="#ch02lvl1sec17">                    
                                                                        <div class="section-name">Basic Breeze data types</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec18" class="chapter-section">
                                                                    <a href="#ch02lvl1sec18">                    
                                                                        <div class="section-name">An example logistic regression</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec19" class="chapter-section">
                                                                    <a href="#ch02lvl1sec19">                    
                                                                        <div class="section-name">Towards re-usable code</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec20" class="chapter-section">
                                                                    <a href="#ch02lvl1sec20">                    
                                                                        <div class="section-name">Alternatives to Breeze</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec21" class="chapter-section">
                                                                    <a href="#ch02lvl1sec21">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="2" data-section-id="ch02lvl1sec22" class="chapter-section">
                                                                    <a href="#ch02lvl1sec22">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="3">
                                                        <div class="section-name">3: Plotting with breeze-viz</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="3" class="chapter-section">
                                                                    <a href="#ch03">        
                                                                        <div class="section-name">Chapter 3: Plotting with breeze-viz</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec23" class="chapter-section">
                                                                    <a href="#ch03lvl1sec23">                    
                                                                        <div class="section-name">Diving into Breeze</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec24" class="chapter-section">
                                                                    <a href="#ch03lvl1sec24">                    
                                                                        <div class="section-name">Customizing plots</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec25" class="chapter-section">
                                                                    <a href="#ch03lvl1sec25">                    
                                                                        <div class="section-name">Customizing the line type</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec26" class="chapter-section">
                                                                    <a href="#ch03lvl1sec26">                    
                                                                        <div class="section-name">More advanced scatter plots</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec27" class="chapter-section">
                                                                    <a href="#ch03lvl1sec27">                    
                                                                        <div class="section-name">Multi-plot example scatterplot matrix plots</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec28" class="chapter-section">
                                                                    <a href="#ch03lvl1sec28">                    
                                                                        <div class="section-name">Managing without documentation</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec29" class="chapter-section">
                                                                    <a href="#ch03lvl1sec29">                    
                                                                        <div class="section-name">Breeze-viz reference</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec30" class="chapter-section">
                                                                    <a href="#ch03lvl1sec30">                    
                                                                        <div class="section-name">Data visualization beyond breeze-viz</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="3" data-section-id="ch03lvl1sec31" class="chapter-section">
                                                                    <a href="#ch03lvl1sec31">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="4">
                                                        <div class="section-name">4: Parallel Collections and Futures</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="4" class="chapter-section">
                                                                    <a href="#ch04">        
                                                                        <div class="section-name">Chapter 4: Parallel Collections and Futures</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec32" class="chapter-section">
                                                                    <a href="#ch04lvl1sec32">                    
                                                                        <div class="section-name">Parallel collections</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec33" class="chapter-section">
                                                                    <a href="#ch04lvl1sec33">                    
                                                                        <div class="section-name">Futures</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec34" class="chapter-section">
                                                                    <a href="#ch04lvl1sec34">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="4" data-section-id="ch04lvl1sec35" class="chapter-section">
                                                                    <a href="#ch04lvl1sec35">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="5">
                                                        <div class="section-name">5: Scala and SQL through JDBC</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="5" class="chapter-section">
                                                                    <a href="#ch05">        
                                                                        <div class="section-name">Chapter 5: Scala and SQL through JDBC</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec36" class="chapter-section">
                                                                    <a href="#ch05lvl1sec36">                    
                                                                        <div class="section-name">Interacting with JDBC</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec37" class="chapter-section">
                                                                    <a href="#ch05lvl1sec37">                    
                                                                        <div class="section-name">First steps with JDBC</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec38" class="chapter-section">
                                                                    <a href="#ch05lvl1sec38">                    
                                                                        <div class="section-name">JDBC summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec39" class="chapter-section">
                                                                    <a href="#ch05lvl1sec39">                    
                                                                        <div class="section-name">Functional wrappers for JDBC</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec40" class="chapter-section">
                                                                    <a href="#ch05lvl1sec40">                    
                                                                        <div class="section-name">Safer JDBC connections with the loan pattern</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec41" class="chapter-section">
                                                                    <a href="#ch05lvl1sec41">                    
                                                                        <div class="section-name">Enriching JDBC statements with the &amp;quot;pimp my library&amp;quot; pattern</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec42" class="chapter-section">
                                                                    <a href="#ch05lvl1sec42">                    
                                                                        <div class="section-name">Wrapping result sets in a stream</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec43" class="chapter-section">
                                                                    <a href="#ch05lvl1sec43">                    
                                                                        <div class="section-name">Looser coupling with type classes</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec44" class="chapter-section">
                                                                    <a href="#ch05lvl1sec44">                    
                                                                        <div class="section-name">Creating a data access layer</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec45" class="chapter-section">
                                                                    <a href="#ch05lvl1sec45">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="5" data-section-id="ch05lvl1sec46" class="chapter-section">
                                                                    <a href="#ch05lvl1sec46">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="6">
                                                        <div class="section-name">6: Slick â€“ A Functional Interface for SQL</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="6" class="chapter-section">
                                                                    <a href="#ch06">        
                                                                        <div class="section-name">Chapter 6: Slick â€“ A Functional Interface for SQL</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec47" class="chapter-section">
                                                                    <a href="#ch06lvl1sec47">                    
                                                                        <div class="section-name">FEC data</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec48" class="chapter-section">
                                                                    <a href="#ch06lvl1sec48">                    
                                                                        <div class="section-name">Invokers</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec49" class="chapter-section">
                                                                    <a href="#ch06lvl1sec49">                    
                                                                        <div class="section-name">Operations on columns</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec50" class="chapter-section">
                                                                    <a href="#ch06lvl1sec50">                    
                                                                        <div class="section-name">Aggregations with &amp;quot;Group by&amp;quot;</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec51" class="chapter-section">
                                                                    <a href="#ch06lvl1sec51">                    
                                                                        <div class="section-name">Accessing database metadata</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec52" class="chapter-section">
                                                                    <a href="#ch06lvl1sec52">                    
                                                                        <div class="section-name">Slick versus JDBC</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec53" class="chapter-section">
                                                                    <a href="#ch06lvl1sec53">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="6" data-section-id="ch06lvl1sec54" class="chapter-section">
                                                                    <a href="#ch06lvl1sec54">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="7">
                                                        <div class="section-name">7: Web APIs</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="7" class="chapter-section">
                                                                    <a href="#ch07">        
                                                                        <div class="section-name">Chapter 7: Web APIs</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec55" class="chapter-section">
                                                                    <a href="#ch07lvl1sec55">                    
                                                                        <div class="section-name">A whirlwind tour of JSON</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec56" class="chapter-section">
                                                                    <a href="#ch07lvl1sec56">                    
                                                                        <div class="section-name">Querying web APIs</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec57" class="chapter-section">
                                                                    <a href="#ch07lvl1sec57">                    
                                                                        <div class="section-name">JSON in Scala an exercise in pattern matching</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec58" class="chapter-section">
                                                                    <a href="#ch07lvl1sec58">                    
                                                                        <div class="section-name">Extraction using case classes</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec59" class="chapter-section">
                                                                    <a href="#ch07lvl1sec59">                    
                                                                        <div class="section-name">Concurrency and exception handling with futures</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec60" class="chapter-section">
                                                                    <a href="#ch07lvl1sec60">                    
                                                                        <div class="section-name">Authentication adding HTTP headers</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec61" class="chapter-section">
                                                                    <a href="#ch07lvl1sec61">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="7" data-section-id="ch07lvl1sec62" class="chapter-section">
                                                                    <a href="#ch07lvl1sec62">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="8">
                                                        <div class="section-name">8: Scala and MongoDB</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="8" class="chapter-section">
                                                                    <a href="#ch08">        
                                                                        <div class="section-name">Chapter 8: Scala and MongoDB</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec63" class="chapter-section">
                                                                    <a href="#ch08lvl1sec63">                    
                                                                        <div class="section-name">MongoDB</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec64" class="chapter-section">
                                                                    <a href="#ch08lvl1sec64">                    
                                                                        <div class="section-name">Connecting to MongoDB with Casbah</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec65" class="chapter-section">
                                                                    <a href="#ch08lvl1sec65">                    
                                                                        <div class="section-name">Inserting documents</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec66" class="chapter-section">
                                                                    <a href="#ch08lvl1sec66">                    
                                                                        <div class="section-name">Extracting objects from the database</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec67" class="chapter-section">
                                                                    <a href="#ch08lvl1sec67">                    
                                                                        <div class="section-name">Complex queries</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec68" class="chapter-section">
                                                                    <a href="#ch08lvl1sec68">                    
                                                                        <div class="section-name">Casbah query DSL</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec69" class="chapter-section">
                                                                    <a href="#ch08lvl1sec69">                    
                                                                        <div class="section-name">Custom type serialization</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec70" class="chapter-section">
                                                                    <a href="#ch08lvl1sec70">                    
                                                                        <div class="section-name">Beyond Casbah</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec71" class="chapter-section">
                                                                    <a href="#ch08lvl1sec71">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="8" data-section-id="ch08lvl1sec72" class="chapter-section">
                                                                    <a href="#ch08lvl1sec72">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="9">
                                                        <div class="section-name">9: Concurrency with Akka</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="9" class="chapter-section">
                                                                    <a href="#ch09">        
                                                                        <div class="section-name">Chapter 9: Concurrency with Akka</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec73" class="chapter-section">
                                                                    <a href="#ch09lvl1sec73">                    
                                                                        <div class="section-name">GitHub follower graph</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec74" class="chapter-section">
                                                                    <a href="#ch09lvl1sec74">                    
                                                                        <div class="section-name">Actors as people</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec75" class="chapter-section">
                                                                    <a href="#ch09lvl1sec75">                    
                                                                        <div class="section-name">Hello world with Akka</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec76" class="chapter-section">
                                                                    <a href="#ch09lvl1sec76">                    
                                                                        <div class="section-name">Case classes as messages</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec77" class="chapter-section">
                                                                    <a href="#ch09lvl1sec77">                    
                                                                        <div class="section-name">Actor construction</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec78" class="chapter-section">
                                                                    <a href="#ch09lvl1sec78">                    
                                                                        <div class="section-name">Anatomy of an actor</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec79" class="chapter-section">
                                                                    <a href="#ch09lvl1sec79">                    
                                                                        <div class="section-name">Follower network crawler</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec80" class="chapter-section">
                                                                    <a href="#ch09lvl1sec80">                    
                                                                        <div class="section-name">Fetcher actors</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec81" class="chapter-section">
                                                                    <a href="#ch09lvl1sec81">                    
                                                                        <div class="section-name">Routing</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec82" class="chapter-section">
                                                                    <a href="#ch09lvl1sec82">                    
                                                                        <div class="section-name">Message passing between actors</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec83" class="chapter-section">
                                                                    <a href="#ch09lvl1sec83">                    
                                                                        <div class="section-name">Queue control and the pull pattern</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec84" class="chapter-section">
                                                                    <a href="#ch09lvl1sec84">                    
                                                                        <div class="section-name">Accessing the sender of a message</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec85" class="chapter-section">
                                                                    <a href="#ch09lvl1sec85">                    
                                                                        <div class="section-name">Stateful actors</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec86" class="chapter-section">
                                                                    <a href="#ch09lvl1sec86">                    
                                                                        <div class="section-name">Follower network crawler</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec87" class="chapter-section">
                                                                    <a href="#ch09lvl1sec87">                    
                                                                        <div class="section-name">Fault tolerance</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec88" class="chapter-section">
                                                                    <a href="#ch09lvl1sec88">                    
                                                                        <div class="section-name">Custom supervisor strategies</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec89" class="chapter-section">
                                                                    <a href="#ch09lvl1sec89">                    
                                                                        <div class="section-name">Life-cycle hooks</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec90" class="chapter-section">
                                                                    <a href="#ch09lvl1sec90">                    
                                                                        <div class="section-name">What we have not talked about</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec91" class="chapter-section">
                                                                    <a href="#ch09lvl1sec91">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="9" data-section-id="ch09lvl1sec92" class="chapter-section">
                                                                    <a href="#ch09lvl1sec92">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="10">
                                                        <div class="section-name">10: Distributed Batch Processing with Spark</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="10" class="chapter-section">
                                                                    <a href="#ch10">        
                                                                        <div class="section-name">Chapter 10: Distributed Batch Processing with Spark</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec93" class="chapter-section">
                                                                    <a href="#ch10lvl1sec93">                    
                                                                        <div class="section-name">Installing Spark</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec94" class="chapter-section">
                                                                    <a href="#ch10lvl1sec94">                    
                                                                        <div class="section-name">Acquiring the example data</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec95" class="chapter-section">
                                                                    <a href="#ch10lvl1sec95">                    
                                                                        <div class="section-name">Resilient distributed datasets</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec96" class="chapter-section">
                                                                    <a href="#ch10lvl1sec96">                    
                                                                        <div class="section-name">Building and running standalone programs</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec97" class="chapter-section">
                                                                    <a href="#ch10lvl1sec97">                    
                                                                        <div class="section-name">Spam filtering</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec98" class="chapter-section">
                                                                    <a href="#ch10lvl1sec98">                    
                                                                        <div class="section-name">Lifting the hood</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec99" class="chapter-section">
                                                                    <a href="#ch10lvl1sec99">                    
                                                                        <div class="section-name">Data shuffling and partitions</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec100" class="chapter-section">
                                                                    <a href="#ch10lvl1sec100">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="10" data-section-id="ch10lvl1sec101" class="chapter-section">
                                                                    <a href="#ch10lvl1sec101">                    
                                                                        <div class="section-name">Reference</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="11">
                                                        <div class="section-name">11: Spark SQL and DataFrames</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="11" class="chapter-section">
                                                                    <a href="#ch11">        
                                                                        <div class="section-name">Chapter 11: Spark SQL and DataFrames</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec102" class="chapter-section">
                                                                    <a href="#ch11lvl1sec102">                    
                                                                        <div class="section-name">DataFrames a whirlwind introduction</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec103" class="chapter-section">
                                                                    <a href="#ch11lvl1sec103">                    
                                                                        <div class="section-name">Aggregation operations</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec104" class="chapter-section">
                                                                    <a href="#ch11lvl1sec104">                    
                                                                        <div class="section-name">Joining DataFrames together</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec105" class="chapter-section">
                                                                    <a href="#ch11lvl1sec105">                    
                                                                        <div class="section-name">Custom functions on DataFrames</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec106" class="chapter-section">
                                                                    <a href="#ch11lvl1sec106">                    
                                                                        <div class="section-name">DataFrame immutability and persistence</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec107" class="chapter-section">
                                                                    <a href="#ch11lvl1sec107">                    
                                                                        <div class="section-name">SQL statements on DataFrames</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec108" class="chapter-section">
                                                                    <a href="#ch11lvl1sec108">                    
                                                                        <div class="section-name">Complex data types arrays, maps, and structs</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec109" class="chapter-section">
                                                                    <a href="#ch11lvl1sec109">                    
                                                                        <div class="section-name">Interacting with data sources</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec110" class="chapter-section">
                                                                    <a href="#ch11lvl1sec110">                    
                                                                        <div class="section-name">Standalone programs</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec111" class="chapter-section">
                                                                    <a href="#ch11lvl1sec111">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="11" data-section-id="ch11lvl1sec112" class="chapter-section">
                                                                    <a href="#ch11lvl1sec112">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="12">
                                                        <div class="section-name">12: Distributed Machine Learning with MLlib</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="12" class="chapter-section">
                                                                    <a href="#ch12">        
                                                                        <div class="section-name">Chapter 12: Distributed Machine Learning with MLlib</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec113" class="chapter-section">
                                                                    <a href="#ch12lvl1sec113">                    
                                                                        <div class="section-name">Introducing MLlib Spam classification</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec114" class="chapter-section">
                                                                    <a href="#ch12lvl1sec114">                    
                                                                        <div class="section-name">Pipeline components</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec115" class="chapter-section">
                                                                    <a href="#ch12lvl1sec115">                    
                                                                        <div class="section-name">Evaluation</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec116" class="chapter-section">
                                                                    <a href="#ch12lvl1sec116">                    
                                                                        <div class="section-name">Regularization in logistic regression</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec117" class="chapter-section">
                                                                    <a href="#ch12lvl1sec117">                    
                                                                        <div class="section-name">Cross-validation and model selection</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec118" class="chapter-section">
                                                                    <a href="#ch12lvl1sec118">                    
                                                                        <div class="section-name">Beyond logistic regression</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec119" class="chapter-section">
                                                                    <a href="#ch12lvl1sec119">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="12" data-section-id="ch12lvl1sec120" class="chapter-section">
                                                                    <a href="#ch12lvl1sec120">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="13">
                                                        <div class="section-name">13: Web APIs with Play</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="13" class="chapter-section">
                                                                    <a href="#ch13">        
                                                                        <div class="section-name">Chapter 13: Web APIs with Play</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec121" class="chapter-section">
                                                                    <a href="#ch13lvl1sec121">                    
                                                                        <div class="section-name">Client-server applications</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec122" class="chapter-section">
                                                                    <a href="#ch13lvl1sec122">                    
                                                                        <div class="section-name">Introduction to web frameworks</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec123" class="chapter-section">
                                                                    <a href="#ch13lvl1sec123">                    
                                                                        <div class="section-name">Model-View-Controller architecture</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec124" class="chapter-section">
                                                                    <a href="#ch13lvl1sec124">                    
                                                                        <div class="section-name">Single page applications</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec125" class="chapter-section">
                                                                    <a href="#ch13lvl1sec125">                    
                                                                        <div class="section-name">Building an application</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec126" class="chapter-section">
                                                                    <a href="#ch13lvl1sec126">                    
                                                                        <div class="section-name">The Play framework</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec127" class="chapter-section">
                                                                    <a href="#ch13lvl1sec127">                    
                                                                        <div class="section-name">Dynamic routing</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec128" class="chapter-section">
                                                                    <a href="#ch13lvl1sec128">                    
                                                                        <div class="section-name">Actions</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec129" class="chapter-section">
                                                                    <a href="#ch13lvl1sec129">                    
                                                                        <div class="section-name">Interacting with JSON</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec130" class="chapter-section">
                                                                    <a href="#ch13lvl1sec130">                    
                                                                        <div class="section-name">Querying external APIs and consuming JSON</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec131" class="chapter-section">
                                                                    <a href="#ch13lvl1sec131">                    
                                                                        <div class="section-name">Creating APIs with Play: a summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec132" class="chapter-section">
                                                                    <a href="#ch13lvl1sec132">                    
                                                                        <div class="section-name">Rest APIs: best practice</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec133" class="chapter-section">
                                                                    <a href="#ch13lvl1sec133">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="13" data-section-id="ch13lvl1sec134" class="chapter-section">
                                                                    <a href="#ch13lvl1sec134">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="14">
                                                        <div class="section-name">14: Visualization with D3 and the Play Framework</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="14" class="chapter-section">
                                                                    <a href="#ch14">        
                                                                        <div class="section-name">Chapter 14: Visualization with D3 and the Play Framework</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec135" class="chapter-section">
                                                                    <a href="#ch14lvl1sec135">                    
                                                                        <div class="section-name">GitHub user data</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec136" class="chapter-section">
                                                                    <a href="#ch14lvl1sec136">                    
                                                                        <div class="section-name">Do I need a backend?</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec137" class="chapter-section">
                                                                    <a href="#ch14lvl1sec137">                    
                                                                        <div class="section-name">JavaScript dependencies through web-jars</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec138" class="chapter-section">
                                                                    <a href="#ch14lvl1sec138">                    
                                                                        <div class="section-name">Towards a web application: HTML templates</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec139" class="chapter-section">
                                                                    <a href="#ch14lvl1sec139">                    
                                                                        <div class="section-name">Modular JavaScript through RequireJS</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec140" class="chapter-section">
                                                                    <a href="#ch14lvl1sec140">                    
                                                                        <div class="section-name">Bootstrapping the applications</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec141" class="chapter-section">
                                                                    <a href="#ch14lvl1sec141">                    
                                                                        <div class="section-name">Client-side program architecture</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec142" class="chapter-section">
                                                                    <a href="#ch14lvl1sec142">                    
                                                                        <div class="section-name">Drawing plots with NVD3</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec143" class="chapter-section">
                                                                    <a href="#ch14lvl1sec143">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="14" data-section-id="ch14lvl1sec144" class="chapter-section">
                                                                    <a href="#ch14lvl1sec144">                    
                                                                        <div class="section-name">References</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="appA">
                                                        <div class="section-name">Appendix A: Pattern Matching and Extractors</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="appA" class="chapter-section">
                                                                    <a href="#appA">
                                                                        <div class="section-name">Chapter Appendix A: Pattern Matching and Extractors</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="appA" data-section-id="ch14lvl1sec145" class="chapter-section">
                                                                    <a href="#ch14lvl1sec145">                    
                                                                        <div class="section-name">Pattern matching in for comprehensions</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="appA" data-section-id="ch14lvl1sec146" class="chapter-section">
                                                                    <a href="#ch14lvl1sec146">                    
                                                                        <div class="section-name">Pattern matching internals</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="appA" data-section-id="ch14lvl1sec147" class="chapter-section">
                                                                    <a href="#ch14lvl1sec147">                    
                                                                        <div class="section-name">Extracting sequences</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="appA" data-section-id="ch14lvl1sec148" class="chapter-section">
                                                                    <a href="#ch14lvl1sec148">                    
                                                                        <div class="section-name">Summary</div>
                                                                    </a>
                                                                </li>
                                                                <li data-chapter="appA" data-section-id="ch14lvl1sec149" class="chapter-section">
                                                                    <a href="#ch14lvl1sec149">                    
                                                                        <div class="section-name">Reference</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                                <div>
                                                    <li data-chapter="backindex">
                                                        <div class="section-name">Appendix B: Index</div>
                                                        <div class="panel-collapse" role="tabpanel">
                                                            <ul>
                                                                <li data-chapter="backindex" class="chapter-section">
                                                                    <a href="#backindex">
                                                                        <div class="section-name">Chapter Appendix B: Index</div>
                                                                    </a>
                                                                </li>
                                                            </ul>
                                                        </div>
                                                    </li>
                                                </div>
                                            </ul>
                                        </div>
                                        
                                        <div role="tabpanel" class="tab-pane fade" id="author">
                                            <div class="visible-xs">
                                                <h4 class="mobile-title">About the Author</h4>
                                                <hr>
                                            </div>
                                            <p><strong>Pascal Bugnion</strong></p>
                                            <div>
                                                <p>Pascal Bugnion is a data engineer at the ASI, a consultancy offering bespoke data science services. Previously, he was the head of data engineering at SCL Elections. He holds a PhD in computational physics from Cambridge University.</p>
                <p>Besides Scala, Pascal is a keen Python developer. He has contributed to NumPy, matplotlib and IPython. He also maintains scikit-monaco, an open source library for Monte Carlo integration. He currently lives in London, UK.</p>
                                            </div>
                                        </div>
                                        
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="next-wrapper">
                        <div class="row ns">
                            <hr />
                            <span class="hidden-xs">
                                <h4 class="pull-left">
                                    <strong>Up Next: </strong><span class="section-title"></span>
                                </h4>
                                <a href="#" class="btn btn-primary pull-right btn-lg">
                                    Next Section
                                </a>
                            </span>
                            <span class="visible-xs">
                                <a href="#" class="btn btn-primary btn-block btn-lg">
                                    Next Section
                                </a>
                            </span>
                        </div>
                        <div class="row ns">
                            <hr>
                        </div>
                    </div>
                </div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch01"></a>ChapterÂ 1.Â Scala and Data Science</h2></div></div></div><p>The second half of the 20<sup>th</sup> century was the age of silicon. In fifty years, computing power went from extremely scarce to entirely mundane. The first half of the 21<sup>st</sup> century is the age of the Internet. The last 20 years have seen the rise of giants such as Google, Twitter, and Facebookâ€”giants that have forever changed the way we view knowledge.</p><p>The Internet is a vast nexus of information. Ninety percent of the data generated by humanity has been generated in the last 18 months. The programmers, statisticians, and scientists who can harness this glut of data to derive real understanding will have an ever greater influence on how businesses, governments, and charities make decisions.</p><p>This book strives to introduce some of the tools that you will need to synthesize the avalanche of data to produce true insight.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec08"></a>Data science</h2></div></div><hr /></div><p>Data science is the <a id="id0" class="indexterm"></a>process of extracting useful information from data. As a <a id="id1" class="indexterm"></a>discipline, it remains somewhat ill-defined, with nearly as many definitions as there are experts. Rather than add yet another definition, I will follow <span class="emphasis"><em>Drew Conway's</em></span> description (<a class="ulink" href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram" target="_blank">http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram</a>). He describes data science as the culmination of three orthogonal sets of skills:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Data scientists must have <span class="emphasis"><em>hacking skills</em></span>. Data is stored and transmitted through computers. Computers, programming languages, and libraries are the hammers and chisels of data scientists; they must wield them with confidence and accuracy to sculpt the data as they please. This is where Scala comes in: it's a powerful tool to have in your programming toolkit.</p></li><li style="list-style-type: disc"><p>Data scientists must have a sound understanding of <span class="emphasis"><em>statistics and numerical algorithms</em></span>. Good data scientists will understand how machine learning algorithms function and how to interpret results. They will not be fooled by misleading metrics, deceptive statistics, or misinterpreted causal links.</p></li><li style="list-style-type: disc"><p>A good data scientist must have a sound understanding of the <span class="emphasis"><em>problem domain</em></span>. The data science process involves building and discovering knowledge about the problem domain in a scientifically rigorous manner. The data scientist must, therefore, ask the right questions, be aware of previous results, and understand how the data science effort fits in the wider business or research context.</p></li></ul></div><p>Drew Conway summarizes <a id="id2" class="indexterm"></a>this elegantly with a Venn diagram showing data science at the intersection of hacking skills, maths and statistics knowledge, and substantive expertise:</p><div class="mediaobject"><img src="graphics/4795_01_01.jpg" /></div><p>It is, of course, rare for people to be experts in more than one of these areas. Data scientists often work in cross-functional teams, with different members providing the expertise for different areas. To function effectively, every member of the team must nevertheless have a general working knowledge of all three areas.</p><p>To give a more concrete overview of the workflow in a data science project, let's imagine that we are trying to write an application that analyzes the public perception of a political campaign. This is what the data science pipeline might look like:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<span class="strong"><strong>Obtaining data</strong></span>: This might involve extracting information from text files, polling a sensor network or querying a web API. We could, for instance, query the Twitter API to obtain lists of tweets with the relevant hashtags.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Data ingestion</strong></span>: Data often comes from many different sources and might be unstructured or semi-structured. Data ingestion involves moving data from the data source, processing it to extract structured information, and storing this information in a database. For tweets, for instance, we might extract the username, the names of other users mentioned in the tweet, the hashtags, text of the tweet, and whether the tweet contains certain keywords.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Exploring data</strong></span>: We often <a id="id3" class="indexterm"></a>have a clear idea of what information we want to extract from the data but very little idea how. For instance, let's imagine that we have ingested thousands of tweets containing hashtags relevant to our political campaign. There is no clear path to go from our database of tweets to the end goal: insight into the overall public perception of our campaign. Data exploration involves mapping out how we are going to get there. This step will often uncover new questions or sources of data, which requires going back to the first step of the pipeline. For our tweet database, we might, for instance, decide that we need to have a human manually label a thousand or more tweets as expressing "positive" or "negative" sentiments toward the political campaign. We could then use these tweets as a training set to construct a model.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Feature building</strong></span>: A machine learning algorithm is only as good as the features that enter it. A significant fraction of a data scientist's time involves transforming and combining existing features to create new features more closely related to the problem that we are trying to solve. For instance, we might construct a new feature corresponding to the number of "positive" sounding words or pairs of words in a tweet.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Model construction and training</strong></span>: Having built the features that enter the model, the data scientist can now train machine learning algorithms on their datasets. This will often involve trying different algorithms and optimizing model <span class="strong"><strong>hyperparameters</strong></span>. We might, for instance, settle on using a random forest algorithm to decide whether a tweet is "positive" or "negative" about the campaign. Constructing the model involves choosing the right number of trees and how to calculate impurity measures. A sound understanding of statistics and the problem domain will help inform these decisions.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Model extrapolation and prediction</strong></span>: The data scientists can now use their new model to try and infer information about previously unseen data points. They might pass a new tweet through their model to ascertain whether it speaks positively or negatively of the political campaign.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Distillation of intelligence and insight from the model</strong></span>: The data scientists combine the outcome of the data analysis process with knowledge of the business domain to inform business decisions. They might discover that specific messages resonate better with the target audience, or with specific segments of the target audience, leading to more accurate targeting. A key part of informing stakeholders involves data visualization and presentation: data scientists create graphs, visualizations, and reports to help make the insights derived clear and compelling.</p></li></ul></div><p>This is far from a linear <a id="id4" class="indexterm"></a>pipeline. Often, insights gained at one stage will require the data scientists to backtrack to a previous stage of the pipeline. Indeed, the generation of business insights from raw data is normally an iterative process: the data scientists might do a rapid first pass to verify the premise of the problem and then gradually refine the approach by adding new data sources or new features or trying new machine learning algorithms.</p><p>In this book, you will learn how to deal with each step of the pipeline in Scala, leveraging existing libraries to build robust applications.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec09"></a>Programming in data science</h2></div></div><hr /></div><p>This book is not <a id="id5" class="indexterm"></a>a book about data science. It is a book about how to use Scala, a programming language, for data science. So, where does programming come in when processing data?</p><p>Computers are involved at every step of the data science pipeline, but not necessarily in the same manner. The style of programs that we build will be drastically different if we are just writing throwaway scripts to explore data or trying to build a scalable application that pushes data through a well-understood pipeline to continuously deliver business intelligence.</p><p>Let's imagine that we work for a company making games for mobile phones in which you can purchase in-game benefits. The majority of users never buy anything, but a small fraction is likely to spend a lot of money. We want to build a model that recognizes big spenders based on their play patterns.</p><p>The first step is to explore data, find the right features, and build a model based on a subset of the data. In this exploration phase, we have a clear goal in mind but little idea of how to get there. We want a light, flexible language with strong libraries to get us a working model as soon as possible.</p><p>Once we have a working model, we need to deploy it on our gaming platform to analyze the usage patterns of all the current users. This is a very different problem: we have a relatively clear understanding of the goals of the program and of how to get there. The challenge comes in designing software that will scale out to handle all the users and be robust to future changes in usage patterns.</p><p>In practice, the type of <a id="id6" class="indexterm"></a>software that we write typically lies on a spectrum ranging from a single throwaway script to production-level code that must be proof against future expansion and load increases. Before writing any code, the data scientist must understand where their software lies on this spectrum. Let's call this the <span class="strong"><strong>permanence </strong></span>
<a id="id7" class="indexterm"></a>
<span class="strong"><strong>spectrum</strong></span>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec10"></a>Why Scala?</h2></div></div><hr /></div><p>You want to write a program that handles data. Which language should you choose?</p><p>There are a few different options. You might choose a dynamic language such as Python or R or a more traditional object-oriented language such as Java. In this section, we will explore how Scala differs from these languages and when it might make sense to use it.</p><p>When choosing a <a id="id8" class="indexterm"></a>language, the architect's trade-off lies in a balance of provable correctness versus development speed. Which of these aspects you need to emphasize will depend on the application requirements and where on the permanence spectrum your program lies. Is this a short script that will be used by a few people who can easily fix any problems that arise? If so, you can probably permit a certain number of bugs in rarely used code paths: when a developer hits a snag, they can just fix the problem as it arises. By contrast, if you are developing a database engine that you plan on releasing to the wider world, you will, in all likelihood, favor correctness over rapid development. The SQLite database engine, for instance, is famous for its extensive test suite, with 800 times as much testing code as application code (<a class="ulink" href="https://www.sqlite.org/testing.html" target="_blank">https://www.sqlite.org/testing.html</a>).</p><p>What matters, when estimating the <span class="emphasis"><em>correctness</em></span> of a program, is not the perceived absence of bugs, it is the degree to which you can prove that certain bugs are absent.</p><p>There are several ways of proving the absence of bugs before the code has even run:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Static type checking occurs at compile time in statically typed languages, but this can also be used in strongly typed dynamic languages that support type annotations or type hints. Type checking helps verify that we are using functions and classes as intended.</p></li><li style="list-style-type: disc"><p>Static analyzers and linters that check for undefined variables or suspicious behavior (such as parts of the code that can never be reached).</p></li><li style="list-style-type: disc"><p>Declaring some attributes as immutable or constant in compiled languages.</p></li><li style="list-style-type: disc"><p>Unit testing to <a id="id9" class="indexterm"></a>demonstrate the absence of bugs along particular code paths.</p></li></ul></div><p>There are several more ways of checking for the absence of some bugs at runtime:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Dynamic type checking in both statically typed and dynamic languages</p></li><li style="list-style-type: disc"><p>Assertions verifying supposed program invariants or expected contracts</p></li></ul></div><p>In the next sections, we will examine how Scala compares to other languages in data science.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec10"></a>Static typing and type inference</h3></div></div></div><p>Scala's static <a id="id10" class="indexterm"></a>typing system is very versatile. A lot of information as to the program's behavior can be encoded in types, allowing the compiler to guarantee a certain level of correctness. This is particularly useful for code paths that are rarely used. A dynamic language cannot catch errors until a particular branch of execution runs, so a bug can persist for a long time until the program runs into it. In a statically typed language, any bug that can be caught by the compiler will be caught at compile time, before the program has even started running.</p><p>Statically typed object-oriented languages have often been criticized for being needlessly verbose. Consider the initialization of an instance of the <code class="literal">Example</code> class in Java:</p><div class="informalexample"><pre class="programlisting">Example myInstance = new Example() ;</pre></div><p>We have to repeat the class name twiceâ€”once to define the compile-time type of the <code class="literal">myInstance</code> variable and once to construct the instance itself. This feels like unnecessary work: the compiler knows that the type of <code class="literal">myInstance</code> is <code class="literal">Example</code> (or a superclass of <code class="literal">Example</code>) as we are binding a value of the <code class="literal">Example</code> type.</p><p>Scala, like most functional languages, uses type inference to allow the compiler to infer the type of variables from the instances bound to them. We would write the equivalent line in Scala as follows:</p><div class="informalexample"><pre class="programlisting">val myInstance = new Example()</pre></div><p>The Scala compiler infers that <code class="literal">myInstance</code> has the <code class="literal">Example</code> type at compile time. A lot of the time, it is enough to specify the types of the arguments and of the return value of a function. The compiler can then infer types for all the variables defined in the body of the function. Scala code is usually much more concise and readable than the equivalent Java code, without compromising any of the type safety.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec11"></a>Scala encourages immutability</h3></div></div></div><p>Scala encourages the use of <a id="id11" class="indexterm"></a>immutable objects. In Scala, it is very easy to define an attribute as immutable:</p><div class="informalexample"><pre class="programlisting">val amountSpent = 200</pre></div><p>The default collections are immutable:</p><div class="informalexample"><pre class="programlisting">val clientIds = List("123", "456") // List is immutable
clientIds(1) = "589" // Compile-time error</pre></div><p>Having immutable objects removes a common source of bugs. Knowing that some objects cannot be changed once instantiated reduces the number of places bugs can creep in. Instead of considering the lifetime of the object, we can narrow in on the constructor.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec12"></a>Scala and functional programs</h3></div></div></div><p>Scala encourages <a id="id12" class="indexterm"></a>functional code. A lot of Scala code consists of using higher-order functions to transform collections. You, as a programmer, do not have to deal with the details of iterating over the collection. Let's write an <code class="literal">occurrencesOf</code> function that returns the indices at which an element occurs in a list:</p><div class="informalexample"><pre class="programlisting">def occurrencesOf[A](elem:A, collection:List[A]):List[Int] = {
  for { 
    (currentElem, index) &lt;- collection.zipWithIndex
    if (currentElem == elem)
  } yield index
}</pre></div><p>How does this work? We first declare a new list, <code class="literal">collection.zipWithIndex</code>, whose elements are <code class="literal">(collection(0), 0)</code>, <code class="literal">(collection(1), 1)</code>, and so on: pairs of the collection's elements and their indexes.</p><p>We then tell Scala that we want to iterate over this collection, binding the <code class="literal">currentElem</code> variable to the current element and <code class="literal">index</code> to the index. We apply a filter on the iteration, selecting only those elements for which <code class="literal">currentElem == elem</code>. We then tell Scala to just return the <code class="literal">index</code> variable.</p><p>We did not need to deal with the details of the iteration process in Scala. The syntax is very declarative: we tell the compiler that we want the index of every element equal to <code class="literal">elem</code> in collection and let the compiler worry about how to iterate over collection.</p><p>Consider the equivalent in Java:</p><div class="informalexample"><pre class="programlisting">static &lt;T&gt; List&lt;Integer&gt; occurrencesOf(T elem, List&lt;T&gt; collection) {
  List&lt;Integer&gt; occurrences = new ArrayList&lt;Integer&gt;() ;
  for (int i=0; i&lt;collection.size(); i++) {
    if (collection.get(i).equals(elem)) {
      occurrences.add(i) ;
    }
  }
  return occurrences ;
}</pre></div><p>In Java, you start by defining a (mutable) list in which to put occurrences as you find them. You then iterate over the collection by defining a counter, considering each element in turn and adding its <a id="id13" class="indexterm"></a>index to the list of occurrences, if need be. There are many more moving parts that we need to get right for this method to work. These moving parts exist because we must tell Java how to iterate over the collection, and they represent a common source of bugs.</p><p>Furthermore, as a lot of code is taken up by the iteration mechanism, the line that defines the logic of the function is harder to find:</p><div class="informalexample"><pre class="programlisting">static &lt;T&gt; List&lt;Integer&gt; occurrencesOf(T elem, List&lt;T&gt; collection) {
  List&lt;Integer&gt; occurences = new ArrayList&lt;Integer&gt;() ;
  for (int i=0; i&lt;collection.size(); i++) {
    <span class="strong"><strong>if (collection.get(i).equals(elem)) { </strong></span>
      occurrences.add(i) ;
    }
  }
  return occurrences ;
}</pre></div><p>Note that this is not meant as an attack on Java. In fact, Java 8 adds a slew of functional constructs, such as lambda expressions, the <code class="literal">Optional</code> type that mirrors Scala's <code class="literal">Option</code>, or stream processing. Rather, it is meant to demonstrate the benefit of functional approaches in minimizing the potential for errors and maximizing clarity.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec13"></a>Null pointer uncertainty</h3></div></div></div><p>We often need to <a id="id14" class="indexterm"></a>represent the possible absence of a value. For instance, imagine that we are reading a list of usernames from a CSV file. The CSV file contains name and e-mail information. However, some users have declined to enter their e-mail into the system, so this information is absent. In Java, one would typically represent the e-mail as a string or an <code class="literal">Email</code> class and represent the absence of e-mail information for a particular user by setting that reference to <code class="literal">null</code>. Similarly, in Python, we might use <code class="literal">None</code> to demonstrate the absence of a value.</p><p>This approach is dangerous because we are not encoding the possible absence of e-mail information. In any nontrivial program, deciding whether an instance attribute can be <code class="literal">null</code> requires considering every occasion in which this instance is defined. This quickly becomes impractical, so programmers either assume that a variable is not null or code too defensively.</p><p>Scala (following the lead of other functional languages) introduces the <code class="literal">Option[T]</code> type to represent an attribute that might be absent. We might then write the following:</p><div class="informalexample"><pre class="programlisting">class User {
  ...
  val email:Option[Email]
  ...
}</pre></div><p>We have now encoded the possible absence of e-mail in the type information. It is obvious to any programmer using the <code class="literal">User</code> class that e-mail information is possibly absent. Even better, the compiler knows that the <code class="literal">email</code> field can be absent, forcing us to deal with the problem rather than recklessly ignoring it to have the application burn at runtime in a conflagration of null pointer exceptions.</p><p>All this goes back to achieving a certain level of provable correctness. Never using <code class="literal">null</code>, we know that we will never run into null pointer exceptions. Achieving the same level of correctness in languages without <code class="literal">Option[T]</code> requires writing unit tests on the client code to verify that it behaves correctly when the e-mail attribute is null.</p><p>Note that it is possible to achieve this in Java using, for instance, Google's Guava library (<a class="ulink" href="https://code.google.com/p/guava-libraries/wiki/UsingAndAvoidingNullExplained" target="_blank">https://code.google.com/p/guava-libraries/wiki/UsingAndAvoidingNullExplained</a>) or the <code class="literal">Optional</code> class in Java 8. It is more a matter of convention: using <code class="literal">null</code> in Java to denote the absence of a value has long been the norm.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec14"></a>Easier parallelism</h3></div></div></div><p>Writing programs that <a id="id15" class="indexterm"></a>take advantage of parallel architectures is challenging. It is nevertheless necessary to tackle all but the simplest data science problems.</p><p>Parallel programming is difficult because we, as programmers, tend to think sequentially. Reasoning about the order in which different events can happen in a concurrent program is very challenging.</p><p>Scala provides several abstractions that greatly facilitate the writing of parallel code. These abstractions work by imposing constraints on the way parallelism is achieved. For instance, parallel collections force the user to phrase the computation as a sequence of operations (such as <span class="strong"><strong>map</strong></span>, <span class="strong"><strong>reduce</strong></span>, and <span class="strong"><strong>filter</strong></span>) on collections. Actor systems require the developer to think in terms of actors that encapsulate the application state and communicate by passing messages.</p><p>It might seem paradoxical that restricting the programmer's freedom to write parallel code as they please avoids many of the problems associated with concurrency. However, limiting the number of ways in which a program behaves facilitates thinking about its behavior. For instance, if an actor is misbehaving, we know that the problem lies either in the code for this actor or in one of the messages that the actor receives.</p><p>As an example of the power afforded by having coherent, restrictive abstractions, let's use parallel collections to solve a simple probability problem. We will calculate the probability of getting at least 60 heads out of 100 coin tosses. We can estimate this using Monte Carlo: we simulate 100 coin tosses by drawing 100 random Boolean values and check whether the number of true values is at least 60. We repeat this until results have converged to the required accuracy, or we get bored of waiting.</p><p>Let's run through this in a Scala console:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val nTosses = 100</strong></span>
<span class="strong"><strong>nTosses: Int = 100</strong></span>

<span class="strong"><strong>scala&gt; def trial = (0 until nTosses).count { i =&gt;</strong></span>
<span class="strong"><strong>  util.Random.nextBoolean() // count the number of heads</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>trial: Int</strong></span>
</pre></div><p>The <code class="literal">trial</code> function runs a single set of 100 throws, returning the number of heads:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; trial</strong></span>
<span class="strong"><strong>Int = 51</strong></span>
</pre></div><p>To get our answer, we just need to repeat <code class="literal">trial</code> as many times as we can and aggregate the results. Repeating the same set of operations is ideally suited to parallel collections:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val nTrials = 100000</strong></span>
<span class="strong"><strong>nTrials: Int = 100000</strong></span>

<span class="strong"><strong>scala&gt; (0 until nTrials).par.count { i =&gt; trial &gt;= 60 }</strong></span>
<span class="strong"><strong>Int = 2745</strong></span>
</pre></div><p>The probability is thus approximately 2.5% to 3%. All we had to do to distribute the calculation over every CPU in our computer is use the <code class="literal">par</code> method to parallelize the range <code class="literal">(0 until nTrials)</code>. This demonstrates the benefits of having a coherent abstraction: parallel <a id="id16" class="indexterm"></a>collections let us trivially parallelize any computation that can be phrased in terms of higher-order functions on collections.</p><p>Clearly, not every problem is as easy to parallelize as a simple Monte Carlo problem. However, by offering a rich set of intuitive abstractions, Scala makes writing parallel applications manageable.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec15"></a>Interoperability with Java</h3></div></div></div><p>Scala runs <a id="id17" class="indexterm"></a>on the Java virtual machine. The Scala compiler compiles programs to Java byte code. Thus, Scala developers have access to Java libraries natively. Given the phenomenal number of applications written in Java, both open source and as part of the legacy code in organizations, the interoperability of Scala and Java helps explain the rapid uptake of Scala.</p><p>Interoperability has not just been unidirectional: some Scala libraries, such as the Play framework, are becoming increasingly popular among Java developers.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec11"></a>When not to use Scala</h2></div></div><hr /></div><p>In the previous sections, we described how Scala's strong type system, preference for immutability, functional capabilities, and parallelism abstractions make it easy to write reliable programs and minimize the risk of unexpected behavior.</p><p>What reasons might <a id="id18" class="indexterm"></a>you have to avoid Scala in your next project? One important reason is familiarity. Scala introduces many concepts such as implicits, type classes, and composition using traits that might not be familiar to programmers coming from the object-oriented world. Scala's type system is very expressive, but getting to know it well enough to use its full power takes time and requires adjusting to a new programming paradigm. Finally, dealing with immutable data structures can feel alien to programmers coming from Java or Python.</p><p>Nevertheless, these are all drawbacks that can be overcome with time. Scala does fall short of the other data science languages in library availability. The IPython Notebook, coupled with matplotlib, is an unparalleled resource for data exploration. There are ongoing efforts to provide similar functionality in Scala (Spark Notebooks or Apache Zeppelin, for instance), but there are no projects with the same level of maturity. The type system can also be a minor hindrance when one is exploring data or trying out different models.</p><p>Thus, in this author's biased opinion, Scala excels for more <span class="emphasis"><em>permanent</em></span> programs. If you are writing a throwaway script or exploring data, you might be better served with Python. If you are writing <a id="id19" class="indexterm"></a>something that will need to be reused and requires a certain level of provable correctness, you will find Scala extremely powerful.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec12"></a>Summary</h2></div></div><hr /></div><p>Now that the obligatory introduction is over, it is time to write some Scala code. In the next chapter, you will learn about leveraging Breeze for numerical computations with Scala. For our first foray into data science, we will use logistic regression to predict the gender of a person given their height and weight.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec13"></a>References</h2></div></div><hr /></div><p>By far, the best <a id="id20" class="indexterm"></a>book on Scala is <span class="emphasis"><em>Programming in Scala</em></span> by <span class="emphasis"><em>Martin Odersky</em></span>, <span class="emphasis"><em>Lex Spoon</em></span>, and <span class="emphasis"><em>Bill Venners</em></span>. Besides being authoritative (<span class="emphasis"><em>Martin Odersky</em></span> is the driving force behind Scala), this book is also approachable and readable.</p><p>
<span class="emphasis"><em>Scala Puzzlers</em></span> by <span class="emphasis"><em>Andrew Phillips</em></span> and <span class="emphasis"><em>Nermin Å erifoviÄ‡</em></span> provides a fun way to learn more advanced Scala.</p><p>
<span class="emphasis"><em>Scala for Machine Learning</em></span> by <span class="emphasis"><em>Patrick R. Nicholas</em></span> provides examples of how to write machine learning algorithms with Scala.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch02"></a>ChapterÂ 2.Â Manipulating Data with Breeze</h2></div></div></div><p>Data science is, by and large, concerned with the manipulation of structured data. A large fraction of structured datasets can be viewed as tabular data: each row represents a particular instance, and columns represent different attributes of that instance. The ubiquity of tabular representations explains the success of spreadsheet programs like Microsoft Excel, or of tools like SQL databases.</p><p>To be useful to data scientists, a language must support the manipulation of columns or tables of data. Python does this through NumPy and pandas, for instance. Unfortunately, there is no single, coherent ecosystem for numerical computing in Scala that quite measures up to the SciPy ecosystem in Python.</p><p>In this chapter, we will introduce Breeze, a library for fast linear algebra and manipulation of data arrays as well as many other features necessary for scientific computing and data science.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec14"></a>Code examples</h2></div></div><hr /></div><p>The easiest way to access <a id="id21" class="indexterm"></a>the code examples in this book is to clone the GitHub repository:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ git clone 'https://github.com/pbugnion/s4ds'</strong></span>
</pre></div><p>The code samples for each chapter are in a single, standalone folder. You may also browse the code online on GitHub.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec15"></a>Installing Breeze</h2></div></div><hr /></div><p>If you have <a id="id22" class="indexterm"></a>downloaded the code examples for this book, the easiest way of using Breeze is to go into the <code class="literal">chap02</code> directory and type <code class="literal">sbt console</code> at the command line. This will open a Scala console in which you can import Breeze.</p><p>If you want to build a standalone project, the most common way of installing Breeze (and, indeed, any Scala module) is through SBT. To fetch the dependencies required for this chapter, copy the following lines to a file called <code class="literal">build.sbt</code>, taking care to leave an empty line after <code class="literal">scalaVersion</code>:</p><div class="informalexample"><pre class="programlisting">scalaVersion := "2.11.7"

libraryDependencies ++= Seq(
  "org.scalanlp" %% "breeze" % "0.11.2",
  "org.scalanlp" %% "breeze-natives" % "0.11.2"
)</pre></div><p>Open a Scala console in the same directory as your <code class="literal">build.sbt</code> file by typing <code class="literal">sbt console</code> in a terminal. You <a id="id23" class="indexterm"></a>can check that Breeze is working correctly by importing Breeze from the Scala prompt:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import breeze.linalg._</strong></span>
<span class="strong"><strong>import breeze.linalg._</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec16"></a>Getting help on Breeze</h2></div></div><hr /></div><p>This chapter <a id="id24" class="indexterm"></a>gives a reasonably detailed introduction to Breeze, but it does not aim to give a complete API reference.</p><p>To get a full list of <a id="id25" class="indexterm"></a>Breeze's functionality, consult the Breeze Wiki page on GitHub at <a class="ulink" href="https://github.com/scalanlp/breeze/wiki" target="_blank">https://github.com/scalanlp/breeze/wiki</a>. This is very complete for some modules and less complete for others. The source code (<a class="ulink" href="https://github.com/scalanlp/breeze/" target="_blank">https://github.com/scalanlp/breeze/</a>) is detailed and gives a lot of information. To understand how a particular function is meant to be used, look at the unit tests for that function.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec17"></a>Basic Breeze data types</h2></div></div><hr /></div><p>Breeze is an <a id="id26" class="indexterm"></a>extensive library providing fast and easy manipulation of arrays of data, routines for optimization, interpolation, linear algebra, signal processing, and numerical integration.</p><p>The basic linear algebra <a id="id27" class="indexterm"></a>operations underlying Breeze rely on the <code class="literal">netlib-java</code> library, which can use system-optimized <span class="strong"><strong>BLAS</strong></span> and <span class="strong"><strong>LAPACK</strong></span> libraries, if <a id="id28" class="indexterm"></a>present. Thus, linear algebra operations in Breeze are often extremely <a id="id29" class="indexterm"></a>fast. Breeze is still undergoing rapid development and can, therefore, be somewhat unstable.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec16"></a>Vectors</h3></div></div></div><p>Breeze makes <a id="id30" class="indexterm"></a>manipulating one- and two-dimensional data structures easy. To <a id="id31" class="indexterm"></a>start, open a Scala console through SBT and import Breeze:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sbt console</strong></span>
<span class="strong"><strong>scala&gt; import breeze.linalg._</strong></span>
<span class="strong"><strong>import breeze.linalg._</strong></span>
</pre></div><p>Let's dive straight in and define a vector:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val v = DenseVector(1.0, 2.0, 3.0)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)</strong></span>
</pre></div><p>We have just defined a three-element vector, <code class="literal">v</code>. Vectors are just one-dimensional arrays of data exposing methods tailored to numerical uses. They can be indexed like other Scala collections:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v(1)</strong></span>
<span class="strong"><strong>Double = 2.0</strong></span>
</pre></div><p>They support element-wise operations with a scalar:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v :* 2.0 // :* is 'element-wise multiplication'</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(2.0, 4.0, 6.0)</strong></span>
</pre></div><p>They also support element-wise operations with another vector:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v :+ DenseVector(4.0, 5.0, 6.0) // :+ is 'element-wise addition'</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(5.0, 7.0, 9.0)</strong></span>
</pre></div><p>Breeze makes writing vector operations intuitive and considerably more readable than the native Scala equivalent.</p><p>Note that Breeze will <a id="id32" class="indexterm"></a>refuse (at compile time) to coerce operands to the correct type:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v :* 2 // element-wise multiplication by integer</strong></span>
<span class="strong"><strong>&lt;console&gt;:15: error: could not find implicit value for parameter op:</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>It will also <a id="id33" class="indexterm"></a>refuse (at runtime) to add vectors together if they have different lengths:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v :+ DenseVector(8.0, 9.0)</strong></span>
<span class="strong"><strong>java.lang.IllegalArgumentException: requirement failed: Vectors must have same length: 3 != 2</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>Basic manipulation of vectors in Breeze will feel natural to anyone used to working with NumPy, MATLAB, or R.</p><p>So far, we have only looked at <span class="emphasis"><em>element-wise</em></span> operators. These are all prefixed with a colon. All the usual suspects are present: <code class="literal">:+</code>, <code class="literal">:*</code>, <code class="literal">:-</code>, <code class="literal">:/</code>, <code class="literal">:%</code> (remainder), and <code class="literal">:^</code> (power) as well as Boolean operators. To see the full list of operators, have a look at the API documentation for <a id="id34" class="indexterm"></a>
<code class="literal">DenseVector </code>or <code class="literal">DenseMatrix </code>(<a class="ulink" href="https://github.com/scalanlp/breeze/wiki/Linear-Algebra-Cheat-Sheet" target="_blank">https://github.com/scalanlp/breeze/wiki/Linear-Algebra-Cheat-Sheet</a>).</p><p>Besides <a id="id35" class="indexterm"></a>element-wise operations, Breeze vectors support the operations you <a id="id36" class="indexterm"></a>might expect of mathematical vectors, such as the dot product:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val v2 = DenseVector(4.0, 5.0, 6.0)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(4.0, 5.0, 6.0)</strong></span>

<span class="strong"><strong>scala&gt; v dot v2</strong></span>
<span class="strong"><strong>Double = 32.0</strong></span>
</pre></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip02"></a>Tip</h3><p>
<span class="strong"><strong>Pitfalls of element-wise operators</strong></span>
</p><p>Besides the <code class="literal">:+ </code>and <code class="literal">:- </code>operators for element-wise addition and subtraction that we have seen so far, we <a id="id37" class="indexterm"></a>can also use the more traditional <code class="literal">+</code> and <code class="literal">-</code> operators:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v + v2</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(5.0, 7.0, 9.0)</strong></span>
</pre></div><p>One must, however, be very careful with operator precedence rules when mixing <code class="literal">:+</code> or <code class="literal">:*</code> with <code class="literal">:+</code> operators. The <code class="literal">:+</code> and <code class="literal">:*</code> operators have very low operator precedence, so they will be evaluated last. This can lead to some counter-intuitive behavior:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; 2.0 :* v + v2 // !! equivalent to 2.0 :* (v + v2)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(10.0, 14.0, 18.0)</strong></span>
</pre></div><p>By contrast, if we use <code class="literal">:+</code> instead of <code class="literal">+</code>, the mathematical precedence of operators is respected:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; 2.0 :* v :+ v2 // equivalent to (2.0 :* v) :+ v2</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(6.0, 9.0, 12.0)</strong></span>
</pre></div><p>In summary, one should avoid mixing the <code class="literal">:+</code> style operators with the <code class="literal">+</code> style operators as much as possible.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec17"></a>Dense and sparse vectors and the vector trait</h3></div></div></div><p>All the vectors we have <a id="id38" class="indexterm"></a>looked at thus far have been dense vectors. Breeze also supports <a id="id39" class="indexterm"></a>sparse vectors. When dealing with arrays of numbers that are mostly <a id="id40" class="indexterm"></a>zero, it may be more computationally efficient to use sparse vectors. The point at which a vector has enough zeros to warrant switching to a sparse representation depends strongly on the type of operations, so you should run your own benchmarks to determine which type to use. Nevertheless, a good heuristic is that, if your vector is about 90% zero, you may benefit from using a sparse representation.</p><p>Sparse vectors are available in Breeze as the <code class="literal">SparseVector</code> and <code class="literal">HashVector</code> classes. Both these types support many of the same operations as <code class="literal">DenseVector</code> but use a different internal <a id="id41" class="indexterm"></a>implementation. The <code class="literal">SparseVector</code> instances are very memory-efficient, but adding non-zero elements is slow. <code class="literal">HashVector </code>is more versatile, at the cost of an <a id="id42" class="indexterm"></a>increase in memory footprint and computational time for iterating over non-zero elements. Unless you need to squeeze the last bits of memory out of <a id="id43" class="indexterm"></a>your application, I recommend using <code class="literal">HashVector</code>. We will not discuss these further in this book, but the reader should find them straightforward to use if needed. <code class="literal">DenseVector</code>, <code class="literal">SparseVector</code>, and <code class="literal">HashVector</code> all implement the <code class="literal">Vector</code> trait, giving them a common interface.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip06"></a>Tip</h3><p>Breeze remains very experimental and, as of this writing, somewhat unstable. I have found dealing with specific implementations of the <code class="literal">Vector</code> trait, such as<code class="literal"> DenseVector</code> or <code class="literal">SparseVector</code>, to be more reliable than dealing with the <code class="literal">Vector</code> trait directly. In this chapter, we will explicitly type every vector as <code class="literal">DenseVector</code>.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec18"></a>Matrices</h3></div></div></div><p>Breeze <a id="id44" class="indexterm"></a>allows the construction and manipulation of two-dimensional <a id="id45" class="indexterm"></a>arrays in a similar manner:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val m = DenseMatrix((1.0, 2.0, 3.0), (4.0, 5.0, 6.0))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseMatrix[Double] =</strong></span>
<span class="strong"><strong>1.0  2.0  3.0</strong></span>
<span class="strong"><strong>4.0  5.0  6.0</strong></span>

<span class="strong"><strong>scala&gt; 2.0 :* m</strong></span>
<span class="strong"><strong>breeze.linalg.DenseMatrix[Double] =</strong></span>
<span class="strong"><strong>2.0  4.0   6.0</strong></span>
<span class="strong"><strong>8.0  10.0  12.0</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec19"></a>Building vectors and matrices</h3></div></div></div><p>We have <a id="id46" class="indexterm"></a>seen how to explicitly build vectors and <a id="id47" class="indexterm"></a>matrices by passing their values <a id="id48" class="indexterm"></a>to <a id="id49" class="indexterm"></a>the constructor (or rather, to the companion object's <code class="literal">apply</code> method): <code class="literal">DenseVector(1.0, 2.0, 3.0)</code>. Breeze offers several other powerful ways of building vectors and matrices:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; DenseVector.ones[Double](5)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(1.0, 1.0, 1.0, 1.0, 1.0)</strong></span>

<span class="strong"><strong>scala&gt; DenseVector.zeros[Int](3)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Int] = DenseVector(0, 0, 0)</strong></span>
</pre></div><p>The <code class="literal">linspace</code> method (available in the <code class="literal">breeze.linalg</code> package object) creates a <code class="literal">Double</code> vector of equally spaced values. For instance, to create a vector of 10 values distributed uniformly between <code class="literal">0</code> and <code class="literal">1</code>, perform the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; linspace(0.0, 1.0, 10)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.1111111111111111, ..., 1.0)</strong></span>
</pre></div><p>The <code class="literal">tabulate</code> method lets us construct vectors and matrices from functions:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; DenseVector.tabulate(4) { i =&gt; 5.0 * i }</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 5.0, 10.0, 15.0)</strong></span>

<span class="strong"><strong>scala&gt; DenseMatrix.tabulate[Int](2, 3) { </strong></span>
<span class="strong"><strong>  (irow, icol) =&gt; irow*2 + icol </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>breeze.linalg.DenseMatrix[Int] =</strong></span>
<span class="strong"><strong>0  1  2</strong></span>
<span class="strong"><strong>2  3  4</strong></span>
</pre></div><p>The first argument to <code class="literal">DenseVector.tabulate</code> is the size of the vector, and the second is a function returning the value of the vector at a particular position. This is useful for creating ranges of data, among other things.</p><p>The <code class="literal">rand</code> function lets us create random vectors and matrices:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; DenseVector.rand(2)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.8072865137359484, 0.5566507203838562)</strong></span>

<span class="strong"><strong>scala&gt; DenseMatrix.rand(2, 3)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseMatrix[Double] =</strong></span>
<span class="strong"><strong>0.5755491874682879   0.8142161471517582  0.9043780212739738</strong></span>
<span class="strong"><strong>0.31530195124023974  0.2095094278911871  0.22069103504148346</strong></span>
</pre></div><p>Finally, we <a id="id50" class="indexterm"></a>can <a id="id51" class="indexterm"></a>construct vectors from Scala arrays:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; DenseVector(Array(2, 3, 4))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Int] = DenseVector(2, 3, 4)</strong></span>
</pre></div><p>To construct <a id="id52" class="indexterm"></a>vectors from other Scala collections, you <a id="id53" class="indexterm"></a>must use the <span class="emphasis"><em>splat</em></span> operator, <code class="literal">:_ *</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val l = Seq(2, 3, 4)</strong></span>
<span class="strong"><strong>l: Seq[Int] = List(2, 3, 4)</strong></span>

<span class="strong"><strong>scala&gt; DenseVector(l :_ *)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Int] = DenseVector(2, 3, 4)</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec20"></a>Advanced indexing and slicing</h3></div></div></div><p>We have <a id="id54" class="indexterm"></a>already seen how to select a particular element in a <a id="id55" class="indexterm"></a>vector <code class="literal">v</code> by its index with, for instance, <code class="literal">v(2)</code>. Breeze <a id="id56" class="indexterm"></a>also offers several powerful methods for selecting parts of a <a id="id57" class="indexterm"></a>vector.</p><p>Let's start by creating a vector to play around with:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val v = DenseVector.tabulate(5) { _.toDouble }</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 1.0, 2.0, 3.0, 4.0)</strong></span>
</pre></div><p>Unlike native Scala collections, Breeze vectors support negative indexing:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v(-1) // last element</strong></span>
<span class="strong"><strong>Double = 4.0</strong></span>
</pre></div><p>Breeze lets us slice the vector using a range:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v(1 to 3)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)</strong></span>

<span class="strong"><strong>scala v(1 until 3) // equivalent to Python v[1:3]</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0)</strong></span>

<span class="strong"><strong>scala&gt; v(v.length-1 to 0 by -1) // reverse view of v</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(4.0, 3.0, 2.0, 1.0, 0.0)</strong></span>
</pre></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip07"></a>Tip</h3><p>Indexing by a range returns a <span class="emphasis"><em>view</em></span> of the original vector: when running <code class="literal">val v2 = v(1 to 3)</code>, no data is copied. This means that slicing is extremely efficient. Taking a slice of a huge vector does not increase the memory footprint at all. It also means that one should be careful updating a slice, since it will also update the original vector. We will discuss mutating vectors and matrices in a subsequent section in this chapter.</p></div><p>Breeze also lets us select an arbitrary set of elements from a vector:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val vSlice = v(2, 4) // Select elements at index 2 and 4</strong></span>
<span class="strong"><strong>breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@9c04d22</strong></span>
</pre></div><p>This creates a <a id="id58" class="indexterm"></a>
<code class="literal">SliceVector</code>, which behaves like a <code class="literal">DenseVector</code> (both implement the <code class="literal">Vector</code> interface), but does not actually have memory <a id="id59" class="indexterm"></a>allocated for values: it just knows how to map from its indices <a id="id60" class="indexterm"></a>to values in its parent vector. One should think of <code class="literal">vSlice</code> as a specific <a id="id61" class="indexterm"></a>view of <code class="literal">v</code>. We can materialize the view (give it its own data rather than acting as a lens through which <code class="literal">v</code> is viewed) by converting it to <code class="literal">DenseVector</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; vSlice.toDenseVector</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(2.0, 4.0)</strong></span>
</pre></div><p>Note that if an element of a slice is out of bounds, an exception will only be thrown when that element is accessed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val vSlice = v(2, 7) // there is no v(7)</strong></span>
<span class="strong"><strong>breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@2a83f9d1</strong></span>

<span class="strong"><strong>scala&gt; vSlice(0) // valid since v(2) is still valid</strong></span>
<span class="strong"><strong>Double = 2.0</strong></span>

<span class="strong"><strong>scala&gt; vSlice(1) // invalid since v(7) is out of bounds</strong></span>
<span class="strong"><strong>java.lang.IndexOutOfBoundsException: 7 not in [-5,5)</strong></span>
<span class="strong"><strong>  ...</strong></span>
</pre></div><p>Finally, one can index vectors using Boolean arrays. Let's start by defining an array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val mask = DenseVector(true, false, false, true, true)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Boolean] = DenseVector(true, false, false, true, true)</strong></span>
</pre></div><p>Then, <code class="literal">v(mask)</code> results in a view containing the elements of <code class="literal">v</code> for which <code class="literal">mask</code> is <code class="literal">true</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v(mask).toDenseVector</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 3.0, 4.0)</strong></span>
</pre></div><p>This can be used as a way of filtering certain elements in a vector. For instance, to select the elements of <code class="literal">v</code> which are less than <code class="literal">3.0</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val filtered = v(v :&lt; 3.0) // :&lt; is element-wise "less than"</strong></span>
<span class="strong"><strong>breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@2b1edef3</strong></span>

<span class="strong"><strong>scala&gt; filtered.toDenseVector</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 1.0, 2.0)</strong></span>
</pre></div><p>Matrices can be indexed in much the same way as vectors. Matrix indexing functions take two <a id="id62" class="indexterm"></a>argumentsâ€”the first argument selects the row(s) and <a id="id63" class="indexterm"></a>the second one slices the column(s):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val m = DenseMatrix((1.0, 2.0, 3.0), (5.0, 6.0, 7.0))</strong></span>
<span class="strong"><strong>m: breeze.linalg.DenseMatrix[Double] =</strong></span>
<span class="strong"><strong>1.0  2.0  3.0</strong></span>
<span class="strong"><strong>5.0  6.0  7.0</strong></span>

<span class="strong"><strong>scala&gt; m(1, 2)</strong></span>
<span class="strong"><strong>Double = 7.0</strong></span>

<span class="strong"><strong>scala&gt; m(1, -1)</strong></span>
<span class="strong"><strong>Double = 7.0</strong></span>

<span class="strong"><strong>scala&gt; m(0 until 2, 0 until 2)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseMatrix[Double] =</strong></span>
<span class="strong"><strong>1.0  2.0</strong></span>
<span class="strong"><strong>5.0  6.0</strong></span>
</pre></div><p>You can also mix <a id="id64" class="indexterm"></a>different slicing types for rows and columns:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; m(0 until 2, 0)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(1.0, 5.0)</strong></span>
</pre></div><p>Note how, in this case, Breeze returns a vector. In general, slicing returns the following objects:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>A scalar when <a id="id65" class="indexterm"></a>single indices are passed as the row and column arguments</p></li><li style="list-style-type: disc"><p>A vector when the row argument is a range and the column argument is a single index</p></li><li style="list-style-type: disc"><p>A vector transpose when the column argument is a range and the row argument is a single index</p></li><li style="list-style-type: disc"><p>A matrix otherwise</p></li></ul></div><p>The symbol <code class="literal">::</code> can be used to indicate <span class="emphasis"><em>every element along a particular direction</em></span>. For instance, we can select the second column of <code class="literal">m</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; m(::, 1)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(2.0, 6.0)</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec21"></a>Mutating vectors and matrices</h3></div></div></div><p>Breeze <a id="id66" class="indexterm"></a>vectors and matrices are mutable. Most of the <a id="id67" class="indexterm"></a>slicing operations described above <a id="id68" class="indexterm"></a>can also be used to set elements of a vector or matrix:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val v = DenseVector(1.0, 2.0, 3.0)</strong></span>
<span class="strong"><strong>v: breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)</strong></span>

<span class="strong"><strong>scala&gt; v(1) = 22.0 // v is now DenseVector(1.0, 22.0, 3.0)</strong></span>
</pre></div><p>We are not <a id="id69" class="indexterm"></a>limited to mutating single elements. In fact, all the indexing operations outlined above can be used to set the elements of vectors or matrices. When mutating slices of vectors or matrices, use the element-wise assignment operator, <code class="literal">:=</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v(0 until 2) := DenseVector(50.0, 51.0) // set elements at position 0 and 1</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(50.0, 51.0)</strong></span>

<span class="strong"><strong>scala&gt; v</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(50.0, 51.0, 3.0)</strong></span>
</pre></div><p>The assignment operator, <code class="literal">:=</code>, works like other element-wise operators in Breeze. If the right-hand side is a scalar, it will automatically be broadcast to a vector of the given shape:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; v(0 until 2) := 0.0 // equivalent to v(0 until 2) := DenseVector(0.0, 0.0)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0)</strong></span>

<span class="strong"><strong>scala&gt; v</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0, 3.0)</strong></span>
</pre></div><p>All element-wise operators have an update counterpart. For instance, the <code class="literal">:+=</code> operator acts like the element-wise addition operator <code class="literal">:+</code>, but also updates its left-hand operand:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val v = DenseVector(1.0, 2.0, 3.0)</strong></span>
<span class="strong"><strong>v: breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)</strong></span>

<span class="strong"><strong>scala&gt; v :+= 4.0</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(5.0, 6.0, 7.0)</strong></span>

<span class="strong"><strong>scala&gt; v</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(5.0, 6.0, 7.0)</strong></span>
</pre></div><p>Notice how the update operator updates the vector in place and returns it.</p><p>We have learnt how to slice vectors and matrices in Breeze to create new views of the original data. These views are not independent of the vector they were created fromâ€”updating the view will update the underlying vector and vice-versa. This is best illustrated with <a id="id70" class="indexterm"></a>an example:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val v = DenseVector.tabulate(6) { _.toDouble }</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 1.0, 2.0, 3.0, 4.0, 5.0)</strong></span>

<span class="strong"><strong>scala&gt; val viewEvens = v(0 until v.length by 2)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 2.0, 4.0)</strong></span>

<span class="strong"><strong>scala&gt; viewEvens := 10.0 // mutate viewEvens</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(10.0, 10.0, 10.0)</strong></span>

<span class="strong"><strong>scala&gt; viewEvens</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(10.0, 10.0, 10.0)</strong></span>

<span class="strong"><strong>scala&gt; v  // v has also been mutated!</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(10.0, 1.0, 10.0, 3.0, 10.0, 5.0)</strong></span>
</pre></div><p>This quickly <a id="id71" class="indexterm"></a>becomes intuitive if we remember that, when <a id="id72" class="indexterm"></a>we create a vector or matrix, we are creating a view of an <a id="id73" class="indexterm"></a>underlying data array rather than creating the data itself:</p><div class="mediaobject"><img src="graphics/4795_02_01.jpg" /><div class="caption"><p>A vector slice <code class="literal">v(0 to 6 by 2)</code> of the <code class="literal">v</code> vector is just a different view of the array underlying <code class="literal">v</code>. The view itself contains no data. It just contains pointers to the data in the original array. Internally, the view is just stored as a pointer to the underlying data and a recipe for iterating over that data: in the case of this slice, the recipe is just "start at the first element of the underlying data and go to the seventh element of the underlying data in steps of two".</p></div></div><p>Breeze offers a <code class="literal">copy</code> function for when we want to create independent copies of data. In the previous example, we can construct a copy of <code class="literal">viewEvens</code> as:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val copyEvens = v(0 until v.length by 2).copy</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(10.0, 10.0, 10.0)</strong></span>
</pre></div><p>We can now <a id="id74" class="indexterm"></a>update <a id="id75" class="indexterm"></a>
<code class="literal">copyEvens</code> independently of <code class="literal">v</code>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec22"></a>Matrix multiplication, transposition, and the orientation of vectors</h3></div></div></div><p>So far, we <a id="id76" class="indexterm"></a>have mostly looked at element-wise <a id="id77" class="indexterm"></a>operations on vectors and matrices. Let's <a id="id78" class="indexterm"></a>now look at matrix multiplication and related operations.</p><p>The matrix multiplication operator is <code class="literal">*</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val m1 = DenseMatrix((2.0, 3.0), (5.0, 6.0), (8.0, 9.0))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseMatrix[Double] =</strong></span>
<span class="strong"><strong>2.0  3.0</strong></span>
<span class="strong"><strong>5.0  6.0</strong></span>
<span class="strong"><strong>8.0  9.0</strong></span>

<span class="strong"><strong>scala&gt; val m2 = DenseMatrix((10.0, 11.0), (12.0, 13.0))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseMatrix[Double] </strong></span>
<span class="strong"><strong>10.0  11.0</strong></span>
<span class="strong"><strong>12.0  13.0</strong></span>

<span class="strong"><strong>scala&gt; m1 * m2</strong></span>
<span class="strong"><strong>56.0   61.0</strong></span>
<span class="strong"><strong>122.0  133.0</strong></span>
<span class="strong"><strong>188.0  205.0</strong></span>
</pre></div><p>Besides matrix-matrix multiplication, we can use the matrix multiplication operator between matrices and vectors. All vectors in Breeze are column vectors. This means that, when multiplying matrices and vectors together, a vector should be viewed as an (<span class="emphasis"><em>n * 1</em></span>) matrix. Let's walk through an example of matrix-vector multiplication. We want the following operation:</p><div class="mediaobject"><img src="graphics/4795_02_02.jpg" /></div><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val v = DenseVector(1.0, 2.0)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0)</strong></span>

<span class="strong"><strong>scala&gt; m1 * v </strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(8.0, 17.0, 26.0)</strong></span>
</pre></div><p>By <a id="id79" class="indexterm"></a>contrast, if we wanted:</p><div class="mediaobject"><img src="graphics/4795_02_03.jpg" /></div><p>We must <a id="id80" class="indexterm"></a>convert <code class="literal">v</code> to a row vector. We can do this <a id="id81" class="indexterm"></a>using the transpose operation:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val vt = v.t</strong></span>
<span class="strong"><strong>breeze.linalg.Transpose[breeze.linalg.DenseVector[Double]] = Transpose(DenseVector(1.0, 2.0))</strong></span>

<span class="strong"><strong>scala&gt; vt * m2</strong></span>
<span class="strong"><strong>breeze.linalg.Transpose[breeze.linalg.DenseVector[Double]] = Transpose(DenseVector(34.0, 37.0))</strong></span>
</pre></div><p>Note that the type of <code class="literal">v.t</code> is <code class="literal">Transpose[DenseVector[_]]</code>. A <code class="literal">Transpose[DenseVector[_]]</code> behaves in much the same way as a <code class="literal">DenseVector</code> as far as element-wise operations are concerned, but it does not support mutation or slicing.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec23"></a>Data preprocessing and feature engineering</h3></div></div></div><p>We have now <a id="id82" class="indexterm"></a>discovered the basic components of <a id="id83" class="indexterm"></a>Breeze. In the next few sections, we will apply them to real examples to understand how they fit together to form a robust base for data science.</p><p>An important part of data science involves preprocessing datasets to construct useful features. Let's walk through an example of this. To follow this example and access the data, you will need to download the code examples for the book (<a class="ulink" href="http://www.github.com/pbugnion/s4ds" target="_blank">www.github.com/pbugnion/s4ds</a>).</p><p>You will find, in directory <code class="literal">chap02/data/</code> of the code attached to this book, a CSV file with true heights and weights as well as self-reported heights and weights for 181 men and women. The original <a id="id84" class="indexterm"></a>dataset was collected as part of a study on body image. Refer to the following link for more information: <a class="ulink" href="http://vincentarelbundock.github.io/Rdatasets/doc/car/Davis.html" target="_blank">http://vincentarelbundock.github.io/Rdatasets/doc/car/Davis.html</a>.</p><p>There is a helper function in the package provided with the book to load the data into Breeze arrays:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val data = HWData.load</strong></span>
<span class="strong"><strong>HWData [ 181 rows ]</strong></span>

<span class="strong"><strong>scala&gt; data.genders</strong></span>
<span class="strong"><strong>breeze.linalg.Vector[Char] = DenseVector(M, F, F, M, ... )</strong></span>
</pre></div><p>The <code class="literal">data</code> <a id="id85" class="indexterm"></a>object contains five vectors, each 181 <a id="id86" class="indexterm"></a>element long:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">data.genders</code>: A <code class="literal">Char</code> vector describing the gender of the participants</p></li><li style="list-style-type: disc"><p>
<code class="literal">data.heights</code>: A <code class="literal">Double</code> vector of the true height of the participants</p></li><li style="list-style-type: disc"><p>
<code class="literal">data.weights</code>: A <code class="literal">Double</code> vector of the true weight of the participants</p></li><li style="list-style-type: disc"><p>
<code class="literal">data.reportedHeights</code>: A <code class="literal">Double</code> vector of the self-reported height of the participants</p></li><li style="list-style-type: disc"><p>
<code class="literal">data.reportedWeights</code>: A <code class="literal">Double</code> vector of the self-reported weight of the participants</p></li></ul></div><p>Let's start by counting the number of men and women in the study. We will define an array that contains just <code class="literal">'M'</code> and do an element-wise comparison with <code class="literal">data.genders</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val maleVector = DenseVector.fill(data.genders.length)('M')</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Char] = DenseVector(M, M, M, M, M, M,... )</strong></span>

<span class="strong"><strong>scala&gt; val isMale = (data.genders :== maleVector)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Boolean] = DenseVector(true, false, false, true ...)</strong></span>
</pre></div><p>The <code class="literal">isMale</code> vector is the same length as <code class="literal">data.genders</code>. It is <code class="literal">true</code> where the participant is male, and <code class="literal">false</code> otherwise. We can use this Boolean array as a mask for the other arrays in the dataset (remember that <code class="literal">vector(mask)</code> selects the elements of <code class="literal">vector</code> where mask is <code class="literal">true</code>). Let's get the height of the men in our dataset:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val maleHeights = data.heights(isMale)</strong></span>
<span class="strong"><strong>breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@61717d42</strong></span>

<span class="strong"><strong>scala&gt; maleHeights.toDenseVector</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(182.0, 177.0, 170.0, ...</strong></span>
</pre></div><p>To count the number of men in our dataset, we can use the indicator function. This transforms a Boolean array into an array of doubles, mapping <code class="literal">false</code> to <code class="literal">0.0</code> and <code class="literal">true</code> to <code class="literal">1.0</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import breeze.numerics._</strong></span>
<span class="strong"><strong>import breeze.numerics._</strong></span>

<span class="strong"><strong>scala&gt; sum(I(isMale))</strong></span>
<span class="strong"><strong>Double: 82.0</strong></span>
</pre></div><p>Let's calculate the <a id="id87" class="indexterm"></a>
<code class="literal">mean</code> height of men and women in the experiment. We can calculate the mean of a vector using <code class="literal">mean(v)</code>, which we can access by importing <code class="literal">breeze.stats._</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import breeze.stats._</strong></span>
<span class="strong"><strong>import breeze.stats._</strong></span>

<span class="strong"><strong>scala&gt; mean(data.heights)</strong></span>
<span class="strong"><strong>Double = 170.75690607734808</strong></span>
</pre></div><p>To calculate the <a id="id88" class="indexterm"></a>
<code class="literal">mean</code> height of the men, we can use our <code class="literal">isMale</code> array to slice <code class="literal">data.heights</code>; <code class="literal">data.heights(isMale)</code> is a view of the <code class="literal">data.heights</code> array with all the height values for the men:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; mean(data.heights(isMale)) // mean male height</strong></span>
<span class="strong"><strong>Double = 178.0121951219512</strong></span>

<span class="strong"><strong>scala&gt; mean(data.heights(!isMale)) // mean female height</strong></span>
<span class="strong"><strong>Double = 164.74747474747474</strong></span>
</pre></div><p>As a somewhat more involved example, let's look at the discrepancy between real and reported weight for both men and women in this experiment. We can get an array of the percentage difference between the reported weight and the true weight:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val discrepancy = (data.weights - data.reportedWeights) / data.weights</strong></span>
<span class="strong"><strong>breeze.linalg.Vector[Double] = DenseVector(0.0, 0.1206896551724138, -0.018867924528301886, -0.029411764705882353, ... )</strong></span>
</pre></div><p>Notice how Breeze's overloading of mathematical operators allows us to manipulate data arrays easily and elegantly.</p><p>We can now calculate the mean and standard deviation of this array for men:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; mean(discrepancy(isMale))</strong></span>
<span class="strong"><strong>res6: Double = -0.008451852933123775</strong></span>

<span class="strong"><strong>scala&gt; stddev(discrepancy(isMale))</strong></span>
<span class="strong"><strong>res8: Double = 0.031901519634244195</strong></span>
</pre></div><p>We can also calculate the fraction of men who overestimated their height:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val overReportMask = (data.reportedHeights :&gt; data.heights).toDenseVector</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Boolean] = DenseVector(false, false, false, false...</strong></span>

<span class="strong"><strong>scala&gt; sum(I(overReportMask :&amp; isMale))</strong></span>
<span class="strong"><strong>Double: 10.0</strong></span>
</pre></div><p>There are <a id="id89" class="indexterm"></a>thus ten men who believe they are taller than <a id="id90" class="indexterm"></a>they actually are. The element-wise AND operator <code class="literal">:&amp;</code> returns a vector that is true for all indices for which both its arguments are true.  The vector <code class="literal">overReportMask :&amp; isMale</code> is thus true for all participants that are male and over-reported their height.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec24"></a>Breeze â€“ function optimization</h3></div></div></div><p>Having studied <a id="id91" class="indexterm"></a>feature engineering, let's now look <a id="id92" class="indexterm"></a>at the other end of the data science pipeline. Typically, a machine learning algorithm defines a loss function that is a function of a set of parameters. The value of the loss function represents how well the model fits the data. The parameters are then optimized to minimize (or maximize) the loss function.</p><p>In <a class="link" href="#" linkend="ch12">Chapter 12</a>, <span class="emphasis"><em>Distributed Machine Learning with MLlib</em></span>, we will look at <span class="strong"><strong>MLlib</strong></span>, a machine learning <a id="id93" class="indexterm"></a>library that contains many well-known algorithms. Often, we don't need to worry about optimizing loss functions directly since we can rely on the machine learning algorithms provided by MLlib. It is nevertheless useful to have a basic knowledge of optimization.</p><p>Breeze has an <code class="literal">optimize</code> module that contains functions for finding a local minimum:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import breeze.optimize._</strong></span>
<span class="strong"><strong>import breeze.optimize._</strong></span>
</pre></div><p>Let's create a toy function that we want to optimize:</p><div class="mediaobject"><img src="graphics/4795_02_04.jpg" /></div><p>We can represent this function in Scala as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; def f(xs:DenseVector[Double]) = sum(xs :^ 2.0)</strong></span>
<span class="strong"><strong>f: (xs: breeze.linalg.DenseVector[Double])Double</strong></span>
</pre></div><p>Most local optimizers also require the gradient of the function being optimized. The gradient is a vector of the same dimension as the arguments to the function. In our case, the gradient is:</p><div class="mediaobject"><img src="graphics/4795_02_05.jpg" /></div><p>We can represent the gradient in Breeze with a function that takes a vector argument and returns a vector of the same length:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; def gradf(xs:DenseVector[Double]) = 2.0 :* xs</strong></span>
<span class="strong"><strong>gradf: (xs:breeze.linalg.DenseVector[Double])breeze.linalg.DenseVector[Double]</strong></span>
</pre></div><p>For instance, at the point <code class="literal">(1, 1, 1)</code>, we have:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val xs = DenseVector.ones[Double](3)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(1.0, 1.0, 1.0)</strong></span>

<span class="strong"><strong>scala&gt; f(xs)</strong></span>
<span class="strong"><strong>Double = 3.0</strong></span>

<span class="strong"><strong>scala&gt; gradf(xs)</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(2.0, 2.0, 2.0)</strong></span>
</pre></div><p>Let's set up the <a id="id94" class="indexterm"></a>optimization problem. Breeze's <a id="id95" class="indexterm"></a>optimization methods require that we pass in an implementation of the <code class="literal">DiffFunction</code> trait with a single method, <code class="literal">calculate</code>. This method must return a tuple of the function and its gradient:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val optTrait = new DiffFunction[DenseVector[Double]] {</strong></span>
<span class="strong"><strong>  def calculate(xs:DenseVector[Double]) = (f(xs), gradf(xs))</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>breeze.optimize.DiffFunction[breeze.linalg.DenseVector[Double]] = &lt;function1&gt;</strong></span>
</pre></div><p>We are now ready to run the optimization. The optimize module provides a <code class="literal">minimize</code> function that does just what we want. We pass it <code class="literal">optTrait</code> and a starting point for the optimization:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val minimum = minimize(optTrait, DenseVector(1.0, 1.0, 1.0))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0, 0.0)</strong></span>
</pre></div><p>The true minimum is at <code class="literal">(0.0, 0.0, 0.0)</code>. The optimizer therefore correctly finds the minimum.</p><p>The <code class="literal">minimize</code> function uses the <a id="id96" class="indexterm"></a>
<span class="strong"><strong>L-BFGS</strong></span> method to run the optimization by default. It takes several additional arguments to control the optimization. We will explore these in the next sections.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec25"></a>Numerical derivatives</h3></div></div></div><p>In the previous <a id="id97" class="indexterm"></a>example, we specified the gradient of <code class="literal">f</code> explicitly. While this is generally good practice, calculating the gradient of a function can often be tedious. Breeze provides a gradient approximation function using finite differences. Reusing the same objective function <code class="literal">def f(xs:DenseVector[Double]) = sum(xs :^ 2.0)</code> as in the previous section:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val approxOptTrait = new ApproximateGradientFunction(f)</strong></span>
<span class="strong"><strong>breeze.optimize.ApproximateGradientFunction[Int,breeze.linalg.DenseVector[Double]] = &lt;function1&gt;</strong></span>
</pre></div><p>The trait<code class="literal"> approxOptTrait</code> has a <code class="literal">gradientAt</code> method that returns an approximation to the gradient at a point:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; approxOptTrait.gradientAt(DenseVector.ones(3))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(2.00001000001393, 2.00001000001393, 2.00001000001393)</strong></span>
</pre></div><p>Note that this can be quite inaccurate. The <code class="literal">ApproximateGradientFunction</code> constructor takes an <code class="literal">epsilon</code> optional argument that controls the size of the step taken when calculating the finite differences. Changing the value of <code class="literal">epsilon</code> can improve the accuracy of the finite difference algorithm.</p><p>The <a id="id98" class="indexterm"></a>
<code class="literal">ApproximateGradientFunction</code> instance implements the <code class="literal">DiffFunction</code> trait. It can therefore be passed to <code class="literal">minimize</code> directly:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; minimize(approxOptTrait, DenseVector.ones[Double](3))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(-5.000001063126813E-6, -5.000001063126813E-6, -5.000001063126813E-6)</strong></span>
</pre></div><p>This, again, gives a result close to zero, but somewhat further away than when we specified the gradient explicitly. In general, it will be significantly more efficient and more accurate to calculate the gradient of a function analytically than to rely on Breeze's numerical gradient. It is probably best to only use the numerical gradient during data exploration or to check analytical gradients.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec26"></a>Regularization</h3></div></div></div><p>The <code class="literal">minimize</code> <a id="id99" class="indexterm"></a>function takes many optional arguments relevant <a id="id100" class="indexterm"></a>to machine learning algorithms. In particular, we can instruct the optimizer to use a regularization parameter when performing the optimization. Regularization introduces a penalty in the loss function to prevent the parameters from growing arbitrarily. This is useful to avoid overfitting. We will discuss regularization in greater detail in <a class="link" href="#" linkend="ch12">Chapter 12</a>, <span class="emphasis"><em>Distributed Machine Learning with MLlib</em></span>.</p><p>For instance, to use <code class="literal">L2Regularization</code> with a hyperparameter of <code class="literal">0.5</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; minimize(optTrait, DenseVector(1.0, 1.0, 1.0), L2Regularization(0.5))</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0, 0.0)</strong></span>
</pre></div><p>The regularization makes no difference in this case, since the parameters are zero at the minimum.</p><p>To see a list of <a id="id101" class="indexterm"></a>optional arguments that can be passed to <code class="literal">minimize</code>, consult <a id="id102" class="indexterm"></a>the Breeze documentation online.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec18"></a>An example â€“ logistic regression</h2></div></div><hr /></div><p>Let's now imagine we <a id="id103" class="indexterm"></a>want to build a classifier that takes a person's <span class="strong"><strong>height</strong></span> and <span class="strong"><strong>weight</strong></span> and assigns a probability to their being <span class="strong"><strong>Male</strong></span> or <span class="strong"><strong>Female</strong></span>. We will reuse the height and weight data introduced earlier in this chapter. Let's start by plotting the dataset:</p><div class="mediaobject"><img src="graphics/chap02_height_weight.jpg" /><div class="caption"><p>Height versus weight data for 181 men and women</p></div></div><p>There are many different algorithms for classification. A first glance at the data shows that we can, approximately, separate men from women by drawing a straight line across the plot. A linear method is therefore a reasonable initial attempt at classification. In this section, we will use logistic regression to build a classifier.</p><p>A detailed explanation of logistic regression is beyond the scope of this book. The reader unfamiliar with logistic regression is referred to <span class="emphasis"><em>The Elements of Statistical Learning</em></span> by <span class="emphasis"><em>Hastie</em></span>, <span class="emphasis"><em>Tibshirani</em></span>, and <span class="emphasis"><em>Friedman</em></span>. We will just give a brief summary here.</p><p>Logistic regression <a id="id104" class="indexterm"></a>estimates the probability of a given <span class="emphasis"><em>height</em></span> and <span class="emphasis"><em>weight</em></span> belonging to a <span class="emphasis"><em>male</em></span> with the following sigmoid function:</p><div class="mediaobject"><img src="graphics/4795_02_06.jpg" /></div><p>Here, <span class="emphasis"><em>f</em></span> is a linear function:</p><div class="mediaobject"><img src="graphics/4795_02_07.jpg" /></div><p>Here, <span class="inlinemediaobject"><img src="graphics/4795_02_19.jpg" /></span> is an array of parameters that we need to determine using the training set. If we consider the height and weight as a <span class="emphasis"><em>features = (height, weight)</em></span> matrix, we can re-write the sigmoid kernel <span class="emphasis"><em>f</em></span> as a matrix multiplication of the <span class="emphasis"><em>features</em></span> matrix with the <span class="emphasis"><em>params</em></span> vector:</p><div class="mediaobject"><img src="graphics/4795_02_08.jpg" /></div><p>To simplify this expression further, it is common to add a dummy feature whose value is always <span class="emphasis"><em>1 </em></span>to the <span class="emphasis"><em>features</em></span> matrix. We can then multiply <span class="emphasis"><em>params(0)</em></span> by this feature, allowing us to write the entire sigmoid kernel <span class="emphasis"><em>f </em></span>as a single matrix-vector multiplication:</p><div class="mediaobject"><img src="graphics/4795_02_09.jpg" /></div><p>The feature matrix, <span class="emphasis"><em>features</em></span>, is now a (<span class="emphasis"><em>181 * 3</em></span>) matrix, where each row is <span class="emphasis"><em>(1, height, weight)</em></span> for a particular participant.</p><p>To find the optimal values of the parameters, we can maximize the likelihood function, <span class="emphasis"><em>L(params|features)</em></span>. The likelihood takes a given set of parameter values as input and returns the probability that these particular parameters gave rise to the training set. For a set of parameters and associated probability function <span class="emphasis"><em>P(male|features<sub>i</sub>),</em></span> the likelihood is:</p><div class="mediaobject"><img src="graphics/4795_02_18.jpg" /></div><p>If we magically know, ahead of time, the gender of everyone in the population, we can assign <span class="emphasis"><em>P(male)=1</em></span> for the men and <span class="emphasis"><em>P(male)=0</em></span> for the women. The likelihood function would then be <span class="strong"><strong>1</strong></span>. Conversely, any uncertainty leads to a reduction in the likelihood function. If we choose a set of parameters that consistently lead to classification errors (low <span class="emphasis"><em>P(male)</em></span> for men or high <span class="emphasis"><em>P(male)</em></span> for women), the likelihood function drops to <span class="emphasis"><em>0</em></span>.</p><p>The maximum likelihood <a id="id105" class="indexterm"></a>corresponds to those values of the parameters most likely to describe the observed data. Thus, to find the parameters that best describe our training set, we just need to find parameters that maximize <span class="emphasis"><em>L(params|features)</em></span>. However, maximizing the likelihood function itself is very rarely done, since it involves multiplying many small values together, which quickly leads to floating point underflow. It is best to maximize the log of the likelihood, which has the same maximum as the likelihood. Finally, since most optimization algorithms are geared to minimize a function rather than maximize it, we will minimize<span class="inlinemediaobject"><img src="graphics/4795_02_10.jpg" /></span>.</p><p>For logistic regression, this is equivalent to minimizing:</p><div class="mediaobject"><img src="graphics/4795_02_add01.jpg" /></div><p>Here, the sum runs over all participants in the training data, <span class="inlinemediaobject"><img src="graphics/4795_02_16.jpg" /></span> is a vector <span class="inlinemediaobject"><img src="graphics/4795_02_12.jpg" /></span> of the <span class="emphasis"><em>i</em></span>-th observation in the training set, and <span class="inlinemediaobject"><img src="graphics/4795_02_17.jpg" /></span> is <span class="emphasis"><em>1</em></span> if the person is male, and <span class="emphasis"><em>0</em></span> if the participant is female.</p><p>To minimize the <span class="emphasis"><em>Cost</em></span> function, we must also know its gradient with respect to the parameters. This is:</p><div class="mediaobject"><img src="graphics/4795_02_21.jpg" /></div><p>We will start by rescaling the height and weight by their mean and standard deviation. While this is not strictly necessary for logistic regression, it is generally good practice. It facilitates the optimization and would become necessary if we wanted to use regularization methods or <a id="id106" class="indexterm"></a>build superlinear features (features that allow the boundary separating men from women to be curved rather than a straight line).</p><p>For this example, we will move away from the Scala shell and write a standalone Scala script. Here's the full code listing. Don't worry if this looks daunting. We will break it up into manageable chunks in a minute:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">import breeze.linalg._</code>
import breeze.numerics._
import breeze.optimize._
import breeze.stats._

object LogisticRegressionHWData extends App {

  val data = HWData.load

  // Rescale the features to have mean of 0.0 and s.d. of 1.0
  def rescaled(v:DenseVector[Double]) =
    (v - mean(v)) / stddev(v)

  val rescaledHeights = rescaled(data.heights)
  val rescaledWeights = rescaled(data.weights)

  // Build the feature matrix as a matrix with 
  //181 rows and 3 columns.
  val rescaledHeightsAsMatrix = rescaledHeights.toDenseMatrix.t
  val rescaledWeightsAsMatrix = rescaledWeights.toDenseMatrix.t

  val featureMatrix = DenseMatrix.horzcat(
    DenseMatrix.ones[Double](rescaledHeightsAsMatrix.rows, 1),
    rescaledHeightsAsMatrix,
    rescaledWeightsAsMatrix
  )

  println(s"Feature matrix size: ${featureMatrix.rows} x " +s"${featureMatrix.cols}")

  // Build the target variable to be 1.0 where a participant
  // is male, and 0.0 where the participant is female.
  val target = data.genders.values.map {
    gender =&gt; if(gender == 'M') 1.0 else 0.0
  }

  // Build the loss function ready for optimization.
  // We will worry about refactoring this to be more 
  // efficient later.
  def costFunction(parameters:DenseVector[Double]):Double = {
    val xBeta = featureMatrix * parameters
    val expXBeta = exp(xBeta)
    - sum((target :* xBeta) - log1p(expXBeta))
  }

  def costFunctionGradient(parameters:DenseVector[Double])
  :DenseVector[Double] = {
    val xBeta = featureMatrix * parameters
    val probs = sigmoid(xBeta)
    featureMatrix.t * (probs - target)
  }

  val f = new DiffFunction[DenseVector[Double]] {
    def calculate(parameters:DenseVector[Double]) =
      (costFunction(parameters), costFunctionGradient(parameters))
  }

  val optimalParameters = minimize(f, DenseVector(0.0, 0.0, 0.0))

  println(optimalParameters)
  // =&gt; DenseVector(-0.0751454743, 2.476293647, 2.23054540)
}</pre></div><p>That was a mouthful! Let's <a id="id107" class="indexterm"></a>take this one step at a time. After the obvious imports, we start with:</p><div class="informalexample"><pre class="programlisting">object LogisticRegressionHWData extends App {</pre></div><p>By extending the built-in <code class="literal">App</code> trait, we tell Scala to treat the entire object as a <code class="literal">main</code> function. This just cuts out <code class="literal">def main(args:Array[String])</code> boilerplate. We then load the data and rescale the height and weight to have a <code class="literal">mean</code> of zero and a standard deviation of one:</p><div class="informalexample"><pre class="programlisting">def rescaled(v:DenseVector[Double]) =
  (v - mean(v)) / stddev(v)

val rescaledHeights = rescaled(data.heights)
val rescaledWeights = rescaled(data.weights)</pre></div><p>The <code class="literal">rescaledHeights</code> and <code class="literal">rescaledWeights</code> vectors will be the features of our model. We can now build the <a id="id108" class="indexterm"></a>training set matrix for this model. This is a (<span class="emphasis"><em>181 * 3</em></span>) matrix, for which the <span class="emphasis"><em>i</em></span>-th row is <code class="literal">(1, height(i), weight(i))</code>, corresponding to the values of the height and weight for the <span class="emphasis"><em>i</em></span>th participant. We start by transforming both <code class="literal">rescaledHeights</code> and <code class="literal">rescaledWeights</code> from vectors to (<span class="emphasis"><em>181 * 1</em></span>) matrices</p><div class="informalexample"><pre class="programlisting">val rescaledHeightsAsMatrix = rescaledHeights.toDenseMatrix.t
val rescaledWeightsAsMatrix = rescaledWeights.toDenseMatrix.t</pre></div><p>We must also create a (<span class="emphasis"><em>181 * 1</em></span>) matrix containing just <span class="emphasis"><em>1</em></span> to act as the dummy feature. We can do this using:</p><div class="informalexample"><pre class="programlisting">DenseMatrix.ones[Double](rescaledHeightsAsMatrix.rows, 1)</pre></div><p>We now need to combine our three (<span class="emphasis"><em>181 * 1</em></span>) matrices together into a single feature matrix of shape (<span class="emphasis"><em>181 * 3</em></span>). We can use the <code class="literal">horzcat</code> method to concatenate the three matrices together:</p><div class="informalexample"><pre class="programlisting">val featureMatrix = DenseMatrix.horzcat(
  DenseMatrix.ones[Double](rescaledHeightsAsMatrix.rows, 1),
  rescaledHeightsAsMatrix,
  rescaledWeightsAsMatrix
)</pre></div><p>The final step in the data preprocessing stage is to create the target variable. We need to convert the <code class="literal">data.genders</code> vector to a vector of ones and zeros. We assign a value of one for men and zero for women. Thus, our classifier will predict the probability that any given person is male. We will use the <code class="literal">.values.map</code> method, a method equivalent to the <code class="literal">.map</code> method on Scala collections:</p><div class="informalexample"><pre class="programlisting">val target = data.genders.values.map {
  gender =&gt; if(gender == 'M') 1.0 else 0.0
}</pre></div><p>Note that we could also have used the indicator function which we discovered earlier:</p><div class="informalexample"><pre class="programlisting">val maleVector = DenseVector.fill(data.genders.size)('M')
val target = I(data.genders :== maleVector)</pre></div><p>This results in the allocation of a temporary array, <code class="literal">maleVector</code>, and might therefore increase the program's memory footprint if there were many participants in the experiment.</p><p>We now have a matrix representing the training set and a vector denoting the target variable. We can write the loss function that we want to minimize. As mentioned previously, we will minimize <span class="inlinemediaobject"><img src="graphics/4795_02_22.jpg" /></span>. The loss function takes as input a set of <a id="id109" class="indexterm"></a>values for the linear coefficients and returns a number indicating how well those values of the linear coefficients fit the training data:</p><div class="informalexample"><pre class="programlisting">def costFunction(parameters:DenseVector[Double]):Double = {
  val xBeta = featureMatrix * parameters 
  val expXBeta = exp(xBeta)
  - sum((target :* xBeta) - log1p(expXBeta))
}</pre></div><p>Note that we use <code class="literal">log1p(x)</code> to calculate <span class="emphasis"><em>log(1+x)</em></span>. This is robust to underflow for small values of <code class="literal">x</code>.</p><p>Let's explore the cost function:</p><div class="informalexample"><pre class="programlisting">costFunction(DenseVector(0.0, 0.0, 0.0)) // 125.45963968135031
costFunction(DenseVector(0.0, 0.1, 0.1)) // 113.33336518036882
costFunction(DenseVector(0.0, -0.1, -0.1)) // 139.17134594294433</pre></div><p>We can see that the cost function is somewhat lower for slightly positive values of the height and weight parameters. This indicates that the likelihood function is larger for slightly positive values of the height and weight. This, in turn, implies (as we expect from the plot) that people who are taller and heavier than average are more likely to be male.</p><p>We also need a function that calculates the gradient of the loss function, since that will help with the optimization:</p><div class="informalexample"><pre class="programlisting">def costFunctionGradient(parameters:DenseVector[Double])
:DenseVector[Double] = {
  val xBeta = featureMatrix * parameters 
  val probs = sigmoid(xBeta)
  featureMatrix.t * (probs - target)
}</pre></div><p>Having defined the loss function and gradient, we are now in a position to set up the optimization:</p><div class="informalexample"><pre class="programlisting"> val f = new DiffFunction[DenseVector[Double]] {
   def calculate(parameters:DenseVector[Double]) = 
     (costFunction(parameters), costFunctionGradient(parameters))
 }</pre></div><p>All that is left now is to run the optimization. The cost function for logistic regression is convex (it has a single minimum), so the starting point for optimization is irrelevant in principle. In practice, it is common to start with a coefficient vector that is zero everywhere (equating to assigning a 0.5 probability of being male to every participant):</p><div class="informalexample"><pre class="programlisting">  val optimalParameters = minimize(f, DenseVector(0.0, 0.0, 0.0))</pre></div><p>This returns the vector of optimal parameters:</p><div class="informalexample"><pre class="programlisting">DenseVector(-0.0751454743, 2.476293647, 2.23054540)</pre></div><p>How can we interpret the values of the optimal parameters? The coefficients for the height and weight are both positive, indicating that people who are taller and heavier are more likely to be male.</p><p>We can also get the decision <a id="id110" class="indexterm"></a>boundary (the line separating (height, weight) pairs more likely to belong to a woman from (height, weight) pairs more likely to belong to a man) directly from the coefficients. The decision boundary is:</p><div class="mediaobject"><img src="graphics/4795_02_13.jpg" /></div><div class="mediaobject"><img src="graphics/chap02_height_weight_line.jpg" /><div class="caption"><p>Height and weight data (shifted by the mean and rescaled by the standard deviation). The orange line is the logistic regression decision boundary. Logistic regression predicts that individuals above the boundary are male.</p></div></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec19"></a>Towards re-usable code</h2></div></div><hr /></div><p>In the previous <a id="id111" class="indexterm"></a>section, we performed all of the computation in a single script. While this is fine for data exploration, it means that we cannot reuse the logistic regression code that we have built. In this section, we will start the construction of a machine learning library that you can reuse across different projects.</p><p>We will factor the logistic regression algorithm out into its own class. We construct a <code class="literal">LogisticRegression</code> class:</p><div class="informalexample"><pre class="programlisting">import breeze.linalg._
import breeze.numerics._
import breeze.optimize._

class LogisticRegression(
    val training:DenseMatrix[Double], 
    val target:DenseVector[Double])
{</pre></div><p>The class takes, as input, a matrix representing the training set and a vector denoting the target variable. Notice how we assign these to <code class="literal">vals</code>, meaning that they are set on class creation and will <a id="id112" class="indexterm"></a>remain the same until the class is destroyed. Of course, the <code class="literal">DenseMatrix</code> and <code class="literal">DenseVector</code> objects are mutable, so the values that <code class="literal">training</code> and <code class="literal">target</code> point to might change. Since programming best practice dictates that mutable state makes reasoning about program behavior difficult, we will avoid taking advantage of this mutability.</p><p>Let's add a method that calculates the cost function and its gradient:</p><div class="informalexample"><pre class="programlisting">  def costFunctionAndGradient(coefficients:DenseVector[Double])
  :(Double, DenseVector[Double]) = {
    val xBeta = training * coefficients
    val expXBeta = exp(xBeta)
    val cost = - sum((target :* xBeta) - log1p(expXBeta))
    val probs = sigmoid(xBeta)
    val grad = training.t * (probs - target)
    (cost, grad)
  }</pre></div><p>We are now all set up to run the optimization to calculate the coefficients that best reproduce the training set. In traditional object-oriented languages, we might define a <code class="literal">getOptimalCoefficients</code> method that returns a <code class="literal">DenseVector</code> of the coefficients. Scala, however, is more elegant. Since we have defined the <code class="literal">training</code> and <code class="literal">target</code> attributes as <code class="literal">vals</code>, there is only one possible set of values of the optimal coefficients. We could, therefore, define a <code class="literal">val optimalCoefficients = ???</code> class attribute that holds the optimal coefficients. The problem with this is that it forces all the computation to happen when the instance is constructed. This will be unexpected for the user and might be wasteful: if the user is only interested in accessing the cost function, for instance, the time spent minimizing it will be wasted. The solution is to use a <code class="literal">lazy val</code>. This value will only be evaluated when the client code requests it:</p><div class="informalexample"><pre class="programlisting">lazy val optimalCoefficients = ???</pre></div><p>To help with the calculation of the coefficients, we will define a private helper method:</p><div class="informalexample"><pre class="programlisting">private def calculateOptimalCoefficients
:DenseVector[Double] = {
  val f = new DiffFunction[DenseVector[Double]] {
    def calculate(parameters:DenseVector[Double]) = 
      costFunctionAndGradient(parameters)
  }

  minimize(f, DenseVector.zeros[Double](training.cols))
}

lazy val optimalCoefficients = calculateOptimalCoefficients</pre></div><p>We have refactored the logistic regression into its own class, that we can reuse across different projects.</p><p>If we were planning <a id="id113" class="indexterm"></a>on reusing the height-weight data, we could, similarly, refactor it into a class of its own that facilitates data loading, feature scaling, and any other functionality that we find ourselves reusing often.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec20"></a>Alternatives to Breeze</h2></div></div><hr /></div><p>Breeze is the most <a id="id114" class="indexterm"></a>feature-rich and approachable Scala framework for linear algebra and numeric computation. However, do not take my word for it: experiment with other libraries for tabular data. In particular, I recommend trying <span class="emphasis"><em>Saddle</em></span>, which provides a <code class="literal">Frame</code> object similar to data frames in pandas or R. In the Java world, the <span class="emphasis"><em>Apache Commons Maths library</em></span> provides a very rich toolkit for numerical computation. In <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Distributed Batch Processing with Spark</em></span>, <a class="link" href="#" linkend="ch11">Chapter 11</a>, <span class="emphasis"><em>Spark SQL and DataFrames</em></span>, and <a class="link" href="#" linkend="ch12">Chapter 12</a>, <span class="emphasis"><em>Distributed Machine Learning with MLlib</em></span>, we will explore <span class="emphasis"><em>Spark</em></span> and <span class="emphasis"><em>MLlib</em></span>, which allow the user to run distributed machine learning algorithms.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec21"></a>Summary</h2></div></div><hr /></div><p>This concludes our brief overview of Breeze. We have learned how to manipulate basic Breeze data types, how to use them for linear algebra, and how to perform convex optimization. We then used our knowledge to clean a real dataset and performed logistic regression on it.</p><p>In the next chapter, we will discuss breeze-viz, a plotting library for Scala.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec22"></a>References</h2></div></div><hr /></div><p>
<span class="emphasis"><em>The Elements of Statistical Learning</em></span>, by <span class="emphasis"><em>Hastie</em></span>, <span class="emphasis"><em>Tibshirani</em></span>, and <span class="emphasis"><em>Friedman</em></span>, gives a lucid, practical description of the mathematical underpinnings of machine learning. Anyone aspiring to do more than mindlessly apply machine learning algorithms as black boxes ought to have a well-thumbed copy of this book.</p><p>
<span class="emphasis"><em>Scala for Machine Learning</em></span>, by <span class="emphasis"><em>Patrick R. Nicholas</em></span>, describes practical implementations of many useful machine learning algorithms in Scala.</p><p>The Breeze <a id="id115" class="indexterm"></a>documentation (<a class="ulink" href="https://github.com/scalanlp/breeze/wiki/Quickstart" target="_blank">https://github.com/scalanlp/breeze/wiki/Quickstart</a>), API docs (<a class="ulink" href="http://www.scalanlp.org/api/breeze/#package" target="_blank">http://www.scalanlp.org/api/breeze/#package</a>), and source code (<a class="ulink" href="https://github.com/scalanlp/breeze" target="_blank">https://github.com/scalanlp/breeze</a>) provide the most up-to-date sources of documentation <a id="id116" class="indexterm"></a>on Breeze.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch03"></a>ChapterÂ 3.Â Plotting with breeze-viz</h2></div></div></div><p>Data visualization <a id="id117" class="indexterm"></a>is an integral part of data science. Visualization needs fall into two broad categories: during the development and validation of new models and, at the end of the pipeline, to distill meaning from the data and the models to provide insight to external stakeholders.</p><p>The two types of visualizations are quite different. At the data exploration and model development stage, the most important feature of a visualization library is its ease of use. It should take as few steps as possible to go from having data as arrays of numbers (or CSVs or in a database) to having data displayed on a screen. The lifetime of graphs is also quite short: once the data scientist has learned all he can from the graph or visualization, it is normally discarded. By contrast, when developing visualization widgets for external stakeholders, one is willing to tolerate increased development time for greater flexibility. The visualizations can have significant lifetime, especially if the underlying data changes over time.</p><p>The tool of choice in Scala for the first type of visualization is breeze-viz. When developing visualizations for external stakeholders, web-based visualizations (such as D3) and Tableau tend to be favored.</p><p>In this chapter, we will explore breeze-viz. In <a class="link" href="#" linkend="ch14">Chapter 14</a>, <span class="emphasis"><em>Visualization with D3 and the Play Framework</em></span>, we will learn how to build Scala backends for JavaScript visualizations.</p><p>Breeze-viz is (no points for guessing) Breeze's visualization library. It wraps <span class="strong"><strong>JFreeChart</strong></span>, a very <a id="id118" class="indexterm"></a>popular Java charting library. Breeze-viz is still very experimental. In particular, it is much less feature-rich than matplotlib in Python, or R or MATLAB. Nevertheless, breeze-viz allows access to the underlying JFreeChart objects so one can always fall back to editing these objects directly. The syntax for breeze-viz is inspired by MATLAB and matplotlib.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec23"></a>Diving into Breeze</h2></div></div><hr /></div><p>Let's get started. We <a id="id119" class="indexterm"></a>will work in the Scala console, but a program similar to this example is available in <code class="literal">BreezeDemo.scala</code> in the examples corresponding to this chapter. Create a <code class="literal">build.sbt</code> file with the following lines:</p><div class="informalexample"><pre class="programlisting">scalaVersion := "2.11.7"

libraryDependencies ++= Seq(
  "org.scalanlp" %% "breeze" % "0.11.2",
  "org.scalanlp" %% "breeze-viz" % "0.11.2",
  "org.scalanlp" %% "breeze-natives" % "0.11.2"
)</pre></div><p>Start an <code class="literal">sbt</code> console:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sbt console</strong></span>

<span class="strong"><strong>scala&gt; import breeze.linalg._</strong></span>
<span class="strong"><strong>import breeze.linalg._</strong></span>

<span class="strong"><strong>scala&gt; import breeze.plot._</strong></span>
<span class="strong"><strong>import breeze.plot._</strong></span>

<span class="strong"><strong>scala&gt; import breeze.numerics._</strong></span>
<span class="strong"><strong>import breeze.numerics._</strong></span>
</pre></div><p>Let's start by plotting a sigmoid curve, <span class="inlinemediaobject"><img src="graphics/4795_03_01.jpg" /></span>. We will first generate the data using Breeze. Recall that the <code class="literal">linspace</code> method creates a vector of doubles, uniformly distributed between two values:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val x = linspace(-4.0, 4.0, 200)</strong></span>
<span class="strong"><strong>x: DenseVector[Double] = DenseVector(-4.0, -3.959798...</strong></span>

<span class="strong"><strong>scala&gt; val fx = sigmoid(x)</strong></span>
<span class="strong"><strong>fx: DenseVector[Double] = DenseVector(0.0179862099620915,...</strong></span>
</pre></div><p>We now have the data ready for plotting. The first step is to create a figure:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val fig = Figure()</strong></span>
<span class="strong"><strong>fig: breeze.plot.Figure = breeze.plot.Figure@37e36de9</strong></span>
</pre></div><p>This creates an empty Java Swing window (which may appear on your taskbar or equivalent). A figure can contain one or more plots. Let's add a plot to our figure:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val plt = fig.subplot(0)</strong></span>
<span class="strong"><strong>plt: breeze.plot.Plot = breeze.plot.Plot@171c2840</strong></span>
</pre></div><p>For now, let's ignore the <code class="literal">0</code> passed as argument to <code class="literal">.subplot</code>. We can add data points to our <code class="literal">plot</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; plt += plot(x, fx)</strong></span>
<span class="strong"><strong>breeze.plot.Plot = breeze.plot.Plot@63d6a0f8</strong></span>
</pre></div><p>The <code class="literal">plot</code> function takes two arguments, corresponding to the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> values of the data series to be plotted. To view the changes, you need to refresh the figure:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; fig.refresh()</strong></span>
</pre></div><p>Look at the Swing window <a id="id120" class="indexterm"></a>now. You should see a beautiful sigmoid, similar to the one below. Right-clicking on the window lets you interact with the plot and save the image as a PNG:</p><div class="mediaobject"><img src="graphics/4795_03_02.jpg" /></div><p>You can also save the image programmatically as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; fig.saveas("sigmoid.png")</strong></span>
</pre></div><p>Breeze-viz currently only supports exporting to PNG.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec24"></a>Customizing plots</h2></div></div><hr /></div><p>We now have a <a id="id121" class="indexterm"></a>curve on our chart. Let's add a few more:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val f2x = sigmoid(2.0*x)</strong></span>
<span class="strong"><strong>f2x: breeze.linalg.DenseVector[Double] = DenseVector(3.353501304664E-4...</strong></span>

<span class="strong"><strong>scala&gt; val f10x = sigmoid(10.0*x)</strong></span>
<span class="strong"><strong>f10x: breeze.linalg.DenseVector[Double] = DenseVector(4.24835425529E-18...</strong></span>

<span class="strong"><strong>scala&gt; plt += plot(x, f2x, name="S(2x)")</strong></span>
<span class="strong"><strong>breeze.plot.Plot = breeze.plot.Plot@63d6a0f8</strong></span>

<span class="strong"><strong>scala&gt; plt += plot(x, f10x, name="S(10x)")</strong></span>
<span class="strong"><strong>breeze.plot.Plot = breeze.plot.Plot@63d6a0f8</strong></span>

<span class="strong"><strong>scala&gt; fig.refresh()</strong></span>
</pre></div><p>Looking at the figure now, you should see all three curves in different colors. Notice that we named the data series as we added them to the plot, using the <code class="literal">name=""</code> keyword argument. To view the names, we must set the <code class="literal">legend</code> attribute:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; plt.legend = true</strong></span>
</pre></div><div class="mediaobject"><img src="graphics/4795_03_03.jpg" /></div><p>Our plot still leaves a <a id="id122" class="indexterm"></a>lot to be desired. Let's start by restricting the range of the <span class="emphasis"><em>x</em></span> axis to remove the bands of white space on either side of the plot:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; plt.xlim = (-4.0, 4.0)</strong></span>
<span class="strong"><strong>plt.xlim: (Double, Double) = (-4.0,4.0)</strong></span>
</pre></div><p>Now, notice how, while the <span class="emphasis"><em>x</em></span> ticks are sensibly spaced, there are only two <span class="emphasis"><em>y</em></span> ticks: at <span class="emphasis"><em>0</em></span> and <span class="emphasis"><em>1</em></span>. It would be useful to have ticks every <span class="emphasis"><em>0.1</em></span> increment. Breeze does not provide a way to set this directly. Instead, it exposes the underlying JFreeChart Axis object belonging to the current plot:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; plt.yaxis</strong></span>
<span class="strong"><strong>org.jfree.chart.axis.NumberAxis = org.jfree.chart.axis.NumberAxis@0</strong></span>
</pre></div><p>The <code class="literal">Axis</code> object supports a <code class="literal">.setTickUnit</code> method that lets us set the tick spacing:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.jfree.chart.axis.NumberTickUnit</strong></span>
<span class="strong"><strong>import org.jfree.chart.axis.NumberTickUnit</strong></span>

<span class="strong"><strong>scala&gt; plt.yaxis.setTickUnit(new NumberTickUnit(0.1))</strong></span>
</pre></div><p>JFreeChart allows extensive customization of the <code class="literal">Axis</code> object. For a full list of methods available, consult <a id="id123" class="indexterm"></a>the JFreeChart documentation (<a class="ulink" href="http://www.jfree.org/jfreechart/api/javadoc/org/jfree/chart/axis/Axis.html" target="_blank">http://www.jfree.org/jfreechart/api/javadoc/org/jfree/chart/axis/Axis.html</a>).</p><p>Let's also add a vertical line at <span class="emphasis"><em>x=0</em></span> and a horizontal line at <span class="emphasis"><em>f(x)=1</em></span>. We will need to access the underlying JFreeChart plot to add these lines. This is available (somewhat confusingly) as the <code class="literal">.plot</code> attribute in our Breeze <code class="literal">Plot</code> object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; plt.plot</strong></span>
<span class="strong"><strong>org.jfree.chart.plot.XYPlot = org.jfree.chart.plot.XYPlot@17e4db6c</strong></span>
</pre></div><p>We can use the <code class="literal">.addDomainMarker</code> and <code class="literal">.addRangeMarker</code> methods to add vertical and horizontal lines to <a id="id124" class="indexterm"></a>JFreeChart <code class="literal">XYPlot</code> objects:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.jfree.chart.plot.ValueMarker</strong></span>
<span class="strong"><strong>import org.jfree.chart.plot.ValueMarker</strong></span>

<span class="strong"><strong>scala&gt; plt.plot.addDomainMarker(new ValueMarker(0.0))</strong></span>

<span class="strong"><strong>scala&gt; plt.plot.addRangeMarker(new ValueMarker(1.0))</strong></span>
</pre></div><p>Let's also add labels to the axes:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; plt.xlabel = "x"</strong></span>
<span class="strong"><strong>plt.xlabel: String = x</strong></span>

<span class="strong"><strong>scala&gt; plt.ylabel = "f(x)"</strong></span>
<span class="strong"><strong>plt.ylabel: String = f(x)</strong></span>
</pre></div><p>If you have run all these commands, you should have a graph that looks like this:</p><div class="mediaobject"><img src="graphics/4795_03_04.jpg" /></div><p>We now know how to <a id="id125" class="indexterm"></a>customize the basic building blocks of a graph. The next step is to learn how to change how curves are drawn.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec25"></a>Customizing the line type</h2></div></div><hr /></div><p>So far, we have <a id="id126" class="indexterm"></a>just plotted lines using the default settings. Breeze lets us customize how lines are drawn, at least to some extent.</p><p>For this example, we will use the height-weight data discussed in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>. We will use the Scala shell here for demonstrative purposes, but you will find a program in <code class="literal">BreezeDemo.scala</code> that follows the example shell session.</p><p>The code examples for this chapter come with a module for loading the data, <code class="literal">HWData.scala</code>, that loads the data from the CSVs:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val data = HWData.load</strong></span>
<span class="strong"><strong>data: HWData = HWData [ 181 rows ]</strong></span>

<span class="strong"><strong>scala&gt; data.heights</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(182.0, ...</strong></span>

<span class="strong"><strong>scala&gt; data.weights</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(77.0, 58.0...</strong></span>
</pre></div><p>Let's create a scatter plot of the heights against the weights:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val fig = Figure("height vs. weight")</strong></span>
<span class="strong"><strong>fig: breeze.plot.Figure = breeze.plot.Figure@743f2558</strong></span>

<span class="strong"><strong>scala&gt; val plt = fig.subplot(0)</strong></span>
<span class="strong"><strong>plt: breeze.plot.Plot = breeze.plot.Plot@501ea274</strong></span>

<span class="strong"><strong>scala&gt; plt += plot(data.heights, data.weights, '+',         colorcode="black")</strong></span>
<span class="strong"><strong>breeze.plot.Plot = breeze.plot.Plot@501ea274</strong></span>
</pre></div><p>This produces a <a id="id127" class="indexterm"></a>scatter-plot of the height-weight data:</p><div class="mediaobject"><img src="graphics/4795_03_05.jpg" /></div><p>Note that we passed a third argument to the <code class="literal">plot</code> method, <code class="literal">'+'</code>. This controls the plotting style. As of this writing, there are three available styles: <code class="literal">'-'</code> (the default), <code class="literal">'+'</code>, and <code class="literal">'.'</code>. Experiment with these to see what they do. Finally, we pass a <code class="literal">colorcode="black"</code> argument to control the color of the line. This is either a color name or an RGB triple, written as a string. Thus, to plot red points, we could have passed <code class="literal">colorcode="[255,0,0]"</code>.</p><p>Looking at the height-weight plot, there is clearly a trend between height and weight. Let's try and fit a straight <a id="id128" class="indexterm"></a>line through the data points. We will fit the following function:</p><div class="mediaobject"><img src="graphics/4795_03_06.jpg" /></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note02"></a>Note</h3><p>Scientific literature suggests that it would be better to fit something more like <span class="inlinemediaobject"><img src="graphics/4795_03_add01.jpg" /></span>. You should find it straightforward to fit a quadratic line to the data, should you wish to.</p></div><p>We will use Breeze's least squares function to find the values of <code class="literal">a</code> and <code class="literal">b</code>. The <code class="literal">leastSquares</code> method expects an input matrix of features and a target vector, just like the <code class="literal">LogisticRegression</code> class that we defined in the previous chapter. Recall that in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>, when we prepared the training set for logistic regression classification, we introduced a dummy feature that was one for every participant to provide the degree of freedom for the <span class="emphasis"><em>y</em></span> intercept. We will use the same approach here. Our feature matrix, therefore, contains two columnsâ€”one that is <code class="literal">1</code> everywhere and one for the height:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val features = DenseMatrix.horzcat(</strong></span>
<span class="strong"><strong>  DenseMatrix.ones[Double](data.npoints, 1),</strong></span>
<span class="strong"><strong>  data.heights.toDenseMatrix.t</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>features: breeze.linalg.DenseMatrix[Double] =</strong></span>
<span class="strong"><strong>1.0  182.0</strong></span>
<span class="strong"><strong>1.0  161.0</strong></span>
<span class="strong"><strong>1.0  161.0</strong></span>
<span class="strong"><strong>1.0  177.0</strong></span>
<span class="strong"><strong>1.0  157.0</strong></span>
<span class="strong"><strong>...</strong></span>

<span class="strong"><strong>scala&gt; import breeze.stats.regression._</strong></span>
<span class="strong"><strong>import breeze.stats.regression._</strong></span>

<span class="strong"><strong>scala&gt; val leastSquaresResult = leastSquares(features, data.weights)</strong></span>
<span class="strong"><strong>leastSquaresResult: breeze.stats.regression.LeastSquaresRegressionResult = &lt;function1&gt;</strong></span>
</pre></div><p>The <code class="literal">leastSquares</code> method returns an instance of <code class="literal">LeastSquareRegressionResult</code>, which contains a <a id="id129" class="indexterm"></a>
<code class="literal">coefficients </code>attribute containing the coefficients that best fit the data:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; leastSquaresResult.coefficients</strong></span>
<span class="strong"><strong>breeze.linalg.DenseVector[Double] = DenseVector(-131.042322, 1.1521875)</strong></span>
</pre></div><p>The best-fit line is therefore:</p><div class="mediaobject"><img src="graphics/4795_03_07.jpg" /></div><p>Let's extract the coefficients. An elegant way of doing this is to use Scala's pattern matching capabilities:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val Array(a, b) = leastSquaresResult.coefficients.toArray</strong></span>
<span class="strong"><strong>a: Double = -131.04232269750622</strong></span>
<span class="strong"><strong>b: Double = 1.1521875435418725</strong></span>
</pre></div><p>By writing <code class="literal">val Array(a, b) = ...</code>, we are telling Scala that the right-hand side of the expression is a two-element array and to bind the first element of that array to the value <code class="literal">a</code> and the second to the value <code class="literal">b</code>. See <a class="link" href="#" linkend="appA">Appendix</a>, <span class="emphasis"><em>Pattern Matching and Extractors</em></span>, for a discussion of pattern matching.</p><p>We can now add the best-fit line to our graph. We start by generating evenly-spaced dummy height values:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val dummyHeights = linspace(min(data.heights), max(data.heights), 200)</strong></span>
<span class="strong"><strong>dummyHeights: breeze.linalg.DenseVector[Double] = DenseVector(148.0, ...</strong></span>

<span class="strong"><strong>scala&gt; val fittedWeights = a :+ (b :* dummyHeights)</strong></span>
<span class="strong"><strong>fittedWeights: breeze.linalg.DenseVector[Double] = DenseVector(39.4814...</strong></span>

<span class="strong"><strong>scala&gt; plt += plot(dummyHeights, fittedWeights, colorcode="red")</strong></span>
<span class="strong"><strong>breeze.plot.Plot = breeze.plot.Plot@501ea274</strong></span>
</pre></div><p>Let's also add the equation for the best-fit line to the graph as an annotation. We will first generate the label:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val label = f"weight = $a%.4f + $b%.4f * height"</strong></span>
<span class="strong"><strong>label: String = weight = -131.0423 + 1.1522 * height</strong></span>
</pre></div><p>To add an annotation, we must access the underlying JFreeChart plot:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.jfree.chart.annotations.XYTextAnnotation</strong></span>
<span class="strong"><strong>import org.jfree.chart.annotations.XYTextAnnotation</strong></span>

<span class="strong"><strong>scala&gt; plt.plot.addAnnotation(new XYTextAnnotation(label, 175.0, 105.0))</strong></span>
</pre></div><p>The <a id="id130" class="indexterm"></a>
<code class="literal">XYTextAnnotation</code> constructor takes three parameters: the annotation string and a pair of (<span class="emphasis"><em>x</em></span>, <span class="emphasis"><em>y</em></span>) coordinates defining the centre of the annotation on the graph. The coordinates of the annotation are expressed in the coordinate system of the data. Thus, calling <code class="literal">new XYTextAnnotation(label, 175.0, 105.0)</code> generates an annotation whose centroid is at the point corresponding to a height of 175 cm and weight of 105 kg:</p><div class="mediaobject"><img src="graphics/4795_03_08.jpg" /></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec26"></a>More advanced scatter plots</h2></div></div><hr /></div><p>Breeze-viz offers a <a id="id131" class="indexterm"></a>
<code class="literal">scatter</code> function that adds a significant degree of customization to scatter plots. In particular, we can use the size and color of the marker points to add additional dimensions of information to the plot.</p><p>The <code class="literal">scatter</code> function takes, as its first two arguments, collections of <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> points. The third argument is a function mapping an integer <code class="literal">i</code> to a <code class="literal">Double</code> indicating the size of the <span class="emphasis"><em>ith</em></span> point. The size of the point is measured in units of the <span class="emphasis"><em>x</em></span> axis. If you have the sizes as a Scala collection or a Breeze vector, you can use that collection's <code class="literal">apply</code> method as the function. Let's see how this works in practice.</p><p>As with the previous examples, we will use the REPL, but you can find a sample program in <code class="literal">BreezeDemo.scala</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val fig = new Figure("Advanced scatter example")</strong></span>
<span class="strong"><strong>fig: breeze.plot.Figure = breeze.plot.Figure@220821bc</strong></span>

<span class="strong"><strong>scala&gt; val plt = fig.subplot(0)</strong></span>
<span class="strong"><strong>plt: breeze.plot.Plot = breeze.plot.Plot@668f8ae0</strong></span>

<span class="strong"><strong>scala&gt; val xs = linspace(0.0, 1.0, 100)</strong></span>
<span class="strong"><strong>xs: breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.010101010101010102, 0.0202 ...</strong></span>

<span class="strong"><strong>scala&gt; val sizes = 0.025 * DenseVector.rand(100) // random sizes</strong></span>
<span class="strong"><strong>sizes: breeze.linalg.DenseVector[Double] = DenseVector(0.014879265631723166, 0.00219551...</strong></span>

<span class="strong"><strong>scala&gt; plt += scatter(xs, xs :^ 2.0, sizes.apply)</strong></span>
<span class="strong"><strong>breeze.plot.Plot = breeze.plot.Plot@668f8ae0</strong></span>
</pre></div><p>Selecting custom colors works in a similar manner: we pass in a <code class="literal">colors</code> argument that maps an integer index to a <code class="literal">java.awt.Paint</code> object. Using these directly can be cumbersome, so Breeze provides some default palettes. For instance, the <code class="literal">GradientPaintScale</code> maps doubles in a given domain to a uniform color gradient. Let's map doubles in the range <code class="literal">0.0</code> to <code class="literal">1.0</code> to the colors between red and green:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val palette = new GradientPaintScale(</strong></span>
<span class="strong"><strong>  0.0, 1.0, PaintScale.RedToGreen)</strong></span>
<span class="strong"><strong>palette: breeze.plot.GradientPaintScale[Double] = &lt;function1&gt;</strong></span>

<span class="strong"><strong>scala&gt; palette(0.5) // half-way between red and green</strong></span>
<span class="strong"><strong>java.awt.Paint = java.awt.Color[r=127,g=127,b=0]</strong></span>

<span class="strong"><strong>scala&gt; palette(1.0) // green</strong></span>
<span class="strong"><strong>java.awt.Paint = java.awt.Color[r=0,g=254,b=0]</strong></span>
</pre></div><p>Besides the <code class="literal">GradientPaintScale</code>, breeze-viz provides a <code class="literal">CategoricalPaintScale</code> class for categorical <a id="id132" class="indexterm"></a>palettes. For an overview of the different palettes, consult the source file <code class="literal">PaintScale.scala</code> at <code class="literal">scala</code>: <a class="ulink" href="https://github.com/scalanlp/breeze/blob/master/viz/src/main/scala/breeze/plot/PaintScale.scala" target="_blank">https://github.com/scalanlp/breeze/blob/master/viz/src/main/scala/breeze/plot/PaintScale.scala</a>.</p><p>Let's use our <a id="id133" class="indexterm"></a>newfound knowledge to draw a multicolor scatter plot. We will assume the same initialization as the previous example. We will assign a random color to each point:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val palette = new GradientPaintScale(0.0, 1.0, PaintScale.MaroonToGold)</strong></span>
<span class="strong"><strong>palette: breeze.plot.GradientPaintScale[Double] = &lt;function1&gt;</strong></span>

<span class="strong"><strong>scala&gt; val colors = DenseVector.rand(100).mapValues(palette)</strong></span>
<span class="strong"><strong>colors: breeze.linalg.DenseVector[java.awt.Paint] = DenseVector(java.awt.Color[r=162,g=5,b=0], ...</strong></span>

<span class="strong"><strong>scala&gt; plt += scatter(xs, xs :^ 2.0, sizes.apply, colors.apply)</strong></span>
<span class="strong"><strong>breeze.plot.Plot = breeze.plot.Plot@8ff7e27</strong></span>
</pre></div><div class="mediaobject"><img src="graphics/4795_03_11.jpg" /></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec27"></a>Multi-plot example â€“ scatterplot matrix plots</h2></div></div><hr /></div><p>In this section, we <a id="id134" class="indexterm"></a>will learn how to have several plots in the same figure.</p><p>The key new method that allows multiple plots in the same figure is <code class="literal">fig.subplot(nrows, ncols, plotIndex)</code>. This method, an overloaded version of the <code class="literal">fig.subplot</code> method we have been using up to now, both sets the number of rows and columns in the figure and returns a specific subplot. It takes three arguments:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">nrows</code>: The number of rows of subplots in the figure</p></li><li style="list-style-type: disc"><p>
<code class="literal">ncols</code>: The number of columns of subplots in the figure</p></li><li style="list-style-type: disc"><p>
<code class="literal">plotIndex</code>: The index of the plot to return</p></li></ul></div><p>Users familiar with MATLAB or matplotlib will note that the <code class="literal">.subplot</code> method is identical to the eponymous methods in these frameworks. This might seem a little complex, so let's look at an example (you will find the code for this in <code class="literal">BreezeDemo.scala</code>):</p><div class="informalexample"><pre class="programlisting">import breeze.plot._

def subplotExample {
  val data = HWData.load
  val fig = new Figure("Subplot example")

  // upper subplot: plot index '0' refers to the first plot
  var plt = fig.subplot(2, 1, 0)
  plt += plot(data.heights, data.weights, '.')

  // lower subplot: plot index '1' refers to the second plot
  plt = fig.subplot(2, 1, 1)
  plt += plot(data.heights, data.reportedHeights, '.', colorcode="black")

  fig.refresh
}</pre></div><p>Running this example produces the following plot:</p><div class="mediaobject"><img src="graphics/4795_03_09.jpg" /></div><p>Now that we have a basic grasp of how to add several subplots to the same figure, let's do something a <a id="id135" class="indexterm"></a>little more interesting. We will write a class to draw scatterplot matrices. These are useful for exploring correlations between different features.</p><p>If you are not familiar with scatterplot matrices, have a look at the figure at the end of this section for an idea of what we are constructing. The idea is to build a square matrix of scatter plots for each pair of features. Element (<span class="emphasis"><em>i</em></span>, <span class="emphasis"><em>j</em></span>) in the matrix is a scatter plot of feature <span class="emphasis"><em>i</em></span> against feature <span class="emphasis"><em>j</em></span>. Since a scatter plot of a variable against itself is of limited use, one normally draws histograms of each feature along the diagonal. Finally, since a scatter plot of feature <span class="emphasis"><em>i</em></span> against feature <span class="emphasis"><em>j</em></span> contains the same information as a scatter plot of feature <span class="emphasis"><em>j</em></span> against feature <span class="emphasis"><em>i</em></span>, one normally only plots the upper triangle or the lower triangle of the matrix.</p><p>Let's start by writing functions for the individual plots. These will take a <code class="literal">Plot</code> object referencing the correct subplot and vectors of the data to plot:</p><div class="informalexample"><pre class="programlisting">import breeze.plot._
import breeze.linalg._

class ScatterplotMatrix(val fig:Figure) {

  /** Draw the histograms on the diagonal */
  private def plotHistogram(plt:Plot)(
  data:DenseVector[Double], label:String) {
     plt += hist(data)
     plt.xlabel = label
  }

  /** Draw the off-diagonal scatter plots */
  private def plotScatter(plt:Plot)(
    xdata:DenseVector[Double],
    ydata:DenseVector[Double],
    xlabel:String,
    ylabel:String) {
      plt += plot(xdata, ydata, '.')
      plt.xlabel = xlabel
      plt.ylabel = ylabel
  }

...</pre></div><p>Notice the use <a id="id136" class="indexterm"></a>of <code class="literal">hist(data)</code> to draw a histogram. The argument to <code class="literal">hist</code> must be a vector of data points. The <code class="literal">hist</code> method will bin these and represent them as a histogram.</p><p>Now that we have the machinery for drawing individual plots, we just need to wire everything together. The tricky part is to know how to select the correct subplot for a given row and column position in the matrix. We can select a single plot by calling <code class="literal">fig.subplot(nrows, ncolumns, plotIndex)</code>, but translating from a (<span class="emphasis"><em>row</em></span>, <span class="emphasis"><em>column</em></span>) index pair to a single <code class="literal">plotIndex</code> is not obvious. The plots are numbered in increasing order, first from left to right, then from top to bottom:</p><div class="informalexample"><pre class="programlisting">0 1 2 3
4 5 6 7
...</pre></div><p>Let's write a short function to select a plot at a (<span class="emphasis"><em>row</em></span>, <span class="emphasis"><em>column</em></span>) index pair:</p><div class="informalexample"><pre class="programlisting">  private def selectPlot(ncols:Int)(irow:Int, icol:Int):Plot = {
    fig.subplot(ncols, ncols, (irow)*ncols + icol)
  }</pre></div><p>We are now in a position to draw the matrix plot itself:</p><div class="informalexample"><pre class="programlisting">  /** Draw a scatterplot matrix.
    *
    * This function draws a scatterplot matrix of the correlation
    * between each pair of columns in `featureMatrix`.
    *
    * @param featureMatrix A matrix of features, with each column
    *   representing a feature.
    * @param labels Names of the features.
    */
  def plotFeatures(featureMatrix:DenseMatrix[Double], labels:List[String]) {
    val ncols = featureMatrix.cols
    require(ncols == labels.size,
      "Number of columns in feature matrix "+ "must match length of labels"
    )
    fig.clear
    fig.subplot(ncols, ncols, 0)

    (0 until ncols) foreach { irow =&gt;
      val p = selectPlot(ncols)(irow, irow)
      plotHistogram(p)(featureMatrix(::, irow), labels(irow))

      (0 until irow) foreach { icol =&gt;
        val p = selectPlot(ncols)(irow, icol)
        plotScatter(p)(
          featureMatrix(::, irow),
          featureMatrix(::, icol),
          labels(irow),
          labels(icol)
        )
      }
    }
  }
}</pre></div><p>Let's write an <a id="id137" class="indexterm"></a>example for our class. We will use the height-weight data again:</p><div class="informalexample"><pre class="programlisting">import breeze.linalg._
import breeze.numerics._
import breeze.plot._

object ScatterplotMatrixDemo extends App {

  val data = HWData.load
  val m = new ScatterplotMatrix(Figure("Scatterplot matrix demo"))

  // Make a matrix with three columns: the height, weight and
  // reported weight data.
  val featureMatrix = DenseMatrix.horzcat(
    data.heights.toDenseMatrix.t,
    data.weights.toDenseMatrix.t,
    data.reportedWeights.toDenseMatrix.t
  )
  m.plotFeatures(featureMatrix,List("height", "weight", "reportedWeights"))

}</pre></div><p>Running this <a id="id138" class="indexterm"></a>through SBT produces the following plot:</p><div class="mediaobject"><img src="graphics/4795_03_10.jpg" /></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec28"></a>Managing without documentation</h2></div></div><hr /></div><p>Breeze-viz is <a id="id139" class="indexterm"></a>unfortunately rather poorly documented. This can make the learning curve somewhat steep. Fortunately, it is still quite a small project: at the time of writing, there are just ten source files (<a class="ulink" href="https://github.com/scalanlp/breeze/tree/master/viz/src/main/scala/breeze/plot" target="_blank">https://github.com/scalanlp/breeze/tree/master/viz/src/main/scala/breeze/plot</a>). A good <a id="id140" class="indexterm"></a>way to understand exactly what breeze-viz does is to read the source code. For instance, to see what methods are available on a <code class="literal">Plot</code> object, read the source file <code class="literal">Plot.scala</code>. If you need functionality beyond that provided by Breeze, consult the documentation for JFreeChart to discover if you can implement what you need by accessing the underlying JFreeChart objects.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec29"></a>Breeze-viz reference</h2></div></div><hr /></div><p>Writing a <a id="id141" class="indexterm"></a>reference in a programming book is a dangerous exercise: you quickly become out of date. Nevertheless, given the paucity of documentation for breeze-viz, this section becomes more relevant â€“ it is easier to compete against something that does not exist. Take this section with a pinch of salt, and if a command in this section does not work, head over to the source code:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><thead><tr><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Command</p>
</th><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt += plot(xs, ys)</code>
</p>
</td><td style="" align="left" valign="top">
<p>This plots a series of (<code class="literal">xs</code>,<code class="literal"> ys</code>) values. The <code class="literal">xs</code> and <code class="literal">ys</code> values must be collection-like objects (Breeze vectors, Scala arrays, or lists, for instance).</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt += scatter(xs, ys, size)</code>
</p>
<p>
<code class="literal">plt += scatter(xs, ys, size, color)</code>
</p>
</td><td style="" align="left" valign="top">
<p>This plots a series of (<code class="literal">xs</code>, <code class="literal">ys</code>) values as a scatter plot. The <code class="literal">size</code> argument is an <code class="literal">(Int) =&gt; Double</code> function mapping the index of a point to its size (in the same units as the <span class="emphasis"><em>x</em></span> axis). The <code class="literal">color</code> argument is an <code class="literal">(Int) =&gt; java.awt.Paint</code> function mapping from integers to colors. Read the <span class="emphasis"><em>more advanced scatter plots</em></span> section for further details.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt += hist(xs)</code>
</p>
<p>
<code class="literal">plt += hist(xs, bins=10)</code>
</p>
</td><td style="" align="left" valign="top">
<p>This bins <code class="literal">xs</code> and plots a histogram. The <code class="literal">bins</code> argument controls the number of bins.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt += image(mat)</code>
</p>
</td><td style="" align="left" valign="top">
<p>This <a id="id142" class="indexterm"></a>plots an image or matrix. The <code class="literal">mat</code> argument should be <code class="literal">Matrix[Double]</code>. Read the <code class="literal">package.scala</code> source file in <code class="literal">breeze.plot</code> for details (<a class="ulink" href="https://github.com/scalanlp/breeze/blob/master/viz/src/main/scala/breeze/plot/package.scala" target="_blank">https://github.com/scalanlp/breeze/blob/master/viz/src/main/scala/breeze/plot/package.scala</a>).</p>
</td></tr></tbody></table></div><p>It is also useful to summarize the options available on a <code class="literal">plot</code> object:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><thead><tr><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Attribute</p>
</th><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt.xlabel = "x-label"</code>
</p>
<p>
<code class="literal">plt.ylabel = "y-label"</code>
</p>
</td><td style="" align="left" valign="top">
<p>This sets the axis label</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt.xlim = (0.0, 1.0)</code>
</p>
<p>
<code class="literal">plt.ylim = (0.0, 1.0)</code>
</p>
</td><td style="" align="left" valign="top">
<p>This <a id="id143" class="indexterm"></a>sets the axis maximum and minimum value</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt.logScaleX = true</code>
</p>
<p>
<code class="literal">plt.logScaleY = true</code>
</p>
</td><td style="" align="left" valign="top">
<p>This switches the axis to a log scale</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">plt.title = "title"</code>
</p>
</td><td style="" align="left" valign="top">
<p>This sets the plot title</p>
</td></tr></tbody></table></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec30"></a>Data visualization beyond breeze-viz</h2></div></div><hr /></div><p>Other tools for data <a id="id144" class="indexterm"></a>visualization in Scala are emerging: Spark notebooks (<a class="ulink" href="https://github.com/andypetrella/spark-notebook#description" target="_blank">https://github.com/andypetrella/spark-notebook#description</a>) based on the IPython notebook and Apache Zeppelin (<a class="ulink" href="https://zeppelin.incubator.apache.org" target="_blank">https://zeppelin.incubator.apache.org</a>). Both of these rely on Apache Spark, which we will explore later in this book.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec31"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we learned how to draw simple charts with breeze-viz. In the last chapter of this book, we will learn how to build interactive visualizations using JavaScript libraries.</p><p>Next, we will learn about basic Scala concurrency constructsâ€”specifically, parallel collections.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch04"></a>ChapterÂ 4.Â Parallel Collections and Futures</h2></div></div></div><p>Data science often involves processing medium or large amounts of data. Since the previously exponential growth in the speed of individual CPUs has slowed down and the amount of data continues to increase, leveraging computers effectively must entail parallel computation.</p><p>In this chapter, we will look at ways of parallelizing computation and data processing over a single computer. Virtually all new computers have more than one processing unit, and distributing a calculation over these cores can be an effective way of hastening medium-sized calculations.</p><p>Parallelizing calculations over a single chip is suitable for calculations involving gigabytes or a few terabytes of data. For larger data flows, we must resort to distributing the computation over several computers in parallel. We will discuss Apache Spark, a framework for parallel data processing in <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Distributed Batch Processing with Spark</em></span>.</p><p>In this book, we will look at three common ways of leveraging parallel architectures in a single machine: parallel collections, futures, and actors. We will consider the first two in this chapter, and leave the study of actors to <a class="link" href="#" linkend="ch09">Chapter 9</a>, <span class="emphasis"><em>Concurrency with Akka</em></span>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec32"></a>Parallel collections</h2></div></div><hr /></div><p>Parallel collections <a id="id145" class="indexterm"></a>offer an extremely easy way to parallelize independent tasks. The reader, being familiar with Scala, will know that many tasks can be phrased as operations on collections, such as <span class="emphasis"><em>map</em></span>, <span class="emphasis"><em>reduce</em></span>, <span class="emphasis"><em>filter</em></span>, or <span class="emphasis"><em>groupBy</em></span>. Parallel collections are an implementation of Scala collections that parallelize these operations to run over several threads.</p><p>Let's start with an example. We want to calculate the frequency of occurrence of each letter in a sentence:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val sentence = "The quick brown fox jumped over the lazy dog"</strong></span>
<span class="strong"><strong>sentence: String = The quick brown fox jumped ...</strong></span>
</pre></div><p>Let's start by converting our sentence from a string to a vector of characters:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val characters = sentence.toVector</strong></span>
<span class="strong"><strong>Vector[Char] = Vector(T, h, e,  , q, u, i, c, k, ...)</strong></span>
</pre></div><p>We can now convert <code class="literal">characters</code> to a <span class="emphasis"><em>parallel</em></span> vector, a <code class="literal">ParVector</code>. To do this, we use the <code class="literal">par</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val charactersPar = characters.par</strong></span>
<span class="strong"><strong>ParVector[Char] = ParVector(T, h, e,  , q, u, i, c, k,  , ...)</strong></span>
</pre></div><p>
<code class="literal">ParVector</code> collections support the same operations as regular vectors, but their methods are executed in parallel over several threads.</p><p>Let's start by filtering out the spaces in <code class="literal">charactersPar</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val lettersPar = charactersPar.filter { _ != ' ' }</strong></span>
<span class="strong"><strong>ParVector[Char] = ParVector(T, h, e, q, u, i, c, k, ...)</strong></span>
</pre></div><p>Notice how Scala hides <a id="id146" class="indexterm"></a>the execution details. The <code class="literal">filter</code> operation was performed using multiple threads, and you barely even noticed! The interface and behavior of a parallel vector is identical to its serial counterpart, save for a few details that we will explore in the next section.</p><p>Let's now use the <code class="literal">toLower</code> function to make the letters lowercase:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val lowerLettersPar = lettersPar.map { _.toLower }</strong></span>
<span class="strong"><strong>ParVector[Char] = ParVector(t, h, e, q, u, i, c, k, ...)</strong></span>
</pre></div><p>As before, the <code class="literal">map</code> method was applied in parallel. To find the frequency of occurrence of each letter, we use the <code class="literal">groupBy</code> method to group characters into vectors containing all the occurrences of that character:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val intermediateMap = lowerLettersPar.groupBy(identity)</strong></span>
<span class="strong"><strong>ParMap[Char,ParVector[Char]] = ParMap(e -&gt; ParVector(e, e, e, e), ...)</strong></span>
</pre></div><p>Note how the <code class="literal">groupBy</code> method has created a <code class="literal">ParMap</code> instance, the parallel equivalent of an immutable map. To get the number of occurrences of each letter, we do a <code class="literal">mapValues</code> call on <code class="literal">intermediateMap</code>, replacing each vector by its length:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val occurenceNumber = intermediateMap.mapValues { _.length }</strong></span>
<span class="strong"><strong>ParMap[Char,Int] = ParMap(e -&gt; 4, x -&gt; 1, n -&gt; 1, j -&gt; 1, ...)</strong></span>
</pre></div><p>Congratulations! We've written a multi-threaded algorithm for finding the frequency of occurrence of each letter in a few lines of code. You should find it straightforward to adapt this to find the frequency of occurrence of each word in a document, a common preprocessing problem for analyzing text data.</p><p>Parallel collections make it very easy to parallelize some operation pipelines: all we had to do was call <code class="literal">.par</code> on the <code class="literal">characters</code> vector. All subsequent operations were parallelized. This makes <a id="id147" class="indexterm"></a>switching from a serial to a parallel implementation very easy.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec27"></a>Limitations of parallel collections</h3></div></div></div><p>Part of the power and the <a id="id148" class="indexterm"></a>appeal of parallel collections is that they present the same interface as their serial counterparts: they have a <code class="literal">map</code> method, a <code class="literal">foreach</code> method, a <code class="literal">filter</code> method, and so on. By and large, these methods work in the same way on parallel collections as they do in serial. There are, however, some notable caveats. The most important one has to do with side effects. If an operation on a parallel collection has a side effect, this may result in a race condition: a situation in which the final result depends on the order in which the threads perform their operations.</p><p>Side effects in collections arise most commonly when we update a variable defined outside of the collection. To give a trivial example of unexpected behavior, let's define a <code class="literal">count</code> variable and increment it a thousand times using a parallel range:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; var count = 0</strong></span>
<span class="strong"><strong>count: Int = 0</strong></span>

<span class="strong"><strong>scala&gt; (0 until 1000).par.foreach { i =&gt; count += 1 }</strong></span>

<span class="strong"><strong>scala&gt; count</strong></span>
<span class="strong"><strong>count: Int = 874 // not 1000!</strong></span>
</pre></div><p>What happened here? The function passed to <code class="literal">foreach</code> has a side effect: it increments <code class="literal">count</code>, a variable outside of the scope of the function. This is a problem because the <code class="literal">+=</code> operator is a sequence of two operations:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Retrieve the value of <code class="literal">count</code> and add one to it</p></li><li style="list-style-type: disc"><p>Assign the result back to <code class="literal">count</code>
</p></li></ul></div><p>To understand why this causes unexpected behavior, let's imagine that the <code class="literal">foreach</code> loop has been parallelized over two threads. <span class="strong"><strong>Thread A</strong></span> might read the <span class="strong"><strong>count</strong></span> variable when it is <span class="strong"><strong>832</strong></span> and add one to it to give <span class="strong"><strong>833</strong></span>. Before it has time to reassign <span class="strong"><strong>833</strong></span> to <span class="strong"><strong>count</strong></span>, <span class="strong"><strong>Thread B</strong></span> reads <span class="strong"><strong>count</strong></span>, still at <span class="strong"><strong>832</strong></span>, and adds one to give <span class="strong"><strong>833</strong></span>. <span class="strong"><strong>Thread A</strong></span> then assigns <span class="strong"><strong>833</strong></span> to <span class="strong"><strong>count</strong></span>. <span class="strong"><strong>Thread B</strong></span> then assigns <span class="strong"><strong>833</strong></span> to <span class="strong"><strong>count</strong></span>. We've run through two updates but only incremented the count by one. The problem arises because <code class="literal">+=</code> can be separated into two instructions: it is not <span class="emphasis"><em>atomic</em></span>. This leaves room for threads to interleave their operations:</p><div class="mediaobject"><img src="graphics/4795_race_condition.jpg" /><div class="caption"><p>The anatomy of a race condition: both thread A and thread B are trying to update <code class="literal">count</code> concurrently, resulting in one of the updates being overwritten. The final value of <code class="literal">count</code> is 833 instead of 834.</p></div></div><p>To give a somewhat more realistic example of problems caused by non-atomicity, let's look at a different method for counting the frequency of occurrence of each letter in our sentence. We define a mutable <code class="literal">Char -&gt; Int</code> hash map outside of the loop. Each time we encounter a letter, we <a id="id149" class="indexterm"></a>increment the corresponding integer in the map:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.collection.mutable</strong></span>
<span class="strong"><strong>import scala.collection.mutable</strong></span>

<span class="strong"><strong>scala&gt; val occurenceNumber = mutable.Map.empty[Char, Int]</strong></span>
<span class="strong"><strong>occurenceNumber: mutable.Map[Char,Int] = Map()</strong></span>

<span class="strong"><strong>scala&gt; lowerLettersPar.foreach { c =&gt; </strong></span>
<span class="strong"><strong>  occurenceNumber(c) = occurenceNumber.getOrElse(c, 0) + 1</strong></span>
<span class="strong"><strong>}</strong></span>

<span class="strong"><strong>scala&gt; occurenceNumber('e') // Should be 4</strong></span>
<span class="strong"><strong>Int = 2</strong></span>
</pre></div><p>The discrepancy occurs because of the non-atomicity of the operations in the <code class="literal">foreach</code> loop.</p><p>In general, it is good practice to avoid side effects in higher-order functions on collections. They make the code harder to understand and preclude switching from serial to parallel collections. It is also good practice to avoid exposing mutable state: immutable objects can be shared freely between threads and cannot be affected by side effects.</p><p>Another limitation of parallel collections occurs in reduction (or folding) operations. The function used to combine items together must be <span class="emphasis"><em>associative</em></span>. For instance:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; (0 until 1000).par.reduce {_ - _ } // should be -499500</strong></span>
<span class="strong"><strong>Int = 63620</strong></span>
</pre></div><p>The <span class="emphasis"><em>minus</em></span> operator, <code class="literal">â€“</code>, is not associative. The order in which consecutive operations are applied matters: <code class="literal">(a â€“ b) â€“ c</code> is not the same as <code class="literal">a â€“ (b â€“ c)</code>. The function used to reduce a parallel <a id="id150" class="indexterm"></a>collection must be associative because the order in which the reduction occurs is not tied to the order of the collection.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec28"></a>Error handling</h3></div></div></div><p>In single-threaded <a id="id151" class="indexterm"></a>programs, exception handling is relatively straightforward: if an exception occurs, the function can either handle it or escalate it. This is not nearly as obvious when parallelism is introduced: a single thread might fail, but the others might return successfully.</p><p>Parallel collection methods will throw an exception if they fail on any element, just like their serial counterparts:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; Vector(2, 0, 5).par.map { 10 / _ }</strong></span>
<span class="strong"><strong>java.lang.ArithmeticException: / by zero</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>There are cases when this isn't the behavior that we want. For instance, we might be using a parallel collection to retrieve a large number of web pages in parallel. We might not mind if a few of the pages cannot be fetched.</p><p>Scala's <code class="literal">Try</code> type was designed for sandboxing code that might throw exceptions. It is similar to <code class="literal">Option</code> in that it is a one-element container:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.util._</strong></span>
<span class="strong"><strong>import scala.util._</strong></span>

<span class="strong"><strong>scala&gt; Try { 2 + 2 }</strong></span>
<span class="strong"><strong>Try[Int] = Success(4)</strong></span>
</pre></div><p>Unlike the <code class="literal">Option</code> type, which indicates whether an expression has a useful value, the <code class="literal">Try</code> type indicates whether an expression can be executed without throwing an exception. It takes on the following two values:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">Try { 2 + 2 } == Success(4)</code> if the expression in the <code class="literal">Try</code> statement is evaluated successfully</p></li><li style="list-style-type: disc"><p>
<code class="literal">Try { 2 / 0 } == Failure(java.lang.ArithmeticException: / by zero)</code> if the expression in the <code class="literal">Try</code> block results in an exception</p></li></ul></div><p>This will make more sense with an example. To see the <code class="literal">Try</code> type in action, we will try to fetch web pages in a fault tolerant manner. We will use the built-in <code class="literal">Source.fromURL </code>method which fetches a web page and opens an iterator of the page's content. If it fails to fetch the web page, it throws an error:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.io.Source</strong></span>
<span class="strong"><strong>import scala.io.Source</strong></span>

<span class="strong"><strong>scala&gt; val html = Source.fromURL("http://www.google.com")</strong></span>
<span class="strong"><strong>scala.io.BufferedSource = non-empty iterator</strong></span>

<span class="strong"><strong>scala&gt; val html = Source.fromURL("garbage")</strong></span>
<span class="strong"><strong>java.net.MalformedURLException: no protocol: garbage</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>Instead of letting the <a id="id152" class="indexterm"></a>expression propagate out and crash the rest of our code, we can wrap the call to <code class="literal">Source.fromURL</code> in <code class="literal">Try</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; Try { Source.fromURL("http://www.google.com") }</strong></span>
<span class="strong"><strong>Try[BufferedSource] = Success(non-empty iterator)</strong></span>

<span class="strong"><strong>scala&gt; Try { Source.fromURL("garbage") }</strong></span>
<span class="strong"><strong>Try[BufferedSource] = Failure(java.net.MalformedURLException: no protocol: garbage)</strong></span>
</pre></div><p>To see the power of our <code class="literal">Try</code> statement, let's now retrieve a list of URLs in parallel in a fault tolerant manner:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val URLs = Vector("http://www.google.com", </strong></span>
<span class="strong"><strong>  "http://www.bbc.co.uk",</strong></span>
<span class="strong"><strong>  "not-a-url"</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>URLs: Vector[String] = Vector(http://www.google.com, http://www.bbc.co.uk, not-a-url)</strong></span>

<span class="strong"><strong>scala&gt; val pages = URLs.par.map { url =&gt;</strong></span>
<span class="strong"><strong>  url -&gt; Try { Source.fromURL(url) } </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>pages: ParVector[(String, Try[BufferedSource])] = ParVector((http://www.google.com,Success(non-empty iterator)), (http://www.bbc.co.uk,Success(non-empty iterator)), (not-a-url,Failure(java.net.MalformedURLException: no protocol: not-a-url)))</strong></span>
</pre></div><p>We can then use a <code class="literal">collect</code> statement to act on the pages we could fetch successfully. For instance, to get the number of characters on each page:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; pages.collect { case(url, Success(it)) =&gt; url -&gt; it.size }</strong></span>
<span class="strong"><strong>ParVector[(String, Int)] = ParVector((http://www.google.com,18976), (http://www.bbc.co.uk,132893))</strong></span>
</pre></div><p>By making good use of Scala's built-in <code class="literal">Try</code> classes and parallel collections, we have built a fault tolerant, multithreaded URL retriever in a few lines of code. (Compare this to the myriad of Java/C++ <a id="id153" class="indexterm"></a>books that prefix code examples with 'error handling is left out for clarity'.)</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip08"></a>Tip</h3><p>
<span class="strong"><strong>The Try type versus try/catch statements</strong></span>
</p><p>Programmers <a id="id154" class="indexterm"></a>with imperative or object-oriented <a id="id155" class="indexterm"></a>backgrounds will be more familiar with try/catch blocks for handling exceptions. We could have accomplished similar functionality here by wrapping the code for fetching URLs in a try block, returning null if the call raises an exception.</p><p>However, besides being more verbose, returning null is less satisfactory: we lose all information about the exception and null is less expressive than <code class="literal">Failure(exception)</code>. Furthermore, returning a <code class="literal">Try[T]</code> type forces the caller to consider the possibility that the function might fail, by encoding this possibility in the type of the return value. In contrast, just returning <code class="literal">T</code> and coding failure with a null value allows the caller to ignore failure, raising the possibility of a confusing <code class="literal">NullPointerException</code> being thrown at a completely different point in the program.</p><p>In short, <code class="literal">Try[T]</code> is just another higher-order type, like <code class="literal">Option[T]</code> or <code class="literal">List[T]</code>. Treating the possibility of failure in the same way as the rest of the code adds coherence to the program and encourages programmers to tackle the possibility of exceptions explicitly.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec29"></a>Setting the parallelism level</h3></div></div></div><p>So far, we have <a id="id156" class="indexterm"></a>considered parallel collections as black boxes: add <code class="literal">par</code> to a normal collection and all the operations are performed in parallel. Often, we will want more control over how the tasks are executed.</p><p>Internally, parallel collections work by distributing an operation over multiple threads. Since the threads share memory, parallel collections do not need to copy any data. Changing the number of threads available to the parallel collection will change the number of CPUs that are used to perform the tasks.</p><p>Parallel collections have a <code class="literal">tasksupport</code> attribute that controls task execution:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val parRange = (0 to 100).par</strong></span>
<span class="strong"><strong>parRange: ParRange = ParRange(0, 1, 2, 3, 4, 5,...</strong></span>

<span class="strong"><strong>scala&gt; parRange.tasksupport</strong></span>
<span class="strong"><strong>TaskSupport = scala.collection.parallel.ExecutionContextTaskSupport@311a0b3e</strong></span>

<span class="strong"><strong>scala&gt; parRange.tasksupport.parallelismLevel</strong></span>
<span class="strong"><strong>Int = 8 // Number of threads to be used</strong></span>
</pre></div><p>The task support object of a collection is an <span class="emphasis"><em>execution context</em></span>, an abstraction capable of executing Scala expressions in a separate thread. By default, the execution context in Scala 2.11 is a <span class="emphasis"><em>work-stealing thread pool</em></span>. When a parallel collection submits tasks, the context allocates these tasks to its threads. If a thread finds that it has finished its queued tasks, it will try and steal outstanding tasks from the other threads. The default execution context maintains a thread pool with number of threads equal to the number of CPUs.</p><p>The number of <a id="id157" class="indexterm"></a>threads over which the parallel collection distributes the work can be changed by changing the task support. For instance, to parallelize the operations performed by a range over four threads:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.collection.parallel._</strong></span>
<span class="strong"><strong>import scala.collection.parallel._</strong></span>

<span class="strong"><strong>scala&gt; parRange.tasksupport = new ForkJoinTaskSupport(</strong></span>
<span class="strong"><strong>  new scala.concurrent.forkjoin.ForkJoinPool(4)</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>parRange.tasksupport: scala.collection.parallel.TaskSupport = scala.collection.parallel.ForkJoinTaskSupport@6e1134e1</strong></span>

<span class="strong"><strong>scala&gt; parRange.tasksupport.parallelismLevel</strong></span>
<span class="strong"><strong>Int: 4</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec30"></a>An example â€“ cross-validation with parallel collections</h3></div></div></div><p>Let's apply <a id="id158" class="indexterm"></a>what you have learned so far to solve data science problems. There are many parts of a machine learning pipeline that can be parallelized trivially. One such part is cross-validation.</p><p>We will give a brief description of cross-validation here, but you can refer to <span class="emphasis"><em>The Elements of Statistical Learning</em></span>, by <span class="emphasis"><em>Hastie</em></span>, <span class="emphasis"><em>Tibshirani</em></span>, and <span class="emphasis"><em>Friedman</em></span> for a more in-depth discussion.</p><p>Typically, a supervised machine learning problem involves training an algorithm over a training set. For instance, when we built a model to calculate the probability of a person being male based on their height and weight, the training set was the (height, weight) data for each participant, together with the male/female label for each row. Once the algorithm is trained on the training set, we can use it to classify new data. This process only really makes sense if the training set is representative of the new data that we are likely to encounter.</p><p>The training set has a finite number of entries. It will thus, inevitably, have idiosyncrasies that are not representative of the population at large, merely due to its finite nature. These idiosyncrasies <a id="id159" class="indexterm"></a>will result in prediction errors when predicting whether a new person is male or female, over and above the prediction error of the algorithm on the training set itself. Cross-validation is a tool for estimating the error caused by the idiosyncrasies of the training set that do not reflect the population at large.</p><p>Cross-validation works by dividing the training set in two parts: a smaller, new training set and a cross-validation set. The algorithm is trained on the reduced training set. We then see how well the algorithm models the cross-validation set. Since we know the right answer for the cross-validation set, we can measure how well our algorithm is performing when shown new information. We repeat this procedure many times with different cross-validation sets.</p><p>There are several different types of cross-validation, which differ in how we choose the cross-validation set. In this chapter, we will look at repeated random subsampling: we select <span class="emphasis"><em>k</em></span> rows at random from the training data to form the cross-validation set. We do this many times, calculating the cross-validation error for each subsample. Since each iteration is independent of the previous ones, we can parallelize this process trivially. It is therefore a good candidate for parallel collections. We will look at an alternative form of cross-validation, <span class="emphasis"><em>k-fold cross-validation</em></span>, in <a class="link" href="#" linkend="ch12">Chapter 12</a>, <span class="emphasis"><em>Distributed Machine Learning with MLlib</em></span>.</p><p>We will build a class that performs cross-validation in parallel. I encourage you to write the code as you go, but you will find the source code corresponding to these examples on GitHub (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>).We will use parallel collections to handle the parallelism and Breeze data types in the inner loop. The <code class="literal">build.sbt</code> file is identical to the one we used in  
<a class="link" href="#" linkend="ch02">Chapter 2</a>
, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scalaVersion := "2.11.7"</strong></span>

<span class="strong"><strong>libraryDependencies ++= Seq(</strong></span>
<span class="strong"><strong>  "org.scalanlp" %% "breeze" % "0.11.2",</strong></span>
<span class="strong"><strong>  "org.scalanlp" %% "breeze-natives" % "0.11.2"</strong></span>
<span class="strong"><strong>)</strong></span>
</pre></div><p>We will build a <code class="literal">RandomSubsample</code> class. The class exposes a type alias, <code class="literal">CVFunction</code>, for a function that takes two lists of indicesâ€”the first corresponding to the reduced training set and the second to the validation setâ€”and returns a <code class="literal">Double</code> corresponding to the cross-validation error:</p><div class="informalexample"><pre class="programlisting">type CVFunction = (Seq[Int], Seq[Int]) =&gt; Double</pre></div><p>The <code class="literal">RandomSubsample</code> class will expose a single method, <code class="literal">mapSamples</code>, which takes a <code class="literal">CVFunction</code>, repeatedly passes it different partitions of indices, and returns a vector of the errors. This is <a id="id160" class="indexterm"></a>what the class looks like:</p><div class="informalexample"><pre class="programlisting">// RandomSubsample.scala

import breeze.linalg._
import breeze.numerics._

/** <span class="strong"><strong>Random subsample cross-validation</strong></span>
  * 
  * @param nElems Total number of elements in the training set.
  * @param nCrossValidation Number of elements to leave out of training set.
*/
class RandomSubsample(val nElems:Int, val nCrossValidation:Int) {

  type CVFunction = (Seq[Int], Seq[Int]) =&gt; Double

  require(nElems &gt; nCrossValidation,
    "nCrossValidation, the number of elements " +
    "withheld, must be &lt; nElems")

  private val indexList = DenseVector.range(0, nElems)

  /** <span class="strong"><strong>Perform multiple random sub-sample CV runs on f</strong></span>
    *
    * @param nShuffles Number of random sub-sample runs.
    * @param f user-defined function mapping from a list of
    *   indices in the training set and a list of indices in the
    *   test-set to a double indicating the out-of sample score
    *   for this split.
    * @returns DenseVector of the CV error for each random split.
    */
  def mapSamples(nShuffles:Int)(f:CVFunction)
  :DenseVector[Double] = {
    val cvResults = (0 to nShuffles).par.map { i =&gt;
      
      <span class="strong"><strong>// Randomly split indices between test and training</strong></span>
      val shuffledIndices = breeze.linalg.shuffle(indexList)
      val Seq(testIndices, trainingIndices) =
        split(shuffledIndices, Seq(nCrossValidation))
 
<span class="strong"><strong>       // Apply f for this split</strong></span>
      f(trainingIndices.toScalaVector, 
        testIndices.toScalaVector)
    }
    DenseVector(cvResults.toArray)
  }
}</pre></div><p>Let's look at what happens in more detail, starting with the arguments passed to the constructor:</p><div class="informalexample"><pre class="programlisting">class RandomSubsample(val nElems:Int, val nCrossValidation:Int)</pre></div><p>We pass the total number of elements in the training set and the number of elements to leave out for cross-validation in the class constructor. Thus, passing 100 to <code class="literal">nElems</code> and 20 to <code class="literal">nCrossValidation</code> implies that our training set will have 80 random elements of the total data and that the test set will have 20 elements.</p><p>We then construct a <a id="id161" class="indexterm"></a>list of all integers between <code class="literal">0</code> and <code class="literal">nElems</code>:</p><div class="informalexample"><pre class="programlisting">private val indexList = DenseVector.range(0, nElems)</pre></div><p>For each iteration of the cross-validation, we will shuffle this list and take the first <code class="literal">nCrossValidation</code> elements to be the indices of rows in our test set and the remaining to be the indices of rows in our training set.</p><p>Our class exposes a single method, <code class="literal">mapSamples</code>, that takes two curried arguments: <code class="literal">nShuffles</code>, the number of times to perform random subsampling, and <code class="literal">f</code>, a <code class="literal">CVFunction</code>:</p><div class="informalexample"><pre class="programlisting">  def mapSamples(nShuffles:Int)(f:CVFunction):DenseVector[Double] </pre></div><p>With all this set up, the code for doing cross-validation is deceptively simple. We generate a parallel range from <code class="literal">0</code> to <code class="literal">nShuffles</code> and, for each item in the range, generate a new train-test split and calculate the cross-validation error:</p><div class="informalexample"><pre class="programlisting">    val cvResults = (0 to nShuffles).par.map { i =&gt;
      val shuffledIndices = breeze.linalg.shuffle(indexList)
      val Seq(testIndices, trainingIndices) = 
        split(shuffledIndices, Seq(nCrossValidation))
      f(trainingIndices.toScalaVector, testIndices.toScalaVector)
    }</pre></div><p>The only tricky part of this function is splitting the shuffled index list into a list of indices for the training set and a list of indices for the test set. We use Breeze's <code class="literal">split</code> method. This takes a vector as its first argument and a list of split-points as its second, and returns a list of fragments of the original vector. We then use pattern matching to extract the individual parts.</p><p>Finally, <code class="literal">mapSamples</code> converts <code class="literal">cvResults</code> to a Breeze vector:</p><div class="informalexample"><pre class="programlisting">DenseVector(cvResults.toArray) </pre></div><p>Let's see this in action. We can test our class by running cross-validation on the logistic regression example <a id="id162" class="indexterm"></a>developed in  
<a class="link" href="#" linkend="ch02">Chapter 2</a>
, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>. In that chapter, we developed a <code class="literal">LogisticRegression</code> class that takes a training set (in the form of a <code class="literal">DenseMatrix</code>) and target (in the form of a <code class="literal">DenseVector</code>) at construction time. The class then calculates the parameters that best represent the training set. We will first add two methods to the <code class="literal">LogisticRegression</code> class to use the trained model to classify previously unseen examples:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The <code class="literal">predictProbabilitiesMany</code> method uses the trained model to calculate the probability of having the target variable set to one. In the context of our example, this is the probability of being male, given a height and weight.</p></li><li style="list-style-type: disc"><p>The <code class="literal">classifyMany</code> method assigns classification labels (one or zero) to members of a test set. We will assign a one if <code class="literal">predictProbabilitiesMany</code> returns a value greater than <code class="literal">0.5</code>.</p></li></ul></div><p>With these two functions, our <code class="literal">LogisticRegression</code> class becomes:</p><div class="informalexample"><pre class="programlisting">// Logistic Regression.scala

class LogisticRegression(
  val training:DenseMatrix[Double],
  val target:DenseVector[Double]
) {
  ...
  /** Probability of classification for each row
    * in test set.
    */
  def <span class="strong"><strong>predictProbabilitiesMany</strong></span>(test:DenseMatrix[Double])
  :DenseVector[Double] = {
    val xBeta = test * optimalCoefficients
    sigmoid(xBeta)
  }

  /** Predict the value of the target variable 
    * for each row in test set.
    */
  def <span class="strong"><strong>classifyMany</strong></span>(test:DenseMatrix[Double])
  :DenseVector[Double] = {
    val probabilities = predictProbabilitiesMany(test)
    I((probabilities :&gt; 0.5).toDenseVector)
  }
  ...
}</pre></div><p>We can now put together an example program for our <code class="literal">RandomSubsample</code> class. We will use the same height-weight data as in  
<a class="link" href="#" linkend="ch02">Chapter 2</a>
, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>. The data preprocessing will be similar. The code examples for this chapter provide a helper module, <code class="literal">HWData</code>, to load the height-weight data into Breeze vectors. The data itself is in the <code class="literal">data/ </code>directory of the code examples for this chapter (available on GitHub at <a class="ulink" href="https://github.com/pbugnion/s4ds/tree/master/chap04" target="_blank">https://github.com/pbugnion/s4ds/tree/master/chap04</a>).</p><p>For each new <a id="id163" class="indexterm"></a>subsample, we create a new <code class="literal">LogisticRegression </code>instance, train it on the subset of the training set to get the best coefficients for this train-test split, and use <code class="literal">classifyMany</code> to generate predictions on the cross-validation set in this split. We then calculate the classification error and report the average classification error over every train-test split:</p><div class="informalexample"><pre class="programlisting">// RandomSubsampleDemo.scala

import breeze.linalg._
import breeze.linalg.functions.manhattanDistance
import breeze.numerics._
import breeze.stats._

object RandomSubsampleDemo extends App {

  <span class="strong"><strong>/* Load and pre-process data */</strong></span>
  val data = HWData.load

  val rescaledHeights:DenseVector[Double] =
    (data.heights - mean(data.heights)) / stddev(data.heights)

  val rescaledWeights:DenseVector[Double] =
    (data.weights - mean(data.weights)) / stddev(data.weights)

  val featureMatrix:DenseMatrix[Double] =
    DenseMatrix.horzcat(
      DenseMatrix.ones[Double](data.npoints, 1),
      rescaledHeights.toDenseMatrix.t,
      rescaledWeights.toDenseMatrix.t
    )

  val target:DenseVector[Double] = data.genders.values.map { 
    gender =&gt; if(gender == 'M') 1.0 else 0.0 
  }

  <span class="strong"><strong>/* Cross-validation */</strong></span>
  val testSize = 20
  val cvCalculator = new RandomSubsample(data.npoints, testSize)

  <span class="strong"><strong>// Start parallel CV loop</strong></span>
  val cvErrors = cvCalculator.mapSamples(1000) { 
    (trainingIndices, testIndices) =&gt;

    val regressor = new LogisticRegression(
      data.featureMatrix(trainingIndices, ::).toDenseMatrix,
      data.target(trainingIndices).toDenseVector
    )
    <span class="strong"><strong>// Predictions on test-set</strong></span>
    val genderPredictions = regressor.classifyMany(
      data.featureMatrix(testIndices, ::).toDenseMatrix
    )
    <span class="strong"><strong>// Calculate number of mis-classified examples</strong></span>
    val dist = manhattanDistance(
      genderPredictions, data.target(testIndices)
    )
    <span class="strong"><strong>// Calculate mis-classification rate</strong></span>
    dist / testSize.toDouble
  }

  println(s"Mean classification error: ${mean(cvErrors)}")
}</pre></div><p>Running this <a id="id164" class="indexterm"></a>program on the height-weight data gives a classification error of 10%.</p><p>We now have a fully working, parallelized cross-validation class. Scala's parallel range made it simple to repeatedly compute the same function in different threads.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec33"></a>Futures</h2></div></div><hr /></div><p>Parallel collections <a id="id165" class="indexterm"></a>offer a simple, yet powerful, framework for parallel operations. However, they are limited in one respect: the total amount of work must be known in advance, and each thread must perform the same function (possibly on different inputs).</p><p>Imagine that we want to write a program that fetches a web page (or queries a web API) every few seconds and extracts data for further processing from this web page. A typical example might involve querying a web API to maintain an up-to-date value of a particular stock price. Fetching data from an external web page takes a few hundred milliseconds, typically. If we perform this operation on the main thread, it will needlessly waste CPU cycles waiting for the web server to reply.</p><p>The solution is to wrap the code for fetching the web page in a <span class="emphasis"><em>future</em></span>. A future is a one-element container containing the future result of a computation. When you create a future, the computation in it gets off-loaded to a different thread in order to avoid blocking the main thread. When the computation finishes, the result is written to the future and thus made accessible to the main thread.</p><p>As an example, we will <a id="id166" class="indexterm"></a>write a program that queries the "Markit on demand" API to <a id="id167" class="indexterm"></a>fetch the price of a given stock. For instance, the URL for the current price of a Google share is <a class="ulink" href="http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG" target="_blank">http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG</a>. Go ahead and paste this in the address box of your web browser. You will see an XML string appear with, among other things, the current stock price. Let's fetch this programmatically without resorting to a future first:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.io._</strong></span>
<span class="strong"><strong>import scala.io_</strong></span>

<span class="strong"><strong>scala&gt; val url = "http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG"</strong></span>
<span class="strong"><strong>url: String = http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG</strong></span>

<span class="strong"><strong>scala&gt; val response = Source.fromURL(url).mkString</strong></span>
<span class="strong"><strong>response: String = &lt;StockQuote&gt;&lt;Status&gt;SUCCESS&lt;/Status&gt;</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>Notice how it takes a little bit of time to query the API. Let's now do the same, but using a future (don't worry about the imports for now, we will discuss what they mean in more detail further on):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.concurrent._</strong></span>
<span class="strong"><strong>import scala.concurrent._</strong></span>

<span class="strong"><strong>scala&gt; import scala.util._</strong></span>
<span class="strong"><strong>import scala.util._</strong></span>

<span class="strong"><strong>scala&gt; import scala.concurrent.ExecutionContext.Implicits.global</strong></span>
<span class="strong"><strong>import scala.concurrent.ExecutionContext.Implicits.global</strong></span>

<span class="strong"><strong>scala&gt; val response = Future { Source.fromURL(url).mkString }</strong></span>
<span class="strong"><strong>response: Future[String] = Promise$DefaultPromise@3301801b</strong></span>
</pre></div><p>If you run this, you will notice that control returns to the shell instantly before the API has had a chance to respond. To make this evident, let's simulate a slow connection by adding a call to <code class="literal">Thread.sleep</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val response = Future { </strong></span>
<span class="strong"><strong>  Thread.sleep(10000) // sleep for 10s</strong></span>
<span class="strong"><strong>  Source.fromURL(url).mkString</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>response: Future[String] = Promise$DefaultPromise@231f98ef</strong></span>
</pre></div><p>When you run this, you <a id="id168" class="indexterm"></a>do not have to wait for ten seconds for the next prompt to appear: you regain control of the shell straightaway. The bit of code in the future is executed asynchronously: its execution is independent of the main program flow.</p><p>How do we retrieve the result of the computation? We note that <code class="literal">response</code> has type <code class="literal">Future[String]</code>. We can check whether the computation wrapped in the future has finished by querying the future's <code class="literal">isCompleted</code> attribute:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; response.isCompleted</strong></span>
<span class="strong"><strong>Boolean = true</strong></span>
</pre></div><p>The future exposes a <code class="literal">value</code> attribute that contains the computation result:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; response.value</strong></span>
<span class="strong"><strong>Option[Try[String]] = Some(Success(&lt;StockQuote&gt;&lt;Status&gt;SUCCESS&lt;/Status&gt;</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>The <code class="literal">value</code> attribute of a future has type <code class="literal">Option[Try[T]]</code>. We have already seen how to use the <code class="literal">Try</code> type to handle exceptions gracefully in the context of parallel collections. It is used in the same way here. A future's <code class="literal">value</code> attribute is <code class="literal">None</code> until the future is complete, then it is set to <code class="literal">Some(Success(value))</code> if the future ran successfully, or <code class="literal">Some(Failure(error))</code> if an exception was thrown.</p><p>Repeatedly calling <code class="literal">f.value</code> until the future completes works well in the shell, but it does not generalize to more complex programs. Instead, we want to tell the computer to do something once the future is complete: we want to bind a <span class="emphasis"><em>callback</em></span> function to the future. We can do this by setting the future's <code class="literal">onComplete</code> attribute. Let's tell the future to print the API response when it completes:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; response.onComplete {</strong></span>
<span class="strong"><strong>  case Success(s) =&gt; println(s)</strong></span>
<span class="strong"><strong>  case Failure(e) =&gt; println(s"Error fetching page: $e")</strong></span>
<span class="strong"><strong>}</strong></span>

<span class="strong"><strong>scala&gt; </strong></span>
<span class="strong"><strong>// Wait for response to complete, then prints:</strong></span>
<span class="strong"><strong>&lt;StockQuote&gt;&lt;Status&gt;SUCCESS&lt;/Status&gt;&lt;Name&gt;Alphabet Inc&lt;/Name&gt;&lt;Symbol&gt;GOOGL&lt;/Symbol&gt;&lt;LastPrice&gt;695.22&lt;/LastPrice&gt;&lt;Chan...</strong></span>
</pre></div><p>The function passed <a id="id169" class="indexterm"></a>to <code class="literal">onComplete</code> runs when the future is finished. It takes a single argument of type <code class="literal">Try[T]</code> containing the result of the future.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip09"></a>Tip</h3><p>
<span class="strong"><strong>Failure is normal: how to build resilient applications</strong></span>
</p><p>By <a id="id170" class="indexterm"></a>wrapping the output of the code that it runs in a <code class="literal">Try</code> type, futures force the client code to consider the possibility that the code might fail. The client can isolate the effect of failure to avoid crashing the whole application. They might, for instance, log the exception. In the case of a web API query, they might add the offending URL to be queried again at a later date. In the case of a database failure, they might roll back the transaction.</p><p>By treating failure as a first-class citizen rather than through exceptional control flow bolted on at the end, we can build applications that are much more resilient.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec31"></a>Future composition â€“ using a future's result</h3></div></div></div><p>In the previous <a id="id171" class="indexterm"></a>section, you learned about the <code class="literal">onComplete </code>method to bind a callback to a future. This is useful to cause a side effect to happen when the future is complete. It does not, however, let us transform the future's return value easily.</p><p>To carry on with our stocks example, let's imagine that we want to convert the query response from a string to an XML object. Let's start by including the <code class="literal">scala-xml</code> library as a dependency in <code class="literal">build.sbt</code>:</p><div class="informalexample"><pre class="programlisting">libraryDependencies += "org.scala-lang" % "scala-xml" % "2.11.0-M4"</pre></div><p>Let's restart the console and reimport the dependencies on <code class="literal">scala.concurrent._</code>, <code class="literal">scala.concurrent.ExecutionContext.Implicits.global</code>, and <code class="literal">scala.io._</code>. We also want to import the <code class="literal">XML</code> library:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.xml.XML</strong></span>
<span class="strong"><strong>import scala.xml.XML</strong></span>
</pre></div><p>We will use the same URL as in the previous section:</p><p>
<a class="ulink" href="http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG" target="_blank">http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG</a>
</p><p>It is sometimes useful to think of a future as a collection that either contains one element if a calculation has been successful, or zero elements if it has failed. For instance, if the web API has been queried successfully, our future contains a string representation of the response. Like other container types in Scala, futures support a <code class="literal">map</code> method that applies a function to the element contained in the future, returning a new future, and does nothing if the calculation in the future failed. But what does this mean in the context of a computation that might not be finished yet? The map method gets applied as soon as the future is complete, like the <code class="literal">onComplete</code> method.</p><p>We can use the <a id="id172" class="indexterm"></a>future's <code class="literal">map</code> method to apply a transformation to the result of the future asynchronously. Let's poll the "Markit on demand" API again. This time, instead of printing the result, we will parse it as XML.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val strResponse = Future { </strong></span>
<span class="strong"><strong>  Thread.sleep(20000) // Sleep for 20s</strong></span>
<span class="strong"><strong>  val res = Source.fromURL(url).mkString</strong></span>
<span class="strong"><strong>  println("finished fetching url")</strong></span>
<span class="strong"><strong>  res</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>strResponse: Future[String] = Promise$DefaultPromise@1dda9bc8</strong></span>

<span class="strong"><strong>scala&gt; val xmlResponse = strResponse.map { s =&gt;</strong></span>
<span class="strong"><strong>  println("applying string to xml transformation")</strong></span>
<span class="strong"><strong>  XML.loadString(s) </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>xmlResponse: Future[xml.Elem] = Promise$DefaultPromise@25d1262a</strong></span>

<span class="strong"><strong>// wait while the remainder of the 20s elapses</strong></span>
<span class="strong"><strong>finished fetching url</strong></span>
<span class="strong"><strong>applying string to xml transformation</strong></span>

<span class="strong"><strong>scala&gt; xmlResponse.value</strong></span>
<span class="strong"><strong>Option[Try[xml.Elem]] = Some(Success(&lt;StockQuote&gt;&lt;Status&gt;SUCCESS&lt;/Status&gt;...</strong></span>
</pre></div><p>By registering subsequent maps on futures, we are providing a road map to the executor running the future for what to do.</p><p>If any of the steps fail, the failed <code class="literal">Try</code> instance containing the exception gets propagated instead:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val strResponse = Future { </strong></span>
<span class="strong"><strong>  Source.fromURL("empty").mkString </strong></span>
<span class="strong"><strong>}</strong></span>

<span class="strong"><strong>scala&gt; val xmlResponse = strResponse.map { </strong></span>
<span class="strong"><strong>  s =&gt; XML.loadString(s) </strong></span>
<span class="strong"><strong>}</strong></span>

<span class="strong"><strong>scala&gt; xmlResponse.value </strong></span>
<span class="strong"><strong>Option[Try[xml.Elem]] = Some(Failure(MalformedURLException: no protocol: empty))</strong></span>
</pre></div><p>This behavior makes <a id="id173" class="indexterm"></a>sense if you think of a failed future as an empty container. When applying a map to an empty list, it returns the same empty list. Similarly, when applying a map to an empty (failed) future, the empty future is returned.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec32"></a>Blocking until completion</h3></div></div></div><p>The code for <a id="id174" class="indexterm"></a>fetching stock prices works fine in the shell. However, if you paste it in a standalone program, you will notice that nothing gets printed and the program finishes straightaway. Let's look at a trivial example of this:</p><div class="informalexample"><pre class="programlisting">// BlockDemo.scala
import scala.concurrent._
import scala.concurrent.ExecutionContext.Implicits.global
import scala.concurrent.duration._

object BlockDemo extends App {
  val f = Future { Thread.sleep(10000) }
  f.onComplete { _ =&gt; println("future completed") }
  // "future completed" is not printed
}</pre></div><p>The program stops running as soon as the main thread has completed its tasks, which, in this example, just involves creating the futures. In particular, the line <code class="literal">"future completed"</code> is never printed. If we want the main thread to wait for a future to execute, we must explicitly tell it to block execution until the future has finished running. This is done using the <code class="literal">Await.ready</code> or <code class="literal">Await.result</code> methods. Both these methods block the execution of the main thread until the future completes. We could make the above program work as intended by adding this line:</p><div class="informalexample"><pre class="programlisting">Await.ready(f, 1 minute)</pre></div><p>The <code class="literal">Await</code> methods take the future as their first argument and a <code class="literal">Duration</code> object as the second. If the future takes longer to complete than the specified duration, a <code class="literal">TimeoutException</code> is thrown. Pass <code class="literal">Duration.Inf</code> to set an infinite timeout.</p><p>The difference between <code class="literal">Await.ready</code> and <code class="literal">Await.result</code> is that the latter returns the value inside the future. In particular, if the future resulted in an exception, that exception will get thrown. In contrast, <code class="literal">Await.ready</code> returns the future itself.</p><p>In general, one should try to avoid blocking as much as possible: the whole point of futures is to run code in background threads in order to keep the main thread of execution responsive. However, a common, legitimate use case for blocking is at the end of a program. If we are <a id="id175" class="indexterm"></a>running a large-scale integration process, we might dispatch several futures to query web APIs, read from text files, or insert data into a database. Embedding the code in futures is more scalable than performing these operations sequentially. However, as the majority of the intensive work is running in background threads, we are left with many outstanding futures when the main thread completes. It makes sense, at this stage, to block until all the futures have completed.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec33"></a>Controlling parallel execution with execution contexts</h3></div></div></div><p>Now that <a id="id176" class="indexterm"></a>we know <a id="id177" class="indexterm"></a>how to define futures, let's <a id="id178" class="indexterm"></a>look at controlling how they run. In particular, you might want to control the number of threads to use when running a large number of futures.</p><p>When a future is defined, it is passed an <span class="emphasis"><em>execution context</em></span>, either directly or implicitly. An execution context is an object that exposes an <code class="literal">execute</code> method that takes a block of code and runs it, possibly asynchronously. By changing the execution context, we can change the "backend" that runs the futures. We have already seen how to use execution contexts to control the execution of parallel collections.</p><p>So far, we have just been using the default execution context by importing <code class="literal">scala.concurrent.ExecutionContext.Implicits.global</code>. This is a fork / join thread pool with as many threads as there are underlying CPUs.</p><p>Let's now define a new execution context that uses sixteen threads:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import java.util.concurrent.Executors</strong></span>
<span class="strong"><strong>import java.util.concurrent.Executors</strong></span>

<span class="strong"><strong>scala&gt; val ec = ExecutionContext.fromExecutorService(</strong></span>
<span class="strong"><strong>  Executors.newFixedThreadPool(16)</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>ec: ExecutionContextExecutorService = ExecutionContextImpl$$anon$1@1351ce60</strong></span>
</pre></div><p>Having defined the execution context, we can pass it explicitly to futures as they are defined:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val f = Future { Thread.sleep(1000) } (ec)</strong></span>
<span class="strong"><strong>f: Future[Unit] = Promise$DefaultPromise@458b456</strong></span>
</pre></div><p>Alternatively, we can define the execution context implicitly:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; implicit val context = ec</strong></span>
<span class="strong"><strong>context: ExecutionContextExecutorService = ExecutionContextImpl$$anon$1@1351ce60</strong></span>
</pre></div><p>It is then passed as an implicit parameter to all new futures as they are constructed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val f = Future { Thread.sleep(1000) }</strong></span>
<span class="strong"><strong>f: Future[Unit] = Promise$DefaultPromise@3c4b7755</strong></span>
</pre></div><p>You can shut the execution context down to destroy the thread pool:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; ec.shutdown()</strong></span>
</pre></div><p>When an <a id="id179" class="indexterm"></a>execution context receives a shutdown command, it will finish executing its current tasks but will refuse any new tasks.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl2sec34"></a>Futures example â€“ stock price fetcher</h3></div></div></div><p>Let's bring some <a id="id180" class="indexterm"></a>of the concepts that we covered in this section together to build a command-line application that prompts the user for the name of a stock and fetches the value of that stock. The catch is that, to keep the UI responsive, we will fetch the stock using a future:</p><div class="informalexample"><pre class="programlisting">// StockPriceDemo.scala

import scala.concurrent._
import scala.concurrent.ExecutionContext.Implicits.global
import scala.io._
import scala.xml.XML
import scala.util._

object StockPriceDemo extends App {

<span class="strong"><strong>  /* Construct URL for a stock symbol */</strong></span>
  def urlFor(stockSymbol:String) =
    ("http://dev.markitondemand.com/MODApis/Api/v2/Quote?" + 
     s"symbol=${stockSymbol}")

  <span class="strong"><strong>/* Build a future that fetches the stock price */</strong></span>
  def fetchStockPrice(stockSymbol:String):Future[BigDecimal] = {
    val url = urlFor(stockSymbol)
    val strResponse = Future { Source.fromURL(url).mkString }
    val xmlResponse = strResponse.map { s =&gt; XML.loadString(s) }
    val price = xmlResponse.map { 
      r =&gt; BigDecimal((r \ "LastPrice").text) 
    }
    price
  }

  <span class="strong"><strong>/* Command line interface */</strong></span>
  println("Enter symbol at prompt.")
  while (true) {
    val symbol = readLine("&gt; ") // Wait for user input
    // When user puts in symbol, fetch data in background
    // thread and print to screen when complete
    fetchStockPrice(symbol).onComplete { res =&gt;
      println()
      res match {
        case Success(price) =&gt; println(s"$symbol: USD $price")
        case Failure(e) =&gt; println(s"Error fetching  $symbol: $e")
      }
      print("&gt; ") // Simulate the appearance of a new prompt
    }
  }

}</pre></div><p>Try running the <a id="id181" class="indexterm"></a>program and entering the code for some stocks:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[info] Running StockPriceDemo</strong></span>
<span class="strong"><strong>Enter symbol at prompt:</strong></span>
<span class="strong"><strong>&gt; GOOG</strong></span>
<span class="strong"><strong>&gt; MSFT</strong></span>
<span class="strong"><strong>&gt;</strong></span>
<span class="strong"><strong>GOOG: USD 695.22</strong></span>
<span class="strong"><strong>&gt;</strong></span>
<span class="strong"><strong>MSFT: USD 47.48</strong></span>
<span class="strong"><strong>&gt; AAPL</strong></span>
<span class="strong"><strong>&gt; </strong></span>
<span class="strong"><strong>AAPL: USD 111.01</strong></span>
</pre></div><p>Let's summarize how the code works. when you enter a stock, the main thread constructs a future that fetches the stock information from the API, converts it to XML, and extracts the price. We use <code class="literal">(r \ "LastPrice").text</code> to extract the text inside the <code class="literal">LastPrice</code> tag from the XML node <code class="literal">r</code>. We then convert the value to a big decimal. When the transformations are complete, the result is printed to screen by binding a callback through <code class="literal">onComplete</code>. Exception handling is handled naturally through our use of <code class="literal">.map</code> methods to handle transformations.</p><p>By wrapping the code for fetching a stock price in a future, we free up the main thread to just respond to the user. This means that the user interface does not get blocked if we have, for instance, a slow internet connection.</p><p>This example is somewhat artificial, but you could easily wrap much more complicated logic: stock prices could be written to a database and we could add additional commands to plot the stock price over time, for instance.</p><p>We have only scratched the surface of what futures can offer in this section. We will revisit futures in more detail when we look at polling web APIs in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>
and <a class="link" href="#" linkend="ch09">Chapter 9</a>, <span class="emphasis"><em>Concurrency with Akka</em></span>.</p><p>Futures are a key <a id="id182" class="indexterm"></a>part of the data scientist's toolkit for building scalable systems. Moving expensive computation (either in terms of CPU time or wall time) to background threads improves scalability greatly. For this reason, futures are an <a id="id183" class="indexterm"></a>important part of many Scala libraries such as <span class="strong"><strong>Akka</strong></span> and the <a id="id184" class="indexterm"></a>
<span class="strong"><strong>Play</strong></span> framework.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec34"></a>Summary</h2></div></div><hr /></div><p>By providing high-level concurrency abstractions, Scala makes writing parallel code intuitive and straightforward. Parallel collections and futures form an invaluable part of a data scientist's toolbox, allowing them to parallelize their code with minimal effort. However, while these high-level abstractions obviate the need to deal directly with threads, an understanding of the internals of Scala's concurrency model is necessary to avoid race conditions.</p><p>In the next chapter, we will put concurrency on hold and study how to interact with SQL databases. However, this is only temporary: futures will play an important role in many of the remaining chapters in this book.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec35"></a>References</h2></div></div><hr /></div><p>
<span class="emphasis"><em>Aleksandar Prokopec</em></span>, <span class="emphasis"><em>Learning Concurrent Programming in Scala</em></span>. This is a detailed introduction to the basics of concurrent programming in Scala. In particular, it explores parallel collections and futures in much greater detail than this chapter.</p><p>Daniel Westheide's blog gives an excellent introduction to many Scala concepts, in particular:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<span class="strong"><strong>Futures</strong></span>: <a id="id185" class="indexterm"></a>
<a class="ulink" href="http://danielwestheide.com/blog/2013/01/09/the-neophytes-guide-to-scala-part-8-welcome-to-the-future.html" target="_blank">http://danielwestheide.com/blog/2013/01/09/the-neophytes-guide-to-scala-part-8-welcome-to-the-future.html</a>
</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>The Try </strong></span>
<a id="id186" class="indexterm"></a>
<span class="strong"><strong>type</strong></span>: <a class="ulink" href="http://danielwestheide.com/blog/2012/12/26/the-neophytes-guide-to-scala-part-6-error-handling-with-try.html" target="_blank">http://danielwestheide.com/blog/2012/12/26/the-neophytes-guide-to-scala-part-6-error-handling-with-try.html</a>
</p></li></ul></div><p>For a discussion of cross-validation, see <span class="emphasis"><em>The Elements of Statistical Learning</em></span> by <span class="emphasis"><em>Hastie</em></span>, <span class="emphasis"><em>Tibshirani</em></span>, and <span class="emphasis"><em>Friedman</em></span>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch05"></a>ChapterÂ 5.Â Scala and SQL through JDBC</h2></div></div></div><p>One of data science's raison d'Ãªtre is the difficulty of manipulating large datasets. Much of the data of interest to a company or research group cannot fit conveniently in a single computer's RAM. Storing the data in a way that is easy to query is therefore a complex problem.</p><p>Relational databases have been successful at solving the data storage problem. Originally proposed in 1970 (<a class="ulink" href="http://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf" target="_blank">http://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf</a>), the overwhelming majority of databases in active use today are still relational. In that time, the price of RAM per megabyte has decreased by a factor of a hundred million. Similarly, hard drive capacity has increased from tens or hundreds of megabytes to terabytes. It is remarkable that, despite this exponential growth in data storage capacity, the relational model has remained dominant.</p><p>Virtually all <a id="id187" class="indexterm"></a>relational databases are described and queried with variants of <span class="strong"><strong>SQL</strong></span> (<span class="strong"><strong>Structured Query Language</strong></span>). With the advent of distributed computing, the position of SQL databases as the de facto data storage standard is being challenged by other types of databases, commonly grouped under the umbrella term NoSQL. Many NoSQL databases are more partition-tolerant than SQL databases: they can be split into several parts residing on different computers. While this author expects that NoSQL databases will become increasingly popular, SQL databases are likely to remain prevalent as a data persistence mechanism; hence, a significant portion of this book is devoted to interacting with SQL from Scala.</p><p>While SQL is standardized, most implementations do not follow the full standard. Additionally, most implementations provide extensions to the standard. This means that, while many of the concepts in this book will apply to all SQL backends, the exact syntax will need to be adjusted. We will consider only the MySQL implementation here.</p><p>In this chapter, you will learn how to interact with SQL databases from Scala using JDBC, a bare bones Java API. In the next chapter, we will consider Slick, an <span class="strong"><strong>Object Relational </strong></span>
<a id="id188" class="indexterm"></a>
<span class="strong"><strong>Mapper </strong></span>(<span class="strong"><strong>ORM</strong></span>) that gives a more Scala-esque feel to interacting with SQL.</p><p>This chapter is roughly composed of two sections: we will first discuss the basic functionality for connecting and interacting with SQL databases, and then discuss useful functional patterns that can be used to create an elegant, loosely coupled, and coherent data access layer.</p><p>This chapter assumes that you have a basic working knowledge of SQL. If you do not, you would be better off first reading one of the reference books mentioned at the end of the chapter.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec36"></a>Interacting with JDBC</h2></div></div><hr /></div><p>JDBC is an API for <a id="id189" class="indexterm"></a>connecting to SQL databases in Java. It remains the simplest way of connecting to SQL databases from Scala. Furthermore, the majority of higher-level abstractions for interacting with databases still use JDBC as a backend.</p><p>JDBC is not a library in itself. Rather, it exposes a set of interfaces to interact with databases. Relational database vendors then provide specific implementations of these interfaces.</p><p>Let's start by creating a <code class="literal">build.sbt</code> file. We will declare a dependency on the MySQL JDBC connector:</p><div class="informalexample"><pre class="programlisting">scalaVersion := "2.11.7"

libraryDependencies += "mysql" % "mysql-connector-java" % "5.1.36"</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec37"></a>First steps with JDBC</h2></div></div><hr /></div><p>Let's start by <a id="id190" class="indexterm"></a>connecting to JDBC from the command line. To follow with the examples, you will need access to a running MySQL server. If you added the MySQL connector to the list of dependencies, open a Scala console by typing the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sbt console</strong></span>
</pre></div><p>Let's import JDBC:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import java.sql._</strong></span>
<span class="strong"><strong>import java.sql._</strong></span>
</pre></div><p>We then need to tell JDBC to use a specific connector. This is normally done using reflection, loading the driver at runtime:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; Class.forName("com.mysql.jdbc.Driver")</strong></span>
<span class="strong"><strong>Class[_] = class com.mysql.jdbc.Driver</strong></span>
</pre></div><p>This loads the appropriate driver into the namespace at runtime. If this seems somewhat magical to you, it's probably not worth worrying about exactly how this works. This is the only example of <a id="id191" class="indexterm"></a>reflection that we will consider in this book, and it is not particularly idiomatic Scala.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec35"></a>Connecting to a database server</h3></div></div></div><p>Having specified the <a id="id192" class="indexterm"></a>SQL connector, we can now connect to a database. Let's assume that we have a database called <code class="literal">test</code> on host <code class="literal">127.0.0.1</code>, listening on port <code class="literal">3306</code>. We create a connection as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val connection = DriverManager.getConnection(</strong></span>
<span class="strong"><strong>  "jdbc:mysql://127.0.0.1:3306/test",</strong></span>
<span class="strong"><strong>  "root", // username when connecting</strong></span>
<span class="strong"><strong>  "" // password</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>java.sql.Connection = com.mysql.jdbc.JDBC4Connection@12e78a69</strong></span>
</pre></div><p>The first argument to <code class="literal">getConnection</code> is a URL-like string with <code class="literal">jdbc:mysql://host[:port]/database</code>. The second and third arguments are the username and password. Pass in an empty string if you can connect without a password.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec36"></a>Creating tables</h3></div></div></div><p>Now that we have a <a id="id193" class="indexterm"></a>database connection, let's interact with the server. For these examples, you will find it useful to have a MySQL shell open (or a MySQL GUI such as <span class="strong"><strong>MySQLWorkbench</strong></span>) as well as the Scala console. You can open a MySQL shell by typing the following command in a terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ mysql</strong></span>
</pre></div><p>As an example, we will create a small table to keep track of famous physicists. In a <code class="literal">mysql</code> shell, we would run the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mysql&gt; USE test;</strong></span>
<span class="strong"><strong>mysql&gt; CREATE TABLE physicists (</strong></span>
<span class="strong"><strong>    id INT(11) AUTO_INCREMENT PRIMARY KEY,</strong></span>
<span class="strong"><strong>    name VARCHAR(32) NOT NULL</strong></span>
<span class="strong"><strong>);</strong></span>
</pre></div><p>To achieve the same with Scala, we send a JDBC statement to the connection:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val statementString = """</strong></span>
<span class="strong"><strong>CREATE TABLE physicists (</strong></span>
<span class="strong"><strong>    id INT(11) AUTO_INCREMENT PRIMARY KEY,</strong></span>
<span class="strong"><strong>    name VARCHAR(32) NOT NULL</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>"""</strong></span>

<span class="strong"><strong>scala&gt; val statement = connection.prepareStatement(statementString)</strong></span>
<span class="strong"><strong>PreparedStatement = JDBC4PreparedStatement@c983201: CREATE TABLE ...</strong></span>

<span class="strong"><strong>scala&gt; statement.executeUpdate()</strong></span>
<span class="strong"><strong>results: Int = 0</strong></span>
</pre></div><p>Let's ignore the return <a id="id194" class="indexterm"></a>value of <code class="literal">executeUpdate</code> for now.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec37"></a>Inserting data</h3></div></div></div><p>Now that we have created a <a id="id195" class="indexterm"></a>table, let's insert some data into it. We can do this with a SQL <code class="literal">INSERT</code> statement:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val statement = connection.prepareStatement("""</strong></span>
<span class="strong"><strong>    INSERT INTO physicists (name) VALUES ('Isaac Newton')</strong></span>
<span class="strong"><strong>""")</strong></span>

<span class="strong"><strong>scala&gt; statement.executeUpdate()</strong></span>
<span class="strong"><strong>Int = 1</strong></span>
</pre></div><p>In this case, <code class="literal">executeUpdate</code> returns <code class="literal">1</code>. When inserting rows, it returns the number of rows that were inserted. Similarly, if we had used a <code class="literal">SQL UPDATE</code> statement, this would return the number of rows that were updated. For statements that do not manipulate rows directly (such as the <code class="literal">CREATE TABLE</code> statement in the previous section), <code class="literal">executeUpdate</code> just returns <code class="literal">0</code>.</p><p>Let's just jump into a <code class="literal">mysql</code> shell to verify the insertion performed correctly:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mysql&gt; select * from physicists ;</strong></span>
<span class="strong"><strong>+----+--------------+</strong></span>
<span class="strong"><strong>| id | name         |</strong></span>
<span class="strong"><strong>+----+--------------+</strong></span>
<span class="strong"><strong>|  1 | Isaac Newton |</strong></span>
<span class="strong"><strong>+----+--------------+</strong></span>
<span class="strong"><strong>1 row in set (0.00 sec)</strong></span>
</pre></div><p>Let's quickly summarize what we have seen so far: to execute SQL statements that do not return results, use the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>val statement = connection.prepareStatement("SQL statement string")</strong></span>
<span class="strong"><strong>statement.executeUpdate()</strong></span>
</pre></div><p>In the context of data science, we frequently need to insert or update many rows at a time. For instance, we might have a list of physicists:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val physicistNames = List("Marie Curie", "Albert Einstein", "Paul Dirac")</strong></span>
</pre></div><p>We want to insert all of these into the database. While we could create a statement for each physicist and send it to the database, this is quite inefficient. A better solution is to create a <span class="emphasis"><em>batch</em></span> of statements and send them to the database together. We start by creating a statement template:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val statement = connection.prepareStatement("""</strong></span>
<span class="strong"><strong>    INSERT INTO physicists (name) VALUES (?)</strong></span>
<span class="strong"><strong>""")</strong></span>
<span class="strong"><strong>PreparedStatement = JDBC4PreparedStatement@621a8225: INSERT INTO physicists (name) VALUES (** NOT SPECIFIED **)</strong></span>
</pre></div><p>This is identical to the previous <code class="literal">prepareStatement</code> calls, except that we replaced the physicist's name with a <code class="literal">?</code> placeholder. We can set the placeholder value with the <code class="literal">statement.setString</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; statement.setString(1, "Richard Feynman")</strong></span>
</pre></div><p>This replaces the first placeholder in the statement with the string <code class="literal">Richard Feynman</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; statement</strong></span>
<span class="strong"><strong>com.mysql.jdbc.JDBC4PreparedStatement@5fdd16c3:</strong></span>
<span class="strong"><strong>INSERT INTO physicists (name) VALUES ('Richard Feynman')</strong></span>
</pre></div><p>Note that JDBC, somewhat counter-intuitively, counts the placeholder positions from 1 rather than 0.</p><p>We have now created the first statement in the batch of updates. Run the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; statement.addBatch()</strong></span>
</pre></div><p>By running the preceding <a id="id196" class="indexterm"></a>command, we initiate a batch insert: the statement is added to a temporary buffer that will be executed when we run the <code class="literal">executeBatch</code> method. Let's add all the physicists in our list:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; physicistNames.foreach { name =&gt; </strong></span>
<span class="strong"><strong>  statement.setString(1, name)</strong></span>
<span class="strong"><strong>  statement.addBatch()</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>We can now execute all the statements in the batch:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; statement.executeBatch</strong></span>
<span class="strong"><strong>Array[Int] = Array(1, 1, 1, 1)</strong></span>
</pre></div><p>The return value of <code class="literal">executeBatch</code> is an array of the number of rows altered or inserted by each item in the batch.</p><p>Note that we used <code class="literal">statement.setString</code> to fill in the template with a particular name. The <a id="id197" class="indexterm"></a>
<code class="literal">PreparedStatement</code> object has <code class="literal">setXXX</code> <a id="id198" class="indexterm"></a>methods for all basic types. To get a complete list, read the <code class="literal">PreparedStatement</code> API documentation (<a class="ulink" href="http://docs.oracle.com/javase/7/docs/api/java/sql/PreparedStatement.html" target="_blank">http://docs.oracle.com/javase/7/docs/api/java/sql/PreparedStatement.html</a>).</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec38"></a>Reading data</h3></div></div></div><p>Now that we know how <a id="id199" class="indexterm"></a>to insert data into a database, let's look at the converse: reading data. We use SQL <code class="literal">SELECT</code> statements to query the database. Let's do this in the MySQL shell first:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mysql&gt; SELECT * FROM physicists;</strong></span>
<span class="strong"><strong>+----+-----------------+</strong></span>
<span class="strong"><strong>| id | name            |</strong></span>
<span class="strong"><strong>+----+-----------------+</strong></span>
<span class="strong"><strong>|  1 | Isaac Newton    |</strong></span>
<span class="strong"><strong>|  2 | Richard Feynman |</strong></span>
<span class="strong"><strong>|  3 | Marie Curie     |</strong></span>
<span class="strong"><strong>|  4 | Albert Einstein |</strong></span>
<span class="strong"><strong>|  5 | Paul Dirac      |</strong></span>
<span class="strong"><strong>+----+-----------------+</strong></span>
<span class="strong"><strong>5 rows in set (0.01 sec)</strong></span>
</pre></div><p>To extract this information in Scala, we define a <code class="literal">PreparedStatement</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val statement = connection.prepareStatement("""</strong></span>
<span class="strong"><strong>    SELECT name FROM physicists</strong></span>
<span class="strong"><strong>""")</strong></span>
<span class="strong"><strong>PreparedStatement = JDBC4PreparedStatement@3c577c9d:</strong></span>
<span class="strong"><strong>SELECT name FROM physicists</strong></span>
</pre></div><p>We execute this statement by running the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val results = statement.executeQuery()</strong></span>
<span class="strong"><strong>results: java.sql.ResultSet = com.mysql.jdbc.JDBC4ResultSet@74a2e158</strong></span>
</pre></div><p>This returns a JDBC <code class="literal">ResultSet</code> instance. The <code class="literal">ResultSet</code> is an abstraction representing a set of rows from the database. Note that we used <code class="literal">statement.executeQuery</code> rather than <code class="literal">statement.executeUpdate</code>. In general, one should execute statements that return data (in the form of <code class="literal">ResultSet</code>) with <code class="literal">executeQuery</code>. Statements that modify the database without returning data (insert, create, alter, or update statements, among others) are executed with <code class="literal">executeUpdate</code>.</p><p>The <code class="literal">ResultSet</code> object behaves somewhat like an iterator. It exposes a <code class="literal">next</code> method that advances itself to the next record, returning <code class="literal">true</code> if there are records left in <code class="literal">ResultSet</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; results.next // Advance to the first record</strong></span>
<span class="strong"><strong>Boolean = true</strong></span>
</pre></div><p>When the <code class="literal">ResultSet</code> instance points to a record, we can extract fields in this record by passing in the field name:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; results.getString("name")</strong></span>
<span class="strong"><strong>String = Isaac Newton</strong></span>
</pre></div><p>We can also extract fields using positional arguments. The fields are indexed from one:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; results.getString(1) // first positional argument</strong></span>
<span class="strong"><strong>String = Isaac Newton</strong></span>
</pre></div><p>When we are done with a <a id="id200" class="indexterm"></a>particular record, we call the <code class="literal">next</code> method to advance the <code class="literal">ResultSet</code> to the next record:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; results.next // advances the ResultSet by one record</strong></span>
<span class="strong"><strong>Boolean = true</strong></span>

<span class="strong"><strong>scala&gt; results.getString("name")</strong></span>
<span class="strong"><strong>String = Richard Feynman</strong></span>
</pre></div><div class="mediaobject"><img src="graphics/4795_05_01.jpg" /><div class="caption"><p>A ResultSet object supports the getXXX(fieldName) methods to access the fields of a record and a <code class="literal">next</code> method to advance to the next record in the result set.</p></div></div><p>One can iterate over a result set using a <code class="literal">while</code> loop:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; while(results.next) { println(results.getString("name")) }</strong></span>
<span class="strong"><strong>Marie Curie</strong></span>
<span class="strong"><strong>Albert Einstein</strong></span>
<span class="strong"><strong>Paul Dirac</strong></span>
</pre></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip10"></a>Tip</h3><p>A word of warning applies to reading fields that are nullable. While one might expect JDBC to return null when faced with a null SQL field, the return type depends on the <code class="literal">getXXX</code> command used. For instance, <code class="literal">getInt</code> and <code class="literal">getLong</code> will return <code class="literal">0</code> for any field that is null. Similarly, <code class="literal">getDouble</code> and <code class="literal">getFloat</code> return <code class="literal">0.0</code>. This can lead to some subtle bugs in code. In general, one should be careful with getters that return Java value types (<code class="literal">int</code>, <code class="literal">long</code>) rather than objects. To find out if a value is <code class="literal">null</code> in the database, query it first with <code class="literal">getInt</code> (or <code class="literal">getLong</code> or <code class="literal">getDouble</code>, as appropriate), then use the <code class="literal">wasNull</code> method that returns a Boolean if the <a id="id201" class="indexterm"></a>last read value was null:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; rs.getInt("field")</strong></span>
<span class="strong"><strong>0</strong></span>
<span class="strong"><strong>scala&gt; rs.wasNull // was the last item read null?</strong></span>
<span class="strong"><strong>true</strong></span>
</pre></div><p>This (surprising) behavior makes reading from <code class="literal">ResultSet</code> instances error-prone. One of the goals of the second part of this chapter is to give you the tools to build an abstraction layer on top of the <code class="literal">ResultSet</code> interface to avoid having to call methods such as <code class="literal">getInt</code> directly.</p></div><p>Reading values directly from <code class="literal">ResultSet</code> objects feels quite unnatural in Scala. We will look, further on in this chapter, at constructing a layer through which you can access the result set using type classes.</p><p>We now know how to read and write to a database. Having finished with the database for now, we close the result sets, prepared statements, and connections:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; results.close</strong></span>

<span class="strong"><strong>scala&gt; statement.close</strong></span>

<span class="strong"><strong>scala&gt; connection.close</strong></span>
</pre></div><p>While closing statements and connections is not important in the Scala shell (they will get closed when you exit), it is important when you run programs; otherwise, the objects will persist, leading to "out of memory exceptions". In the next sections, we will look at establishing connections and <a id="id202" class="indexterm"></a>statements with the <span class="strong"><strong>loan pattern</strong></span>, a design pattern that closes a resource automatically when we finish using it.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec38"></a>JDBC summary</h2></div></div><hr /></div><p>We now have an overview of <a id="id203" class="indexterm"></a>JDBC. The rest of this chapter will concentrate on writing abstractions that sit above JDBC, making database accesses feel more natural. Before we do this, let's summarize what we have seen so far.</p><p>We have used three JDBC classes:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The <code class="literal">Connection</code> class represents a connection to a specific SQL database. Instantiate a connection as follows:</p><div class="informalexample"><pre class="programlisting">import java.sql._
Class.forName("com.mysql.jdbc.Driver")val connection = DriverManager.getConnection(
  "jdbc:mysql://127.0.0.1:3306/test",
  "root", // username when connecting
  "" // password
)</pre></div><p>Our main use of <code class="literal">Connection</code> instances has been to generate <code class="literal">PreparedStatement</code> objects:</p><div class="informalexample"><pre class="programlisting">connection.prepareStatement("SELECT * FROM physicists")</pre></div></li><li style="list-style-type: disc"><p>A <code class="literal">PreparedStatement</code> instance represents a SQL statement about to be sent to the database. It <a id="id204" class="indexterm"></a>also represents the template for a SQL statement with placeholders for values yet to be filled in. The class exposes the following methods:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><tbody><tr><td style="" align="left" valign="top">
<p>
<code class="literal">statement.executeUpdate</code>
</p>
</td><td style="" align="left" valign="top">
<p>This sends the statement to the database. Use this for SQL statements that modify the database and do not return any data, such as <code class="literal">INSERT</code>, <code class="literal">UPDATE</code>, <code class="literal">DELETE</code>, and <code class="literal">CREATE</code> statements.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">val results = statement.executeQuery</code>
</p>
</td><td style="" align="left" valign="top">
<p>This sends the statement to the database. Use this for SQL statements that return data (predominantly, the <code class="literal">SELECT </code>statements). This returns a <code class="literal">ResultSet</code> instance.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">statement.addBatch</code>
</p>
<p>
<code class="literal">statement.executeBatch</code>
</p>
</td><td style="" align="left" valign="top">
<p>The <code class="literal">addBatch</code> method adds the current statement to a batch of statements, and <code class="literal">executeBatch</code> sends the batch of statements to the database.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">statement.setString(1, "Scala")</code>
</p>
<p>
<code class="literal">statement.setInt(1, 42)</code>
</p>
<p>
<code class="literal">statement.setBoolean(1, true)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Fill in the placeholder values in the <code class="literal">PreparedStatement</code>. The first argument is the position in the statement (counting from 1). The second argument is the value.</p>
<p>One common use case for these is in a batch update or insert: we might have a Scala list of objects that we want to insert into the database. We fill in the placeholders for each object in the list using the <code class="literal">.setXXX</code> methods, then add this statement to the batch using <code class="literal">.addBatch</code>. We can then send the entire batch to the database using <code class="literal">.executeBatch</code>.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">statement.setNull(1, java.sql.Types.BOOLEAN)</code>
</p>
</td><td style="" align="left" valign="top">
<p>This sets a particular item in the statement to <code class="literal">NULL</code>. The second argument specifies the <code class="literal">NULL</code> type. If we are setting a cell in a Boolean column, for instance, this should be <code class="literal">Types.BOOLEAN</code>. A full list of types is given in the API documentation <a id="id205" class="indexterm"></a>for the <code class="literal">java.sql.Types</code> package (<a class="ulink" href="http://docs.oracle.com/javase/7/docs/api/java/sql/Types.html" target="_blank">http://docs.oracle.com/javase/7/docs/api/java/sql/Types.html</a>).</p>
</td></tr></tbody></table></div></li><li style="list-style-type: disc"><p>A <code class="literal">ResultSet</code> instance <a id="id206" class="indexterm"></a>represents a set of rows returned by a <code class="literal">SELECT</code> or <code class="literal">SHOW</code> statement. <code class="literal">ResultSet</code> exposes methods to access fields in the current row:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><tbody><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rs.getString(i)</code>
</p>
<p>
<code class="literal">rs.getInt(i)</code>
</p>
</td><td style="" align="left" valign="top">
<p>These methods get the value of the <code class="literal">ith</code> field in the current row; <code class="literal">i</code> is measured from 1.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rs.getString("name")</code>
</p>
<p>
<code class="literal">rs.getInt("age")</code>
</p>
</td><td style="" align="left" valign="top">
<p>These methods get the value of a specific field, which is indexed by the column name.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rs.wasNull</code>
</p>
</td><td style="" align="left" valign="top">
<p>This returns whether the last column read was<code class="literal"> NULL. </code>This is particularly important when reading Java value types, such as <code class="literal">getInt</code>, <code class="literal">getBoolean</code>, or <code class="literal">getDouble</code>, as these return a default value when reading a <code class="literal">NULL</code> value.</p>
</td></tr></tbody></table></div></li></ul></div><p>The <code class="literal">ResultSet</code> instance exposes the <code class="literal">.next </code>method to move to the next row; <code class="literal">.next</code> returns <code class="literal">true</code> until the <code class="literal">ResultSet</code> has advanced to just beyond the last row.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec39"></a>Functional wrappers for JDBC</h2></div></div><hr /></div><p>We now have a basic <a id="id207" class="indexterm"></a>overview of the tools afforded by JDBC. All the objects that we have interacted with so far feel somewhat clunky and out of place in Scala. They do not encourage a functional style of programming.</p><p>Of course, elegance is not necessarily a goal in itself (or, at least, you will probably struggle to convince your CEO that he should delay the launch of a product because the code lacks elegance). However, it is usually a symptom: either the code is not extensible or too tightly coupled, or it is easy to introduce bugs. The latter is particularly the case for JDBC. Forgot to check <code class="literal">wasNull</code>? That will come back to bite you. Forgot to close your connections? You'll get an "out of memory exception" (hopefully not in production).</p><p>In the next sections, we will look at patterns that we can use to wrap JDBC types in order to mitigate many of these risks. The patterns that we introduce here are used very commonly in Scala libraries and applications. Thus, besides writing robust classes to interact with JDBC, learning about these patterns will, I hope, give you greater understanding of Scala programming.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec40"></a>Safer JDBC connections with the loan pattern</h2></div></div><hr /></div><p>We have already seen <a id="id208" class="indexterm"></a>how to connect to a JDBC database <a id="id209" class="indexterm"></a>and send statements to the database for execution. This technique, however, is somewhat error prone: you have to remember to close statements; otherwise, you will quickly run out of memory. In more traditional imperative style, we write the following try-finally block around every connection:</p><div class="informalexample"><pre class="programlisting">// WARNING: poor Scala code
val connection = DriverManager.getConnection(url, user, password)
try {
  // do something with connection
}
finally {
  connection.close()
}</pre></div><p>Scala, with first-class functions, provides us with an alternative: the <span class="emphasis"><em>loan pattern</em></span>. We write a function that is responsible for opening the connection, loaning it to the client code to do something interesting with it, and then closing it when the client code is done. Thus, the client code is not responsible for closing the connection any more.</p><p>Let's create a new <code class="literal">SqlUtils</code> object with a <code class="literal">usingConnection</code> method that leverages the loan pattern:</p><div class="informalexample"><pre class="programlisting">// SqlUtils.scala

import java.sql._

object SqlUtils {

  /** Create an auto-closing connection using 
    * the loan pattern */
  def usingConnection[T](
    db:String,
    host:String="127.0.0.1",
    user:String="root",
    password:String="",
    port:Int=3306
  )(f:Connection =&gt; T):T = {
    
    // Create the connection
    val Url = s"jdbc:mysql://$host:$port/$db"
    Class.forName("com.mysql.jdbc.Driver")
    val connection = DriverManager.getConnection(
      Url, user, password)

    // give the connection to the client, through the callable 
    // `f` passed in as argument
    try {
      f(connection)
    }
    finally {
      // When client is done, close the connection
      connection.close()
    }
  }
}</pre></div><p>Let's see this function in action:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; SqlUtils.usingConnection("test") {</strong></span>
<span class="strong"><strong>  connection =&gt; println(connection)</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>com.mysql.jdbc.JDBC4Connection@46fd3d66</strong></span>
</pre></div><p>Thus, the client doesn't <a id="id210" class="indexterm"></a>have to remember to close the connection, and the resultant code (for the client) feels much more like Scala.</p><p>How does our <code class="literal">usingConnection</code> function work? The function definition is <code class="literal">def usingConnection( ... )(f : Connection =&gt; T ):T</code>. It takes, as its second set of arguments, a function <a id="id211" class="indexterm"></a>that acts on a <code class="literal">Connection</code> object. The body of <code class="literal">usingConnection</code> creates the connection, then passes it to <code class="literal">f</code>, and finally closes the connection. This syntax is somewhat similar to code blocks in Ruby or the <code class="literal">with</code> statement in Python.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip12"></a>Tip</h3><p>Be careful when mixing the loan pattern with lazy operations. This applies particularly to returning iterators, streams, and futures from <code class="literal">f</code>. As soon as the thread of execution leaves <code class="literal">f</code>, the connection will be closed. Any data structure that is not materialized at this point will not be able to carry on accessing the connection.</p></div><p>The loan pattern is, of course, not exclusive to database connections. It is useful whenever you have the following pattern, in pseudocode:</p><div class="informalexample"><pre class="programlisting">open resource (eg. database connection, file ...)
use resource somehow // loan resource to client for this part.
close resource</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec41"></a>Enriching JDBC statements with the "pimp my library" pattern</h2></div></div><hr /></div><p>In the <a id="id212" class="indexterm"></a>previous section, we <a id="id213" class="indexterm"></a>saw how to create self-closing connections with the loan pattern. This allows us to open connections to the database without having to remember to close them. However, we still have to remember to close any <code class="literal">ResultSet</code> and <code class="literal">PreparedStatement</code> that we open:</p><div class="informalexample"><pre class="programlisting">// WARNING: Poor Scala code
SqlUtils.usingConnection("test") { connection =&gt;
  val statement = connection.prepareStatement(
    "SELECT * FROM physicists")
  val results = statement.executeQuery
  // do something useful with the results
  <span class="strong"><strong>results.close</strong></span>
  <span class="strong"><strong>statement.close</strong></span>
}</pre></div><p>Having to open and close the statement is somewhat ugly and error prone. This is another natural use case for the loan pattern. Ideally, we would like to write the following:</p><div class="informalexample"><pre class="programlisting">usingConnection("test") { connection =&gt;
  <span class="strong"><strong>connection.withQuery</strong></span>("SELECT * FROM physicists") {
    resultSet =&gt; // process results
  }
}</pre></div><p>How can we define a <code class="literal">.withQuery</code> method on the <code class="literal">Connection</code> class? We do not control the <code class="literal">Connection</code> class definition as it is part of the JDBC API. We would like to be able to somehow reopen the <code class="literal">Connection</code> class definition to add the <code class="literal">withQuery </code>method.</p><p>Scala does not let us reopen classes to add new methods (a practice known as monkey-patching). We can still, however, enrich existing libraries with implicit conversions using the <span class="strong"><strong>pimp </strong></span>
<a id="id214" class="indexterm"></a>
<span class="strong"><strong>my library</strong></span> pattern (<a class="ulink" href="http://www.artima.com/weblogs/viewpost.jsp?thread=179766" target="_blank">http://www.artima.com/weblogs/viewpost.jsp?thread=179766</a>). We first define a <code class="literal">RichConnection</code> class that contains the <code class="literal">withQuery</code> method. This <code class="literal">RichConnection</code> class is created from an existing <code class="literal">Connection</code> instance.</p><div class="informalexample"><pre class="programlisting">
<code class="literal">// RichConnection.scala</code>

import java.sql.{Connection, ResultSet}

class RichConnection(val underlying:Connection) {

  /** Execute a SQL query and process the ResultSet */
  def withQuery[T](query:String)(f:ResultSet =&gt; T):T = {
    val statement = underlying.prepareStatement(query)
    val results = statement.executeQuery
    try {
      f(results) // loan the ResultSet to the client
    }
    finally {
      // Ensure all the resources get freed.
      results.close
      statement.close
    }
  }
}</pre></div><p>We could use <a id="id215" class="indexterm"></a>this class by <a id="id216" class="indexterm"></a>just wrapping every <code class="literal">Connection</code> instance in a <code class="literal">RichConnection</code> instance:</p><div class="informalexample"><pre class="programlisting">// Warning: poor Scala code
SqlUtils.usingConnection("test") { connection =&gt;
  val richConnection = new RichConnection(connection)
  richConnection.withQuery("SELECT * FROM physicists") {
    resultSet =&gt; // process resultSet
  }
}</pre></div><p>This adds unnecessary boilerplate: we have to remember to convert every connection instance to <code class="literal">RichConnection</code> to use <code class="literal">withQuery</code>. Fortunately, Scala provides an easier way with implicit conversions: we tell Scala how to convert from <code class="literal">Connection</code> to <code class="literal">RichConnection</code> and vice versa, and tell it to perform this conversion automatically (implicitly), if necessary:</p><div class="informalexample"><pre class="programlisting">// Implicits.scala
import java.sql.Connection

// Implicit conversion methods are often put in 
// an object called Implicits.
object Implicits {
  implicit def pimpConnection(conn:Connection) = 
    new RichConnection(conn)
  implicit def depimpConnection(conn:RichConnection) =  
    conn.underlying
}</pre></div><p>Now, whenever <code class="literal">pimpConnection</code> and <code class="literal">depimpConnection</code> are in the current scope, Scala will automatically use them to convert from <code class="literal">Connection</code> instances to <code class="literal">RichConnection</code> and back as needed.</p><p>We can now write the following (I have added type information for emphasis):</p><div class="informalexample"><pre class="programlisting">// Bring the conversion functions into the current scope
import Implicits._ 

SqlUtils.usingConnection("test") { (connection:Connection) =&gt;
  <span class="strong"><strong>connection.withQuery</strong></span>("SELECT * FROM physicists") {
    // Wow! It's like we have just added 
    // .withQuery to the JDBC Connection class!
    resultSet =&gt; // process results
  }
}</pre></div><p>This might look like magic, so let's step back and look at what happens when we call <code class="literal">withQuery</code> on a <code class="literal">Connection</code> instance. The Scala compiler will first look to see if the class definition of <a id="id217" class="indexterm"></a>
<code class="literal">Connection</code> defines a <code class="literal">withQuery</code> method. When it finds that it does not, it will look for implicit <a id="id218" class="indexterm"></a>methods that convert a <code class="literal">Connection</code> instance to a class that defines <code class="literal">withQuery</code>. It will find that the <code class="literal">pimpConnection</code> method allows conversion from <code class="literal">Connection</code> to <code class="literal">RichConnection</code>, which defines <code class="literal">withQuery</code>. The Scala compiler automatically uses <code class="literal">pimpConnection</code> to transform the <code class="literal">Connection</code> instance to <code class="literal">RichConnection</code>.</p><p>Note that we used the names <code class="literal">pimpConnection</code> and <code class="literal">depimpConnection</code> for the conversion functions, but they could have been anything. We never call these methods explicitly.</p><p>Let's summarize how to use the <span class="emphasis"><em>pimp my library</em></span> pattern to add methods to an existing class:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>Write a class that wraps the class you want to enrich: <code class="literal">class</code> <code class="literal">RichConnection(val underlying:Connection)</code>. Add all the methods that you wish the original class had.</p></li><li><p>Write a method to convert from your original class to your enriched class as part of an object called (conventionally) <code class="literal">Implicits</code>. Make sure that you tell Scala to use this conversion automatically with the <code class="literal">implicit</code> keyword: <code class="literal">implicit def pimpConnection(conn:Connection):RichConnection</code>. You can also tell Scala to automatically convert back from the enriched class to the original class by adding the reverse conversion method.</p></li><li><p>Allow implicit conversions by importing the implicit conversion methods: <code class="literal">import Implicits._</code>.</p></li></ol></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec42"></a>Wrapping result sets in a stream</h2></div></div><hr /></div><p>The JDBC <a id="id219" class="indexterm"></a>
<code class="literal">ResultSet</code> object plays very badly with Scala collections. The only real way of doing anything useful with it is to loop through it directly with a <code class="literal">while</code> loop. For instance, to get a list of the names of physicists in our database, we could write the following code:</p><div class="informalexample"><pre class="programlisting">// WARNING: poor Scala code
import Implicits._ // import implicit conversions

SqlUtils.usingConnection("test") { connection =&gt;
  connection.withQuery("SELECT * FROM physicists") { resultSet =&gt;
    var names = List.empty[String]
    <span class="strong"><strong>while(resultSet.next) {</strong></span>
      val name = resultSet.getString("name")
      names = name :: names
    <span class="strong"><strong>}</strong></span>
<span class="strong"><strong>    names</strong></span>
  }
}
//=&gt; List[String] = List(Paul Dirac, Albert Einstein, Marie Curie, Richard Feynman, Isaac Newton)</pre></div><p>The <code class="literal">ResultSet</code> interface feels unnatural because it behaves very differently from Scala collections. In <a id="id220" class="indexterm"></a>particular, it does not support the higher-order functions that we take for granted in Scala: no <code class="literal">map</code>, <code class="literal">filter</code>, <code class="literal">fold</code>, or <code class="literal">for</code> comprehensions. Thankfully, writing a <span class="emphasis"><em>stream</em></span> that wraps <code class="literal">ResultSet</code> is quite straightforward. A Scala stream is a lazily evaluated list: it evaluates the next element in the collection when it is needed and forgets previous elements when they are no longer used.</p><p>We can define a <code class="literal">stream</code> method that wraps <code class="literal">ResultSet</code> as follows:</p><div class="informalexample"><pre class="programlisting">// SqlUtils.scala
object SqlUtils {   
  ... 
  def stream(results:ResultSet):Stream[ResultSet] = 
    if (results.next) { results #:: stream(results) }
    else { Stream.empty[ResultSet] }
}</pre></div><p>This might look quite confusing, so let's take it slowly. We define a <code class="literal">stream</code> method that wraps <code class="literal">ResultSet</code>, returning a <code class="literal">Stream[ResultSet]</code>. When the client calls <code class="literal">stream</code> on an empty result set, this just returns an empty stream. When the client calls <code class="literal">stream</code> on a non-empty <code class="literal">ResultSet</code>, the <code class="literal">ResultSet</code> instance is advanced by one row, and the client gets back <code class="literal">results #:: stream(results)</code>. The <code class="literal">#::</code> operator on a stream is similar to the cons operator, <code class="literal">::</code>, on a list: it prepends <code class="literal">results</code> to an existing <code class="literal">Stream</code>. The critical difference is that, unlike a list, <code class="literal">stream(results)</code> does not get evaluated until necessary. This, therefore, avoids duplicating the entire <code class="literal">ResultSet</code> in memory.</p><p>Let's use our brand new <code class="literal">stream</code> function to get the name of all the physicists in our database:</p><div class="informalexample"><pre class="programlisting">import Implicits._

SqlUtils.usingConnection("test") { connection =&gt;
  connection.withQuery("SELECT * FROM physicists") { results =&gt;
    <span class="strong"><strong>val resultsStream = SqlUtils.stream(results)</strong></span>
    resultsStream.map { _.getString("name") }.toVector
  }
}
//=&gt; Vector(Richard Feynman, Albert Einstein, Marie Curie, Paul Dirac)</pre></div><p>Streaming the <a id="id221" class="indexterm"></a>results, rather than using the result set directly, lets us interact with the data much more naturally as we are now dealing with just a Scala collection.</p><p>When you use <code class="literal">stream</code> in a <code class="literal">withQuery</code> block (or, generally, in a block that automatically closes the result set), you must always materialize the stream within the function, hence the call to <code class="literal">toVector</code>. Otherwise, the stream will wait until its elements are needed to materialize them, and by then, the <code class="literal">ResultSet</code> instance will be closed.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec43"></a>Looser coupling with type classes</h2></div></div><hr /></div><p>So far, we have <a id="id222" class="indexterm"></a>been reading and writing simple types to the <a id="id223" class="indexterm"></a>database. Let's imagine that we want to add a <code class="literal">gender</code> column to our database. We will store the gender as an enumeration in our physicists database. Our table is now as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mysql&gt; CREATE TABLE physicists (</strong></span>
<span class="strong"><strong>        id INT(11) AUTO_INCREMENT PRIMARY KEY,</strong></span>
<span class="strong"><strong>        name VARCHAR(32) NOT NULL,</strong></span>
<span class="strong"><strong>        gender ENUM("Female", "Male") NOT NULL</strong></span>
<span class="strong"><strong>);</strong></span>
</pre></div><p>How can we represent genders in Scala? A good way of doing this is with an enumeration:</p><div class="informalexample"><pre class="programlisting">// Gender.scala

object Gender extends Enumeration {
  val Male = Value
  val Female = Value
}</pre></div><p>However, we now have a problem when deserializing objects from the database: JDBC has no built-in mechanism to convert from a SQL <code class="literal">ENUM</code> type to a Scala <code class="literal">Gender</code> type. We could achieve this by just converting manually every time we need to read gender information:</p><div class="informalexample"><pre class="programlisting">resultsStream.map { 
  rs =&gt; Gender.withName(rs.getString("gender")) 
}.toVector</pre></div><p>However, we would need to write this everywhere that we want to read the <code class="literal">gender</code> field. This goes against the DRY (don't repeat yourself) principle, leading to code that is difficult to maintain. If we decide to change the way gender is stored in the database, we would need to find every instance in the code where we read the <code class="literal">gender</code> field and change it.</p><p>A somewhat better <a id="id224" class="indexterm"></a>solution would be to add a <code class="literal">getGender</code> method <a id="id225" class="indexterm"></a>to the <code class="literal">ResultSet</code> class using the pimp my library idiom that we used extensively in this chapter. This solution is still not optimal. We are adding unnecessary specificity to <code class="literal">ResultSet</code>: it is now coupled to the structure of our databases.</p><p>We could create a subclass of <code class="literal">ResultSet</code> using inheritance, such as <code class="literal">PhysicistResultSet</code>, that can read the fields in a specific table. However, this approach is not composable: if we had another table that kept track of pets, with name, species, and gender fields, we would have to either reimplement the code for reading gender in a new <code class="literal">PetResultSet</code> or factor out a <code class="literal">GenderedResultSet</code> superclass. As the number of tables grows, the inheritance hierarchy would become unmanageable. A better approach would let us compose the functionality that we need. In particular, we want to decouple the process of extracting Scala objects from a result set from the code for iterating over a result set.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec39"></a>Type classes</h3></div></div></div><p>Scala provides an <a id="id226" class="indexterm"></a>elegant solution using <span class="emphasis"><em>type classes</em></span>. Type classes <a id="id227" class="indexterm"></a>are a very powerful arrow in the Scala architect's quiver. However, they can present a bit of a learning curve, especially as there is no direct equivalent in object-oriented programming.</p><p>Instead of presenting an abstract explanation, I will dive into an example: I will describe how we can leverage type classes to convert fields in a <code class="literal">ResultSet</code> to Scala types. The aim is to define a <code class="literal">read[T](field)</code> method on <code class="literal">ResultSet</code> that knows exactly how to deserialize to objects of type <code class="literal">T</code>. This method will replace and extend the <code class="literal">getXXX</code> methods in <code class="literal">ResultSet</code>:</p><div class="informalexample"><pre class="programlisting">// results is a ResultSet instance
val name = results.read[String]("name")
val gender = results.read[Gender.Value]("gender")</pre></div><p>We start by defining an abstract <code class="literal">SqlReader[T]</code> trait that exposes a <code class="literal">read</code> method to read a specific field from a <code class="literal">ResultSet</code> and return an instance of type <code class="literal">T</code>:</p><div class="informalexample"><pre class="programlisting">// SqlReader.scala

import java.sql._

trait SqlReader[T] {
  def read(results:ResultSet, field:String):T
}</pre></div><p>We now need to <a id="id228" class="indexterm"></a>provide a concrete implementation of <code class="literal">SqlReader[T]</code> for every <code class="literal">T</code> type that we want to read. Let's provide concrete implementations for the <code class="literal">Gender</code> and <code class="literal">String</code> fields. We will place the implementation in a <code class="literal">SqlReader</code> companion object:</p><div class="informalexample"><pre class="programlisting">// SqlReader.scala

object SqlReader {
  implicit object StringReader extends SqlReader[String] {
    def read(results:ResultSet, field:String):String =
      results.getString(field)
  }

  implicit object GenderReader extends SqlReader[Gender.Value] {
    def read(results:ResultSet, field:String):Gender.Value =
      Gender.withName(StringReader.read(results, field))
  }
}</pre></div><p>We could now use our <code class="literal">ReadableXXX</code> objects to read from a result set:</p><div class="informalexample"><pre class="programlisting">import SqlReader._
val name = StringReader.read(results, "name")
val gender = GenderReader.read(results, "gender")</pre></div><p>This is already somewhat better than using the following:</p><div class="informalexample"><pre class="programlisting">Gender.withName(results.getString("gender"))</pre></div><p>This is because the code to map from a <code class="literal">ResultSet</code> field to <code class="literal">Gender.Value</code> is centralized in a single place: <code class="literal">ReadableGender</code>. However, it would be great if we could tell Scala to use <code class="literal">ReadableGender</code> whenever it needs to read <code class="literal">Gender.Value</code>, and use <code class="literal">ReadableString</code> whenever it needs to read a String value. This is exactly what type classes do.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec40"></a>Coding against type classes</h3></div></div></div><p>We defined a <a id="id229" class="indexterm"></a>
<code class="literal">Readable[T]</code> interface that <a id="id230" class="indexterm"></a>abstracts how to read an object of type <code class="literal">T</code> from a field in a <code class="literal">ResultSet</code>. How do we tell Scala that it needs to use this <code class="literal">Readable</code> object to convert from the <code class="literal">ResultSet</code> fields to the appropriate Scala type?</p><p>The key is the <code class="literal">implicit</code> keyword that we used to prefix the <code class="literal">GenderReader</code> and <code class="literal">StringReader</code> object definitions. It lets us write:</p><div class="informalexample"><pre class="programlisting">implicitly[SqlReader[Gender.Value]].read(results, "gender")
implicitly[SqlReader[String]].read(results, "name")</pre></div><p>By writing <code class="literal">implicitly[SqlReader[T]]</code>, we are telling the Scala compiler to find a class (or an object) that extends <code class="literal">SqlReader[T]</code> that is marked for implicit use. Try this out by pasting the following in the command line, for instance:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; :paste</strong></span>

<span class="strong"><strong>import Implicits._ // Connection to RichConnection conversion</strong></span>
<span class="strong"><strong>SqlUtils.usingConnection("test") {</strong></span>
<span class="strong"><strong>  _.withQuery("select * from physicists") {</strong></span>
<span class="strong"><strong>    rs =&gt; {</strong></span>
<span class="strong"><strong>      rs.next() // advance to first record</strong></span>
<span class="strong"><strong>      implicitly[SqlReader[Gender.Value]].read(rs, "gender")</strong></span>
<span class="strong"><strong>    }</strong></span>
<span class="strong"><strong>  }</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>Of course, using <code class="literal">implicitly[SqlReader[T]]</code> everywhere is not particularly elegant. Let's use the pimp my library idiom to add a <code class="literal">read[T]</code> method to <code class="literal">ResultSet</code>. We first define a <code class="literal">RichResultSet</code> class that we can use to "pimp" the <code class="literal">ResultSet</code> class:</p><div class="informalexample"><pre class="programlisting">// RichResultSet.scala

import java.sql.ResultSet

class RichResultSet(val underlying:ResultSet) {
  def read[T : SqlReader](field:String):T = {
    implicitly[SqlReader[T]].read(underlying, field)
  }
}</pre></div><p>The only unfamiliar part of this should be the <code class="literal">read[T : SqlReader]</code> generic definition. We are stating here that <code class="literal">read</code> will accept any <code class="literal">T</code> type, provided an instance of <code class="literal">SqlReader[T]</code> exists. This is <a id="id231" class="indexterm"></a>called a <span class="emphasis"><em>context bound.</em></span>
</p><p>We must also add implicit methods to the <code class="literal">Implicits</code> object to convert from <code class="literal">ResultSet</code> to <code class="literal">RichResultSet</code>. You <a id="id232" class="indexterm"></a>should be familiar with this now, so I will not bore you with the details. You can now call <code class="literal">results.read[T](fieldName)</code> for any <code class="literal">T</code> for which you have a <code class="literal">SqlReader[T]</code> implicit object defined:</p><div class="informalexample"><pre class="programlisting">import Implicits._

SqlUtils.usingConnection("test") { connection =&gt;
  connection.withQuery("SELECT * FROM physicists") {
    results =&gt;
      val resultStream = SqlUtils.stream(results)
      resultStream.map { row =&gt; 
<span class="strong"><strong>        val name = row.read[String]("name")</strong></span>
<span class="strong"><strong>        val gender = row.read[Gender.Value]("gender")</strong></span>
        (name, gender)
      }.toVector
  }
}
//=&gt; Vector[(String, Gender.Value)] = Vector((Albert Einstein,Male), (Marie Curie,Female))</pre></div><p>Let's summarize the <a id="id233" class="indexterm"></a>steps needed for type classes to work. We will do this in the context of deserializing from SQL, but you will be able to adapt these steps to solve other problems:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Define an abstract generic trait that provides the interface for the type class, for example, <code class="literal">SqlReader[T]</code>. Any functionality that is independent of <code class="literal">T</code> can be added to this base trait.</p></li><li style="list-style-type: disc"><p>Create the companion object for the base trait and add implicit objects extending the trait for each <code class="literal">T</code>, for example,</p><div class="informalexample"><pre class="programlisting">implicit object <code class="literal">StringReader</code> extends <code class="literal">SqlReader[T]</code>.</pre></div></li><li style="list-style-type: disc"><p>Type classes are always used in generic methods. A method that relies on the existence of a type class for an argument must contain a context bound in the generic definition, for example, <code class="literal">def read[T : SqlReader](field:String):T</code>. To access the type class in this method, use the <code class="literal">implicitly</code> keyword: <code class="literal">implicitly[SqlReader[T]]</code>.</p></li></ul></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec41"></a>When to use type classes</h3></div></div></div><p>Type classes <a id="id234" class="indexterm"></a>are useful when you need a particular behavior for many different types, but exactly how this behavior is implemented varies between these types. For instance, we need to be able to read several different types from <code class="literal">ResultSet</code>, but exactly how each type is read differs between types: for strings, we must read from <code class="literal">ResultSet</code> using <code class="literal">getString</code>, whereas for integers, we must use <code class="literal">getInt</code> followed by <code class="literal">wasNull</code>.</p><p>A good rule of <a id="id235" class="indexterm"></a>thumb is when you start thinking "Oh, I could just write a generic method to do this. Ah, but wait, I will have to write the <code class="literal">Int</code> implementation as a specific edge case as it behaves differently. Oh, and the <code class="literal">Gender</code> implementation. I wonder if there's a better way?", then type classes might be useful.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec42"></a>Benefits of type classes</h3></div></div></div><p>Data scientists <a id="id236" class="indexterm"></a>frequently have to deal with new input streams, changing requirements, and new data types. Having an object-relational mapping layer <a id="id237" class="indexterm"></a>that is easy to extend or alter is therefore critical to responding to changes efficiently. Minimizing coupling between code entities and separation of concerns are the only ways to ensure that the code can be changed in response to new data.</p><p>With type classes, we maintain orthogonality between accessing records in the database (through the <code class="literal">ResultSet</code> class) and how individual fields are transformed to Scala objects: both can vary independently. The only coupling between these two concerns is through the <code class="literal">SqlReader[T]</code> interface.</p><p>This means that both concerns can evolve independently: to read a new data type, we just need to implement a <code class="literal">SqlReader[T]</code> object. Conversely, we can add functionality to <code class="literal">ResultSet</code> without needing to reimplement how fields are converted. For instance, we could add a <code class="literal">getColumn</code> method that returns a <code class="literal">Vector[T]</code> of all the values of a field in a <code class="literal">ResultSet</code> instance:</p><div class="informalexample"><pre class="programlisting">def getColumn[T : SqlReader](field:String):Vector[T] = {
  val resultStream = SqlUtils.stream(results)
  resultStream.map { _.read[T](field) }.toVector
}</pre></div><p>Note how we could do this without increasing the coupling to the way in which individual fields are read.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec44"></a>Creating a data access layer</h2></div></div><hr /></div><p>Let's bring together <a id="id238" class="indexterm"></a>everything that we have seen and build a <span class="emphasis"><em>data-mapper</em></span> class for fetching <code class="literal">Physicist</code> objects from the database. These classes (also called <span class="emphasis"><em>data access objects</em></span>) are useful to decouple the internal representation of an object from its representation in the database.</p><p>We start by defining the <code class="literal">Physicist</code> class:</p><div class="informalexample"><pre class="programlisting">// Physicist.scala
case class Physicist(
  val name:String,
  val gender:Gender.Value
)</pre></div><p>The data access object <a id="id239" class="indexterm"></a>will expose a single method, <code class="literal">readAll</code>, that returns a <code class="literal">Vector[Physicist]</code> of all the physicists in our database:</p><div class="informalexample"><pre class="programlisting">// PhysicistDao.scala

import java.sql.{ ResultSet, Connection }
import Implicits._ // implicit conversions

object PhysicistDao {

  /* Helper method for reading a single row */
  private def readFromResultSet(results:ResultSet):Physicist = {
    Physicist(
      results.read[String]("name"),
      results.read[Gender.Value]("gender")
    )
  }

  /* Read the entire 'physicists' table. */
  def readAll(connection:Connection):Vector[Physicist] = {
    connection.withQuery("SELECT * FROM physicists") {
      results =&gt;
        val resultStream = SqlUtils.stream(results)
        resultStream.map(readFromResultSet).toVector
    }
  }
}</pre></div><p>The data access layer can be used by client code as in the following example:</p><div class="informalexample"><pre class="programlisting">object PhysicistDaoDemo extends App {

  val physicists = SqlUtils.usingConnection("test") {
    connection =&gt; PhysicistDao.readAll(connection)
  }

  // physicists is a Vector[Physicist] instance.
  physicists.foreach { println }
  //=&gt; Physicist(Albert Einstein,Male)
  //=&gt; Physicist(Marie Curie,Female)
}</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec45"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we learned how to interact with SQL databases using JDBC. We wrote a library to wrap native JDBC objects, aiming to give them a more functional interface.</p><p>In the next chapter, you will learn about Slick, a Scala library that provides functional wrappers to interact with relational databases.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec46"></a>References</h2></div></div><hr /></div><p>The API <a id="id240" class="indexterm"></a>documentation for JDBC is very complete: <a class="ulink" href="http://docs.oracle.com/javase/7/docs/api/java/sql/package-summary.html" target="_blank">http://docs.oracle.com/javase/7/docs/api/java/sql/package-summary.html</a>
</p><p>The <a id="id241" class="indexterm"></a>API documentation for the <code class="literal">ResultSet</code> interface (<a class="ulink" href="http://docs.oracle.com/javase/7/docs/api/java/sql/ResultSet.html" target="_blank">http://docs.oracle.com/javase/7/docs/api/java/sql/ResultSet.html</a>), for the <a id="id242" class="indexterm"></a>
<code class="literal">PreparedStatement</code> class (<a class="ulink" href="http://docs.oracle.com/javase/7/docs/api/java/sql/PreparedStatement.html" target="_blank">http://docs.oracle.com/javase/7/docs/api/java/sql/PreparedStatement.html</a>) and the <a id="id243" class="indexterm"></a>
<code class="literal">Connection</code> class (<a class="ulink" href="http://docs.oracle.com/javase/7/docs/api/java/sql/Connection.html" target="_blank">http://docs.oracle.com/javase/7/docs/api/java/sql/Connection.html</a>) is particularly relevant.</p><p>The data mapper <a id="id244" class="indexterm"></a>pattern is described extensively in Martin Fowler's <span class="emphasis"><em>Patterns of Enterprise Application Architecture</em></span>. A brief description is also available on his website (<a class="ulink" href="http://martinfowler.com/eaaCatalog/dataMapper.html" target="_blank">http://martinfowler.com/eaaCatalog/dataMapper.html</a>).</p><p>For an introduction to SQL, I suggest <span class="emphasis"><em>Learning SQL</em></span> by <span class="emphasis"><em>Alan Beaulieu</em></span> (<span class="emphasis"><em>O'Reilly</em></span>).</p><p>For another <a id="id245" class="indexterm"></a>discussion of type classes, read <a class="ulink" href="http://danielwestheide.com/blog/2013/02/06/the-neophytes-guide-to-scala-part-12-type-classes.html" target="_blank">http://danielwestheide.com/blog/2013/02/06/the-neophytes-guide-to-scala-part-12-type-classes.html</a>.</p><p>This post describes how some common object-oriented design patterns can be reimplemented more <a id="id246" class="indexterm"></a>elegantly in Scala using type classes:</p><p>
<a class="ulink" href="https://staticallytyped.wordpress.com/2013/03/24/gang-of-four-patterns-with-type-classes-and-implicits-in-scala-part-2/" target="_blank">https://staticallytyped.wordpress.com/2013/03/24/gang-of-four-patterns-with-type-classes-and-implicits-in-scala-part-2/</a>
</p><p>This post by <span class="emphasis"><em>Martin Odersky</em></span> <a id="id247" class="indexterm"></a>details the <span class="emphasis"><em>Pimp my Library</em></span> pattern:</p><p>
<a class="ulink" href="http://www.artima.com/weblogs/viewpost.jsp?thread=179766" target="_blank">http://www.artima.com/weblogs/viewpost.jsp?thread=179766</a>
</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch06"></a>ChapterÂ 6.Â Slick â€“ A Functional Interface for SQL</h2></div></div></div><p>In <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Scala and SQL through JDBC</em></span>, we investigated how to access SQL databases with JDBC. As interacting with JDBC feels somewhat unnatural, we extended JDBC using custom wrappers. The wrappers were developed to provide a functional interface to hide the imperative nature of JDBC.</p><p>With the difficulty of interacting directly with JDBC from Scala and the ubiquity of SQL databases, you would expect there to be existing Scala libraries that wrap JDBC. <span class="emphasis"><em>Slick</em></span> is such a library.</p><p>Slick styles itself as a <span class="emphasis"><em>functional-relational mapping</em></span> library, a play on the more traditional <span class="emphasis"><em>object-relational mapping</em></span> name used to denote libraries that build objects from relational databases. It presents a functional interface to SQL databases, allowing the client to interact with them in a manner similar to native Scala collections.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec47"></a>FEC data</h2></div></div><hr /></div><p>In this chapter, we <a id="id248" class="indexterm"></a>will use a somewhat more involved example dataset. The <span class="strong"><strong>Federal Electoral Commission of the United </strong></span>
<a id="id249" class="indexterm"></a>
<span class="strong"><strong>States</strong></span> (<span class="strong"><strong>FEC</strong></span>) records all donations to presidential candidates greater than $200. These records are publicly available. We will look at the donations for the campaign leading up to the 2012 general elections that resulted in Barack Obama's re-election. The data includes donations to the two presidential candidates, Obama and Romney, and also to the other contenders in the Republican primaries (there were no Democrat primaries).</p><p>In this chapter, we will take the transaction data provided by the FEC, store it in a table, and learn how to query and analyze it.</p><p>The first step is to acquire the data. If you have downloaded the code samples from the Packt website, you should already have two CSVs in the <code class="literal">data</code> directory of the code samples for this chapter. If not, you can download the files using the following links:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">data.scala4datascience.com/fec/ohio.csv.gz</code> (or <code class="literal">ohio.csv.zip</code>)</p></li><li style="list-style-type: disc"><p>
<code class="literal">data.scala4datascience.com/fec/us.csv.gz</code> (or <code class="literal">us.csv.zip</code>)</p></li></ul></div><p>Decompress the two files and place them in a directory called <code class="literal">data/</code> in the same location as the source code examples for this chapter. The data files correspond to the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The <code class="literal">ohio.csv</code> file is a CSV of all the donations made by donors in Ohio.</p></li><li style="list-style-type: disc"><p>The <code class="literal">us.csv</code> file is a CSV of all the donations made by donors across the country. This is quite a large file, with six million rows.</p></li></ul></div><p>The two CSV <a id="id250" class="indexterm"></a>files contain identical columns. Use the Ohio dataset for more responsive behavior, or the nationwide data file if you want to wrestle with a larger dataset. The dataset is adapted from a list of contributions <a id="id251" class="indexterm"></a>downloaded from <a class="ulink" href="http://www.fec.gov/disclosurep/PDownload.do" target="_blank">http://www.fec.gov/disclosurep/PDownload.do</a>.</p><p>Let's start by creating a Scala case class to represent a transaction. In the context of this chapter, a transaction is a single donation from an individual to a candidate:</p><div class="informalexample"><pre class="programlisting">// Transaction.scala
import java.sql.Date

case class Transaction(
  id:Option[Int], // unique identifier
  candidate:String, // candidate receiving the donation
  contributor:String, // name of the contributor
  contributorState:String, // contributor state
  contributorOccupation:Option[String], // contributor job
  amount:Long, // amount in cents
  date:Date // date of the donation
)</pre></div><p>The code repository for this chapter includes helper functions in an <code class="literal">FECData</code> singleton object to load the data from CSVs:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val ohioData = FECData.loadOhio</strong></span>
<span class="strong"><strong>s4ds.FECData = s4ds.FECData@718454de</strong></span>
</pre></div><p>Calling <code class="literal">FECData.loadOhio</code> or <code class="literal">FECData.loadAll</code> will create an <code class="literal">FECData</code> object with a single attribute, <code class="literal">transactions</code>, which is an iterator over all the donations coming from Ohio or the entire United States:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val ohioTransactions = ohioData.transactions</strong></span>
<span class="strong"><strong>Iterator[Transaction] = non-empty iterator</strong></span>

<span class="strong"><strong>scala&gt; ohioTransactions.take(5).foreach(println)</strong></span>
<span class="strong"><strong>Transaction(None,Paul, Ron,BROWN, TODD W MR.,OH,Some(ENGINEER),5000,2011-01-03)</strong></span>
<span class="strong"><strong>Transaction(None,Paul, Ron,DIEHL, MARGO SONJA,OH,Some(RETIRED),2500,2011-01-03)</strong></span>
<span class="strong"><strong>Transaction(None,Paul, Ron,KIRCHMEYER, BENJAMIN,OH,Some(COMPUTER PROGRAMMER),20120,2011-01-03)</strong></span>
<span class="strong"><strong>Transaction(None,Obama, Barack,KEYES, STEPHEN,OH,Some(HR EXECUTIVE / ATTORNEY),10000,2011-01-03)</strong></span>
<span class="strong"><strong>Transaction(None,Obama, Barack,MURPHY, MIKE W,OH,Some(MANAGER),5000,2011-01-03)</strong></span>
</pre></div><p>Now that <a id="id252" class="indexterm"></a>we have some data to play with, let's try <a id="id253" class="indexterm"></a>and put it in the database so that we can run some useful queries on it.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec43"></a>Importing Slick</h3></div></div></div><p>To add Slick to <a id="id254" class="indexterm"></a>the list of dependencies, you will need to add <code class="literal">"com.typesafe.slick" %% "slick" % "2.1.0"</code> to the list of dependencies in your <code class="literal">build.sbt</code> file. You will also need to make sure that Slick has access to a JDBC driver. In this <a id="id255" class="indexterm"></a>chapter, we will connect to a MySQL database, and must, therefore, add the MySQL connector <code class="literal">"mysql" % "mysql-connector-java" % "5.1.37"</code> to the list of dependencies.</p><p>Slick is imported by importing a specific database driver. As we are using MySQL, we must import the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import slick.driver.MySQLDriver.simple._</strong></span>
<span class="strong"><strong>import slick.driver.MySQLDriver.simple._</strong></span>
</pre></div><p>To connect to a different flavor of SQL database, import the relevant driver. The easiest way of seeing what <a id="id256" class="indexterm"></a>drivers are available is to consult the API documentation for the <code class="literal">slick.driver</code> package, which is available at <a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.driver.package" target="_blank">http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.driver.package</a>. All the common SQL flavors are supported (including <span class="strong"><strong>H2</strong></span>, <span class="strong"><strong>PostgreSQL</strong></span>, <span class="strong"><strong>MS SQL Server</strong></span>, and <span class="strong"><strong>SQLite</strong></span>).</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec44"></a>Defining the schema</h3></div></div></div><p>Let's create a <a id="id257" class="indexterm"></a>table to represent our transactions. We will use the <a id="id258" class="indexterm"></a>following schema:</p><div class="informalexample"><pre class="programlisting">CREATE TABLE transactions(
    id INT(11) AUTO_INCREMENT PRIMARY KEY,
    candidate VARCHAR(254) NOT NULL,
    contributor VARCHAR(254) NOT NULL,
    contributor_state VARCHAR(2) NOT NULL,
    contributor_occupation VARCHAR(254),
    amount BIGINT(20) NOT NULL,
    date DATE 
);</pre></div><p>Note that the donation amount is in <span class="emphasis"><em>cents</em></span>. This allows us to use an integer field (rather than a fixed point decimal, or worse, a float).</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note03"></a>Note</h3><p>You should never use a floating point format to represent money or, in fact, any discrete quantity because floats cannot represent most fractions exactly:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; 0.1 + 0.2</strong></span>
<span class="strong"><strong>Double = 0.30000000000000004</strong></span>
</pre></div><p>This seemingly nonsensical result occurs because there is no way to store 0.3 exactly in doubles.</p><p>This post gives an <a id="id259" class="indexterm"></a>extensive discussion of the limitations of the floating point format:</p><p>
<a class="ulink" href="http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html" target="_blank">http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html</a>
</p></div><p>To use Slick with tables in our database, we first need to tell Slick about the database schema. We do this by creating a class that extends the <code class="literal">Table</code> abstract class. The way in which a schema is defined is quite straightforward, so let's dive straight into the code. We will store our schema in a <code class="literal">Tables</code> singleton. We define a <code class="literal">Transactions</code> class that provides the mapping to go from collections of <code class="literal">Transaction</code> instances to SQL tables structured like the <code class="literal">transactions</code> table:</p><div class="informalexample"><pre class="programlisting">// Tables.scala

import java.sql.Date
import slick.driver.MySQLDriver.simple._

/** Singleton object for table definitions */
object Tables {

  // Transactions table definition
  class Transactions(tag:Tag)
  extends Table[Transaction](tag, "transactions") {
    def id = column[Int]("id", O.PrimaryKey, O.AutoInc)
    def candidate = column[String]("candidate")
    def contributor = column[String]("contributor")
    def contributorState = column[String](
      "contributor_state", O.DBType("VARCHAR(2)"))
    def contributorOccupation = column[Option[String]](
      "contributor_occupation")
    def amount = column[Long]("amount")
    def date = column[Date]("date")

    def * = (id.?, candidate, contributor, 
      contributorState, contributorOccupation, amount, date) &lt;&gt; (
      Transaction.tupled, Transaction.unapply)
  }

  val transactions = TableQuery[Transactions]

}</pre></div><p>Let's go <a id="id260" class="indexterm"></a>through this line by line. We first define a <code class="literal">Transactions</code> class, which must take a Slick <code class="literal">Tag</code> object as its first argument. The <code class="literal">Tag</code> object is <a id="id261" class="indexterm"></a>used by Slick internally to construct SQL statements. The <code class="literal">Transactions</code> class extends a <code class="literal">Table</code> object, passing it the tag and name of the table in the database. We could, optionally, have added a database name by extending <code class="literal">Table[Transaction](tag, Some("fec"), "transactions")</code> rather than just <code class="literal">Table[Transaction](tag, "transactions")</code>. The <code class="literal">Table</code> type is parametrized by <code class="literal">Transaction</code>. This means that running <code class="literal">SELECT</code> statements on the database returns <code class="literal">Transaction</code> objects. Similarly, we will insert data into the database by passing a transaction or list of transactions to the relevant Slick methods.</p><p>Let's look at the <code class="literal">Transactions</code> class definition in more detail. The body of the class starts by listing the database columns. For instance, the <code class="literal">id</code> column is defined as follows:</p><div class="informalexample"><pre class="programlisting">def id = column[Int]("id", O.PrimaryKey, O.AutoInc)</pre></div><p>We tell Slick that it should read the column called <code class="literal">id</code> and transform it to a Scala integer. Additionally, we tell Slick that this column is the primary key and that it is auto-incrementing. The Slick documentation contains a list of available options for <code class="literal">column</code>.</p><p>The <code class="literal">candidate</code> and <code class="literal">contributor</code> columns are straightforward: we tell Slick to read these as <code class="literal">String</code> from the database. The <code class="literal">contributor_state</code> column is a little more interesting. Besides specifying that it should be read from the database as a <code class="literal">String</code>, we also tell Slick that it should be stored in the database with type <code class="literal">VARCHAR(2)</code>.</p><p>The <a id="id262" class="indexterm"></a>
<code class="literal">contributor_occupation</code> column in our table can contain <code class="literal">NULL</code> values. When defining the schema, we pass the <code class="literal">Option[String]</code> type to the column method:</p><div class="informalexample"><pre class="programlisting">def contributorOccupation = column[<span class="strong"><strong>Option[String]</strong></span>]("contributor_occupation")</pre></div><p>When reading from the database, a <code class="literal">NULL</code> field will get converted to <code class="literal">None</code> for columns specified as <code class="literal">Option[T]</code>. Conversely, if the field has a value, it will be returned as <code class="literal">Some(value)</code>.</p><p>The last line of the class body is the most interesting part: it specifies how to transform the raw data read from the database into a <code class="literal">Transaction</code> object and how to convert a <code class="literal">Transaction</code> object to raw fields ready for insertion:</p><div class="informalexample"><pre class="programlisting">def * = (id.?, candidate, contributor, 
contributorState, contributorOccupation, amount, date) &lt;&gt; (
Transaction.tupled, Transaction.unapply)</pre></div><p>The first part is just a tuple of fields to be read from the database: <code class="literal">(id.?, candidate, contributor, contributorState, contributorOccupation, amount, date)</code>, with a small amount of metadata. The second part is a pair of functions that describe how to transform this tuple into a <code class="literal">Transaction</code> object and back. In this case, as <code class="literal">Transaction</code> is a case class, we can take advantage of the <code class="literal">Transaction.tupled</code> and <code class="literal">Transaction.unapply</code> methods automatically provided for case classes.</p><p>Notice how we followed the <code class="literal">id</code> entry with <code class="literal">.?</code>. In our <code class="literal">Transaction</code> class, the donation <code class="literal">id</code> has the <code class="literal">Option[Int]</code> type, but the column in the database has the <code class="literal">INT</code> type with the additional <code class="literal">O.AutoInc</code> option. The <code class="literal">.?</code> suffix tells Slick to use the default value provided by the database (in this case, the database's auto-increment) if <code class="literal">id</code> is <code class="literal">None</code>.</p><p>Finally, we define the value:</p><div class="informalexample"><pre class="programlisting">val transactions = TableQuery[Transactions]</pre></div><p>This is the handle that we use to actually interact with the database. For instance, as we will see later, to get a list of donations to Barack Obama, we run the following query (don't worry about the details of the query for now):</p><div class="informalexample"><pre class="programlisting">Tables.<span class="strong"><strong>transactions</strong></span>.filter {_.candidate === "Obama, Barack"}.list</pre></div><p>Let's summarize the parts of our <code class="literal">Transactions</code> mapper class:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The <code class="literal">Transactions</code> class must extend the <code class="literal">Table</code> abstract class parametrized by the type that we want to return: <code class="literal">Table[Transaction]</code>.</p></li><li style="list-style-type: disc"><p>We <a id="id263" class="indexterm"></a>define the columns to read from the database explicitly using <code class="literal">column</code>, for example, <code class="literal">def contributorState = column[String]("contributor_state", O.DBType("VARCHAR(2)"))</code>. The <code class="literal">[String]</code> type parameter defines the Scala type that this column gets read as. The first argument is the SQL column name. Consult the Slick documentation <a id="id264" class="indexterm"></a>for a full list of additional arguments (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/schemas.html" target="_blank">http://slick.typesafe.com/doc/2.1.0/schemas.html</a>).</p></li><li style="list-style-type: disc"><p>We describe how to convert from a tuple of the column values to a Scala object and vice versa using <code class="literal">def * = (id.?, candidate, ...) &lt;&gt; (Transaction.tupled, Transaction.unapply)</code>.</p></li></ul></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec45"></a>Connecting to the database</h3></div></div></div><p>So <a id="id265" class="indexterm"></a>far, you have learned how to define <code class="literal">Table</code> classes that encode the transformation from rows in a SQL table to Scala case classes. To move beyond table definitions and start interacting with a database server, we must connect to a database. As in the previous chapter, we will assume that there is a MySQL server running on localhost on port <code class="literal">3306</code>.</p><p>We will use the console to demonstrate the functionality in this chapter, but you can find an equivalent sample program in <code class="literal">SlickDemo.scala</code>. Let's open a Scala console and connect to the database running on port <code class="literal">3306</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import slick.driver.MySQLDriver.simple._</strong></span>
<span class="strong"><strong>import slick.driver.MySQLDriver.simple._</strong></span>

<span class="strong"><strong>scala&gt; val db = Database.forURL(</strong></span>
<span class="strong"><strong>  "jdbc:mysql://127.0.0.1:3306/test",</strong></span>
<span class="strong"><strong>  driver="com.mysql.jdbc.Driver"</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>db: slick.driver.MySQLDriver.backend.DatabaseDef = slick.jdbc.JdbcBackend$DatabaseDef@3632d1dd</strong></span>
</pre></div><p>If you have read the previous chapter, you will recognize the first argument as a JDBC-style URL. The URL starts by defining a protocol, in this case, <code class="literal">jdbc:mysql</code>, followed by the IP address and port of the database server, followed by the database name (<code class="literal">test</code>, here).</p><p>The second argument to <code class="literal">forURL</code> is the class name of the JDBC driver. This driver is imported at runtime using reflection. Note that the driver specified here must match the Slick driver imported statically.</p><p>Having defined the database, we can now use it to create a connection:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  // do something useful with the database</strong></span>
<span class="strong"><strong>  println(session)</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>scala.slick.jdbc.JdbcBackend$BaseSession@af5a276</strong></span>
</pre></div><p>Slick functions that require access to the database take a <code class="literal">Session</code> argument implicitly: if a <code class="literal">Session</code> instance marked as implicit is available in scope, they will use it. Thus, preceding <code class="literal">session</code> with the <code class="literal">implicit</code> keyword saves us having to pass <code class="literal">session</code> explicitly every time we run an operation on the database.</p><p>If you <a id="id266" class="indexterm"></a>have read the previous chapter, you will recognize that Slick deals with the need to close connections with the <span class="emphasis"><em>loan pattern</em></span>: a database connection is created in the form of a <code class="literal">session</code> object and passed temporarily to the client. When the client code returns, the session is closed, ensuring that all opened connections are closed. The client code is therefore spared the responsibility of closing the connection.</p><p>The loan pattern is very useful in production code, but it can be somewhat cumbersome in the shell. Slick lets us create a session explicitly as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; implicit val session = db.createSession</strong></span>
<span class="strong"><strong>session: slick.driver.MySQLDriver.backend.Session = scala.slick.jdbc.JdbcBackend$BaseSession@2b775b49</strong></span>

<span class="strong"><strong>scala&gt; session.close</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec46"></a>Creating tables</h3></div></div></div><p>Let's <a id="id267" class="indexterm"></a>use our new connection to create the transaction table in the database. We can access methods to create and drop tables using the <code class="literal">ddl</code> attribute on our <code class="literal">TableQuery[Transactions]</code> instance:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  Tables.transactions.ddl.create</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>If you jump into a <code class="literal">mysql</code> shell, you will see that a <code class="literal">transactions</code> table has been created:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mysql&gt; describe transactions ;</strong></span>
<span class="strong"><strong>+------------------------+--------------+------+-----+</strong></span>
<span class="strong"><strong>| Field                  | Type         | Null | Key |</strong></span>
<span class="strong"><strong>+------------------------+--------------+------+-----+</strong></span>
<span class="strong"><strong>| id                     | int(11)      | NO   | PRI |</strong></span>
<span class="strong"><strong>| candidate              | varchar(254) | NO   |     |</strong></span>
<span class="strong"><strong>| contributor            | varchar(254) | NO   |     |</strong></span>
<span class="strong"><strong>| contributor_state      | varchar(2)   | NO   |     |</strong></span>
<span class="strong"><strong>| contributor_occupation | varchar(254) | YES  |     |</strong></span>
<span class="strong"><strong>| amount                 | bigint(20)   | NO   |     |</strong></span>
<span class="strong"><strong>| date                   | date         | NO   |     |</strong></span>
<span class="strong"><strong>+------------------------+--------------+------+-----+</strong></span>
<span class="strong"><strong>7 rows in set (0.01 sec)</strong></span>
</pre></div><p>The <code class="literal">ddl</code> <a id="id268" class="indexterm"></a>attribute also includes a <code class="literal">drop</code> method to drop the table. Incidentally, <code class="literal">ddl</code> stands for "data-definition language" and is commonly used to refer to the parts of SQL relevant to schema and constraint definitions.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec47"></a>Inserting data</h3></div></div></div><p>Slick <a id="id269" class="indexterm"></a>
<code class="literal">TableQuery</code> instances let us interact with SQL tables with an interface similar to Scala collections.</p><p>Let's create a transaction first. We will pretend that a donation occurred on the 22nd of June, 2010. Unfortunately, the code to create dates in Scala and pass these to JDBC is particularly clunky. We first create a <code class="literal">java.util.Date</code> instance, which we must then convert to a <code class="literal">java.sql.Date</code> to use in our newly created transaction:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import java.text.SimpleDateFormat</strong></span>
<span class="strong"><strong>import java.text.SimpleDateFormat</strong></span>

<span class="strong"><strong>scala&gt; val date = new SimpleDateFormat("dd-MM-yyyy").parse("22-06-2010")</strong></span>
<span class="strong"><strong>date: java.util.Date = Tue Jun 22 00:00:00 BST 2010</strong></span>

<span class="strong"><strong>scala&gt; val sqlDate = new java.sql.Date(date.getTime())</strong></span>
<span class="strong"><strong>sqlDate: java.sql.Date = 2010-06-22</strong></span>

<span class="strong"><strong>scala&gt; val transaction = Transaction(</strong></span>
<span class="strong"><strong>  None, "Obama, Barack", "Doe, John", "TX", None, 200, sqlDate</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>transaction: Transaction = Transaction(None,Obama, Barack,Doe, John,TX,None,200,2010-06-22)</strong></span>
</pre></div><p>Much of the interface provided by the <code class="literal">TableQuery</code> instance mirrors that of a mutable list. To insert a single row in the transaction table, we can use the <code class="literal">+=</code> operator:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession {</strong></span>
<span class="strong"><strong>  implicit session =&gt; Tables.transactions += transaction</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>Int = 1</strong></span>
</pre></div><p>Under the <a id="id270" class="indexterm"></a>hood, this will create a JDBC prepared statement and run this statement's <code class="literal">executeUpdate</code> method.</p><p>If you are committing many rows at a time, you should use Slick's bulk insert operator: <code class="literal">++=</code>. This takes a <code class="literal">List[Transaction]</code> as input and inserts all the transactions in a single batch by taking advantage of JDBC's <code class="literal">addBatch</code> and <code class="literal">executeBatch</code> functionality.</p><p>Let's insert all the FEC transactions so that we have some data to play with when running queries in the next section. We can load an iterator of transactions for Ohio by calling the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val transactions = FECData.loadOhio.transactions</strong></span>
<span class="strong"><strong>transactions: Iterator[Transaction] = non-empty iterator</strong></span>
</pre></div><p>We can also load the transactions for the whole of United States:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val transactions = FECData.loadAll.transactions</strong></span>
<span class="strong"><strong>transactions: Iterator[Transaction] = non-empty iterator</strong></span>
</pre></div><p>To avoid materializing all the transactions in a single fell swoopâ€”thus potentially exceeding our computer's available memoryâ€”we will take batches of transactions from the iterator and insert them:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val batchSize = 100000</strong></span>
<span class="strong"><strong>batchSize: Int = 100000</strong></span>

<span class="strong"><strong>scala&gt; val transactionBatches = transactions.grouped(batchSize)</strong></span>
<span class="strong"><strong>transactionBatches: transactions.GroupedIterator[Transaction] = non-empty iterator</strong></span>
</pre></div><p>An iterator's <code class="literal">grouped</code> method splits the iterator into batches. It is useful to split a long collection or iterator into manageable batches that can be processed one after the other. This is important when integrating or processing large datasets.</p><p>All that we have to do now is iterate over our batches, inserting them into the database as we go:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  transactionBatches.foreach { </strong></span>
<span class="strong"><strong>    batch =&gt; Tables.transactions ++= batch.toList</strong></span>
<span class="strong"><strong>  }</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>While this works, it is sometimes useful to see progress reports when doing long-running integration processes. As we have split the integration into batches, we know (to the nearest batch) how far into the integration we are. Let's print the progress information at the beginning <a id="id271" class="indexterm"></a>of every batch:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  transactionBatches.zipWithIndex.foreach { </strong></span>
<span class="strong"><strong>    case (batch, batchNumber) =&gt;</strong></span>
<span class="strong"><strong>      println(s"Processing row ${batchNumber*batchSize}")</strong></span>
<span class="strong"><strong>      Tables.transactions ++= batch.toList</strong></span>
<span class="strong"><strong>  }</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>Processing row 0</strong></span>
<span class="strong"><strong>Processing row 100000</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>We use the <code class="literal">.zipWithIndex</code> method to transform our iterator over batches into an iterator of (<span class="emphasis"><em>batch</em></span>, <span class="emphasis"><em>current</em></span>
<code class="literal"> </code>
<span class="emphasis"><em>index</em></span>) pairs. In a full-scale application, the progress information would probably be written to a log file rather than to the screen.</p><p>Slick's well-designed interface makes inserting data very intuitive, integrating well with native Scala types.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec48"></a>Querying data</h3></div></div></div><p>In the <a id="id272" class="indexterm"></a>previous section, we used Slick to insert donation data into our database. Let's explore this data now.</p><p>When defining the <code class="literal">Transactions</code> class, we defined a <code class="literal">TableQuery</code> object, <code class="literal">transactions</code>, that acts as the handle for accessing the transaction table. It exposes an interface similar to Scala iterators. For instance, to see the first five elements in our database, we can call <code class="literal">take(5)</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  Tables.transactions.take(5).list</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[Tables.Transactions#TableElementType] = List(Transaction(Some(1),Obama, Barack,Doe, ...</strong></span>
</pre></div><p>Internally, Slick implements the <code class="literal">.take</code> method using a SQL <code class="literal">LIMIT</code>. We can, in fact, get the SQL statement using the <code class="literal">.selectStatement</code> method on the query:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  println(Tables.transactions.take(5).selectStatement)</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>select x2.`id`, x2.`candidate`, x2.`contributor`, x2.`contributor_state`, x2.`contributor_occupation`, x2.`amount`, x2.`date` from (select x3.`date` as `date`, x3.`contributor` as `contributor`, x3.`amount` as `amount`, x3.`id` as `id`, x3.`candidate` as `candidate`, x3.`contributor_state` as `contributor_state`, x3.`contributor_occupation` as `contributor_occupation` from `transactions` x3 limit 5) x2</strong></span>
</pre></div><p>Our Slick <a id="id273" class="indexterm"></a>query is made up of the following two parts:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">.take(n)</code>: This part is called the <span class="emphasis"><em>invoker</em></span>. Invokers build up the SQL statement but do not actually fire it to the database. You can chain many invokers together to build complex SQL statements.</p></li><li style="list-style-type: disc"><p>
<code class="literal">.list</code>: This part sends the statement prepared by the invoker to the database and converts the result to Scala object. This takes a <code class="literal">session</code> argument, possibly implicitly.</p></li></ul></div></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec48"></a>Invokers</h2></div></div><hr /></div><p>
<span class="strong"><strong>Invokers</strong></span> are the <a id="id274" class="indexterm"></a>components of a Slick query that build up the SQL select statement. Slick exposes a variety of invokers that allow the construction of complex queries. Let's look at some of these invokers here:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The <code class="literal">map</code> invoker is useful to select individual columns or apply operations to columns:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  Tables.transactions.map {</strong></span>
<span class="strong"><strong>    _.candidate </strong></span>
<span class="strong"><strong>  }.take(5).list       </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[String] = List(Obama, Barack, Paul, Ron, Paul, Ron, Paul, Ron, Obama, Barack)</strong></span>
</pre></div></li><li style="list-style-type: disc"><p>The <code class="literal">filter</code> invoker is the equivalent of the <code class="literal">WHERE</code> statements in SQL. Note that Slick fields must be compared using <code class="literal">===</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt; </strong></span>
<span class="strong"><strong>  Tables.transactions.filter {</strong></span>
<span class="strong"><strong>    _.candidate === "Obama, Barack"</strong></span>
<span class="strong"><strong>  }.take(5).list</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[Tables.Transactions#TableElementType] = List(Transaction(Some(1),Obama, Barack,Doe, John,TX,None,200,2010-06-22), ...</strong></span>
</pre></div><p>Similarly, to filter out donations to Barack Obama, use the <code class="literal">=!=</code> operator:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;   </strong></span>
<span class="strong"><strong>  Tables.transactions.filter { </strong></span>
<span class="strong"><strong>    _.candidate =!= "Obama, Barack"</strong></span>
<span class="strong"><strong>  }.take(5).list</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[Tables.Transactions#TableElementType] = List(Transaction(Some(2),Paul, Ron,BROWN, TODD W MR.,OH,...</strong></span>
</pre></div></li><li style="list-style-type: disc"><p>The <code class="literal">sortBy</code> <a id="id275" class="indexterm"></a>invoker is the equivalent of the <code class="literal">ORDER BY</code> statement in SQL:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;     </strong></span>
<span class="strong"><strong>  Tables.transactions.sortBy { </strong></span>
<span class="strong"><strong>    _.date.desc </strong></span>
<span class="strong"><strong>  }.take(5).list</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[Tables.Transactions#TableElementType] = List(Transaction(Some(65536),Obama, Barack,COPELAND, THOMAS,OH,Some(COLLEGE TEACHING),10000,2012-01-02)</strong></span>
</pre></div></li><li style="list-style-type: disc"><p>The <code class="literal">leftJoin</code>, <code class="literal">rightJoin</code>, <code class="literal">innerJoin</code>, and <code class="literal">outerJoin</code> invokers are used for joining tables. As we do not cover interactions between multiple tables in this tutorial, we <a id="id276" class="indexterm"></a>cannot demonstrate joins. See the Slick documentation (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/queries.html#joining-and-zipping" target="_blank">http://slick.typesafe.com/doc/2.1.0/queries.html#joining-and-zipping</a>) for examples of these.</p></li><li style="list-style-type: disc"><p>Aggregation invokers such as <code class="literal">length</code>, <code class="literal">min</code>, <code class="literal">max</code>, <code class="literal">sum</code>, and <code class="literal">avg</code> can be used for computing summary statistics. These must be executed using <code class="literal">.run</code>, rather than <code class="literal">.list</code>, as they return single numbers. For instance, to get the total donations to Barack Obama:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt; </strong></span>
<span class="strong"><strong>  Tables.transactions.filter {</strong></span>
<span class="strong"><strong>    _.candidate === "Obama, Barack"</strong></span>
<span class="strong"><strong>  }.map { _.amount  }.sum.run</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>Option[Int] = Some(849636799) // (in cents)</strong></span>
</pre></div></li></ul></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec49"></a>Operations on columns</h2></div></div><hr /></div><p>In the previous <a id="id277" class="indexterm"></a>section, you learned about the different invokers and how they mapped to SQL statements. We brushed over the methods supported by columns themselves, however: we can compare for equality using <code class="literal">===</code>, but what other operations are supported by Slick columns?</p><p>Most of the SQL functions are supported. For instance, to get the total donations to candidates whose name starts with <code class="literal">"O"</code>, we could run the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  Tables.transactions.filter { </strong></span>
<span class="strong"><strong>    _.candidate.startsWith("O") </strong></span>
<span class="strong"><strong>  }.take(5).list </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[Tables.Transactions#TableElementType] = List(Transaction(Some(1594098)...</strong></span>
</pre></div><p>Similarly, to count donations that happened between January 1, 2011 and February 1, 2011, we can use the <code class="literal">.between</code> method on the <code class="literal">date</code> column:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val dateParser = new SimpleDateFormat("dd-MM-yyyy")</strong></span>
<span class="strong"><strong>dateParser: java.text.SimpleDateFormat = SimpleDateFormat</strong></span>

<span class="strong"><strong>scala&gt; val startDate = new java.sql.Date(dateParser.parse("01-01-2011").getTime())</strong></span>
<span class="strong"><strong>startDate: java.sql.Date = 2011-01-01</strong></span>

<span class="strong"><strong>scala&gt; val endDate = new java.sql.Date(dateParser.parse("01-02-2011").getTime())</strong></span>
<span class="strong"><strong>endDate: java.sql.Date = 2011-02-01</strong></span>

<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  Tables.transactions.filter { </strong></span>
<span class="strong"><strong>    _.date.between(startDate, endDate)</strong></span>
<span class="strong"><strong>  }.length.run </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>Int = 9772</strong></span>
</pre></div><p>The equivalent of the SQL <code class="literal">IN (...)</code> operator that selects values in a specific set is <code class="literal">inSet</code>. For instance, to select all transactions to Barack Obama and Mitt Romney, we can use the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val candidateList = List("Obama, Barack", "Romney, Mitt")</strong></span>
<span class="strong"><strong>candidateList: List[String] = List(Obama, Barack, Romney, Mitt)</strong></span>

<span class="strong"><strong>scala&gt; val donationCents = db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  Tables.transactions.filter {</strong></span>
<span class="strong"><strong>    _.candidate.inSet(candidateList)</strong></span>
<span class="strong"><strong>  }.map { _.amount }.sum.run</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>donationCents: Option[Long] = Some(2874484657)</strong></span>

<span class="strong"><strong>scala&gt; val donationDollars = donationCents.map { _ / 100 }</strong></span>
<span class="strong"><strong>donationDollars: Option[Long] = Some(28744846)</strong></span>
</pre></div><p>So, between them, Mitt Romney and Barack Obama received over 28 million dollars in registered donations.</p><p>We can also negate a Boolean column with the <code class="literal">!</code> operator. For instance, to calculate the total amount of donations received by all candidates apart from Barack Obama and Mitt Romney:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  Tables.transactions.filter { </strong></span>
<span class="strong"><strong>    ! _.candidate.inSet(candidateList) </strong></span>
<span class="strong"><strong>  }.map { _.amount }.sum.run</strong></span>
<span class="strong"><strong>}.map { _ / 100 }</strong></span>
<span class="strong"><strong>Option[Long] = Some(1930747)</strong></span>
</pre></div><p>Column operations are <a id="id278" class="indexterm"></a>added by implicit conversion on the base <code class="literal">Column</code> instances. For a full list of methods available on String columns, consult the API <a id="id279" class="indexterm"></a>documentation for the <code class="literal">StringColumnExtensionMethods</code> class (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.lifted.StringColumnExtensionMethods" target="_blank">http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.lifted.StringColumnExtensionMethods</a>). For the methods available on Boolean columns, consult the API <a id="id280" class="indexterm"></a>documentation for the <code class="literal">BooleanColumnExtensionMethods</code> class (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.lifted.BooleanColumnExtensionMethods" target="_blank">http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.lifted.BooleanColumnExtensionMethods</a>). For the methods available on numeric columns, consult the API <a id="id281" class="indexterm"></a>documentation for <code class="literal">NumericColumnExtensionMethods</code> (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.lifted.NumericColumnExtensionMethods" target="_blank">http://slick.typesafe.com/doc/2.1.0/api/#scala.slick.lifted.NumericColumnExtensionMethods</a>).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec50"></a>Aggregations with "Group by"</h2></div></div><hr /></div><p>Slick also <a id="id282" class="indexterm"></a>provides a <code class="literal">groupBy</code> method that behaves like the <a id="id283" class="indexterm"></a>
<code class="literal">groupBy</code> method of native Scala collections. Let's get a list of candidates with all the donations for each candidate:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val grouped = Tables.transactions.groupBy { _.candidate }</strong></span>
<span class="strong"><strong>grouped: scala.slick.lifted.Query[(scala.slick.lifted.Column[...</strong></span>

<span class="strong"><strong>scala&gt; val aggregated = grouped.map {</strong></span>
<span class="strong"><strong>  case (candidate, group) =&gt;</strong></span>
<span class="strong"><strong>    (candidate -&gt; group.map { _.amount }.sum)</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>aggregated: scala.slick.lifted.Query[(scala.slick.lifted.Column[...</strong></span>

<span class="strong"><strong>scala&gt; val groupedDonations = db.withSession { </strong></span>
<span class="strong"><strong>  implicit session =&gt; aggregated.list </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>groupedDonations: List[(String, Option[Long])] = List((Bachmann, Michele,Some(7439272)),...</strong></span>
</pre></div><p>Let's break this down. The first statement, <code class="literal">transactions.groupBy { _.candidate }</code>, specifies the key by which to group. You can think of this as building an intermediate list of <code class="literal">(String, List[Transaction])</code> tuples mapping the group key to a list of all the table rows that satisfy this key. This behavior is identical to calling <code class="literal">groupBy</code> on a Scala collection.</p><p>The call to <code class="literal">groupBy</code> <a id="id284" class="indexterm"></a>must be followed by a <code class="literal">map</code> that aggregates the groups. The <a id="id285" class="indexterm"></a>function passed to <code class="literal">map</code> must take the tuple <code class="literal">(String, List[Transaction])</code> pair created by the <code class="literal">groupBy</code> call as its sole argument. The <code class="literal">map</code> call is responsible for aggregating the <code class="literal">List[Transaction]</code> object. We choose to first pick out the <code class="literal">amount</code> field of each transaction, and then to run a sum over these. Finally, we call <code class="literal">.list</code> on the whole pipeline to actually run the query. This just returns a Scala list. Let's convert the total donations from cents to dollars:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val groupedDonationDollars = groupedDonations.map {</strong></span>
<span class="strong"><strong>  case (candidate, donationCentsOption) =&gt;</strong></span>
<span class="strong"><strong>    candidate -&gt; (donationCentsOption.getOrElse(0L) / 100)</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>groupedDonationDollars: List[(String, Long)] = List((Bachmann, Michele,74392),...</strong></span>

<span class="strong"><strong>scala&gt; groupedDonationDollars.sortBy { </strong></span>
<span class="strong"><strong>  _._2 </strong></span>
<span class="strong"><strong>}.reverse.foreach { println }</strong></span>
<span class="strong"><strong>(Romney, Mitt,20248496)</strong></span>
<span class="strong"><strong>(Obama, Barack,8496347)</strong></span>
<span class="strong"><strong>(Paul, Ron,565060)</strong></span>
<span class="strong"><strong>(Santorum, Rick,334926)</strong></span>
<span class="strong"><strong>(Perry, Rick,301780)</strong></span>
<span class="strong"><strong>(Gingrich, Newt,277079)</strong></span>
<span class="strong"><strong>(Cain, Herman,210768)</strong></span>
<span class="strong"><strong>(Johnson, Gary Earl,83610)</strong></span>
<span class="strong"><strong>(Bachmann, Michele,74392)</strong></span>
<span class="strong"><strong>(Pawlenty, Timothy,42500)</strong></span>
<span class="strong"><strong>(Huntsman, Jon,23571)</strong></span>
<span class="strong"><strong>(Roemer, Charles E. 'Buddy' III,8579)</strong></span>
<span class="strong"><strong>(Stein, Jill,5270)</strong></span>
<span class="strong"><strong>(McCotter, Thaddeus G,3210)</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec51"></a>Accessing database metadata</h2></div></div><hr /></div><p>Commonly, especially during development, you might start the script by dropping the table if it <a id="id286" class="indexterm"></a>exists, then recreating it. We can find if a table is defined by accessing the database metadata through the <code class="literal">MTable</code> object. To get a list of tables with name matching a certain pattern, we can run <code class="literal">MTable.getTables(pattern)</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import slick.jdbc.meta.MTable</strong></span>
<span class="strong"><strong>import slick.jdbc.meta.MTable</strong></span>

<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  MTable.getTables("transactions").list</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[scala.slick.jdbc.meta.MTable] = List(MTable(MQName(fec.transactions),TABLE,,None,None,None) ...)</strong></span>
</pre></div><p>Thus, to drop the transactions table if it exists, we can run the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  if(MTable.getTables("transactions").list.nonEmpty) {</strong></span>
<span class="strong"><strong>    Tables.transactions.ddl.drop</strong></span>
<span class="strong"><strong>  }</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>The <code class="literal">MTable</code> instance contains a lot of metadata about the table. Go ahead and recreate the <code class="literal">transactions</code> table if you dropped it in the previous example. Then, to find information about the table's primary keys:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; db.withSession { implicit session =&gt;</strong></span>
<span class="strong"><strong>  val tableMeta = MTable.getTables("transactions").first</strong></span>
<span class="strong"><strong>  tableMeta.getPrimaryKeys.list</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>List[MPrimaryKey] = List(MPrimaryKey(MQName(test.transactions),id,1,Some(PRIMARY)))</strong></span>
</pre></div><p>For a full list of <a id="id287" class="indexterm"></a>methods available on <code class="literal">MTable</code> instances, consult <a id="id288" class="indexterm"></a>the Slick documentation (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/api/index.html#scala.slick.jdbc.meta.MTable" target="_blank">http://slick.typesafe.com/doc/2.1.0/api/index.html#scala.slick.jdbc.meta.MTable</a>).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec52"></a>Slick versus JDBC</h2></div></div><hr /></div><p>This chapter and the <a id="id289" class="indexterm"></a>previous one introduced two different ways of interacting with <a id="id290" class="indexterm"></a>SQL. In the previous chapter, we described how to use JDBC and build extensions on top of JDBC to make it more usable. In this chapter, we introduced Slick, a library that provides a functional interface on top of JDBC.</p><p>Which method should you choose? If you are starting a new project, you should consider using Slick. Even if you spend a considerable amount of time writing wrappers that sit on top of JDBC, it is unlikely that you will achieve the fluidity that Slick offers.</p><p>If you are working on an existing project that makes extensive use of JDBC, I hope that the previous chapter demonstrates that, with a little time and effort, you can write JDBC wrappers that reduce the impedance between the imperative style of JDBC and Scala's functional approach.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec53"></a>Summary</h2></div></div><hr /></div><p>In the previous two chapters, we looked extensively at how to query relational databases from Scala. In this chapter, you learned how to use Slick, a "functional-relational" mapper that allows interacting with SQL databases as one would with Scala collections.</p><p>In the next chapter, you will learn how to ingest data by querying web APIs.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec54"></a>References</h2></div></div><hr /></div><p>To learn more about <a id="id291" class="indexterm"></a>Slick, you can refer to the Slick documentation (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/" target="_blank">http://slick.typesafe.com/doc/2.1.0/</a>) and its API documentation (<a class="ulink" href="http://slick.typesafe.com/doc/2.1.0/api/#package" target="_blank">http://slick.typesafe.com/doc/2.1.0/api/#package</a>).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch07"></a>ChapterÂ 7.Â Web APIs</h2></div></div></div><p>Data scientists and data engineers get data from a variety of different sources. Often, data might come as CSV files or database dumps. Sometimes, we have to obtain the data through a web API.</p><p>An individual or organization sets up a web API to distribute data to programs over the Internet (or an internal network). Unlike websites, where the data is intended to be consumed by a web browser and shown to the user, the data provided by a web API is agnostic to the type of program querying it. Web servers serving HTML and web servers backing an API are queried in essentially the same way: through HTTP requests.</p><p>We have already seen an example of a web API in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>, where we queried the "Markit on demand" API for current stock prices. In this chapter, we will explore how to interact with web APIs in more detail; specifically, how to convert the data returned by the API to Scala objects and how to add additional information to the request through HTTP headers (for authentication, for instance).</p><p>The "Markit on demand" API <a id="id292" class="indexterm"></a>returned the data formatted as an XML object, but increasingly, new web APIs return data formatted as JSON. We will therefore focus on JSON in this chapter, but the concepts will port easily to XML.</p><p>JSON is a language for <a id="id293" class="indexterm"></a>formatting structured data. Many readers will have come across JSON in the past, but if not, there is a brief introduction to the syntax and concepts later on in this chapter. You will find it quite straightforward.</p><p>In this chapter, we will poll the GitHub API. GitHub has, over the last few years, become the de facto tool for collaborating on open source software. It provides a powerful, feature-rich API that gives programmatic access to nearly all the data available through the website.</p><p>Let's get a taste of what we can do. Type <code class="literal">api.github.com/users/odersky</code> in your web browser address bar. This will return the data offered by the API on a particular user (Martin Odersky, in this case):</p><div class="informalexample"><pre class="programlisting">{
  "login": "odersky",
  "id": 795990,
  ...
  "public_repos": 8,
  "public_gists": 3,
  "followers": 707,
  "following": 0,
  "created_at": "2011-05-18T14:51:21Z",
  "updated_at": "2015-09-15T15:14:33Z"
}</pre></div><p>The data is returned as a <a id="id294" class="indexterm"></a>JSON object. This chapter is devoted to learning how to access and parse this data programmatically. In <a class="link" href="#" linkend="ch13">Chapter 13</a>, <span class="emphasis"><em>Web APIs with Play</em></span>, you will learn how to build your own web API.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip13"></a>Tip</h3><p>The GitHub API is extensive and very well-documented. We will <a id="id295" class="indexterm"></a>explore some of the features of the API in this chapter. To see the full extent of the API, visit the documentation (<a class="ulink" href="https://developer.github.com/v3/" target="_blank">https://developer.github.com/v3/</a>).</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec55"></a>A whirlwind tour of JSON</h2></div></div><hr /></div><p>JSON is a <a id="id296" class="indexterm"></a>format for transferring structured data. It is flexible, easy for computers to generate and parse, and relatively readable for humans. It has become very common as a means of persisting program data structures and transferring data between programs.</p><p>JSON has four basic types: <span class="strong"><strong>Numbers</strong></span>, <span class="strong"><strong>Strings</strong></span>, <span class="strong"><strong>Booleans</strong></span>, and <span class="strong"><strong>null</strong></span>, and two compound <a id="id297" class="indexterm"></a>types: <span class="strong"><strong>Arrays</strong></span> and <span class="strong"><strong>Objects</strong></span>. Objects <a id="id298" class="indexterm"></a>are unordered collections of key-value pairs, where the key is always a string and the value can be any simple or compound type. We have already seen a JSON object: the data returned by the API call <code class="literal">api.github.com/users/odersky</code>.</p><p>Arrays are ordered lists of simple or compound types. For instance, type <a class="ulink" href="http://api.github.com/users/odersky/repos" target="_blank">api.github.com/users/odersky/repos</a> in your browser to get an array of objects, each representing a GitHub repository:</p><div class="informalexample"><pre class="programlisting">[
  {
    "id": 17335228,
    "name": "dotty",
    "full_name": "odersky/dotty",
    ...
  },
  {
    "id": 15053153,
    "name": "frontend",
    "full_name": "odersky/frontend",
    ...
  },
  ...
]</pre></div><p>We can construct <a id="id299" class="indexterm"></a>complex structures by nesting objects within other objects or arrays. Nevertheless, most web APIs return JSON structures with no more than one or two levels of nesting. If you are not familiar with JSON, I encourage you to explore the GitHub API through your web browser.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec56"></a>Querying web APIs</h2></div></div><hr /></div><p>The easiest way of <a id="id300" class="indexterm"></a>querying a web API from Scala is to use <code class="literal">Source.fromURL</code>. We have already used this in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>, when we queried the "Markit on demand" API. <code class="literal">Source.fromURL</code> presents an interface similar to <code class="literal">Source.fromFile</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scala.io._</strong></span>
<span class="strong"><strong>import scala.io._</strong></span>

<span class="strong"><strong>scala&gt; val response = Source.fromURL(</strong></span>
<span class="strong"><strong>  "https://api.github.com/users/odersky"</strong></span>
<span class="strong"><strong>).mkString</strong></span>
<span class="strong"><strong>response: String = {"login":"odersky","id":795990, ...</strong></span>
</pre></div><p>
<code class="literal">Source.fromURL</code> returns an iterator over the characters of the response. We materialize the iterator into a string using its <code class="literal">.mkString</code> method. We now have the <a id="id301" class="indexterm"></a>response as a Scala string. The next step is to parse the string with a JSON parser.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec57"></a>JSON in Scala â€“ an exercise in pattern matching</h2></div></div><hr /></div><p>There are several <a id="id302" class="indexterm"></a>libraries for manipulating JSON in Scala. We prefer json4s, but if you are a die-hard fan of another JSON library, you should be able to readily adapt the examples in this chapter. Let's create a <code class="literal">build.sbt</code> file with a dependency on <code class="literal">json4s</code>:</p><div class="informalexample"><pre class="programlisting">// build.sbt
scalaVersion := "2.11.7"

libraryDependencies += "org.json4s" %% "json4s-native" % "3.2.11"</pre></div><p>We can then import <code class="literal">json4s</code> into an SBT console session with:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.json4s._</strong></span>
<span class="strong"><strong>import org.json4s._</strong></span>

<span class="strong"><strong>scala&gt; import org.json4s.native.JsonMethods._</strong></span>
<span class="strong"><strong>import org.json4s.native.JsonMethods._</strong></span>
</pre></div><p>Let's use <code class="literal">json4s</code> to parse the response to our GitHub API query:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val jsonResponse = parse(response)</strong></span>
<span class="strong"><strong>jsonResponse: org.json4s.JValue = JObject(List((login,JString(odersky)),(id,JInt(795990)),...</strong></span>
</pre></div><p>The <code class="literal">parse</code> method takes a string (that contains well-formatted JSON) and converts it to a <code class="literal">JValue</code>, a supertype for all <code class="literal">json4s</code> objects. The runtime type of the response to this particular query is <code class="literal">JObject</code>, which is a <code class="literal">json4s</code> type representing a JSON object.</p><p>
<code class="literal">JObject</code> is a wrapper around a <code class="literal">List[JField]</code>, and <code class="literal">JField</code> represents an individual key-value pair in the object. We can use <span class="emphasis"><em>extractors </em></span>to access this list:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val JObject(fields) = jsonResponse</strong></span>
<span class="strong"><strong>fields: List[JField] = List((login,Jstring(odersky)),...</strong></span>
</pre></div><p>What's happened here? By writing <code class="literal">val JObject(fields) = ...</code>, we are telling Scala:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The right-hand side has runtime type of <code class="literal">JObject</code>
</p></li><li style="list-style-type: disc"><p>Go into the <code class="literal">JObject</code> instance and bind the list of fields to the constant <code class="literal">fields</code>
</p></li></ul></div><p>Readers familiar with Python might recognize the similarity with tuple unpacking, though Scala extractors are much more powerful and versatile. Extractors are used extensively to extract <a id="id303" class="indexterm"></a>Scala types from <code class="literal">json4s</code> types.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip14"></a>Tip</h3><p>
<span class="strong"><strong>Pattern matching using case classes</strong></span>
</p><p>How exactly <a id="id304" class="indexterm"></a>does the Scala compiler know what to do with an extractor such as:</p><div class="informalexample"><pre class="programlisting">val JObject(fields) = ...</pre></div><p>
<code class="literal">JObject</code> is a case <a id="id305" class="indexterm"></a>class with the following constructor:</p><div class="informalexample"><pre class="programlisting">case class JObject(obj:List[JField])</pre></div><p>Case classes all come with an extractor that reverses the constructor exactly. Thus, writing <code class="literal">val JObject(fields)</code> will bind <code class="literal">fields</code> to the <code class="literal">obj</code> attribute of the <code class="literal">JObject</code>. For further details on how extractors work, read <a class="link" href="#" linkend="appA">Appendix</a>, <span class="emphasis"><em>Pattern Matching and Extractors</em></span>.</p></div><p>We have now extracted <code class="literal">fields</code>, a (plain old Scala) list of fields from the <code class="literal">JObject</code>. A <code class="literal">JField</code> is a key-value pair, with the key being a string and value being a subtype of <code class="literal">JValue</code>. Again, we can use extractors to extract the values in the field:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val firstField = fields.head</strong></span>
<span class="strong"><strong>firstField: JField = (login,JString(odersky))</strong></span>

<span class="strong"><strong>scala&gt; val JField(key, JString(value)) = firstField</strong></span>
<span class="strong"><strong>key: String = login</strong></span>
<span class="strong"><strong>value: String = odersky</strong></span>
</pre></div><p>We matched the right-hand side against the pattern <code class="literal">JField(_, JString(_))</code>, binding the first element to <code class="literal">key</code> and the second to <code class="literal">value</code>. What happens if the right-hand side does not match the pattern?</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val JField(key, JInt(value)) = firstField</strong></span>
<span class="strong"><strong>scala.MatchError: (login,JString(odersky)) (of class scala.Tuple2)</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>The code throws a <code class="literal">MatchError</code> at runtime. These examples demonstrate the power of nested pattern matching: in a single line, we managed to verify the type of <code class="literal">firstField</code>, that its value has type <code class="literal">JString</code>, and we have bound the key and value to the <code class="literal">key</code> and <code class="literal">value</code> variables, respectively. As another example, if we <span class="emphasis"><em>know </em></span>that the first field is the login field, we can both verify this and extract the value:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val JField("login", JString(loginName)) = firstField</strong></span>
<span class="strong"><strong>loginName: String = odersky</strong></span>
</pre></div><p>Notice how this style of programming is <span class="emphasis"><em>declarative</em></span> rather than imperative: we declare that we want a <code class="literal">JField("login", JString(_))</code> variable on the right-hand side. We then let the language figure out how to check the variable types. Pattern matching is a recurring theme in functional languages.</p><p>We can also use pattern matching in a for loop when looping over fields. When used in a for loop, a pattern match defines a <span class="emphasis"><em>partial function</em></span>: only elements that match the pattern pass through the <a id="id306" class="indexterm"></a>loop. This lets us filter the collection for elements that match a pattern and also apply a transformation to these elements. For instance, we can extract every string field in our <code class="literal">fields</code> list:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; for {</strong></span>
<span class="strong"><strong>  JField(key, JString(value)) &lt;- fields</strong></span>
<span class="strong"><strong>} yield (key -&gt; value)</strong></span>
<span class="strong"><strong>List[(String, String)] = List((login,odersky), (avatar_url,https://avatars.githubusercontent.com/...</strong></span>
</pre></div><p>We can use this to search for specific fields. For instance, to extract the <code class="literal">"followers"</code> field:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val followersList = for {</strong></span>
<span class="strong"><strong>  JField("followers", JInt(followers)) &lt;- fields</strong></span>
<span class="strong"><strong>} yield followers</strong></span>
<span class="strong"><strong>followersList: List[Int] = List(707)</strong></span>

<span class="strong"><strong>scala&gt; val followers = followersList.headOption</strong></span>
<span class="strong"><strong>blogURL: Option[Int] = Some(707)</strong></span>
</pre></div><p>We first extracted all fields that matched the pattern <code class="literal">JField("follower", JInt(_))</code>, returning the integer inside the <code class="literal">JInt</code>. As the source collection, <code class="literal">fields</code>, is a list, this returns a list of integers. We then extract the first value from this list using <code class="literal">headOption</code>, which returns the head of the list if the list has at least one element, or <code class="literal">None</code> if the list is empty.</p><p>We are not limited to extracting a single field at a time. For instance, to extract the <code class="literal">"id"</code> and <code class="literal">"login"</code> fields together:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; {</strong></span>
<span class="strong"><strong>  for {</strong></span>
<span class="strong"><strong>    JField("login", JString(loginName)) &lt;- fields</strong></span>
<span class="strong"><strong>    JField("id", JInt(id)) &lt;- fields</strong></span>
<span class="strong"><strong>  } yield (id -&gt; loginName)</strong></span>
<span class="strong"><strong>}.headOption      </strong></span>
<span class="strong"><strong>Option[(BigInt, String)] = Some((795990,odersky))</strong></span>
</pre></div><p>Scala's pattern matching <a id="id307" class="indexterm"></a>and extractors provide you with an extremely powerful way of traversing the <code class="literal">json4s</code> tree, extracting the fields that we need.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec49"></a>JSON4S types</h3></div></div></div><p>We have already <a id="id308" class="indexterm"></a>discovered parts of <code class="literal">json4s</code>'s type hierarchy: strings are wrapped in <code class="literal">JString</code> objects, integers (or big integers) are wrapped in <code class="literal">JInt</code>, and so on. In this section, we will take a step <a id="id309" class="indexterm"></a>back and formalize the type structure and what Scala types they extract to. These are the <code class="literal">json4s</code> runtime types:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">val JString(s) // =&gt; extracts to a String</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">val JDouble(d) // =&gt; extracts to a Double</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">val JDecimal(d) // =&gt; extracts to a BigDecimal</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">val JInt(i) // =&gt; extracts to a BigInt</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">val JBool(b) // =&gt; extracts to a Boolean</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">val JObject(l) // =&gt; extracts to a List[JField]</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">val JArray(l) // =&gt; extracts to a List[JValue]</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">JNull // =&gt; represents a JSON null</code>
</p></li></ul></div><p>All these types are subclasses of <code class="literal">JValue</code>. The compile-time result of <code class="literal">parse </code>is <code class="literal">JValue</code>, which you normally need to cast to a concrete type using an extractor.</p><p>The last type in the hierarchy is <code class="literal">JField</code>, which represents a key-value pair. <code class="literal">JField</code> is just a type alias for the <code class="literal">(String, JValue)</code> tuple. It is thus not a subtype of <code class="literal">JValue</code>. We can extract the key and value using the following extractor:</p><div class="informalexample"><pre class="programlisting">val JField(key, JInt(value)) = ...</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec50"></a>Extracting fields using XPath</h3></div></div></div><p>In the previous <a id="id310" class="indexterm"></a>sections, you learned how to traverse JSON objects using extractors. In this section, we will look at a different way of traversing JSON objects and extracting specific fields: the <span class="emphasis"><em>XPath DSL</em></span> (domain-specific language). XPath is a query language for traversing tree-like structures. It was originally designed for addressing specific nodes in an XML <a id="id311" class="indexterm"></a>document, but it works just as well with JSON. We have already seen an example of XPath syntax when we extracted the stock price from the XML document returned by the "Markit on demand" API in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>. We extracted the node with tag <code class="literal">"LastPrice"</code> using <code class="literal">r \ "LastPrice"</code>. The <code class="literal">\</code> operator was defined by the <code class="literal">scala.xml</code> package.</p><p>The <code class="literal">json4s</code> package exposes a similar DSL to extract fields from <code class="literal">JObject</code> instances. For instance, we can extract the <code class="literal">"login"</code> field from the JSON object <code class="literal">jsonResponse</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; jsonResponse \ "login"</strong></span>
<span class="strong"><strong>org.json4s.JValue = JString(odersky)</strong></span>
</pre></div><p>This returns a <code class="literal">JValue</code> that we can transform into a Scala string using an extractor:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val JString(loginName) = jsonResponse \ "login"</strong></span>
<span class="strong"><strong>loginName: String = odersky</strong></span>
</pre></div><p>Notice the similarity between the XPath DSL and traversing a filesystem: we can think of <code class="literal">JObject</code> instances as directories. Field names correspond to file names and the field value to the content of the file. This is more evident for nested structures. The <code class="literal">users</code> endpoint of the GitHub API does not have nested documents, so let's try another endpoint. We will query the API for the repository corresponding to this book: "<a class="ulink" href="https://api.github.com/repos/pbugnion/s4ds" target="_blank">https://api.github.com/repos/pbugnion/s4ds</a>". The response has the following structure:</p><div class="informalexample"><pre class="programlisting">{
  "id": 42269470,
  "name": "s4ds",
  ...
  "owner": { "login": "pbugnion", "id": 1392879 ... }
  ...
}</pre></div><p>Let's fetch this document and use the XPath syntax to extract the repository owner's login name:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val jsonResponse = parse(Source.fromURL(</strong></span>
<span class="strong"><strong>  "https://api.github.com/repos/pbugnion/s4ds"</strong></span>
<span class="strong"><strong>).mkString)</strong></span>
<span class="strong"><strong>jsonResponse: JValue = JObject(List((id,JInt(42269470)), (name,JString(s4ds))...</strong></span>

<span class="strong"><strong>scala&gt; val JString(ownerLogin) = jsonResponse \ "owner" \ "login"</strong></span>
<span class="strong"><strong>ownerLogin: String = pbugnion</strong></span>
</pre></div><p>Again, this is much like <a id="id312" class="indexterm"></a>traversing a filesystem: <code class="literal">jsonResponse \ "owner"</code> returns a <code class="literal">JObject</code> corresponding to the <code class="literal">"owner"</code> object. This <code class="literal">JObject</code> can, in turn, be queried for the <code class="literal">"login"</code> field, returning the value <code class="literal">JString(pbugnion)</code> associated with this key.</p><p>What if the API response is an <a id="id313" class="indexterm"></a>array? The filesystem analogy breaks down somewhat. Let's query the API endpoint listing Martin Odersky's repositories: <a class="ulink" href="https://api.github.com/users/odersky/repos" target="_blank">https://api.github.com/users/odersky/repos</a>. The response is an array of JSON objects, each of which represents a repository:</p><div class="informalexample"><pre class="programlisting">[
  {
    "id": 17335228,
    "name": "dotty",
    "size": 14699,
    ...
  },
  {
    "id": 15053153,
    "name": "frontend",
    "size": 392
    ...
  },
  {
    "id": 2890092,
    "name": "scala",
    "size": 76133,
    ...
  },
  ...
]</pre></div><p>Let's fetch this and parse it as JSON:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val jsonResponse = parse(Source.fromURL(</strong></span>
<span class="strong"><strong>  "https://api.github.com/users/odersky/repos"</strong></span>
<span class="strong"><strong>).mkString)</strong></span>
<span class="strong"><strong>jsonResponse: JValue = JArray(List(JObject(List((id,JInt(17335228)), (name,Jstring(dotty)), ...</strong></span>
</pre></div><p>This returns a <code class="literal">JArray</code>. The <a id="id314" class="indexterm"></a>XPath DSL works in the same way on a <code class="literal">JArray</code> as on a <code class="literal">JObject</code>, but now, instead of returning a single <code class="literal">JValue</code>, it returns an array of fields matching the path in every <a id="id315" class="indexterm"></a>object in the array. Let's get the size of all Martin Odersky's <a id="id316" class="indexterm"></a>repositories:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; jsonResponse \ "size"</strong></span>
<span class="strong"><strong>JValue = JArray(List(JInt(14699), JInt(392), ...</strong></span>
</pre></div><p>We now have a <code class="literal">JArray</code> of the values corresponding to the <code class="literal">"size"</code> field in every repository. We can iterate over this array with a <code class="literal">for</code> comprehension and use extractors to convert elements to Scala objects:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; for {</strong></span>
<span class="strong"><strong>  JInt(size) &lt;- (jsonResponse \ "size")</strong></span>
<span class="strong"><strong>} yield size</strong></span>
<span class="strong"><strong>List[BigInt] = List(14699, 392, 76133, 32010, 98166, 1358, 144, 273)</strong></span>
</pre></div><p>Thus, combining extractors with the XPath DSL gives us powerful, complementary tools to extract information from JSON objects.</p><p>There is much more to the XPath syntax than we have space to cover here, including the ability to extract fields nested at any level of depth below the current root or fields that match a predicate or a certain type. We find that well-designed APIs obviate the need for many of these more powerful functions, but do consult the documentation (<code class="literal">json4s.org</code>) to get an overview of what you can do.</p><p>In the next section, we will look at extracting JSON directly into case classes.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec58"></a>Extraction using case classes</h2></div></div><hr /></div><p>In the <a id="id317" class="indexterm"></a>previous <a id="id318" class="indexterm"></a>sections, we extracted specific fields from the JSON response using Scala extractors. We can do one better and extract full case classes.</p><p>When moving beyond the REPL, programming best practice dictates that we move from <code class="literal">json4s</code> types to Scala objects as soon as possible rather than passing <code class="literal">json4s</code> types around the program. Converting from <code class="literal">json4s</code> types to Scala types (or case classes representing domain objects) is good practice because:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>It decouples the program from the structure of the data that we receive from the API, something we have little control over.</p></li><li style="list-style-type: disc"><p>It improves type safety: a <code class="literal">JObject</code> is, as far as the compiler is concerned, always a <code class="literal">JObject</code>, whatever fields it contains. By contrast, the compiler will never mistake a <code class="literal">User</code> for a <code class="literal">Repository</code>.</p></li></ul></div><p>
<code class="literal">Json4s</code> lets us extract <a id="id319" class="indexterm"></a>case classes directly from <code class="literal">JObject</code> instances, making writing the layer converting <code class="literal">JObject</code> <a id="id320" class="indexterm"></a>instances to custom types easy.</p><p>Let's define a case class representing a GitHub user:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class User(id:Long, login:String)</strong></span>
<span class="strong"><strong>defined class User</strong></span>
</pre></div><p>To extract a case class from a <code class="literal">JObject</code>, we must first define an implicit <code class="literal">Formats</code> value that defines how simple types should be serialized and deserialized. We will use the default <code class="literal">DefaultFormats</code> provided with <code class="literal">json4s</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; implicit val formats = DefaultFormats</strong></span>
<span class="strong"><strong>formats: DefaultFormats.type = DefaultFormats$@750e685a</strong></span>
</pre></div><p>We can now extract instances of <code class="literal">User</code>. Let's do this for Martin Odersky:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val url = "https://api.github.com/users/odersky"</strong></span>
<span class="strong"><strong>url: String = https://api.github.com/users/odersky</strong></span>

<span class="strong"><strong>scala&gt; val jsonResponse = parse(Source.fromURL(url).mkString)</strong></span>
<span class="strong"><strong>jsonResponse: JValue = JObject(List((login,JString(odersky)), ...</strong></span>

<span class="strong"><strong>scala&gt; jsonResponse.extract[User]</strong></span>
<span class="strong"><strong>User = User(795990,odersky)</strong></span>
</pre></div><p>This works as long as the object is well-formatted. The <code class="literal">extract</code> method looks for fields in the <code class="literal">JObject</code> that match the attributes of <code class="literal">User</code>. In this case, <code class="literal">extract</code> will note that the <code class="literal">JObject</code> contains the <code class="literal">"login": "odersky"</code> field and that <code class="literal">JString("odersky")</code> can be converted to a Scala string, so it binds <code class="literal">"odersky"</code> to the <code class="literal">login</code> attribute in <code class="literal">User</code>.</p><p>What if the attribute names differ from the field names in the JSON object? We must first transform the object to have the correct fields. For instance, let's rename the <code class="literal">login</code> attribute to <code class="literal">userName</code> in our <code class="literal">User</code> class:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class User(id:Long, userName:String)</strong></span>
<span class="strong"><strong>defined class User</strong></span>
</pre></div><p>If we try to use <code class="literal">extract[User]</code> on <code class="literal">jsonResponse</code>, we will get a mapping error because the deserializer is <a id="id321" class="indexterm"></a>missing a <code class="literal">login</code> field in the response. We can fix this using the <code class="literal">transformField</code> <a id="id322" class="indexterm"></a>method on <code class="literal">jsonResponse</code> to rename the <code class="literal">login</code> field:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; jsonResponse.transformField { </strong></span>
<span class="strong"><strong>  case("login", n) =&gt; "userName" -&gt; n </strong></span>
<span class="strong"><strong>}.extract[User]</strong></span>
<span class="strong"><strong>User = User(795990,odersky)</strong></span>
</pre></div><p>What about optional fields? Let's assume that the JSON object returned by the GitHub API does not always contain the login field. We could symbolize this in our object model by giving the <code class="literal">login</code> parameter the type <code class="literal">Option[String]</code> rather than <code class="literal">String</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class User(id:Long, login:Option[String])</strong></span>
<span class="strong"><strong>defined class User</strong></span>
</pre></div><p>This works just as you would expect. When the response contains a non-null <code class="literal">login</code> field, calling <code class="literal">extract[User]</code> will deserialize it to <code class="literal">Some(value)</code>, and when it's missing or <code class="literal">JNull</code>, it will produce <code class="literal">None</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; jsonResponse.extract[User]</strong></span>
<span class="strong"><strong>User = User(795990,Some(odersky))</strong></span>

<span class="strong"><strong>scala&gt; jsonResponse.removeField { </strong></span>
<span class="strong"><strong>  case(k, _) =&gt; k == "login" // remove the "login" field</strong></span>
<span class="strong"><strong>}.extract[User]</strong></span>
<span class="strong"><strong>User = User(795990,None)</strong></span>
</pre></div><p>Let's wrap this up in a small program. The program will take a single command-line argument, the user's login name, extract a <code class="literal">User</code> instance, and print it to screen:</p><div class="informalexample"><pre class="programlisting">// GitHubUser.scala

import scala.io._
import org.json4s._
import org.json4s.native.JsonMethods._

object GitHubUser {

  implicit val formats = DefaultFormats

  case class User(id:Long, userName:String)

  /** Query the GitHub API corresponding to `url` 
    * and convert the response to a User.
    */
  def fetchUserFromUrl(url:String):User = {
    val response = Source.fromURL(url).mkString
    val jsonResponse = parse(response)
    extractUser(jsonResponse)
  }

  /** Helper method for transforming the response to a User */
  def extractUser(obj:JValue):User = {
    val transformedObject = obj.transformField {
      case ("login", name) =&gt; ("userName", name)
    }
    transformedObject.extract[User]
  }

  def main(args:Array[String]) {
    // Extract username from argument list
    val name = args.headOption.getOrElse { 
      throw new IllegalArgumentException(
        "Missing command line argument for user.")
    }
    
    val user = fetchUserFromUrl(
      s"https://api.github.com/users/$name")

    println(s"** Extracted for $name:")
    println()
    println(user)

  }

}</pre></div><p>We can run this <a id="id323" class="indexterm"></a>from an SBT console as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sbt</strong></span>
<span class="strong"><strong>&gt; runMain GitHubUser pbugnion</strong></span>
<span class="strong"><strong>** Extracted for pbugnion:</strong></span>
<span class="strong"><strong>User(1392879,pbugnion)</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec59"></a>Concurrency and exception handling with futures</h2></div></div><hr /></div><p>While the <a id="id324" class="indexterm"></a>program that we wrote in the previous section works, it is very brittle. It will crash if we enter a non-existent user name or the GitHub API changes or returns a badly-formatted response. We need to make it fault-tolerant.</p><p>What if we also wanted to fetch multiple users? The program, as written, is entirely single-threaded. The <code class="literal">fetchUserFromUrl</code> method fires a call to the API and blocks until the API sends data back. A better solution would be to fetch multiple users in parallel.</p><p>As you learned in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>, there are two straightforward ways to implement both fault tolerance and parallel execution: we can either put all the user names in a parallel collection and wrap the code for fetching and extracting the user in a <code class="literal">Try</code> block or we can wrap each query in a future.</p><p>When querying web APIs, it is sometimes the case that a request can take abnormally long. To prevent this from blocking the other threads, it is preferable to rely on futures rather than parallel collections for concurrency, as we saw in the <span class="emphasis"><em>Parallel collection or Future?</em></span> section at the end of <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>.</p><p>Let's rewrite the code from the previous section to handle fetching multiple users concurrently in a fault-tolerant manner. We will change the <code class="literal">fetchUserFromUrl</code> method to query the API asynchronously. This is not terribly different from <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>, in which we queried the "Markit on demand" API:</p><div class="informalexample"><pre class="programlisting">// GitHubUserConcurrent.scala

import scala.io._
import scala.concurrent._
import scala.concurrent.duration._
import ExecutionContext.Implicits.global
import scala.util._

import org.json4s._
import org.json4s.native.JsonMethods._

object GitHubUserConcurrent {

  implicit val formats = DefaultFormats

  case class User(id:Long, userName:String)

  // Fetch and extract the `User` corresponding to `url`
  def fetchUserFromUrl(url:String):Future[User] = {
    val response = Future { Source.fromURL(url).mkString }
    val parsedResponse = response.map { r =&gt; parse(r) }
    parsedResponse.map { extractUser }
  }

  // Helper method for extracting a user from a JObject
  def extractUser(jsonResponse:JValue):User = {
    val o = jsonResponse.transformField {
      case ("login", name) =&gt; ("userName", name)
    }
    o.extract[User]
  }

  def main(args:Array[String]) {
    val names = args.toList

    // Loop over each username and send a request to the API 
    // for that user 
    val name2User = for {
      name &lt;- names
      url = s"https://api.github.com/users/$name"
      user = fetchUserFromUrl(url)
    } yield name -&gt; user

    // callback function
    name2User.foreach { case(name, user) =&gt;
      user.onComplete {
        case Success(u) =&gt; println(s" ** Extracted for $name: $u")
        case Failure(e) =&gt; println(s" ** Error fetching $name:$e")
      }
    }

    // Block until all the calls have finished.
    Await.ready(Future.sequence(name2User.map { _._2 }), 1 minute)
  }
}</pre></div><p>Let's run the code <a id="id325" class="indexterm"></a>through <code class="literal">sbt</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sbt</strong></span>
<span class="strong"><strong>&gt; runMain GitHubUserConcurrent odersky derekwyatt not-a-user-675</strong></span>
<span class="strong"><strong> ** Error fetching user not-a-user-675: java.io.FileNotFoundException: https://api.github.com/users/not-a-user-675</strong></span>
<span class="strong"><strong> ** Extracted for odersky: User(795990,odersky)</strong></span>
<span class="strong"><strong> ** Extracted for derekwyatt: User(62324,derekwyatt)</strong></span>
</pre></div><p>The code itself should be straightforward. All the concepts used here have been explored in this chapter or in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>, apart from the last line:</p><div class="informalexample"><pre class="programlisting">Await.ready(Future.sequence(name2User.map { _._2 }), 1 minute)</pre></div><p>This statement tells the program to wait until all futures in our list have been completed. <code class="literal">Await.ready(..., 1 minute)</code> takes a future as its first argument and blocks execution until this future returns. The second argument is a time-out on this future. The only catch is that we need to pass a single future to <code class="literal">Await</code> rather than a list of futures. We can use <code class="literal">Future.sequence</code> to merge a collection of futures into a single future. This future will be completed when all the futures in the sequence have completed.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec60"></a>Authentication â€“ adding HTTP headers</h2></div></div><hr /></div><p>So far, we have <a id="id326" class="indexterm"></a>been using the GitHub API without authentication. This limits us to sixty requests per hour. Now that we can query the API in parallel, we could exceed this limit in seconds.</p><p>Fortunately, GitHub is <a id="id327" class="indexterm"></a>much more generous if you authenticate when you query the API. The limit increases to 5,000 requests per hour. You must have a GitHub user account to <a id="id328" class="indexterm"></a>authenticate, so go ahead and create one now if you need to. After creating an account, navigate to <a class="ulink" href="https://github.com/settings/tokens" target="_blank">https://github.com/settings/tokens</a> and click on the <span class="strong"><strong>Generate new token</strong></span> button. Accept the default settings and enter a token description and a long hexadecimal number should appear on the screen. Copy the token for now.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec51"></a>HTTP â€“ a whirlwind overview</h3></div></div></div><p>Before using our newly generated token, let's take a few minutes to review how HTTP works.</p><p>HTTP is a protocol for transferring information between different computers. It is the protocol that we have been using throughout the chapter, though Scala hid the details from us in the call to <code class="literal">Source.fromURL</code>. It is also the protocol that you use when you point your web browser to a website, for instance.</p><p>In HTTP, a computer will <a id="id329" class="indexterm"></a>typically make a <span class="emphasis"><em>request</em></span> to a remote server, and the server will send back a <span class="emphasis"><em>response</em></span>. Requests contain a <span class="emphasis"><em>verb</em></span>, which defines the type of request, and a URL identifying a <span class="emphasis"><em>resource</em></span>. For instance, when we typed <a class="ulink" href="http://api.github.com/users/pbugnion" target="_blank">api.github.com/users/pbugnion</a> in our browsers, this was translated into a GET (the verb) request for the <code class="literal">users/pbugnion</code> resource. All the calls that we have made so far have been GET requests. You might use a different type of request, for instance, a POST request, to modify (rather than just view) some content on GitHub.</p><p>Besides the verb and resource, there are two more parts to an HTTP request:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The <span class="emphasis"><em>headers</em></span> include metadata about the request, such as the expected format and character set of the response or the authentication credentials. Headers are just a list of key-value pairs. We will pass the OAuth token that we have just generated to the API using the <code class="literal">Authorization</code> header. This Wikipedia article lists commonly used header fields: <a class="ulink" href="http://en.wikipedia.org/wiki/List_of_HTTP_header_fields" target="_blank">en.wikipedia.org/wiki/List_of_HTTP_header_fields</a>.</p></li><li style="list-style-type: disc"><p>The request body is not used in GET requests but becomes important for requests that modify the resource they query. For instance, if I wanted to create a new repository on GitHub programmatically, I would send a POST request to <code class="literal">/pbugnion/repos</code>. The POST body would then be a JSON object describing the new repository. We will not use the request body in this chapter.</p></li></ul></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec52"></a>Adding headers to HTTP requests in Scala</h3></div></div></div><p>We will pass the <a id="id330" class="indexterm"></a>OAuth token as a header with our HTTP request. Unfortunately, the <code class="literal">Source.fromURL</code> method is not particularly suited to adding headers when creating a GET request. We will, instead, use a library, <code class="literal">scalaj-http</code>.</p><p>Let's add <code class="literal">scalaj-http</code> to the dependencies in our <code class="literal">build.sbt</code>:</p><div class="informalexample"><pre class="programlisting">libraryDependencies += "org.scalaj" %% "scalaj-http" % "1.1.6"</pre></div><p>We can now import <code class="literal">scalaj-http</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import scalaj.http._</strong></span>
<span class="strong"><strong>import scalaj.http._</strong></span>
</pre></div><p>We start by creating an <code class="literal">HttpRequest</code> object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val request = Http("https://api.github.com/users/pbugnion")</strong></span>
<span class="strong"><strong>request:scalaj.http.HttpRequest = HttpRequest(api.github.com/users/pbugnion,GET,...</strong></span>
</pre></div><p>We can now add the <a id="id331" class="indexterm"></a>authorization header to the request (add your own token string here):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val authorizedRequest = request.header("Authorization", "token e836389ce ...")</strong></span>
<span class="strong"><strong>authorizedRequest:scalaj.http.HttpRequest = HttpRequest(api.github.com/users/pbugnion,GET,...</strong></span>
</pre></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip17"></a>Tip</h3><p>The <code class="literal">.header</code> method returns a new <code class="literal">HttpRequest</code> instance. It does not modify the request in place. Thus, just calling <code class="literal">request.header(...)</code> does not actually add the header to request itself, which can be a source of confusion.</p></div><p>Let's fire the request. We do this through the request's <code class="literal">asString</code> method, which queries the API, fetches the response, and parses it as a Scala <code class="literal">String</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val response = authorizedRequest.asString</strong></span>
<span class="strong"><strong>response:scalaj.http.HttpResponse[String] = HttpResponse({"login":"pbugnion",...</strong></span>
</pre></div><p>The response is made up of three components:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The status code, which should be <code class="literal">200</code> for a successful request:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; response.code </strong></span>
<span class="strong"><strong>Int = 200</strong></span>
</pre></div></li><li style="list-style-type: disc"><p>The response body, which is the part that we are interested in:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; response.body </strong></span>
<span class="strong"><strong>String = {"login":"pbugnion","id":1392879,...</strong></span>
</pre></div></li><li style="list-style-type: disc"><p>The response headers (metadata about the response):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; response.headers </strong></span>
<span class="strong"><strong>Map[String,String] = Map(Access-Control-Allow-Credentials -&gt; true, ...</strong></span>
</pre></div></li></ul></div><p>To verify that the authorization was successful, query the <code class="literal">X-RateLimit-Limit</code> header:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; response.headers("X-RateLimit-Limit")</strong></span>
<span class="strong"><strong>String = 5000</strong></span>
</pre></div><p>This value is the maximum <a id="id332" class="indexterm"></a>number of requests per hour that you can make to the GitHub API from a single IP address.</p><p>Now that we have some understanding of how to add authentication to GET requests, let's modify our script for fetching users to use the OAuth token for authentication. We first need to import <code class="literal">scalaj-http</code>:</p><div class="informalexample"><pre class="programlisting">import scalaj.http._</pre></div><p>Injecting the value of the token into the code can be somewhat tricky. You might be tempted to hardcode it, but this prohibits you from sharing the code. A better solution is to use an <span class="emphasis"><em>environment variable</em></span>. Environment variables are a set of variables present in your terminal session that are accessible to all processes running in that session. To get a list of the current environment variables, type the following on Linux or Mac OS:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ env</strong></span>
<span class="strong"><strong>HOME=/Users/pascal</strong></span>
<span class="strong"><strong>SHELL=/bin/zsh</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>On Windows, the equivalent command is <code class="literal">SET</code>. Let's add the GitHub token to the environment. Use the following command on Mac OS or Linux:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ export GHTOKEN="e83638..." # enter your token here</strong></span>
</pre></div><p>On Windows, use the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ SET GHTOKEN="e83638..."</strong></span>
</pre></div><p>If you were to reuse this environment variable across many projects, entering <code class="literal">export GHTOKEN=...</code> in the shell for every session gets old quite quickly. A more permanent solution is to add <code class="literal">export GHTOKEN="e83638â€¦"</code> to your shell configuration file (your <code class="literal">.bashrc</code> file if you are using Bash). This is safe provided your <code class="literal">.bashrc</code> is readable by the user only. Any new shell session will have access to the <code class="literal">GHTOKEN</code> environment variable.</p><p>We can access environment variables from a Scala program using <code class="literal">sys.env</code>, which returns a <code class="literal">Map[String, String]</code> of the variables. Let's add a <code class="literal">lazy val token</code> to our class, containing the <code class="literal">token</code> value:</p><div class="informalexample"><pre class="programlisting">lazy val token:Option[String] = sys.env.get("GHTOKEN") orElse {
  println("No token found: continuing without authentication")
  None
}</pre></div><p>Now that we have the <a id="id333" class="indexterm"></a>token, the only part of the code that must change, to add authentication, is the <code class="literal">fetchUserFromUrl</code> method:</p><div class="informalexample"><pre class="programlisting">def fetchUserFromUrl(url:String):Future[User] = {
  val baseRequest = Http(url)
  val request = token match {
    case Some(t) =&gt; baseRequest.header(
      "Authorization", s"token $t")
    case None =&gt; baseRequest
  }
  val response = Future { 
    request.asString.body 
  }
  val parsedResponse = response.map { r =&gt; parse(r) }
  parsedResponse.map(extractUser)
}</pre></div><p>Additionally, we can, to gain clearer error messages, check that the response's status code is 200. As this is straightforward, it is left as an exercise.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec61"></a>Summary</h2></div></div><hr /></div><p>In this chapter, you learned how to query the GitHub API, converting the response to Scala objects. Of course, merely printing results to screen is not terribly interesting. In the next chapter, we will look at the next step of the data ingestion process: storing data in a database. We will query the GitHub API and store the results in a MongoDB database.</p><p>In <a class="link" href="#" linkend="ch13">Chapter 13</a>, <span class="emphasis"><em>Web APIs with Play</em></span>, we will look at building our own simple web API.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec62"></a>References</h2></div></div><hr /></div><p>The GitHub API, with its extensive documentation, is a good place to explore how a rich API is constructed. It <a id="id334" class="indexterm"></a>has a <span class="strong"><strong>Getting Started</strong></span> section that is worth reading:</p><p>
<a class="ulink" href="https://developer.github.com/guides/getting-started/" target="_blank">https://developer.github.com/guides/getting-started/</a>
</p><p>Of course, this is not specific to Scala: it uses cURL to query the API.</p><p>Read the documentation (<a class="ulink" href="http://json4s.org" target="_blank">http://json4s.org</a>) and source code (<a class="ulink" href="https://github.com/json4s/json4s" target="_blank">https://github.com/json4s/json4s</a>) for <code class="literal">json4s</code> for a complete reference. There are many parts of this package that we have not explored, in particular, how to build JSON from Scala.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch08"></a>ChapterÂ 8.Â Scala and MongoDB</h2></div></div></div><p>In <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Scala and SQL through JDBC</em></span>, and <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Slick â€“ A Functional Interface for SQL</em></span>, you learned how to insert, transform, and read data in SQL databases. These databases remain (and are likely to remain) very popular in data science, but NoSQL databases are emerging as strong contenders.</p><p>The needs for data storage are growing rapidly. Companies are producing and storing more data points in the hope of acquiring better business intelligence. They are also building increasingly large teams of data scientists, who all need to access the data store. Maintaining constant access time as the data load increases requires taking advantage of parallel architectures: we need to distribute the database across several computers so that, as the load on the server increases, we can just add more machines to improve throughput.</p><p>In MySQL databases, the data is naturally split across different tables. Complex queries necessitate joining across several tables. This makes partitioning the database across different computers difficult. NoSQL databases emerged to fill this gap.</p><p>In this chapter, you will learn to interact with MongoDB, an open source database that offers high performance and can be distributed easily. MongoDB is one of the more popular NoSQL databases with a strong community. It offers a reasonable balance of speed and flexibility, making it a natural alternative to SQL for storing large datasets with uncertain query requirements, as might happen in data science. Many of the concepts and recipes in this chapter will apply to other NoSQL databases.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec63"></a>MongoDB</h2></div></div><hr /></div><p>MongoDB is <a id="id335" class="indexterm"></a>a <span class="emphasis"><em>document-oriented</em></span> database. It contains collections of documents. Each document is a JSON-like object:</p><div class="informalexample"><pre class="programlisting">{
    _id: ObjectId("558e846730044ede70743be9"),
    name: "Gandalf",
    age: 2000,
    pseudonyms: [ "Mithrandir", "Olorin", "Greyhame" ],
    possessions: [ 
        { name: "Glamdring", type: "sword" }, 
        { name: "Narya", type: "ring" }
    ]
}</pre></div><p>Just as in JSON, a document is a set of key-value pairs, where the values can be strings, numbers, Booleans, dates, arrays, or subdocuments. Documents are grouped in collections, and collections are grouped in databases.</p><p>You might be thinking that this is not very different from SQL: a document is similar to a row and a collection corresponds to a table. There are two important differences:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The values in documents can be simple values, arrays, subdocuments, or arrays of subdocuments. This lets us encode one-to-many and many-to-many relationships in a single collection. For instance, consider the wizard collection. In SQL, if we wanted to store pseudonyms for each wizard, we would have to use a separate <code class="literal">wizard2pseudonym</code> table with a row for each wizard-pseudonym pair. In MongoDB, we can just use an array. In practice, this means that we can normally use a single document to represent an entity (a customer, transaction, or wizard, for instance). In SQL, we would normally have to join across several tables to retrieve all the information on a specific entity.</p></li><li style="list-style-type: disc"><p>MongoDB is <span class="emphasis"><em>schemaless</em></span>. Documents in a collection can have varying sets of fields with different types for the same field across different documents. In practice, MongoDB collections have a loose schema enforced either client side or by convention: most documents will have a subset of the same fields, and fields will, in general, contain the same data type. Having a flexible schema makes adjusting the data structure easy as there is no need for time-consuming <code class="literal">ALTER</code> <code class="literal">TABLE</code> statements. The downside is that there is no easy way of enforcing our flexible schema on the database side.</p></li></ul></div><p>Note the <code class="literal">_id</code> field: this is a unique key. MongoDB will generate one automatically if we insert a document without an <code class="literal">_id</code> field.</p><p>This chapter gives recipes for interacting with a MongoDB database from Scala, including maintaining type safety and best practices. We will not cover advanced MongoDB functionality (such as aggregation or distributing the database). We will assume that you have <a id="id336" class="indexterm"></a>MongoDB installed on your computer (<a class="ulink" href="http://docs.mongodb.org/manual/installation/" target="_blank">http://docs.mongodb.org/manual/installation/</a>). It will also help to have a very basic knowledge of MongoDB (we <a id="id337" class="indexterm"></a>discuss some references at the end of this chapter, but any basic tutorial available online will be sufficient for the needs of this chapter).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec64"></a>Connecting to MongoDB with Casbah</h2></div></div><hr /></div><p>The official <a id="id338" class="indexterm"></a>MongoDB driver for Scala is called <span class="strong"><strong>Casbah</strong></span>. Rather than a fully-fledged driver, Casbah wraps the Java Mongo driver, providing a more functional interface. There are other MongoDB drivers for Scala, which we will discuss briefly at the end of this chapter. For now, we will stick to Casbah.</p><p>Let's start by adding Casbah to our <code class="literal">build.sbt</code> file:</p><div class="informalexample"><pre class="programlisting">scalaVersion := "2.11.7"

libraryDependencies += "org.mongodb" %% "casbah" % "3.0.0"</pre></div><p>Casbah also expects <code class="literal">slf4j</code> bindings (a Scala logging framework) to be available, so let's also add <code class="literal">slf4j-nop</code>:</p><div class="informalexample"><pre class="programlisting">libraryDependencies += "org.slf4j" % "slf4j-nop" % "1.7.12"</pre></div><p>We can now start an SBT console and import Casbah in the Scala shell:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sbt console</strong></span>
<span class="strong"><strong>scala&gt; import com.mongodb.casbah.Imports._</strong></span>
<span class="strong"><strong>import com.mongodb.casbah.Imports._</strong></span>

<span class="strong"><strong>scala&gt; val client = MongoClient()</strong></span>
<span class="strong"><strong>client: com.mongodb.casbah.MongoClient = com.mongodb.casbah.MongoClient@4ac17318</strong></span>
</pre></div><p>This connects to a MongoDB server on the default host (<code class="literal">localhost</code>) and default port (<code class="literal">27017</code>). To connect to a different server, pass the host and port as arguments to <code class="literal">MongoClient</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val client = MongoClient("192.168.1.1", 27017)</strong></span>
<span class="strong"><strong>client: com.mongodb.casbah.MongoClient = com.mongodb.casbah.MongoClient@584c6b02</strong></span>
</pre></div><p>Note that creating a client is a lazy operation: it does not attempt to connect to the server until it needs to. This means that if you enter the wrong URL or password, you will not know about it until you try and access documents on the server.</p><p>Once we have a connection to the server, accessing a database is as simple as using the client's <code class="literal">apply</code> method. For <a id="id339" class="indexterm"></a>instance, to access the <code class="literal">github</code> database:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val db = client("github")</strong></span>
<span class="strong"><strong>db: com.mongodb.casbah.MongoDB = DB{name='github'}</strong></span>
</pre></div><p>We can then access the <code class="literal">"users"</code> collection:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val coll = db("users")</strong></span>
<span class="strong"><strong>coll: com.mongodb.casbah.MongoCollection = users</strong></span>
</pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl2sec53"></a>Connecting with authentication</h3></div></div></div><p>MongoDB supports <a id="id340" class="indexterm"></a>several different authentication mechanisms. In this section, we will assume that your server is using the <span class="strong"><strong>SCRAM-SHA-1</strong></span> mechanism, but you should find adapting the code to a different type of authentication straightforward.</p><p>The easiest way of authenticating is to pass <code class="literal">username</code> and <code class="literal">password</code> in the URI when connecting:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val username = "USER"</strong></span>
<span class="strong"><strong>username: String = USER</strong></span>

<span class="strong"><strong>scala&gt; val password = "PASSWORD"</strong></span>
<span class="strong"><strong>password: String = PASSWORD</strong></span>

<span class="strong"><strong>scala&gt; val uri = MongoClientURI(</strong></span>
<span class="strong"><strong>  s"mongodb://$username:$password@localhost/?authMechanism=SCRAM-SHA-1"</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>uri: MongoClientURI = mongodb://USER:PASSWORD@localhost/?authMechanism=SCRAM-SHA-1</strong></span>

<span class="strong"><strong>scala&gt; val mongoClient = MongoClient(uri)</strong></span>
<span class="strong"><strong>client: com.mongodb.casbah.MongoClient = com.mongodb.casbah.MongoClient@4ac17318</strong></span>
</pre></div><p>In general, you will not want to put your password in plain text in the code. You can either prompt for a password on the command line or pass it through environment variables, as we did with the GitHub OAuth token in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>. The following code snippet <a id="id341" class="indexterm"></a>demonstrates how to pass credentials through the environment:</p><div class="informalexample"><pre class="programlisting">// Credentials.scala

import com.mongodb.casbah.Imports._

object Credentials extends App {

  val username = sys.env.getOrElse("MONGOUSER",
    throw new IllegalStateException(
      "Need a MONGOUSER variable in the environment")
  )
  val password = sys.env.getOrElse("MONGOPASSWORD",
    throw new IllegalStateException(
      "Need a MONGOPASSWORD variable in the environment")
  )

  val host = "127.0.0.1"
  val port = 27017

  val uri = s"mongodb://$username:$password@$host:$port/?authMechanism=SCRAM-SHA-1"

  val client = MongoClient(MongoClientURI(uri))
}</pre></div><p>You can run it through SBT as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ MONGOUSER="pascal" MONGOPASSWORD="scalarulez" sbt</strong></span>
<span class="strong"><strong>&gt; runMain Credentials</strong></span>
</pre></div></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec65"></a>Inserting documents</h2></div></div><hr /></div><p>Let's insert some <a id="id342" class="indexterm"></a>documents into our newly created database. We want to store information about GitHub users, using the following document structure:</p><div class="informalexample"><pre class="programlisting">{
    id: &lt;mongodb object id&gt;,
    login: "pbugnion",
    github_id: 1392879,
    repos: [ 
        {
            name: "scikit-monaco",
            id: 14821551,
            language: "Python"
        },
        {
            name: "contactpp",
            id: 20448325,
            language: "Python"
        }
    ]
}</pre></div><p>Casbah provides a <code class="literal">DBObject</code> class to represent MongoDB documents (and subdocuments) in Scala. Let's start by creating a <code class="literal">DBObject</code> instance for each repository subdocument:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val repo1 = DBObject("name" -&gt; "scikit-monaco", "id" -&gt; 14821551, "language" -&gt; "Python")</strong></span>
<span class="strong"><strong>repo1: DBObject = { "name" : "scikit-monaco" , "id" : 14821551, "language" : "Python"}</strong></span>
</pre></div><p>As you can see, a <code class="literal">DBObject</code> is just a list of key-value pairs, where the keys are strings. The values have compile-time type <code class="literal">AnyRef</code>, but Casbah will fail (at runtime) if you try to add a value that cannot be serialized.</p><p>We can also create <code class="literal">DBObject</code> instances from lists of key-value pairs directly. This is particularly useful when converting from a Scala map to a <code class="literal">DBObject</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val fields:Map[String, Any] = Map(</strong></span>
<span class="strong"><strong>  "name" -&gt; "contactpp",</strong></span>
<span class="strong"><strong>  "id" -&gt; 20448325,</strong></span>
<span class="strong"><strong>  "language" -&gt; "Python"</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>Map[String, Any] = Map(name -&gt; contactpp, id -&gt; 20448325, language -&gt; Python)</strong></span>

<span class="strong"><strong>scala&gt; val repo2 = DBObject(fields.toList)</strong></span>
<span class="strong"><strong>repo2: dDBObject = { "name" : "contactpp" , "id" : 20448325, "language" : "Python"}</strong></span>
</pre></div><p>The <code class="literal">DBObject</code> class provides <a id="id343" class="indexterm"></a>many of the same methods as a map. For instance, we can address individual fields:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; repo1("name")</strong></span>
<span class="strong"><strong>AnyRef = scikit-monaco</strong></span>
</pre></div><p>We can construct a new object by adding a field to an existing object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; repo1 + ("fork" -&gt; true)</strong></span>
<span class="strong"><strong>mutable.Map[String,Any] = { "name" : "scikit-monaco" , "id" : 14821551, "language" : "python", "fork" : true}</strong></span>
</pre></div><p>Note the return type: <code class="literal">mutable.Map[String,Any]</code>. Rather than implementing methods such as <code class="literal">+</code> directly, Casbah adds them to <code class="literal">DBObject</code> by providing an implicit conversion to and from <code class="literal">mutable.Map</code>.</p><p>New <code class="literal">DBObject</code> instances can also be created by concatenating two existing instances:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; repo1 ++ DBObject(</strong></span>
<span class="strong"><strong>  "locs" -&gt; 6342, </strong></span>
<span class="strong"><strong>  "description" -&gt; "Python library for Monte Carlo integration"</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>DBObject = { "name" : "scikit-monaco" , "id" : 14821551, "language" : "Python", "locs" : 6342 , "description" : "Python library for Monte Carlo integration"}</strong></span>
</pre></div><p>
<code class="literal">DBObject</code> instances can then be inserted into a collection using the <code class="literal">+=</code> operator. Let's insert our first document into the <code class="literal">user</code> collection:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val userDocument = DBObject(</strong></span>
<span class="strong"><strong>  "login" -&gt; "pbugnion", </strong></span>
<span class="strong"><strong>  "github_id" -&gt; 1392879, </strong></span>
<span class="strong"><strong>  "repos" -&gt; List(repo1, repo2)</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>userDocument: DBObject = { "login" : "pbugnion" , ... }</strong></span>

<span class="strong"><strong>scala&gt; val coll = MongoClient()("github")("users")</strong></span>
<span class="strong"><strong>coll: com.mongodb.casbah.MongoCollection = users</strong></span>

<span class="strong"><strong>scala&gt; coll += userDocument</strong></span>
<span class="strong"><strong>com.mongodb.casbah.TypeImports.WriteResult = WriteResult{, n=0, updateOfExisting=false, upsertedId=null}</strong></span>
</pre></div><p>A database containing a <a id="id344" class="indexterm"></a>single document is a bit boring, so let's add a few more documents queried directly from the GitHub API. You learned how to query the GitHub API in the previous chapter, so we won't dwell on how to do this here.</p><p>In the code examples for this chapter, we have provided a class called <code class="literal">GitHubUserIterator</code> that queries the GitHub API (specifically the <code class="literal">/users</code> endpoint) for user documents, converts them to a case class, and offers them as an iterator. You will find the class in the code examples for this chapter (available on GitHub at <a class="ulink" href="https://github.com/pbugnion/s4ds/tree/master/chap08" target="_blank">https://github.com/pbugnion/s4ds/tree/master/chap08</a>) in the <code class="literal">GitHubUserIterator.scala</code> file. The easiest way to have access to the class is to open an SBT console in the directory of the code examples for this chapter. The API then fetches users in increasing order of their login ID:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val it = new GitHubUserIterator</strong></span>
<span class="strong"><strong>it: GitHubUserIterator = non-empty iterator</strong></span>

<span class="strong"><strong>scala&gt; it.next // Fetch the first user</strong></span>
<span class="strong"><strong>User = User(mojombo,1,List(Repo(...</strong></span>
</pre></div><p>
<code class="literal">GitHubUserIterator</code> returns instances of the <code class="literal">User</code> case class, defined as follows:</p><div class="informalexample"><pre class="programlisting">// User.scala
case class User(login:String, id:Long, repos:List[Repo])

// Repo.scala
case class Repo(name:String, id:Long, language:String)</pre></div><p>Let's write a short program to fetch 500 users and insert them into the MongoDB database. We will need to authenticate with the GitHub API to retrieve these users. The constructor for <code class="literal">GitHubUserIterator</code> takes the GitHub OAuth token as an optional argument. We will inject the token through the environment, as we did in the previous chapter.</p><p>We first give the entire code listing before breaking it downâ€”if you are typing this out, you will need to copy <code class="literal">GitHubUserIterator.scala</code> from the code examples for this chapter to the directory in which you are running this to access the <code class="literal">GitHubUserIterator</code> class. The <a id="id345" class="indexterm"></a>class relies on <code class="literal">scalaj-http</code> and <code class="literal">json4s</code>, so either copy the <code class="literal">build.sbt</code> file from the code examples or specify those packages as dependencies in your <code class="literal">build.sbt</code> file.</p><div class="informalexample"><pre class="programlisting">// InsertUsers.scala

import com.mongodb.casbah.Imports._

object InsertUsers {

  /** Function for reading GitHub token from environment. */
  lazy val token:Option[String] = sys.env.get("GHTOKEN") orElse {
    println("No token found: continuing without authentication")
    None
  }

  /** Transform a Repo instance to a DBObject */
  def repoToDBObject(repo:Repo):DBObject = DBObject(
    "github_id" -&gt; repo.id,
    "name" -&gt; repo.name,
    "language" -&gt; repo.language
  )

  /** Transform a User instance to a DBObject */
  def userToDBObject(user:User):DBObject = DBObject(
    "github_id" -&gt; user.id,
    "login" -&gt; user.login,
    "repos" -&gt; user.repos.map(repoToDBObject)
  )

  /** Insert a list of users into a collection. */
  def insertUsers(coll:MongoCollection)(users:Iterable[User]) {
    users.foreach { user =&gt; coll += userToDBObject(user) }
  }

  /**  Fetch users from GitHub and passes them to `inserter` */
  def ingestUsers(nusers:Int)(inserter:Iterable[User] =&gt; Unit) {
    val it = new GitHubUserIterator(token)
    val users = it.take(nusers).toList
    inserter(users)
  }

  def main(args:Array[String]) {
    val coll = MongoClient()("github")("users")
    val nusers = 500
    coll.dropCollection()
    val inserter = insertUsers(coll)_
    ingestUsers(inserter)(nusers)
  }

}</pre></div><p>Before diving into the details of how this program works, let's run it through SBT. You will want to query the API with <a id="id346" class="indexterm"></a>authentication to avoid hitting the rate limit. Recall that we need to set the <code class="literal">GHTOKEN</code> environment variable:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ GHTOKEN="e83638..." sbt</strong></span>
<span class="strong"><strong>$ runMain InsertUsers</strong></span>
</pre></div><p>The program will take about five minutes to run (depending on your Internet connection). To verify that the program works, we can query the number of documents in the <code class="literal">users</code> collection of the <code class="literal">github</code> database:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ mongo github --quiet --eval "db.users.count()"</strong></span>
<span class="strong"><strong>500</strong></span>
</pre></div><p>Let's break the code down. We first load the OAuth token to authenticate with the GithHub API. The token is stored as an environment variable, <code class="literal">GHTOKEN</code>. The <code class="literal">token</code> variable is a <code class="literal">lazy val</code>, so the token is loaded only when we formulate the first request to the API. We have already used this pattern in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>.</p><p>We then define two methods to transform from classes in the domain model to <code class="literal">DBObject</code> instances:</p><div class="informalexample"><pre class="programlisting">def repoToDBObject(repo:Repo):DBObject = ...
def userToDBObject(user:User):DBObject = ...</pre></div><p>Armed with these two methods, we can add users to our MongoDB collection easily:</p><div class="informalexample"><pre class="programlisting">def insertUsers(coll:MongoCollection)(users:Iterable[User]) {
  users.foreach { user =&gt; coll += userToDBObject(user) }
}</pre></div><p>We used currying to split the arguments of <code class="literal">insertUsers</code>. This lets us use <code class="literal">insertUsers</code> as a function factory:</p><div class="informalexample"><pre class="programlisting">val inserter = insertUsers(coll)_</pre></div><p>This creates a new method, <code class="literal">inserter</code>, with signature <code class="literal">Iterable[User] =&gt; Unit</code> that inserts users into <code class="literal">coll</code>. To see how this might come in useful, let's write a function to wrap the whole data ingestion process. This is how a first attempt at this function could look:</p><div class="informalexample"><pre class="programlisting">def ingestUsers(nusers:Int)(inserter:Iterable[User] =&gt; Unit) {
  val it = new GitHubUserIterator(token)
  val users = it.take(nusers).toList
  inserter(users)
}</pre></div><p>Notice how <code class="literal">ingestUsers</code> takes a <a id="id347" class="indexterm"></a>method that specifies how the list of users is inserted into the database as its second argument. This function encapsulates the entire code specific to insertion into a MongoDB collection. If we decide, at some later date, that we hate MongoDB and must insert the documents into a SQL database or write them to a flat file, all we need to do is pass a different <code class="literal">inserter</code> function to <code class="literal">ingestUsers</code>. The rest of the code remains the same. This demonstrates the increased flexibility afforded by using higher-order functions: we can easily build a framework and let the client code plug in the components that it needs.</p><p>The <code class="literal">ingestUsers</code> method, as defined previously, has one problem: if the <code class="literal">nusers</code> value is large, it will consume a lot of memory in constructing the entire list of users. A better solution would be to break it down into batches: we fetch a batch of users from the API, insert them into the database, and move on to the next batch. This allows us to control memory usage by changing the batch size. It is also more fault tolerant: if the program crashes, we can just restart from the last successfully inserted batch.</p><p>The <code class="literal">.grouped</code> method, available on all iterables, is useful for batching. It returns an iterator over fragments of the original iterable:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val it = (0 to 10)</strong></span>
<span class="strong"><strong>it: Range.Inclusive = Range(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</strong></span>

<span class="strong"><strong>scala&gt; it.grouped(3).foreach { println } // In batches of 3</strong></span>
<span class="strong"><strong>Vector(0, 1, 2)</strong></span>
<span class="strong"><strong>Vector(3, 4, 5)</strong></span>
<span class="strong"><strong>Vector(6, 7, 8)</strong></span>
<span class="strong"><strong>Vector(9, 10)</strong></span>
</pre></div><p>Let's rewrite our <code class="literal">ingestUsers</code> method to use batches. We will also add a progress report after each batch in order to give the user some feedback:</p><div class="informalexample"><pre class="programlisting">/**  Fetch users from GitHub and pass them to `inserter` */
def ingestUsers(nusers:Int)(inserter:Iterable[User] =&gt; Unit) {
  val batchSize = 100
  val it = new GitHubUserIterator(token)
  print("Inserted #users: ")
  <span class="strong"><strong>it.take(nusers).grouped(batchSize).zipWithIndex.foreach {</strong></span>
    case (users, batchNumber) =&gt;
      print(s"${batchNumber*batchSize} ")
      inserter(users)
  }
  println()
}</pre></div><p>Let's look at the highlighted line more closely. We start from the user iterator, <code class="literal">it</code>. We then take the first <code class="literal">nusers</code>. This returns an <code class="literal">Iterator[User]</code> that, instead of happily churning through every user in the <a id="id348" class="indexterm"></a>GitHub database, will terminate after <code class="literal">nusers</code>. We then group this iterator into batches of 100 users. The <code class="literal">.grouped</code> method returns <code class="literal">Iterator[Iterator[User]]</code>. We then zip each batch with its index so that we know which batch we are currently processing (we use this in the <code class="literal">print</code> statement). The <code class="literal">.zipWithIndex</code> method returns <code class="literal">Iterator[(Iterator[User], Int)]</code>. We unpack this tuple in the loop using a case statement that binds <code class="literal">users</code> to <code class="literal">Iterator[User]</code> and <code class="literal">batchNumber</code> to the index. Let's run this through SBT:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ GHTOKEN="2502761..." sbt </strong></span>
<span class="strong"><strong>&gt; runMain InsertUsers</strong></span>
<span class="strong"><strong>[info] Running InsertUsers</strong></span>
<span class="strong"><strong>Inserted #users: 0 100 200 300 400</strong></span>
<span class="strong"><strong>[success] Total time: 215 s, completed 01-Nov-2015 18:44:30</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec66"></a>Extracting objects from the database</h2></div></div><hr /></div><p>We now have a database <a id="id349" class="indexterm"></a>populated with a few users. Let's query this database from the REPL:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import com.mongodb.casbah.Imports._</strong></span>
<span class="strong"><strong>import com.mongodb.casbah.Imports._</strong></span>

<span class="strong"><strong>scala&gt; val collection = MongoClient()("github")("users")</strong></span>
<span class="strong"><strong>MongoCollection = users</strong></span>

<span class="strong"><strong>scala&gt; val maybeUser = collection.findOne</strong></span>
<span class="strong"><strong>Option[collection.T] = Some({ "_id" : { "$oid" : "562e922546f953739c43df02"} , "github_id" : 1 , "login" : "mojombo" , "repos" : ...</strong></span>
</pre></div><p>The <code class="literal">findOne</code> method returns a single <code class="literal">DBObject</code> object wrapped in an option, unless the collection is empty, in which case it returns <code class="literal">None</code>. We must therefore use the <code class="literal">get</code> method to extract the object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val user = maybeUser.get</strong></span>
<span class="strong"><strong>collection.T = { "_id" : { "$oid" : "562e922546f953739c43df02"} , "github_id" : 1 , "login" : "mojombo" , "repos" : ...</strong></span>
</pre></div><p>As you learned earlier in this chapter, <code class="literal">DBObject</code> is a map-like object with keys of type <code class="literal">String</code> and values of type <code class="literal">AnyRef</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; user("login")</strong></span>
<span class="strong"><strong>AnyRef = mojombo</strong></span>
</pre></div><p>In general, we want to restore compile-time type information as early as possible when importing objects from the database: we do not want to pass <code class="literal">AnyRef</code>s around when we can be more specific. We <a id="id350" class="indexterm"></a>can use the <code class="literal">getAs</code> method to extract a field and cast it to a specific type:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; user.getAs[String]("login")</strong></span>
<span class="strong"><strong>Option[String] = Some(mojombo)</strong></span>
</pre></div><p>If the field is missing in the document or if the value cannot be cast, <code class="literal">getAs</code> will return <code class="literal">None</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; user.getAs[Int]("login")</strong></span>
<span class="strong"><strong>Option[Int] = None</strong></span>
</pre></div><p>The astute reader may note that the interface provided by <code class="literal">getAs[T]</code> is similar to the <code class="literal">read[T]</code> method that we defined on a JDBC result set in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Scala and SQL through JDBC</em></span>.</p><p>If <code class="literal">getAs</code> fails (for instance, because the field is missing), we can use the <code class="literal">orElse</code> partial function to recover:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val loginName = user.getAs[String]("login") orElse {       </strong></span>
<span class="strong"><strong>  println("No login field found. Falling back to 'name'")</strong></span>
<span class="strong"><strong>  user.getAs[String]("name")</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>loginName: Option[String] = Some(mojombo)</strong></span>
</pre></div><p>The <code class="literal">getAsOrElse</code> method allows us to substitute a default value if the cast fails:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; user.getAsOrElse[Int]("id", 5)</strong></span>
<span class="strong"><strong>Int = 1392879</strong></span>
</pre></div><p>Note that we can also use <code class="literal">getAsOrElse</code> to throw an exception:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; user.getAsOrElse[String]("name", </strong></span>
<span class="strong"><strong>  throw new IllegalArgumentException(</strong></span>
<span class="strong"><strong>    "Missing value for name")</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>java.lang.IllegalArgumentException: Missing value for name</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>Arrays embedded in documents <a id="id351" class="indexterm"></a>can be cast to <code class="literal">List[T]</code> objects, where <code class="literal">T</code> is the type of elements in the array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; user.getAsOrElse[List[DBObject]]("repos",</strong></span>
<span class="strong"><strong>  List.empty[DBObject])</strong></span>
<span class="strong"><strong>List[DBObject] = List({ "github_id" : 26899533 , "name" : "30daysoflaptops.github.io" ...</strong></span>
</pre></div><p>Retrieving a single document at a time is not very useful. To retrieve all the documents in a collection, use the <code class="literal">.find</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val userIterator = collection.find()</strong></span>
<span class="strong"><strong>userIterator: collection.CursorType = non-empty iterator</strong></span>
</pre></div><p>This returns an iterator of <code class="literal">DBObject</code>s. To actually fetch the documents from the database, you need to materialize the iterator by transforming it into a collection, using, for instance, <code class="literal">.toList</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val userList = userIterator.toList</strong></span>
<span class="strong"><strong>List[DBObject] = List({ "_id" : { "$oid": ...</strong></span>
</pre></div><p>Let's bring all of this together. We will write a toy program that prints the average number of repositories per user in our collection. The code works by fetching every document in the collection, extracting the number of repositories from each document, and then averaging over these:</p><div class="informalexample"><pre class="programlisting">// RepoNumber.scala

import com.mongodb.casbah.Imports._

object RepoNumber {

  /** Extract the number of repos from a DBObject
    * representing a user.
    */   
  def extractNumber(obj:DBObject):Option[Int] = {
    val repos = obj.getAs[List[DBObject]]("repos") orElse {
      println("Could not find or parse 'repos' field")
      None
    }
    repos.map { _.size }
  }

  val collection = MongoClient()("github")("users")

  def main(args:Array[String]) {    
    val userIterator = collection.find()

    // Convert from documents to Option[Int]
    val repoNumbers = userIterator.map { extractNumber }

    // Convert from Option[Int] to Int
    val wellFormattedNumbers = repoNumbers.collect { 
      case Some(v) =&gt; v 
    }.toList

    // Calculate summary statistics
    val sum = wellFormattedNumbers.reduce { _ + _ }
    val count = wellFormattedNumbers.size
    
    if (count == 0) {
      println("No repos found")
    }
    else {
      val mean = sum.toDouble / count.toDouble
      println(s"Total number of users with repos: $count")
      println(s"Total number of repos: $sum")
      println(s"Mean number of repos: $mean")
    }
  }
}</pre></div><p>Let's run this through SBT:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; runMain RepoNumber</strong></span>
<span class="strong"><strong>Total number of users with repos: 500</strong></span>
<span class="strong"><strong>Total number of repos: 9649</strong></span>
<span class="strong"><strong>Mean number of repos: 19.298</strong></span>
</pre></div><p>The code starts with the <code class="literal">extractNumber</code> function, which extracts the number of repositories from each <code class="literal">DBObject</code>. The return value is <code class="literal">None</code> if the document does not contain the <code class="literal">repos</code> field.</p><p>The main body of the code starts by creating an iterator over <code class="literal">DBObject</code>s in the collection. This iterator is then mapped through the <code class="literal">extractNumber</code> function, which transforms it into an iterator of <code class="literal">Option[Int]</code>. We then run <code class="literal">.collect</code> on this iterator to collect all the values that are not <code class="literal">None</code>, converting from <code class="literal">Option[Int]</code> to <code class="literal">Int</code> in the process. Only then do we materialize the iterator to a list using <code class="literal">.toList</code>. The resulting list, <code class="literal">wellFormattedNumbers</code>, has the <code class="literal">List[Int]</code> type. We then just take the mean of this list and print it to screen.</p><p>Note that, besides the <a id="id352" class="indexterm"></a>
<code class="literal">extractNumber</code> function, none of this program deals with Casbah-specific types: the iterator returned by <code class="literal">.find()</code> is just a Scala iterator. This makes Casbah straightforward to use: the only data type that you need to familiarize yourself with is <code class="literal">DBObject</code> (compare this with JDBC's <code class="literal">ResultSet</code>, which we had to explicitly wrap in a stream, for instance).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec67"></a>Complex queries</h2></div></div><hr /></div><p>We now know how to <a id="id353" class="indexterm"></a>convert <code class="literal">DBObject</code> instances to custom Scala classes. In this section, you will learn how to construct queries that only return a subset of the documents in the collection.</p><p>In the previous section, you learned to retrieve all the documents in a collection as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val objs = collection.find().toList</strong></span>
<span class="strong"><strong>List[DBObject] = List({ "_id" : { "$oid" : "56365cec46f9534fae8ffd7f"} ,...</strong></span>
</pre></div><p>The <code class="literal">collection.find()</code> method returns an iterator over all the documents in the collection. By calling <code class="literal">.toList</code> on this iterator, we materialize it to a list.</p><p>We can customize which documents are returned by passing a query document to the <code class="literal">.find</code> method. For instance, we can retrieve documents for a specific login name:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val query = DBObject("login" -&gt; "mojombo")</strong></span>
<span class="strong"><strong>query: DBObject = { "login" : "mojombo"}</strong></span>

<span class="strong"><strong>scala&gt; val objs = collection.find(query).toList</strong></span>
<span class="strong"><strong>List[DBObject] = List({ "_id" : { "$oid" : "562e922546f953739c43df02"} , "login" : "mojombo",...</strong></span>
</pre></div><p>MongoDB queries are expressed as <code class="literal">DBObject</code> instances. Keys in the <code class="literal">DBObject</code> correspond to fields in the collection's documents, and the values are expressions controlling the allowed values of this field. Thus, <code class="literal">DBObject("login" -&gt; "mojombo")</code> will select all the documents for which the <code class="literal">login</code> field is <code class="literal">mojombo</code>. Using a <code class="literal">DBObject</code> instance to represent a query might seem a little obscure, but it will quickly make sense if you read the MongoDB documentation (<a class="ulink" href="https://docs.mongodb.org/manual/core/crud-introduction/" target="_blank">https://docs.mongodb.org/manual/core/crud-introduction/</a>): queries are themselves just JSON objects in MongoDB. Thus, the fact that the query in Casbah is represented as a <code class="literal">DBObject</code> is consistent with other MongoDB client implementations. It also allows someone familiar with MongoDB to start writing Casbah queries in no time.</p><p>MongoDB supports more complex <a id="id354" class="indexterm"></a>queries. For instance, to query everyone with <code class="literal">"github_id"</code> between <code class="literal">20</code> and <code class="literal">30</code>, we can write the following query:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val query = DBObject("github_id" -&gt; </strong></span>
<span class="strong"><strong>  DBObject("$gte" -&gt; 20, "$lt" -&gt; 30))</strong></span>
<span class="strong"><strong>query: DBObject = { "github_id" : { "$gte" : 20 , "$lt" : 30}}</strong></span>

<span class="strong"><strong>scala&gt; collection.find(query).toList</strong></span>
<span class="strong"><strong>List[com.mongodb.casbah.Imports.DBObject] = List({ "_id" : { "$oid" : "562e922546f953739c43df0f"} , "github_id" : 23 , "login" : "takeo" , ...</strong></span>
</pre></div><p>We limit the range of values that <code class="literal">github_id</code> can take with <code class="literal">DBObject("$gte" -&gt; 20, "$lt" -&gt; 30)</code>. The <code class="literal">"$gte"</code> string indicates that <code class="literal">github_id</code> must be greater or equal to <code class="literal">20</code>. Similarly, <code class="literal">"$lt"</code> denotes the <span class="emphasis"><em>less than</em></span> operator. To get a full list of operators that you can use when <a id="id355" class="indexterm"></a>querying, consult the MongoDB reference documentation (<a class="ulink" href="http://docs.mongodb.org/manual/reference/operator/query/" target="_blank">http://docs.mongodb.org/manual/reference/operator/query/</a>).</p><p>So far, we have only looked at queries on top-level fields. Casbah also lets us query fields in subdocuments and arrays using the <span class="emphasis"><em>dot</em></span> notation. In the context of array values, this will return all the documents for which at least one value in the array matches the query. For instance, to retrieve all users who have a repository whose main language is Scala:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val query = DBObject("repos.language" -&gt; "Scala")</strong></span>
<span class="strong"><strong>query: DBObject = { "repos.language" : "Scala"}</strong></span>

<span class="strong"><strong>scala&gt; collection.find(query).toList</strong></span>
<span class="strong"><strong>List[DBObject] = List({ "_id" : { "$oid" : "5635da4446f953234ca634df"}, "login" : "kevinclark"...</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec68"></a>Casbah query DSL</h2></div></div><hr /></div><p>Using <code class="literal">DBObject</code> instances to express queries can be very verbose and somewhat difficult to read. Casbah <a id="id356" class="indexterm"></a>provides a DSL to express queries much more succinctly. For instance, to get all the documents with the <code class="literal">github_id</code> field between <code class="literal">20</code> and <code class="literal">30</code>, we would write the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; collection.find("github_id" $gte 20 $lt 30).toList</strong></span>
<span class="strong"><strong>List[com.mongodb.casbah.Imports.DBObject] = List({ "_id" : { "$oid" : "562e922546f953739c43df0f"} , "github_id" : 23 , "login" : "takeo" , "repos" : ...</strong></span>
</pre></div><p>The operators provided by the DSL will automatically construct <code class="literal">DBObject</code> instances. Using the DSL operators as much as possible generally leads to much more readable and maintainable code.</p><p>Going into the full details of the query DSL is beyond the scope of this chapter. You should find it quite easy to use. For a full list of the operators supported by the DSL, refer to the Casbah <a id="id357" class="indexterm"></a>documentation at <a class="ulink" href="http://mongodb.github.io/casbah/3.0/reference/query_dsl/" target="_blank">http://mongodb.github.io/casbah/3.0/reference/query_dsl/</a>. We summarize the most important operators here:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><thead><tr><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Operators</p>
</th><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"login" $eq "mojombo"</code>
</p>
</td><td style="" align="left" valign="top">
<p>This selects documents whose <code class="literal">login</code> field is exactly <code class="literal">mojombo</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"login" $ne "mojombo"</code>
</p>
</td><td style="" align="left" valign="top">
<p>This selects documents whose <code class="literal">login</code> field is not <code class="literal">mojombo</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"github_id" $gt 1 $lt 20</code>
</p>
</td><td style="" align="left" valign="top">
<p>This selects documents with <code class="literal">github_id</code> greater than <code class="literal">1</code> and less than <code class="literal">20</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"github_id" $gte 1 $lte 20</code>
</p>
</td><td style="" align="left" valign="top">
<p>This selects documents with <code class="literal">github_id</code> greater than or equal to <code class="literal">1</code> and less than or equal to <code class="literal">20</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"login" $in ("mojombo", "defunkt")</code>
</p>
</td><td style="" align="left" valign="top">
<p>The <code class="literal">login</code> field is either <code class="literal">mojombo</code> or <code class="literal">defunkt</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"login" $nin ("mojombo", "defunkt")</code>
</p>
</td><td style="" align="left" valign="top">
<p>The <code class="literal">login</code> field is not <code class="literal">mojombo</code> or <code class="literal">defunkt</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"login" $regex "^moj.*"</code>
</p>
</td><td style="" align="left" valign="top">
<p>The <code class="literal">login</code> field matches the particular regular expression</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">"login" $exists true</code>
</p>
</td><td style="" align="left" valign="top">
<p>The <code class="literal">login</code> field exists</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">$or("login" $eq "mojombo", "github_id" $gte 22)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Either the <code class="literal">login</code> field is <code class="literal">mojombo</code> or the <code class="literal">github_id</code> field is greater or equal to <code class="literal">22</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">$and("login" $eq "mojombo", "github_id" $gte 22)</code>
</p>
</td><td style="" align="left" valign="top">
<p>The <code class="literal">login</code> field is <code class="literal">mojombo</code> and the <code class="literal">github_id</code> field is greater or equal to <code class="literal">22</code>
</p>
</td></tr></tbody></table></div><p>We can also use the <span class="emphasis"><em>dot</em></span> notation to query arrays and subdocuments. For instance, the following query will count all <a id="id358" class="indexterm"></a>the users who have a repository in Scala:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; collection.find("repos.language" $eq "Scala").size</strong></span>
<span class="strong"><strong>Int = 30</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec69"></a>Custom type serialization</h2></div></div><hr /></div><p>So far, we have only <a id="id359" class="indexterm"></a>tried to serialize and deserialize simple types.  What if we wanted to decode the language field in the repository array to an enumeration rather than a string? We might, for instance, define the following enumeration:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; object Language extends Enumeration {</strong></span>
<span class="strong"><strong>  val Scala, Java, JavaScript = Value</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>defined object Language</strong></span>
</pre></div><p>Casbah lets us define custom serializers tied to a specific Scala type: we can inform Casbah that whenever it encounters an instance of the <code class="literal">Language.Value</code> type in a <code class="literal">DBObject</code>, the instance should be passed through a custom transformer that will convert it to, for instance, a string, before writing it to the database.</p><p>To define a custom serializer, we need to define a class that extends the <code class="literal">Transformer</code> trait. This trait exposes a single method, <code class="literal">transform(o:AnyRef):AnyRef</code>. Let's define a <code class="literal">LanguageTransformer</code> trait that transforms from <code class="literal">Language.Value</code> to <code class="literal">String</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.bson.{BSON, Transformer}</strong></span>
<span class="strong"><strong>import org.bson.{BSON, Transformer}</strong></span>

<span class="strong"><strong>scala&gt; trait LanguageTransformer extends Transformer {</strong></span>
<span class="strong"><strong>  def transform(o:AnyRef):AnyRef = o match {</strong></span>
<span class="strong"><strong>    case l:Language.Value =&gt; l.toString</strong></span>
<span class="strong"><strong>    case _ =&gt; o</strong></span>
<span class="strong"><strong>  }</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>defined trait LanguageTransformer</strong></span>
</pre></div><p>We now need to register the trait to be used whenever an instance of type <code class="literal">Language.Value</code> needs to be decoded. We can do this using the <code class="literal">addEncodingHook</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; BSON.addEncodingHook(</strong></span>
<span class="strong"><strong>  classOf[Language.Value], new LanguageTransformer {})</strong></span>
</pre></div><p>We can now construct <code class="literal">DBObject</code> instances containing values of the <code class="literal">Language</code> enumeration:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val repoObj = DBObject(</strong></span>
<span class="strong"><strong>  "github_id" -&gt; 1234L,</strong></span>
<span class="strong"><strong>  "language" -&gt; Language.Scala</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>repoObj: DBObject = { "github_id" : 1234 , "language" : "Scala"}</strong></span>
</pre></div><p>What about the reverse? How do we tell Casbah to read the <code class="literal">"language"</code> field as <code class="literal">Language.Value</code>? This is not <a id="id360" class="indexterm"></a>possible with custom deserializers: <code class="literal">"Scala"</code> is now stored as a string in the database. Thus, when it comes to deserialization, <code class="literal">"Scala"</code> is no different from, say, <code class="literal">"mojombo"</code>. We thus lose type information when <code class="literal">"Scala"</code> is serialized.</p><p>Thus, while custom encoding hooks are useful for serialization, they are much less useful when deserializing. A cleaner, more consistent alternative to customize both serialization and deserialization is to use <span class="emphasis"><em>type classes</em></span>. We have already covered how to use these extensively in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Scala and SQL through JDBC</em></span>, in the context of serializing to and from SQL. The procedure here would be very similar:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>Define a <code class="literal">MongoReader[T]</code> type class with a <code class="literal">read(v:Any)</code>:<code class="literal">T</code> method.</p></li><li><p>Define concrete implementations of <code class="literal">MongoReader</code> in the <code class="literal">MongoReader</code> companion object for all types of interest, such as <code class="literal">String</code>, <code class="literal">Language.Value</code>.</p></li><li><p>Enrich <code class="literal">DBObject</code> with a <code class="literal">read[T:MongoReader]</code> method using the <span class="emphasis"><em>pimp my library</em></span> pattern.</p></li></ol></div><p>For instance, the implementation of <code class="literal">MongoReader</code> for <code class="literal">Language.Value</code> would be as follows:</p><div class="informalexample"><pre class="programlisting">implicit object LanguageReader extends MongoReader[Language.Value] {
  def read(v:Any):Language.Value = v match {
    case s:String =&gt; Language.withName(s)
  }
}</pre></div><p>We could then do the same with a <code class="literal">MongoWriter</code> type class. Using type classes is an idiomatic and extensible approach to custom serialization and deserialization.</p><p>We provide a complete example of <a id="id361" class="indexterm"></a>type classes in the code examples associated with this chapter (in the <code class="literal">typeclass</code> directory).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec70"></a>Beyond Casbah</h2></div></div><hr /></div><p>We have only considered <a id="id362" class="indexterm"></a>Casbah in this chapter. There are, however, other drivers for MongoDB.</p><p>
<span class="emphasis"><em>ReactiveMongo</em></span> is a driver that focusses on asynchronous read and writes to and from the database. All queries return a future, forcing asynchronous behavior. This fits in well with data streams or web applications.</p><p>
<span class="emphasis"><em>Salat</em></span> sits at a higher level than Casbah and aims to provide easy serialization and deserialization of case classes.</p><p>A full list of drivers is available at <a class="ulink" href="https://docs.mongodb.org/ecosystem/drivers/scala/" target="_blank">https://docs.mongodb.org/ecosystem/drivers/scala/</a>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec71"></a>Summary</h2></div></div><hr /></div><p>In this chapter, you learned how to interact with a MongoDB database. By weaving the constructs learned in the previous chapterâ€”pulling information from a web APIâ€”with those learned in this chapter, we can now build a concurrent, reactive program for data ingestion.</p><p>In the next chapter, you will learn to build distributed, concurrent structures with greater flexibility using Akka actors.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec72"></a>References</h2></div></div><hr /></div><p>
<span class="emphasis"><em>MongoDB: The Definitive Guide</em></span>, by <span class="emphasis"><em>Kristina Chodorow</em></span>, is a good introduction to MongoDB. It does not cover interacting with MongoDB in Scala at all, but Casbah is intuitive enough for anyone familiar with MongoDB.</p><p>Similarly, the MongoDB documentation (<a class="ulink" href="https://docs.mongodb.org/manual/" target="_blank">https://docs.mongodb.org/manual/</a>) provides an in-depth discussion of MongoDB.</p><p>Casbah itself is <a id="id363" class="indexterm"></a>well-documented (<a class="ulink" href="http://mongodb.github.io/casbah/3.0/" target="_blank">http://mongodb.github.io/casbah/3.0/</a>). There is a <span class="emphasis"><em>Getting Started</em></span> guide that is somewhat similar to this chapter and a complete reference guide that will fill in the gaps left by this chapter.</p><p>This gist, <a class="ulink" href="https://gist.github.com/switzer/4218526" target="_blank">https://gist.github.com/switzer/4218526</a>, implements type classes to serialize and deserialize objects in the domain model to <code class="literal">DBObject</code>s. The premise is a little different from the suggested usage of type classes in this chapter: we are converting from Scala types to <code class="literal">AnyRef</code> to be used as values in <code class="literal">DBObject</code>. However, the two approaches are complementary: one could imagine a set of type classes to convert from <code class="literal">User</code> or <code class="literal">Repo</code> to <code class="literal">DBObject</code> and another to convert from <code class="literal">Language.Value</code> to <code class="literal">AnyRef</code>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch09"></a>ChapterÂ 9.Â Concurrency with Akka</h2></div></div></div><p>Much of this book focusses on taking advantage of multicore and distributed architectures. In <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>, you learned how to use parallel collections to distribute batch processing problems over several threads and how to perform asynchronous computations using futures. In <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, we applied this knowledge to query the GitHub API with several concurrent threads.</p><p>Concurrency abstractions such as futures and parallel collections simplify the enormous complexity of concurrent programming by limiting what you can do. Parallel collections, for instance, force you to phrase your parallelization problem as a sequence of pure functions on collections.</p><p>Actors offer a different way of thinking about concurrency. Actors are very good at encapsulating <span class="emphasis"><em>state</em></span>. Managing state shared between different threads of execution is probably the most challenging part of developing concurrent applications, and, as we will discover in this chapter, actors make it manageable.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec73"></a>GitHub follower graph</h2></div></div><hr /></div><p>In the previous <a id="id364" class="indexterm"></a>two chapters, we explored the GitHub API, learning how to query the API and parse the results using <span class="emphasis"><em>json-4s</em></span>.</p><p>Let's imagine that we want to extract the GitHub follower graph: we want a program that will start from a particular user, extract this user followers, and then extract their followers until we tell it to stop. The catch is that we don't know ahead of time what URLs we need to fetch: when we download the login names of a particular user's followers, we need to verify whether we have fetched these users previously. If not, we add them to a queue of users whose followers we need to fetch. Algorithm aficionados might recognize this as <span class="emphasis"><em>breadth-first search</em></span>.</p><p>Let's outline how we might write this in a single-threaded way. The central components are a set of visited users and queue of future users to visit:</p><div class="informalexample"><pre class="programlisting">val seedUser = "odersky" // the origin of the network

// Users whose URLs need to be fetched 
val queue = mutable.Queue(seedUser) 

// set of users that we have already fetched 
// (to avoid re-fetching them)
val fetchedUsers = mutable.Set.empty[String] 

while (queue.nonEmpty) {
  val user = queue.dequeue
  if (!fetchedUsers(user)) {
    val followers = fetchFollowersForUser(user)
    followers foreach { follower =&gt;           
      // add the follower to queue of people whose 
      // followers we want to find.
      queue += follower
    }
    fetchedUsers += user
  }
}</pre></div><p>Here, the <code class="literal">fetchFollowersForUser</code> method has signature <code class="literal">String =&gt; Iterable[String]</code> and is <a id="id365" class="indexterm"></a>responsible for taking a login name, transforming it into a URL in the GitHub API, querying the API, and extracting a list of followers from the response. We will not implement it here, but you can find a complete example in the <code class="literal">chap09/single_threaded</code> directory of the code examples for this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>). You should have all the tools to implement this yourself if you have read <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>.</p><p>While this works, it will be painfully slow. The bottleneck is clearly the <code class="literal">fetchFollowersForUser</code> method, in particular, the part that queries the GitHub API. This program does not lend itself to the concurrency constructs that we have seen earlier in the book because we need to protect the state of the program, embodied by the user queue and set of fetched users, from race conditions. Note that it is not just a matter of making the queue and set thread-safe. We must also keep the two synchronized.</p><p>
<span class="emphasis"><em>Actors</em></span> offer an elegant abstraction to encapsulate state. They are lightweight objects that each perform a single task (possibly repeatedly) and communicate with each other by passing messages. The internal state of an actor can only be changed from within the actor itself. Importantly, actors only process messages one at a time, effectively preventing race conditions.</p><p>By hiding program state inside <a id="id366" class="indexterm"></a>actors, we can reason about the program more effectively: if a bug is introduced that makes this state inconsistent, the culprit will be localized entirely in that actor.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec74"></a>Actors as people</h2></div></div><hr /></div><p>In the previous section, you learned that an actor encapsulates state, interacting with the outside world <a id="id367" class="indexterm"></a>through messages. Actors make concurrent programming more intuitive because they behave a little bit like an ideal workforce.</p><p>Let's think of an actor system representing a start-up with five people. There's Chris, the CEO, and Mark, who's in charge of marketing. Then there's Sally, who heads the engineering team. Sally has two minions, Bob and Kevin. As every good organization needs an organizational chart, refer to the following diagram:</p><div class="mediaobject"><img src="graphics/4795_09_01.jpg" /></div><p>Let's say that Chris receives an order. He will look at the order, decide whether it is something that he can process himself, and if not, he will forward it to Mark or Sally. Let's assume that the order asks for a small program so Bob forwards the order to Sally. Sally is very busy working on a backlog of orders so she cannot process the order message straightaway, and it will just sit in her mailbox for a short while. When she finally gets round to processing the order, she might decide to split the order into several parts, some of which she will give to Kevin and some to Bob.</p><p>As Bob and Kevin complete items, they will send messages back to Sally to inform her. When every part of the order is fulfilled, Sally will aggregate the parts together and message either the customer directly or Chris with the results.</p><p>The task of keeping track of <a id="id368" class="indexterm"></a>which jobs must be fulfilled to complete the order rests with Sally. When she receives messages from Bob and Kevin, she must update her list of tasks in progress and check whether every task related to this order is complete. This sort of coordination would be more challenging with traditional <span class="emphasis"><em>synchronize</em></span> blocks: every access to the list of tasks in progress and to the list of completed tasks would need to be synchronized. By embedding this logic in Sally, who can only process a single message at a time, we can be sure that there will not be race conditions.</p><p>Our start-up works well because each person is responsible for doing a single thing: Chris either delegates to Mark or Sally, Sally breaks up orders into several parts and assigns them to Bob and Kevin, and Bob and Kevin fulfill each part. You might think "hold on, all the logic is embedded in Bob and Kevin, the employees at the bottom of the ladder who do all the actual work". Actors, unlike employees, are cheap, so if the logic embedded in an actor gets too complicated, it is easy to introduce additional layers of delegation until tasks get simple enough.</p><p>The employees in our start-up refuse to multitask. When they get a piece of work, they process it completely and then move on to the next task. This means that they cannot get muddled by the complexities of multitasking. Actors, by processing a single message at a time, greatly reduce the scope for introducing concurrency errors such as race conditions.</p><p>More importantly, by offering an abstraction that programmers can intuitively understandâ€”that of human workersâ€”Akka makes reasoning about concurrency easier.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec75"></a>Hello world with Akka</h2></div></div><hr /></div><p>Let's install Akka. We <a id="id369" class="indexterm"></a>add it as a dependency to our <code class="literal">build.sbt</code> file:</p><div class="informalexample"><pre class="programlisting">scalaVersion := "2.11.7"

libraryDependencies += "com.typesafe.akka" %% "akka-actor" % "2.4.0"</pre></div><p>We can now import Akka as follows:</p><div class="informalexample"><pre class="programlisting">import akka.actor._</pre></div><p>For our first foray into the world of actors, we will build an actor that echoes every message it receives. The code examples for this section are in a directory called <code class="literal">chap09/hello_akka</code> in the sample code provided with this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>):</p><div class="informalexample"><pre class="programlisting">// EchoActor.scala
import akka.actor._

class EchoActor extends Actor with ActorLogging {
  def receive = {
    case msg:String =&gt; 
      Thread.sleep(500)
      log.info(s"Received '$msg'") 
  }
}</pre></div><p>Let's pick this example apart, starting with the constructor. Our actor class must extend <code class="literal">Actor</code>. We also add <code class="literal">ActorLogging</code>, a utility trait that adds the <code class="literal">log</code> attribute.</p><p>The <code class="literal">Echo</code> actor exposes a single method, <code class="literal">receive</code>. This is the actor's only way of communicating with the external world. To be useful, all actors must expose a <code class="literal">receive </code>method. The <code class="literal">receive</code> method is a partial function, typically implemented with multiple <code class="literal">case</code> statements. When an actor starts processing a message, it will match it against every <code class="literal">case</code> statement until it finds one that matches. It will then execute the corresponding block.</p><p>Our echo actor accepts a single type of message, a plain string. When this message gets processed, the actor waits for half a second and then echoes the message to the log file.</p><p>Let's instantiate a couple of Echo actors and send them messages:</p><div class="informalexample"><pre class="programlisting">// HelloAkka.scala

import akka.actor._

object HelloAkka extends App {

  // We need an actor system before we can 
  // instantiate actors
  val system = ActorSystem("HelloActors")

  // instantiate our two actors
  val echo1 = system.actorOf(Props[EchoActor], name="echo1")
  val echo2 = system.actorOf(Props[EchoActor], name="echo2")

  // Send them messages. We do this using the "!" operator
  echo1 ! "hello echo1"
  echo2 ! "hello echo2"
  echo1 ! "bye bye"

  // Give the actors time to process their messages, 
  // then shut the system down to terminate the program
  Thread.sleep(500)
  system.shutdown
}</pre></div><p>Running this gives us the <a id="id370" class="indexterm"></a>following output:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[INFO] [07/19/2015 17:15:23.954] [HelloActor-akka.actor.default-dispatcher-2] [akka://HelloActor/user/echo1] Received 'hello echo1'</strong></span>
<span class="strong"><strong>[INFO] [07/19/2015 17:15:23.954] [HelloActor-akka.actor.default-dispatcher-3] [akka://HelloActor/user/echo2] Received 'hello echo2'</strong></span>
<span class="strong"><strong>[INFO] [07/19/2015 17:15:24.955] [HelloActor-akka.actor.default-dispatcher-2] [akka://HelloActor/user/echo1] Received 'bye bye'</strong></span>
</pre></div><p>Note that the <code class="literal">echo1</code> and <code class="literal">echo2</code> actors are clearly acting concurrently: <code class="literal">hello echo1</code> and <code class="literal">hello echo2</code> are logged at the same time. The second message, passed to <code class="literal">echo1</code>, gets processed after the actor has finished processing <code class="literal">hello echo1</code>.</p><p>There are a few different things to note:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>To start instantiating actors, we must first create an actor system. There is typically a single actor system per application.</p></li><li style="list-style-type: disc"><p>The way in which we instantiate actors looks a little strange. Instead of calling the constructor, we create an actor properties object, <code class="literal">Props[T]</code>. We then ask the actor system to create an actor with these properties. In fact, we never instantiate actors with <code class="literal">new</code>: they are either created by calling the <code class="literal">actorOf</code> method in the actor system or a similar method from within another actor (more on this later).</p></li></ul></div><p>We never call an actor's methods <a id="id371" class="indexterm"></a>from outside that actor. The only way to interact with the actor is to send messages to it. We do this using the <span class="emphasis"><em>tell</em></span> operator, <code class="literal">!</code>. There is thus no way to mess with an actor's internals from outside that actor (or at least, Akka makes it difficult to mess with an actor's internals).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec76"></a>Case classes as messages</h2></div></div><hr /></div><p>In our "hello world" example, we <a id="id372" class="indexterm"></a>constructed an actor that is expected to receive a string as message. Any object can be passed as a message, provided it is immutable. It is very common to use case classes to represent messages. This is better than using strings because of the additional type safety: the compiler will catch a typo in a case class but not in a string.</p><p>Let's rewrite our <code class="literal">EchoActor</code> to accept instances of case classes as messages. We will make it accept two different messages: <code class="literal">EchoMessage(message)</code> and <code class="literal">EchoHello</code>, which just echoes a default message. The examples for this section and the next are in the <code class="literal">chap09/hello_akka_case_classes</code> directory in the sample code provided with this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>).</p><p>A common Akka pattern is to define the messages that an actor can receive in the actor's companion object:</p><div class="informalexample"><pre class="programlisting">// EchoActor.scala

object EchoActor { 
  case object EchoHello
  case class EchoMessage(msg:String)
}</pre></div><p>Let's change the actor definition to accept these messages:</p><div class="informalexample"><pre class="programlisting">class EchoActor extends Actor with ActorLogging {
  import EchoActor._ // import the message definitions
  def receive = {
    case EchoHello =&gt; log.info("hello")
    case EchoMessage(s) =&gt; log.info(s)  
  }
}</pre></div><p>We can now send <code class="literal">EchoHello</code> <a id="id373" class="indexterm"></a>and <code class="literal">EchoMessage</code> to our actors:</p><div class="informalexample"><pre class="programlisting">echo1 ! EchoActor.EchoHello
echo2 ! EchoActor.EchoMessage("We're learning Akka.")</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec77"></a>Actor construction</h2></div></div><hr /></div><p>Actor construction is a <a id="id374" class="indexterm"></a>common source of difficulty for people new to Akka. Unlike (most) ordinary objects, you never instantiate actors explicitly. You would never write, for instance, <code class="literal">val echo = new EchoActor</code>. In fact, if you try this, Akka raises an exception.</p><p>Creating actors in Akka is a two-step process: you first create a <code class="literal">Props</code> object, which encapsulates the properties needed to construct an actor. The way to construct a <code class="literal">Props</code> object differs depending on whether the actor takes constructor arguments. If the constructor takes no arguments, we simply pass the actor class as a type parameter to <code class="literal">Props</code>:</p><div class="informalexample"><pre class="programlisting">val echoProps = Props[EchoActor]</pre></div><p>If we have an actor whose constructor does take arguments, we must pass these as additional arguments when defining the <code class="literal">Props</code> object. Let's consider the following actor, for instance:</p><div class="informalexample"><pre class="programlisting">class TestActor<span class="strong"><strong>(a:String, b:Int)</strong></span> extends Actor { ... }</pre></div><p>We pass the constructor arguments to the <code class="literal">Props</code> object as follows:</p><div class="informalexample"><pre class="programlisting">val testProps = Props(classOf[TestActor], <span class="strong"><strong>"hello"</strong></span>, <span class="strong"><strong>2</strong></span>)</pre></div><p>The <code class="literal">Props</code> instance just embodies the configuration for creating an actor. It does not actually create anything. To create an actor, we pass the <code class="literal">Props</code> instance to the <code class="literal">system.actorOf</code> method, defined on the <code class="literal">ActorSystem</code> instance:</p><div class="informalexample"><pre class="programlisting">val system = ActorSystem("HelloActors")
val echo1 = <span class="strong"><strong>system.actorOf</strong></span>(echoProps, name="hello-1")</pre></div><p>The <code class="literal">name</code> parameter is optional but is useful for logging and error messages. The value returned by <code class="literal">.actorOf</code> is not the actor itself: it is a <span class="emphasis"><em>reference</em></span> to the actor (it helps to think of it as an address that the actor lives at) and has the <code class="literal">ActorRef</code> type. <code class="literal">ActorRef</code> is immutable, but it can be serialized and duplicated without affecting the underlying actor.</p><p>There is another way to create actors besides calling <code class="literal">actorOf</code> on the actor system: each actor exposes a <code class="literal">context.actorOf</code> method that takes a <code class="literal">Props</code> instance as its argument. The context is only accessible from within the actor:</p><div class="informalexample"><pre class="programlisting">class TestParentActor extends Actor {
  val echoChild = <span class="strong"><strong>context.actorOf</strong></span>(echoProps, name="hello-child")
  ...
}</pre></div><p>The difference between an actor <a id="id375" class="indexterm"></a>created from the actor system and an actor created from another actor's context lies in the actor hierarchy: each actor has a parent. Any actor created within another actor's context will have that actor as its parent. An actor created by the actor system has a predefined actor, called the <span class="emphasis"><em>user guardian</em></span>, as its parent. We will understand the importance of the actor hierarchy when we study the actor lifecycle at the end of this chapter.</p><p>A very common idiom is to define a <code class="literal">props</code> method in an actor's companion object that acts as a factory method for <code class="literal">Props</code> instances for that actor. Let's amend the <code class="literal">EchoActor </code>companion object:</p><div class="informalexample"><pre class="programlisting">object EchoActor {
  def props:Props = Props[EchoActor]
  
  // message case class definitions here
}</pre></div><p>We can then instantiate the actor as follows:</p><div class="informalexample"><pre class="programlisting">val echoActor = system.actorOf(EchoActor.props)</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec78"></a>Anatomy of an actor</h2></div></div><hr /></div><p>Before diving into a full-blown application, let's look at the different components of the actor framework and how they fit together:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<span class="strong"><strong>Mailbox</strong></span>: A mailbox is basically a queue. Each actor has its own mailbox.  When you send a message to an actor, the message lands in its mailbox and does nothing until the actor takes it off the queue and passes it through its <code class="literal">receive</code> method.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Messages</strong></span>: Messages make synchronization between actors possible. A message can have any type with the sole requirement that it should be immutable. In general, it is better to use case classes or case objects to gain the compiler's help in checking message types.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Actor reference</strong></span>: When we create an actor using <code class="literal">val echo1 = system.actorOf(Props[EchoActor])</code>, <code class="literal">echo1</code> has type <code class="literal">ActorRef</code>. An <code class="literal">ActorRef</code> is a proxy for an actor and is what the rest of the world interacts with: when you send a message, you send it to the <code class="literal">ActorRef</code>, not to the actor directly. In fact, you can never obtain a handle to an actor directly in Akka. An actor can obtain an <code class="literal">ActorRef</code> for itself using the <code class="literal">.self</code> method.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Actor context</strong></span>: Each actor has a <a id="id376" class="indexterm"></a>
<code class="literal">context</code> attribute through which you can access methods to create or access other actors and find information about the outside world. We have already seen how to create new actors with <code class="literal">context.actorOf(props)</code>. We can also obtain a reference to an actor's parent through <code class="literal">context.parent</code>. An actor can also stop another actor with <code class="literal">context.stop(actorRef)</code>, where <code class="literal">actorRef</code> is a reference to the actor that we want to stop.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Dispatcher</strong></span>: The dispatcher is the machine that actually executes the code in an actor. The default dispatcher uses a fork/join thread pool. Akka lets us use different dispatchers for different actors. Tweaking the dispatcher can be useful to optimize the performance and give priority to certain actors. The dispatcher that an actor runs on is accessible through <code class="literal">context.dispatcher</code>. Dispatchers implement the <code class="literal">ExecutionContext</code> interface so they can be used to run futures.</p></li></ul></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec79"></a>Follower network crawler</h2></div></div><hr /></div><p>The end game for this chapter is to build a crawler to explore GitHub's follower graph. We have already outlined how we can do this in a single-threaded manner earlier in this chapter. Let's design an actor system to do this concurrently.</p><p>The moving parts in the code are the data structures managing which users have been fetched or are being fetched. These need to be encapsulated in an actor to avoid race conditions arising from multiple actors trying to change them concurrently. We will therefore create a <span class="emphasis"><em>fetcher manager</em></span> actor whose job is to keep track of which users have been fetched and which users we are going to fetch next.</p><p>The part of the code that is likely to be a bottleneck is querying the GitHub API. We therefore want to be able to scale the number of workers doing this concurrently. We will create a pool of <span class="emphasis"><em>fetchers</em></span>, actors responsible for querying the API for the followers of a particular user. Finally, we will create an actor whose responsibility is to interpret the API's response. This actor will forward its interpretation of the response to another actor who will extract the followers and give them to the fetcher manager.</p><p>This is what the architecture of the <a id="id377" class="indexterm"></a>program will look like:</p><div class="mediaobject"><img src="graphics/4795_09_02.jpg" /><div class="caption"><p>Actor system for our GitHub API crawler</p></div></div><p>Each actor in our program performs a single task: fetchers just query the GitHub API and the queue manager just distributes work to the fetchers. Akka best practice dictates giving actors as narrow an area of responsibility as possible. This enables better granularity when scaling out (for instance, by adding more fetcher actors, we just parallelize the bottleneck) and better resilience: if an actor fails, it will only affect his area of responsibility. We will explore actor failure later on in this chapter.</p><p>We will build the app in several steps, exploring the Akka toolkit as we write the program. Let's start with the <a id="id378" class="indexterm"></a>
<code class="literal">build.sbt</code> file. Besides Akka, we will mark <code class="literal">scalaj-http</code> and <code class="literal">json4s</code> as dependencies:</p><div class="informalexample"><pre class="programlisting">// build.sbt
scalaVersion := "2.11.7"

libraryDependencies ++= Seq(
  "org.json4s" %% "json4s-native" % "3.2.10",
  "org.scalaj" %% "scalaj-http" % "1.1.4",
  "com.typesafe.akka" %% "akka-actor" % "2.3.12"
)</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec80"></a>Fetcher actors</h2></div></div><hr /></div><p>The workhorse of our <a id="id379" class="indexterm"></a>application is the fetcher, the actor responsible for fetching the follower details from GitHub. In the first instance, our actor will accept a single message, <code class="literal">Fetch(user)</code>. It will fetch the followers corresponding to <code class="literal">user</code> and log the response to screen. We will use the recipes developed in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, to query the GitHub API with an OAuth token. We will inject the token through the actor constructor.</p><p>Let's start with the companion object. This will contain the definition of the <code class="literal">Fetch(user)</code> message and two factory methods to create the <code class="literal">Props</code> instances. You can find the code examples for this section in the <code class="literal">chap09/fetchers_alone</code> directory in the sample code provided with this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>):</p><div class="informalexample"><pre class="programlisting">// Fetcher.scala
import akka.actor._
import scalaj.http._
import scala.concurrent.Future

object Fetcher {
  // message definitions
  case class Fetch(login:String)

  // Props factory definitions
  def props(token:Option[String]):Props = 
    Props(classOf[Fetcher], token)
  def props():Props = Props(classOf[Fetcher], None)
}</pre></div><p>Let's now define the fetcher itself. We will wrap the call to the GitHub API in a future. This avoids a single slow request blocking the actor. When our actor receives a <code class="literal">Fetch</code> request, it wraps this request into a future, sends it off, and can then process the next message. Let's go ahead <a id="id380" class="indexterm"></a>and implement our actor:</p><div class="informalexample"><pre class="programlisting">// Fetcher.scala
class Fetcher(val token:Option[String])
extends Actor with ActorLogging {
  import Fetcher._ // import message definition

  // We will need an execution context for the future.
  // Recall that the dispatcher doubles up as execution
  // context.
  import context.dispatcher

  def receive = {
    case Fetch(login) =&gt; fetchUrl(login)
  }

  private def fetchUrl(login:String) {
    val unauthorizedRequest = Http(
      s"https://api.github.com/users/$login/followers")
    val authorizedRequest = token.map { t =&gt;
      unauthorizedRequest.header("Authorization", s"token $t")
    }

    // Prepare the request: try to use the authorized request
    // if a token was given, and fall back on an unauthorized 
    // request
    val request = authorizedRequest.getOrElse(unauthorizedRequest)

    // Fetch from github
    val response = Future { request.asString }
    response.onComplete { r =&gt;
      log.info(s"Response from $login: $r")
    }
  }

}</pre></div><p>Let's instantiate an actor system and four fetchers to check whether our actor is working as expected. We will read the GitHub token from the environment, as described in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, then create four actors and ask each one to fetch the followers of a particular GitHub user. We wait five seconds for the requests to get completed, and <a id="id381" class="indexterm"></a>then shut the system down:</p><div class="informalexample"><pre class="programlisting">// FetcherDemo.scala
import akka.actor._

object FetcherDemo extends App {
  import Fetcher._ // Import the messages

  val system = ActorSystem("fetchers")

  // Read the github token if present.
  val token = sys.env.get("GHTOKEN")

  val fetchers = (0 until 4).map { i =&gt;
    system.actorOf(Fetcher.props(token))
  }

  fetchers(0) ! Fetch("odersky")
  fetchers(1) ! Fetch("derekwyatt")
  fetchers(2) ! Fetch("rkuhn")
  fetchers(3) ! Fetch("tototoshi")

  Thread.sleep(5000) // Wait for API calls to finish
  system.shutdown // Shut system down

}</pre></div><p>Let's run the code through SBT:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ GHTOKEN="2502761..." sbt run</strong></span>
<span class="strong"><strong>[INFO] [11/08/2015 16:28:06.500] [fetchers-akka.actor.default-dispatcher-2] [akka://fetchers/user/$d] Response from tototoshi: Success(HttpResponse([{"login":"akr4","id":10892,"avatar_url":"https://avatars.githubusercontent.com/u/10892?v=3","gravatar_id":""...</strong></span>
</pre></div><p>Notice how we explicitly need to shut the actor system down using <code class="literal">system.shutdown</code>. The program hangs until the system is shut down. However, shutting down the system will stop all the actors, so we need to make sure that they have finished working. We do this by inserting a call to <code class="literal">Thread.sleep</code>.</p><p>Using <code class="literal">Thread.sleep</code> to wait until the <a id="id382" class="indexterm"></a>API calls have finished to shut down the actor system is a little crude. A better approach could be to let the actors signal back to the system that they have completed their task. We will see examples of this pattern later when we implement the <span class="emphasis"><em>fetcher manager</em></span> actor.</p><p>Akka includes a feature-rich <span class="emphasis"><em>scheduler</em></span> to schedule events. We can use the scheduler to replace the call to <code class="literal">Thread.sleep</code> by scheduling a system shutdown five seconds in the future. This is preferable as the scheduler does not block the calling thread, unlike <code class="literal">Thread.sleep</code>. To use the scheduler, we need to import a global execution context and the duration module:</p><div class="informalexample"><pre class="programlisting">// FetcherDemoWithScheduler.scala

import scala.concurrent.ExecutionContext.Implicits.global
import scala.concurrent.duration._</pre></div><p>We can then schedule a system shutdown by replacing our call to <code class="literal">Thread.sleep</code> with the following:</p><div class="informalexample"><pre class="programlisting">system.scheduler.scheduleOnce(5.seconds) { system.shutdown }</pre></div><p>Besides <code class="literal">scheduleOnce</code>, the scheduler also exposes a <code class="literal">schedule</code> method that lets you schedule events to happen regularly (every two seconds, for instance). This is useful for heartbeat checks or monitoring systems. For more information, read the API documentation on the scheduler available at <a class="ulink" href="http://doc.akka.io/docs/akka/snapshot/scala/scheduler.html" target="_blank">http://doc.akka.io/docs/akka/snapshot/scala/scheduler.html</a>.</p><p>Note that we are actually cheating a little bit here by not fetching every follower. The response to the follower's query is actually paginated, so we would need to fetch several pages to fetch all the followers. Adding logic to the actor to do this is not terribly complicated. We will ignore this for now and assume that users are capped at 100 followers each.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec81"></a>Routing</h2></div></div><hr /></div><p>In the previous example, we created <a id="id383" class="indexterm"></a>four fetchers and dispatched messages to them, one after the other. We have a pool of identical actors among which we distribute tasks. Manually routing the messages to the right actor to maximize the utilization of our pool is painful and error-prone. Fortunately, Akka provides us with several routing strategies that we can use to distribute work among our pool of actors. Let's rewrite the previous example with automatic routing. You can find the code examples for this section in the <code class="literal">chap09/fetchers_routing</code> directory in the sample code provided with this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>). We will reuse the same definition of <code class="literal">Fetchers</code> and its companion object as we did in the previous section.</p><p>Let's start by importing the routing package:</p><div class="informalexample"><pre class="programlisting">// FetcherDemo.scala
import akka.routing._</pre></div><p>A <span class="emphasis"><em>router</em></span> is an actor that forwards the messages that it receives to its children. The easiest way to define a pool of actors is to tell Akka to create a router and pass it a <code class="literal">Props</code> object for its children. The router will then manage the creation of the workers directly. In our example (we will only comment on the parts that differ from the previous example in the text, but you can find the full code in the <code class="literal">fetchers_routing</code> directory with the examples for this chapter), we replace the custom <code class="literal">Fetcher</code> creation code with the following:</p><div class="informalexample"><pre class="programlisting">// FetcherDemo.scala

// Create a router with 4 workers of props Fetcher.props()
val router = system.actorOf(
  RoundRobinPool(4).props(Fetcher.props(token))
)</pre></div><p>We can then send the fetch messages directly to the router. The router will route the messages to the children in a round-robin manner:</p><div class="informalexample"><pre class="programlisting">List("odersky", "derekwyatt", "rkuhn", "tototoshi").foreach { 
  login =&gt; router ! Fetch(login)
}</pre></div><p>We used a round-robin router in this example. Akka offers many different types of routers, including routers with dynamic pool size, to cater to different types of load balancing. Head over to the Akka documentation for a list of all the available routers, at <a class="ulink" href="http://doc.akka.io/docs/akka/snapshot/scala/routing.html" target="_blank">http://doc.akka.io/docs/akka/snapshot/scala/routing.html</a>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec82"></a>Message passing between actors</h2></div></div><hr /></div><p>Merely logging the API <a id="id384" class="indexterm"></a>response is not very useful. To traverse the follower graph, we must perform the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Check the return code of the response to make sure that the GitHub API was happy with our request</p></li><li style="list-style-type: disc"><p>Parse the response as JSON</p></li><li style="list-style-type: disc"><p>Extract the login names of the followers and, if we have not fetched them already, push them into the queue</p></li></ul></div><p>You learned how to do all these things in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, but not in the context of actors.</p><p>We could just add the additional processing steps to the <code class="literal">receive</code> method of our <code class="literal">Fetcher</code> actor: we could add further transformations to the API response by future composition. However, having actors do several different things, and possibly failing in several different ways, is an anti-pattern: when we learn about managing the actor life cycle, we will see that it becomes much more difficult to reason about our actor systems if the actors contain several bits of logic.</p><p>We will therefore use a pipeline of three different actors:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The fetchers, which we have already encountered, are responsible just for fetching a URL from GitHub. They will fail if the URL is badly formatted or they cannot access the GitHub API.</p></li><li style="list-style-type: disc"><p>The response interpreter is responsible for taking the response from the GitHub API and parsing it to JSON. If it fails at any step, it will just log the error (in a real application, we might take different corrective actions depending on the type of failure). If it manages to extract JSON successfully, it will pass the JSON array to the follower extractor.</p></li><li style="list-style-type: disc"><p>The follower extractor will extract the followers from the JSON array and pass them on to the queue of users whose followers we need to fetch.</p></li></ul></div><p>We have already built the fetchers, though we will need to modify them to forward the API response to the response interpreter rather than just logging it.</p><p>You can find the code examples for this section in the <code class="literal">chap09/all_workers</code> directory in the sample code provided with this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>).The first step is to modify the fetchers so that, instead of logging the response, they forward the response to the response interpreter. To be able to forward the response to the response <a id="id385" class="indexterm"></a>interpreter, the fetchers will need a reference to this actor. We will just pass the reference to the response interpreter through the fetcher constructor, which is now:</p><div class="informalexample"><pre class="programlisting">// Fetcher.scala
class Fetcher(
  val token:Option[String], 
  val responseInterpreter:ActorRef) 
extends Actor with ActorLogging {
  ...
}</pre></div><p>We must also modify the <code class="literal">Props</code> factory method in the companion object:</p><div class="informalexample"><pre class="programlisting">// Fetcher.scala
def props(
  token:Option[String], responseInterpreter:ActorRef
):Props = Props(classOf[Fetcher], token, responseInterpreter)</pre></div><p>We must also modify the <code class="literal">receive</code> method to forward the HTTP response to the interpreter rather than just logging it:</p><div class="informalexample"><pre class="programlisting">// Fetcher.scala
class Fetcher(...) extends Actor with ActorLogging {
  ...
  def receive = {
    case Fetch(login) =&gt; fetchFollowers(login)
  }

  private def fetchFollowers(login:String) {
    val unauthorizedRequest = Http(
      s"https://api.github.com/users/$login/followers")
    val authorizedRequest = token.map { t =&gt;
      unauthorizedRequest.header("Authorization", s"token $t")
    }

    val request = authorizedRequest.getOrElse(unauthorizedRequest)
    val response = Future { request.asString }

    // Wrap the response in an InterpretResponse message and
    // forward it to the interpreter.
    response.onComplete { r =&gt;
      responseInterpreter !
        ResponseInterpreter.InterpretResponse(login, r)
    }
  }
}</pre></div><p>The <span class="emphasis"><em>response interpreter</em></span> takes the response, decides if it is valid, parses it to JSON, and forwards it to a follower extractor. The response interpreter will need a reference to the follower extractor, which we will <a id="id386" class="indexterm"></a>pass in the constructor.</p><p>Let's start by defining the <code class="literal">ResponseInterpreter</code> companion. It will just contain the definition of the messages that the response interpreter can receive and a factory to create a <code class="literal">Props</code> object to help with instantiation:</p><div class="informalexample"><pre class="programlisting">// ResponseInterpreter.scala
import akka.actor._
import scala.util._

import scalaj.http._
import org.json4s._
import org.json4s.native.JsonMethods._

object ResponseInterpreter {

  // Messages
  case class InterpretResponse(
    login:String, response:Try[HttpResponse[String]]
  )

  // Props factory
  def props(followerExtractor:ActorRef) = 
    Props(classOf[ResponseInterpreter], followerExtractor)
}</pre></div><p>The body of <code class="literal">ResponseInterpreter</code> should feel familiar: when the actor receives a message giving it a response to interpret, it parses it to JSON using the techniques that you learned in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>. If we parse the response successfully, we forward the parsed JSON to the follower extractor. If we fail to parse the response (possibly because it was badly formatted), we just log the error. We could recover from this in other ways, for instance, by re-adding this login to the queue manager to be fetched again:</p><div class="informalexample"><pre class="programlisting">// ResponseInterpreter.scala
class ResponseInterpreter(followerExtractor:ActorRef) 
extends Actor with ActorLogging {
  // Import the message definitions
  import ResponseInterpreter._

  def receive = {
    case InterpretResponse(login, r) =&gt; interpret(login, r)
  }

  // If the query was successful, extract the JSON response
  // and pass it onto the follower extractor.
  // If the query failed, or is badly formatted, throw an error
  // We should also be checking error codes here.
  private def interpret(
    login:String, response:Try[HttpResponse[String]]
  ) = response match {
    case Success(r) =&gt; responseToJson(r.body) match {
      case Success(jsonResponse) =&gt; 
        followerExtractor ! FollowerExtractor.Extract(
          login, jsonResponse)
      case Failure(e) =&gt; 
        log.error(
          s"Error parsing response to JSON for $login: $e")
    }
    case Failure(e) =&gt; log.error(
      s"Error fetching URL for $login: $e")
  }

  // Try and parse the response body as JSON. 
  // If successful, coerce the `JValue` to a `JArray`.
  private def responseToJson(responseBody:String):Try[JArray] = {
    val jvalue = Try { parse(responseBody) }
    jvalue.flatMap {
      case a:JArray =&gt; Success(a)
      case _ =&gt; Failure(new IllegalStateException(
        "Incorrectly formatted JSON: not an array"))
    }
  }
}</pre></div><p>We now have two-thirds of our <a id="id387" class="indexterm"></a>worker actors. The last link is the follower extractor. This actor's job is simple: it takes the <code class="literal">JArray</code> passed to it by the response interpreter and converts it to a list of followers. For now, we will just log this list, but when we build our fetcher manager, the follower extractor will send messages asking the manager to add the followers to its queue of logins to fetch.</p><p>As before, the companion just defines the messages that this actor can receive and a Props factory method:</p><div class="informalexample"><pre class="programlisting">// FollowerExtractor.scala
import akka.actor._

import org.json4s._
import org.json4s.native.JsonMethods._

object FollowerExtractor {
  
  // Messages
  case class Extract(login:String, jsonResponse:JArray)

  // Props factory method
  def props = Props[FollowerExtractor]
}</pre></div><p>The <code class="literal">FollowerExtractor</code> class receives <code class="literal">Extract</code> messages containing a <code class="literal">JArray</code> of information representing a follower. It <a id="id388" class="indexterm"></a>extracts the <code class="literal">login</code> field and logs it:</p><div class="informalexample"><pre class="programlisting">class FollowerExtractor extends Actor with ActorLogging {
  import FollowerExtractor._
  def receive = {
    case Extract(login, followerArray) =&gt; {
      val followers = extractFollowers(followerArray)
      log.info(s"$login -&gt; ${followers.mkString(", ")}")
    }
  }

  def extractFollowers(followerArray:JArray) = for {
    JObject(follower) &lt;- followerArray
    JField("login", JString(login)) &lt;- follower
  } yield login
}</pre></div><p>Let's write a new <code class="literal">main</code> method to exercise all our actors:</p><div class="informalexample"><pre class="programlisting">// FetchNetwork.scala

import akka.actor._
import akka.routing._
import scala.concurrent.ExecutionContext.Implicits.global
import scala.concurrent.duration._

object FetchNetwork extends App {

  import Fetcher._ // Import messages and factory method

  // Get token if exists
  val token = sys.env.get("GHTOKEN")

  val system = ActorSystem("fetchers")

  // Instantiate actors
  val followerExtractor = system.actorOf(FollowerExtractor.props)
  val responseInterpreter =   
    system.actorOf(ResponseInterpreter.props(followerExtractor))

  val router = system.actorOf(RoundRobinPool(4).props(
    Fetcher.props(token, responseInterpreter))
  )

  List("odersky", "derekwyatt", "rkuhn", "tototoshi") foreach {
    login =&gt; router ! Fetch(login)
  }

  // schedule a shutdown
  system.scheduler.scheduleOnce(5.seconds) { system.shutdown }

}</pre></div><p>Let's run <a id="id389" class="indexterm"></a>this through SBT:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ GHTOKEN="2502761d..." sbt run</strong></span>
<span class="strong"><strong>[INFO] [11/05/2015 20:09:37.048] [fetchers-akka.actor.default-dispatcher-3] [akka://fetchers/user/$a] derekwyatt -&gt; adulteratedjedi, joonas, Psycojoker, trapd00r, tyru, ...</strong></span>
<span class="strong"><strong>[INFO] [11/05/2015 20:09:37.050] [fetchers-akka.actor.default-dispatcher-3] [akka://fetchers/user/$a] tototoshi -&gt; akr4, yuroyoro, seratch, yyuu, ...</strong></span>
<span class="strong"><strong>[INFO] [11/05/2015 20:09:37.051] [fetchers-akka.actor.default-dispatcher-3] [akka://fetchers/user/$a] odersky -&gt; misto, gkossakowski, mushtaq, ...</strong></span>
<span class="strong"><strong>[INFO] [11/05/2015 20:09:37.052] [fetchers-akka.actor.default-dispatcher-3] [akka://fetchers/user/$a] rkuhn -&gt; arnbak, uzoice, jond3k, TimothyKlim, relrod, ...</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec83"></a>Queue control and the pull pattern</h2></div></div><hr /></div><p>We have now defined <a id="id390" class="indexterm"></a>the three worker actors in our crawler application. The next step is to define the manager. The <span class="emphasis"><em>fetcher manager</em></span> is responsible for keeping a queue of logins to fetch as well as a set of login names that we have already seen in order to avoid fetching the same logins more than once.</p><p>A first attempt might involve building an actor that keeps a set of users that we have already seen and just dispatches it to a round-robin router for fetchers when it is given a new user to fetch. The problem with this approach is that the number of messages in the fetchers' mailboxes would accumulate quickly: for each API query, we are likely to get tens of followers, each of which is likely to make it back to a fetcher's inbox. This gives us very little control over the amount of work piling up.</p><p>The first problem that this is likely to cause involves the GitHub API rate limit: even with authentication, we are limited to 5,000 requests per hour. It would be useful to stop queries as soon as we hit this threshold. We cannot be responsive if each fetcher has a backlog of hundreds of users that they need to fetch.</p><p>A better alternative is to use a <span class="emphasis"><em>pull</em></span> system: the fetchers request work from a central queue when they find themselves idle. Pull systems are common in Akka when we have a producer that produces work faster than consumers can process it (refer to <a class="ulink" href="http://www.michaelpollmeier.com/akka-work-pulling-pattern/" target="_blank">http://www.michaelpollmeier.com/akka-work-pulling-pattern/</a>).</p><p>Conversations between the manager and fetchers will proceed as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>If the manager goes from a state of having no work to having work, it sends a <code class="literal">WorkAvailable</code> message to all the fetchers.</p></li><li style="list-style-type: disc"><p>Whenever a fetcher receives a <code class="literal">WorkAvailable</code> message or when it completes an item of work, it sends a <code class="literal">GiveMeWork</code> message to the queue manager.</p></li><li style="list-style-type: disc"><p>When the queue manager receives a <code class="literal">GiveMeWork</code> message, it ignores the request if no work is available or it is throttled. If it has work, it sends a <code class="literal">Fetch(user)</code> message to the actor.</p></li></ul></div><p>Let's start by modifying our fetcher. You can find the code examples for this section in the <code class="literal">chap09/ghub_crawler</code> directory in the sample code provided with this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>). We will pass a reference to the fetcher manager through the constructor. We need to change the companion object to add the <code class="literal">WorkAvailable</code> message and the <code class="literal">props</code> factory to include the reference to the manager:</p><div class="informalexample"><pre class="programlisting">// Fecther.scala
object Fetcher {
  case class Fetch(url:String)
  case object WorkAvailable

  def props(
    token:Option[String], 
    fetcherManager:ActorRef, 
    responseInterpreter:ActorRef):Props =
      Props(classOf[Fetcher], 
        token, fetcherManager, responseInterpreter)
}</pre></div><p>We also need to change the <code class="literal">receive</code> method so that it queries the <code class="literal">FetcherManager</code> asking for more work once it's <a id="id391" class="indexterm"></a>done processing a request or when it receives a <code class="literal">WorkAvailable</code> message.</p><p>This is the final version of the fetchers:</p><div class="informalexample"><pre class="programlisting">class Fetcher(
  val token:Option[String], 
  val fetcherManager:ActorRef,
  val responseInterpreter:ActorRef) 
extends Actor with ActorLogging {
  import Fetcher._
  import context.dispatcher

  def receive = {
    case Fetch(login) =&gt; fetchFollowers(login)
    case WorkAvailable =&gt; 
      fetcherManager ! FetcherManager.GiveMeWork
  }

  private def fetchFollowers(login:String) {
    val unauthorizedRequest = Http(
      s"https://api.github.com/users/$login/followers")
    val authorizedRequest = token.map { t =&gt;
      unauthorizedRequest.header("Authorization", s"token $t")
    }
    val request = authorizedRequest.getOrElse(unauthorizedRequest)
    val response = Future { request.asString }

    response.onComplete { r =&gt;
      responseInterpreter ! 
        ResponseInterpreter.InterpretResponse(login, r)
      fetcherManager ! FetcherManager.GiveMeWork
    }
  }

}</pre></div><p>Now that we have a working definition of the fetchers, let's build the <code class="literal">FetcherManager</code>. This is the most <a id="id392" class="indexterm"></a>complex actor that we have built so far, and, before we dive into building it, we need to learn a bit more about the components of the Akka toolkit.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec84"></a>Accessing the sender of a message</h2></div></div><hr /></div><p>When our fetcher <a id="id393" class="indexterm"></a>manager receives a <code class="literal">GiveMeWork</code> request, we will need to send work back to the correct fetcher. We can access the actor who sent a message using the <code class="literal">sender</code> method, which is a method of <code class="literal">Actor</code> that returns the <code class="literal">ActorRef</code> corresponding to the actor who sent the message currently being processed. The <code class="literal">case</code> statement corresponding to <code class="literal">GiveMeWork</code> in the fetcher manager is therefore:</p><div class="informalexample"><pre class="programlisting">def receive = {
  case GiveMeWork =&gt;
    login = // get next login to fetch
    <span class="strong"><strong>sender ! Fetcher.Fetch(login)</strong></span>
  ...
}</pre></div><p>As <code class="literal">sender</code> is a <span class="emphasis"><em>method</em></span>, its return value will change for every new incoming message. It should therefore only be used synchronously with the <code class="literal">receive</code> method. In particular, using it in a future is dangerous:</p><div class="informalexample"><pre class="programlisting">def receive = {
  case DoSomeWork =&gt;
    val work = Future { Thread.sleep(20000) ; 5 }
    work.onComplete { result =&gt; 
      <span class="strong"><strong>sender ! Complete(result)</strong></span> // NO!
    }
}</pre></div><p>The problem is that when the future is completed 20 seconds after the message is processed, the actor will, in all likelihood, be processing a different message so the return value of <code class="literal">sender</code> will have changed. We will thus send the <code class="literal">Complete</code> message to a completely different actor.</p><p>If you need to reply to a message outside of the <code class="literal">receive</code> method, such as when a future completes, you should bind the <a id="id394" class="indexterm"></a>value of the current sender to a variable:</p><div class="informalexample"><pre class="programlisting">def receive = {
  case DoSomeWork =&gt;
    // bind the current value of sender to a val
    <span class="strong"><strong>val requestor = sender</strong></span>
    val work = Future { Thread.sleep(20000) ; 5 }
    work.onComplete { result =&gt; requestor ! Complete(result) }
}</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec85"></a>Stateful actors</h2></div></div><hr /></div><p>The behavior of the fetcher <a id="id395" class="indexterm"></a>manager depends on whether it has work to give out to the fetchers:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>If it has work to give, it needs to respond to <code class="literal">GiveMeWork</code> messages with a <code class="literal">Fetcher.Fetch</code> message</p></li><li style="list-style-type: disc"><p>If it does not have work, it must ignore the <code class="literal">GiveMeWork</code> messages and, if work gets added, it must send a <code class="literal">WorkAvailable</code> message to the fetchers</p></li></ul></div><p>Encoding the notion of state is straightforward in Akka. We specify different <code class="literal">receive</code> methods and switch from one to the other depending on the state. We will define the following <code class="literal">receive</code> methods for our fetcher manager, corresponding to each of the states:</p><div class="informalexample"><pre class="programlisting">// receive method when the queue is empty
def receiveWhileEmpty: Receive = { 
    ... 
}

// receive method when the queue is not empty
def receiveWhileNotEmpty: Receive = {
    ...
}</pre></div><p>Note that we must define the return type of the receive methods as <code class="literal">Receive</code>. To switch the actor from one method to the other, we can use <code class="literal">context.become(methodName)</code>. Thus, for instance, when the last login name is popped off the queue, we can transition to using the <code class="literal">receiveWhileEmpty</code> method with <code class="literal">context.become(receiveWhileEmpty)</code>. We set the initial state by assigning <code class="literal">receiveWhileEmpty</code> to the <code class="literal">receive</code> method:</p><div class="informalexample"><pre class="programlisting">def receive = receiveWhileEmpty</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec86"></a>Follower network crawler</h2></div></div><hr /></div><p>We are now ready to code <a id="id396" class="indexterm"></a>up the remaining pieces of our network crawler. The largest missing piece is the fetcher manager. Let's start with the companion object. As with the worker actors, this just contains the definitions of the messages that the actor can receive and a factory to create the <code class="literal">Props</code> instance:</p><div class="informalexample"><pre class="programlisting">// FetcherManager.scala
import scala.collection.mutable
import akka.actor._

object FetcherManager {
  case class AddToQueue(login:String)
  case object GiveMeWork

  def props(token:Option[String], nFetchers:Int) = 
    Props(classOf[FetcherManager], token, nFetchers)
}</pre></div><p>The manager can receive two messages: <code class="literal">AddToQueue</code>, which tells it to add a username to the queue of users whose followers need to be fetched, and <code class="literal">GiveMeWork</code>, emitted by the fetchers when they are unemployed.</p><p>The manager will be responsible for launching the fetchers, response interpreter, and follower extractor, as well as maintaining an internal queue of usernames and a set of usernames that we have seen:</p><div class="informalexample"><pre class="programlisting">// FetcherManager.scala

class FetcherManager(val token:Option[String], val nFetchers:Int) 
extends Actor with ActorLogging {

  import FetcherManager._

  // queue of usernames whose followers we need to fetch
  val fetchQueue = mutable.Queue.empty[String]

  // set of users we have already fetched. 
  val fetchedUsers = mutable.Set.empty[String]

  // Instantiate worker actors
  val followerExtractor = context.actorOf(
    FollowerExtractor.props(self))
  val responseInterpreter = context.actorOf(
    ResponseInterpreter.props(followerExtractor))
  val fetchers = (0 until nFetchers).map { i =&gt;
    context.actorOf(
      Fetcher.props(token, self, responseInterpreter))
  }

  // receive method when the actor has work:
  // If we receive additional work, we just push it onto the
  // queue.
  // If we receive a request for work from a Fetcher,
  // we pop an item off the queue. If that leaves the 
  // queue empty, we transition to the 'receiveWhileEmpty'
  // method.
  def receiveWhileNotEmpty:Receive = {
    case AddToQueue(login) =&gt; queueIfNotFetched(login)
    case GiveMeWork =&gt;
      val login = fetchQueue.dequeue
      // send a Fetch message back to the sender.
      // we can use the `sender` method to reply to a message
      sender ! Fetcher.Fetch(login)
      if (fetchQueue.isEmpty) { 
        context.become(receiveWhileEmpty) 
      }
  }

  // receive method when the actor has no work:
  // if we receive work, we add it onto the queue, transition
  // to a state where we have work, and notify the fetchers
  // that work is available.
  def receiveWhileEmpty:Receive = {
    case AddToQueue(login) =&gt;
      queueIfNotFetched(login)
      context.become(receiveWhileNotEmpty)
      fetchers.foreach { _ ! Fetcher.WorkAvailable }
    case GiveMeWork =&gt; // do nothing
  }

  // Start with an empty queue.
  def receive = receiveWhileEmpty

  def queueIfNotFetched(login:String) {
    if (! fetchedUsers(login)) {
      log.info(s"Pushing $login onto queue") 
      // or do something useful...
      fetchQueue += login
      fetchedUsers += login
    }
  }
}</pre></div><p>We now have a fetcher manager. The rest of the code can remain the same, apart from the follower extractor. Instead <a id="id397" class="indexterm"></a>of logging followers names, it must send <code class="literal">AddToQueue</code> messages to the manager. We will pass a reference to the manager at construction time:</p><div class="informalexample"><pre class="programlisting">// FollowerExtractor.scala
import akka.actor._
import org.json4s._
import org.json4s.native.JsonMethods._

object FollowerExtractor {
  
  // messages
  case class Extract(login:String, jsonResponse:JArray)

  // props factory method
  def props(manager:ActorRef) = 
    Props(classOf[FollowerExtractor], manager)
}

class FollowerExtractor(manager:ActorRef)
extends Actor with ActorLogging {
  import FollowerExtractor._
  
  def receive = {
    case Extract(login, followerArray) =&gt;
      val followers = extractFollowers(followerArray)
      followers foreach { f =&gt; 
        <span class="strong"><strong>manager ! FetcherManager.AddToQueue(f) </strong></span>
      }
  }

  def extractFollowers(followerArray:JArray) = for {
    JObject(follower) &lt;- followerArray
    JField("login", JString(login)) &lt;- follower
  } yield login

}</pre></div><p>The <code class="literal">main</code> method running all this is remarkably simple as all the code to instantiate actors has been moved to the <code class="literal">FetcherManager</code>. We just need to instantiate the manager and give it the first node in the network, and it will do the rest:</p><div class="informalexample"><pre class="programlisting">// FetchNetwork.scala
import akka.actor._

object FetchNetwork extends App {

  // Get token if exists
  val token = sys.env.get("GHTOKEN")

  val system = ActorSystem("GithubFetcher")
  val manager = system.actorOf(FetcherManager.props(token, 2))
  manager ! FetcherManager.AddToQueue("odersky")

}</pre></div><p>Notice how we do not attempt to <a id="id398" class="indexterm"></a>shut down the actor system anymore. We will just let it run, crawling the network, until we stop it or hit the authentication limit. Let's run this through SBT:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ GHTOKEN="2502761d..." sbt "runMain FetchNetwork"</strong></span>
<span class="strong"><strong>[INFO] [11/06/2015 06:31:04.614] [GithubFetcher-akka.actor.default-dispatcher-2] [akka://GithubFetcher/user/$a] Pushing odersky onto queue</strong></span>
<span class="strong"><strong>[INFO] [11/06/2015 06:31:05.563] [GithubFetcher-akka.actor.default-dispatcher-4] [akka://GithubFetcher/user/$a] Pushing misto onto queueINFO] [11/06/2015 06:31:05.563] [GithubFetcher-akka.actor.default-dispatcher-4] [akka://GithubFetcher/user/$a] Pushing gkossakowski onto queue</strong></span>
<span class="strong"><strong>^C</strong></span>
</pre></div><p>Our program does not actually do anything useful with the followers that it retrieves besides logging them. We could replace the <code class="literal">log.info</code> call to, for instance, store the nodes in a database or draw the graph to screen.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec87"></a>Fault tolerance</h2></div></div><hr /></div><p>Real programs fail, and they fail in unpredictable ways. Akka, and the Scala community in general, favors planning explicitly for failure rather than trying to write infallible applications. A <span class="emphasis"><em>fault tolerant</em></span> system is a system that can continue to operate when one or more of its components fails. The failure of an individual subsystem does not necessarily mean the failure of the application. How does this apply to Akka?</p><p>The actor model provides a natural unit to encapsulate failure: the actor. When an actor throws an exception while processing a message, the default behavior is for the actor to restart, but the exception does not leak out and affect the rest of the system. For instance, let's introduce an arbitrary failure in the response interpreter. We will modify the <code class="literal">receive</code> method to throw an exception when it is asked to interpret the response for<code class="literal"> misto</code>, one of Martin Odersky's followers:</p><div class="informalexample"><pre class="programlisting">// ResponseInterpreter.scala
def receive = {
  case InterpretResponse("misto", r) =&gt; 
    throw new IllegalStateException("custom error")
  case InterpretResponse(login, r) =&gt; interpret(login, r)
}</pre></div><p>If you rerun the code through SBT, you <a id="id399" class="indexterm"></a>will notice that an error gets logged. The program does not crash, however. It just continues as normal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[ERROR] [11/07/2015 12:05:58.938] [GithubFetcher-akka.actor.default-dispatcher-2] [akka://GithubFetcher/user/$a/$b] custom error</strong></span>
<span class="strong"><strong>java.lang.IllegalStateException: custom error</strong></span>
<span class="strong"><strong>  at ResponseInterpreter$</strong></span>
<span class="strong"><strong>   ...</strong></span>
<span class="strong"><strong>[INFO] [11/07/2015 12:05:59.117] [GithubFetcher-akka.actor.default-dispatcher-2] [akka://GithubFetcher/user/$a] Pushing samfoo onto queue</strong></span>
</pre></div><p>None of the followers of <code class="literal">misto</code> will get added to the queue: he never made it past the <code class="literal">ResponseInterpreter</code> stage. Let's step through what happens when the exception gets thrown:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The interpreter is sent the <code class="literal">InterpretResponse("misto", ...)</code> message. This causes it to throw an exception and it dies. None of the other actors are affected by the exception.</p></li><li style="list-style-type: disc"><p>A fresh instance of the response interpreter is created with the same Props instance as the recently deceased actor.</p></li><li style="list-style-type: disc"><p>When the response interpreter has finished initializing, it gets bound to the same <code class="literal">ActorRef</code> as the deceased actor. This means that, as far as the rest of the system is concerned, nothing has changed.</p></li><li style="list-style-type: disc"><p>The mailbox is tied to <code class="literal">ActorRef</code> rather than the actor, so the new response interpreter will have the same mailbox as its predecessor, without the offending message.</p></li></ul></div><p>Thus, if, for whatever reason, our crawler crashes when fetching or parsing the response for a user, the application will be minimally affectedâ€”we will just not fetch this user's followers.</p><p>Any internal state that an actor carries is lost when it restarts. Thus, if, for instance, the fetcher manager died, we would lose the current value of the queue and visited users. The risks associated with losing the internal state can be mitigated by the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Adopting a different strategy for failure: we can, for instance, carry on processing messages without restarting the actor in the event of failure. Of course, this is of little use if the <a id="id400" class="indexterm"></a>actor died because its internal state is inconsistent. In the next section, we will discuss how to change the failure recovery strategy.</p></li><li style="list-style-type: disc"><p>Backing up the internal state by writing it to disk periodically and loading from the backup on restart.</p></li><li style="list-style-type: disc"><p>Protecting actors that carry critical state by ensuring that all "risky" operations are delegated to other actors. In our crawler example, all the interactions with external services, such as querying the GitHub API and parsing the response, happen with actors that carry no internal state. As we saw in the previous example, if one of these actors dies, the application is minimally affected. By contrast, the precious fetcher manager is only allowed to interact with sanitized inputs. This is called the <span class="emphasis"><em>error kernel</em></span> pattern: code likely to cause errors is delegated to kamikaze actors.</p></li></ul></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec88"></a>Custom supervisor strategies</h2></div></div><hr /></div><p>The default strategy <a id="id401" class="indexterm"></a>of restarting an actor on failure is not always what we want. In particular, for actors that carry a lot of data, we might want to resume processing after an exception rather than restarting the actor. Akka lets us customize this behavior by setting a <span class="emphasis"><em>supervisor strategy</em></span> in the actor's supervisor.</p><p>Recall that all actors have parents, including the top-level actors, who are children of a special actor called the <span class="emphasis"><em>user guardian</em></span>. By default, an actor's supervisor is his parent, and it is the supervisor who decides what happens to the actor on failure.</p><p>Thus, to change how an actor reacts to failure, you must set its parent's supervisor strategy. You do this by setting the <code class="literal">supervisorStrategy</code> attribute. The default strategy is equivalent to the following:</p><div class="informalexample"><pre class="programlisting">val supervisorStrategy = OneForOneStrategy() {
  case _:ActorInitializationException =&gt; Stop
  case _:ActorKilledException =&gt; Stop
  case _:DeathPactException =&gt; Stop
  case _:Exception =&gt; Restart
}</pre></div><p>There are two components to a supervisor strategy:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">OneForOneStrategy</code> determines that the strategy applies only to the actor that failed. By contrast, we can use <code class="literal">AllForOneStrategy</code>, which applies the same strategy to all the supervisees. If a single child fails, all the children will be restarted (or stopped or resumed).</p></li><li style="list-style-type: disc"><p>A partial function <a id="id402" class="indexterm"></a>mapping <code class="literal">Throwables</code> to a <code class="literal">Directive</code>, which is an instruction on what to do in response to a failure. The default strategy, for instance, maps <code class="literal">ActorInitializationException</code> (which happens if the constructor fails) to the <code class="literal">Stop</code> directive and (almost all) other exceptions to <code class="literal">Restart</code>.</p></li></ul></div><p>There are four directives:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">Restart</code>: This destroys the faulty actor and restarts it, binding the newborn actor to the old <code class="literal">ActorRef</code>. This clears the internal state of the actor, which may be a good thing (the actor might have failed because of some internal inconsistency).</p></li><li style="list-style-type: disc"><p>
<code class="literal">Resume</code>: The actor just moves on to processing the next message in its inbox.</p></li><li style="list-style-type: disc"><p>
<code class="literal">Stop</code>: The actor stops and is not restarted. This is useful in throwaway actors that you use to complete a single operation: if this operation fails, the actor is not needed any more.</p></li><li style="list-style-type: disc"><p>
<code class="literal">Escalate</code>: The supervisor itself rethrows the exception, hoping that its supervisor will know what to do with it.</p></li></ul></div><p>A supervisor does not have access to which of its children failed. Thus, if an actor has children that might require different recovery strategies, it is best to create a set of intermediate supervisor actors to supervise the different groups of children.</p><p>As an example of setting the supervisor strategy, let's tweak the <code class="literal">FetcherManager</code> supervisor strategy to adopt an all-for-one strategy and stop its children when one of them fails. We start with the relevant imports:</p><div class="informalexample"><pre class="programlisting">import akka.actor.SupervisorStrategy._</pre></div><p>Then, we just need to <a id="id403" class="indexterm"></a>set the <code class="literal">supervisorStrategy</code> attribute in the <code class="literal">FetcherManager</code> definition:</p><div class="informalexample"><pre class="programlisting">class FetcherManager(...) extends Actor with ActorLogging {

  ...

  override val supervisorStrategy = AllForOneStrategy() {
    case _:ActorInitializationException =&gt; Stop
    case _:ActorKilledException =&gt; Stop
    case _:Exception =&gt; Stop
  }

  ...
}</pre></div><p>If you run this through SBT, you will notice that when the code comes across the custom exception thrown by the response interpreter, the system halts. This is because all the actors apart from the fetcher manager are now defunct.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec89"></a>Life-cycle hooks</h2></div></div><hr /></div><p>Akka lets us specify code that runs in response to specific events in an actor's life, through <span class="emphasis"><em>life-cycle hooks</em></span>. Akka <a id="id404" class="indexterm"></a>defines the following hooks:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">preStart()</code>: This runs after the actor's constructor has finished but before it starts processing messages. This is useful to run initialization code that depends on the actor being fully constructed.</p></li><li style="list-style-type: disc"><p>
<code class="literal">postStop()</code>: This runs when the actor dies after it has stopped processing messages. This is useful to run cleanup code before terminating the actor.</p></li><li style="list-style-type: disc"><p>
<code class="literal">preRestart(reason: Throwable, message: Option[Any])</code>: This is called just after an actor receives an order to restart. The <code class="literal">preRestart</code> method has access to the exception that was thrown and to the offending message, allowing for corrective action. The default behavior of <code class="literal">preRestart</code> is to stop each child and then call <code class="literal">postStop</code>.</p></li><li style="list-style-type: disc"><p>
<code class="literal">postRestart(reason:Throwable)</code>: This is called after an actor has restarted. The default behavior is to call <code class="literal">preStart()</code>.</p></li></ul></div><p>Let's use system hooks to persist the state of <code class="literal">FetcherManager</code> between runs of the programs. You can find the code examples for this section in the <code class="literal">chap09/ghub_crawler_fault_tolerant</code> directory in the sample code provided with this book (<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>). This will make the fetcher manager fault-tolerant. We will use <code class="literal">postStop</code> to write the current queue and set of visited users to text files and <code class="literal">preStart</code> to read these text files from the disk. Let's start by importing the libraries necessary to read and write files:</p><div class="informalexample"><pre class="programlisting">// FetcherManager.scala

import scala.io.Source 
import scala.util._
import java.io._</pre></div><p>We will store the names of the two text <a id="id405" class="indexterm"></a>files in which we persist the state in the <code class="literal">FetcherManager</code> companion object (a better approach would be to store them in a configuration file):</p><div class="informalexample"><pre class="programlisting">// FetcherManager.scala
object FetcherManager {
  ...
  val fetchedUsersFileName = "fetched-users.txt"
  val fetchQueueFileName = "fetch-queue.txt"
}</pre></div><p>In the <code class="literal">preStart</code> method, we load both the set of fetched users and the backlog of users to fetch from the text files, and in the <code class="literal">postStop</code> method, we overwrite these files with the new values of these data structures:</p><div class="informalexample"><pre class="programlisting">class FetcherManager(
  val token:Option[String], val nFetchers:Int
) extends Actor with ActorLogging {

  ...

  /** pre-start method: load saved state from text files */
  <span class="strong"><strong>override def preStart</strong></span> {
    log.info("Running pre-start on fetcher manager")

    loadFetchedUsers
    log.info(
      s"Read ${fetchedUsers.size} visited users from source"
    )

    loadFetchQueue
    log.info(
      s"Read ${fetchQueue.size} users in queue from source"
    )

    // If the saved state contains a non-empty queue, 
    // alert the fetchers so they can start working.
    if (fetchQueue.nonEmpty) {
      context.become(receiveWhileNotEmpty)
      fetchers.foreach { _ ! Fetcher.WorkAvailable }
    }

  }

  /** Dump the current state of the manager */
  <span class="strong"><strong>override def postStop</strong></span> {
    log.info("Running post-stop on fetcher manager")
    saveFetchedUsers
    saveFetchQueue
  }

     /* Helper methods to load from and write to files */
  def loadFetchedUsers {
    val fetchedUsersSource = Try { 
      Source.fromFile(fetchedUsersFileName) 
    }
    fetchedUsersSource.foreach { s =&gt;
      try s.getLines.foreach { l =&gt; fetchedUsers += l }
      finally s.close
    }
  }

  def loadFetchQueue {
    val fetchQueueSource = Try { 
      Source.fromFile(fetchQueueFileName) 
    }
    fetchQueueSource.foreach { s =&gt;
      try s.getLines.foreach { l =&gt; fetchQueue += l }
      finally s.close
    }
  }

  def saveFetchedUsers {
    val fetchedUsersFile = new File(fetchedUsersFileName)
    val writer = new BufferedWriter(
      new FileWriter(fetchedUsersFile))
    fetchedUsers.foreach { user =&gt; writer.write(user + "\n") }
    writer.close()
  }

  def saveFetchQueue {
    val queueUsersFile = new File(fetchQueueFileName)
    val writer = new BufferedWriter(
      new FileWriter(queueUsersFile))
    fetchQueue.foreach { user =&gt; writer.write(user + "\n") }
    writer.close()
  }

...
}</pre></div><p>Now that we save the state of the crawler when it shuts down, we can put a better termination condition for the program than simply interrupting the program once we get bored. In production, we might halt <a id="id406" class="indexterm"></a>the crawler when we have enough names in a database, for instance. In this example, we will simply let the crawler run for 30 seconds and then shut it down.</p><p>Let's modify the <code class="literal">main</code> method:</p><div class="informalexample"><pre class="programlisting">// FetchNetwork.scala
import akka.actor._
import scala.concurrent.ExecutionContext.Implicits.global
import scala.concurrent.duration._

object FetchNetwork extends App {

  // Get token if exists
  val token = sys.env.get("GHTOKEN")

  val system = ActorSystem("GithubFetcher")
  val manager = system.actorOf(FetcherManager.props(token, 2))

  manager ! FetcherManager.AddToQueue("odersky")

  system.scheduler.scheduleOnce(30.seconds) { system.shutdown }

}</pre></div><p>After 30 seconds, we just call <code class="literal">system.shutdown</code>, which stops all the actors recursively. This will stop the fetcher manager, calling the <code class="literal">postStop</code> life cycle hook. After one run of the program, I have 2,164 names in the <code class="literal">fetched-users.txt</code> file. Running it again increases this number to 3,728 users.</p><p>We could improve fault tolerance further by making the fetcher manager dump the data structures at regular intervals while the code runs. As writing to the disk (or to a database) carries a certain element of risk (What if the database server goes down or the disk is full?) it would be better to delegate writing the data structures to a custom actor rather than endangering the manager.</p><p>Our crawler has one minor problem: when the fetcher manager stops, it stops the fetcher actors, response interpreter, and follower extractor. However, none of the users currently going through these actors are stored. This also results in a small number of undelivered messages at the end of the code: if the response interpreter stops before a fetcher, the fetcher will try to deliver to a non-existent actor. This only accounts for a small number of users. To <a id="id407" class="indexterm"></a>recover these login names, we can create a reaper actor whose job is to coordinate the killing of all the worker actors in the correct order and harvest their internal state. This pattern is documented in a blog post by <span class="emphasis"><em>Derek Wyatt</em></span> (<a class="ulink" href="http://letitcrash.com/post/30165507578/shutdown-patterns-in-akka-2" target="_blank">http://letitcrash.com/post/30165507578/shutdown-patterns-in-akka-2</a>).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec90"></a>What we have not talked about</h2></div></div><hr /></div><p>Akka is a very rich <a id="id408" class="indexterm"></a>ecosystem, far too rich to do it justice in a single chapter. There are some important parts of the toolkit that you will need, but we have not covered them here. We will give brief descriptions, but you can refer to the Akka documentation for more details:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The ask operator, <code class="literal">?</code>, offers an alternative to the tell operator, <code class="literal">!</code>, that we have used to send messages to actors. Unlike "tell", which just fires a message to an actor, the ask operator expects a response. This is useful when we need to ask actors questions rather than just telling them what to do. The ask pattern is documented at <a class="ulink" href="http://doc.akka.io/docs/akka/snapshot/scala/actors.html#Ask__Send-And-Receive-Future" target="_blank">http://doc.akka.io/docs/akka/snapshot/scala/actors.html#Ask__Send-And-Receive-Future</a>.</p></li><li style="list-style-type: disc"><p>Deathwatch allows actors to watch another actor and receive a message when it dies. This is useful for actors that might depend on another actor but not be its direct supervisor. This is documented at <a class="ulink" href="http://doc.akka.io/docs/akka/snapshot/scala/actors.html#Lifecycle_Monitoring_aka_DeathWatch" target="_blank">http://doc.akka.io/docs/akka/snapshot/scala/actors.html#Lifecycle_Monitoring_aka_DeathWatch</a>.</p></li><li style="list-style-type: disc"><p>In our crawler, we passed references to actors explicitly through the constructor. We can also look up actors using the actor hierarchy with a syntax reminiscent of files in a filesystem at <a class="ulink" href="http://doc.akka.io/docs/akka/snapshot/scala/actors.html#Identifying_Actors_via_Actor_Selection" target="_blank">http://doc.akka.io/docs/akka/snapshot/scala/actors.html#Identifying_Actors_via_Actor_Selection</a>.</p></li><li style="list-style-type: disc"><p>We briefly explored how to implement stateful actors with different receive methods and using <code class="literal">context.become</code> to switch between them. Akka offers a more powerful alternative, based on finite state machines, to encode a more complex set of states and transitions: <a class="ulink" href="http://doc.akka.io/docs/akka/snapshot/scala/fsm.html" target="_blank">http://doc.akka.io/docs/akka/snapshot/scala/fsm.html</a>.</p></li><li style="list-style-type: disc"><p>We have not discussed <a id="id409" class="indexterm"></a>distributing actor systems across several nodes in this chapter. The message passing architecture works well with distributed setups: <a class="ulink" href="http://doc.akka.io/docs/akka/2.4.0/common/cluster.html" target="_blank">http://doc.akka.io/docs/akka/2.4.0/common/cluster.html</a>.</p></li></ul></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec91"></a>Summary</h2></div></div><hr /></div><p>In this chapter, you learned how to weave actors together to tackle a difficult concurrent problem. More importantly, we saw how Akka's actor framework encourages us to think about concurrent problems in terms of many separate chunks of encapsulated mutable data, synchronized through message passing. Akka makes concurrent programming easier to reason about and more fun.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec92"></a>References</h2></div></div><hr /></div><p>
<span class="emphasis"><em>Derek Wyatt's</em></span> book, <span class="emphasis"><em>Akka Concurrency</em></span>, is a fantastic introduction to Akka. It should definitely be the first stop for anyone wanting to do serious Akka programming.</p><p>The <span class="strong"><strong>LET IT CRASH</strong></span> <a id="id410" class="indexterm"></a>blog (<a class="ulink" href="http://letitcrash.com" target="_blank">http://letitcrash.com</a>) is the official Akka blog, and contains many examples of idioms and patterns to solve common issues.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch10"></a>ChapterÂ 10.Â Distributed Batch Processing with Spark</h2></div></div></div><p>In <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>, we discovered how to use parallel collections for "embarrassingly" parallel problems: problems that can be broken down into a series of tasks that require no (or very little) communication between the tasks.</p><p>Apache Spark provides behavior similar to Scala parallel collections (and much more), but, instead of distributing tasks across different CPUs on the same computer, it allows the tasks to be distributed across a computer cluster. This provides arbitrary horizontal scalability, since we can simply add more computers to the cluster.</p><p>In this chapter, we will learn the basics of Apache Spark and use it to explore a set of emails, extracting features with the view of building a spam filter. We will explore several ways of actually building a spam filter in <a class="link" href="#" linkend="ch12">Chapter 12</a>, <span class="emphasis"><em>Distributed Machine Learning with MLlib</em></span>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec93"></a>Installing Spark</h2></div></div><hr /></div><p>In previous chapters, we included dependencies by specifying them in a <code class="literal">build.sbt</code> file, and relying on SBT to <a id="id411" class="indexterm"></a>fetch them from the Maven Central repositories. For Apache Spark, downloading the source code or pre-built binaries explicitly is more common, since Spark ships with many command line scripts that greatly facilitate launching jobs and interacting with a cluster.</p><p>Head over to <a class="ulink" href="http://spark.apache.org/downloads.html" target="_blank">http://spark.apache.org/downloads.html</a> and download Spark 1.5.2, choosing the "pre-built for Hadoop 2.6 or later" package. You can also build Spark from source if you need <a id="id412" class="indexterm"></a>customizations, but we will stick to the pre-built version since it requires no configuration.</p><p>Clicking <span class="strong"><strong>Download</strong></span> will download a tarball, which you can unpack with the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ tar xzf spark-1.5.2-bin-hadoop2.6.tgz</strong></span>
</pre></div><p>This will create a <code class="literal">spark-1.5.2-bin-hadoop2.6</code> directory. To verify that Spark works correctly, navigate to <code class="literal">spark-1.5.2-bin-hadoop2.6/bin</code> and launch the Spark shell using <code class="literal">./spark-shell</code>. This is just a Scala shell with the Spark libraries loaded.</p><p>You may want to add the <code class="literal">bin/</code> directory to your system path. This will let you call the scripts in that directory from anywhere on your system, without having to reference the full path. On Linux or Mac OS, you can add variables to the system path by entering the following line in your shell configuration file (<code class="literal">.bash_profile</code> on Mac OS, and <code class="literal">.bashrc</code> or <code class="literal">.bash_profile</code> on Linux):</p><div class="informalexample"><pre class="programlisting">export PATH=/path/to/spark/bin:$PATH</pre></div><p>The changes will take effect in new shell sessions. On Windows (if you use PowerShell), you need to enter this line in the <code class="literal">profile.ps1</code> file in the <code class="literal">WindowsPowerShell</code> folder in <code class="literal">Documents</code>:</p><div class="informalexample"><pre class="programlisting">$env:Path += ";C:\Program Files\GnuWin32\bin"</pre></div><p>If this worked <a id="id413" class="indexterm"></a>correctly, you should be able to open a Spark shell in any directory on your system by just typing <code class="literal">spark-shell</code> in a terminal.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec94"></a>Acquiring the example data</h2></div></div><hr /></div><p>In this chapter, we will <a id="id414" class="indexterm"></a>explore the Ling-Spam email dataset (The original dataset is described at <a class="ulink" href="http://csmining.org/index.php/ling-spam-datasets.html" target="_blank">http://csmining.org/index.php/ling-spam-datasets.html</a>). Download the dataset from <a class="ulink" href="http://data.scala4datascience.com/ling-spam.tar.gz" target="_blank">http://data.scala4datascience.com/ling-spam.tar.gz</a> (or <a class="ulink" href="http://ling-spam.zip" target="_blank">ling-spam.zip</a>, depending on <a id="id415" class="indexterm"></a>your preferred mode of compression), and unpack the contents to the directory containing the code examples for this chapter. The archive contains two directories, <code class="literal">spam/</code> and <code class="literal">ham/</code>, containing the spam and legitimate emails, respectively.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec95"></a>Resilient distributed datasets</h2></div></div><hr /></div><p>Spark expresses <a id="id416" class="indexterm"></a>all computations as a sequence of transformations and actions on distributed collections, called <span class="strong"><strong>Resilient Distributed Datasets</strong></span> (<span class="strong"><strong>RDD</strong></span>). Let's explore how RDDs work with the Spark shell. Navigate to the examples directory and open a Spark shell as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ spark-shell</strong></span>
<span class="strong"><strong>scala&gt; </strong></span>
</pre></div><p>Let's start by loading an email in an RDD:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val email = sc.textFile("ham/9-463msg1.txt")</strong></span>
<span class="strong"><strong>email: rdd.RDD[String] = MapPartitionsRDD[1] at textFile</strong></span>
</pre></div><p>
<code class="literal">email</code> is an RDD, with each element corresponding to a line in the input file. Notice how we created the RDD by calling the <code class="literal">textFile</code> method on an object called <code class="literal">sc</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; sc</strong></span>
<span class="strong"><strong>spark.SparkContext = org.apache.spark.SparkContext@459bf87c</strong></span>
</pre></div><p>
<code class="literal">sc</code> is a <code class="literal">SparkContext</code> instance, an object representing the entry point to the Spark cluster (for now, just our local machine). When we start a Spark shell, a context is created and bound to the variable <code class="literal">sc</code> automatically.</p><p>Let's split the email into words using <code class="literal">flatMap</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val words = email.flatMap { line =&gt; line.split("\\s") }</strong></span>
<span class="strong"><strong>words: rdd.RDD[String] = MapPartitionsRDD[2] at flatMap</strong></span>
</pre></div><p>This will feel natural if you are familiar with collections in Scala: the <code class="literal">email</code> RDD behaves just like a list <a id="id417" class="indexterm"></a>of strings. Here, we split using the regular expression <code class="literal">\s</code>, denoting white space characters. Instead of using <code class="literal">flatMap</code> explicitly, we can also manipulate RDDs using Scala's syntactic sugar:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val words = for { </strong></span>
<span class="strong"><strong>  line &lt;- email</strong></span>
<span class="strong"><strong>  word &lt;- line.split("\\s") </strong></span>
<span class="strong"><strong>} yield word</strong></span>
<span class="strong"><strong>words: rdd.RDD[String] = MapPartitionsRDD[3] at flatMap</strong></span>
</pre></div><p>Let's inspect the results. We can use <code class="literal">.take(n)</code> to extract the first <span class="emphasis"><em>n</em></span> elements of an RDD:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; words.take(5)</strong></span>
<span class="strong"><strong>Array[String] = Array(Subject:, tsd98, workshop, -, -)</strong></span>
</pre></div><p>We can also use <code class="literal">.count</code> to get the number of elements in an RDD:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; words.count</strong></span>
<span class="strong"><strong>Long = 939</strong></span>
</pre></div><p>RDDs support many of the operations supported by collections. Let's use <code class="literal">filter</code> to remove punctuation from our email. We will remove all words that contain any non-alphanumeric character. We can do this by filtering out elements that match this <span class="emphasis"><em>regular expression</em></span> anywhere in the word: <code class="literal">[^a-zA-Z0-9]</code>.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val nonAlphaNumericPattern = "[^a-zA-Z0-9]".r</strong></span>
<span class="strong"><strong>nonAlphaNumericPattern: Regex = [^a-zA-Z0-9]</strong></span>

<span class="strong"><strong>scala&gt; val filteredWords = words.filter { </strong></span>
<span class="strong"><strong>  word =&gt; nonAlphaNumericPattern.findFirstIn(word) == None </strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>filteredWords: rdd.RDD[String] = MapPartitionsRDD[4] at filter</strong></span>

<span class="strong"><strong>scala&gt; filteredWords.take(5)</strong></span>
<span class="strong"><strong>Array[String] = Array(tsd98, workshop, 2nd, call, paper)</strong></span>

<span class="strong"><strong>scala&gt; filteredWords.count</strong></span>
<span class="strong"><strong>Long = 627</strong></span>
</pre></div><p>In this example, we created an RDD from a text file. We can also create RDDs from Scala iterables using the <code class="literal">sc.parallelize</code> method available on a Spark context:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val words = "the quick brown fox jumped over the dog".split(" ") </strong></span>
<span class="strong"><strong>words: Array[String] = Array(the, quick, brown, fox, ...)</strong></span>

<span class="strong"><strong>scala&gt; val wordsRDD = sc.parallelize(words)</strong></span>
<span class="strong"><strong>wordsRDD: RDD[String] = ParallelCollectionRDD[1] at parallelize at &lt;console&gt;:23</strong></span>
</pre></div><p>This is useful for <a id="id418" class="indexterm"></a>debugging and for trialling behavior in the shell. The counterpart to parallelize is the <code class="literal">.collect</code> method, which converts an RDD to a Scala array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val wordLengths = wordsRDD.map { _.length }</strong></span>
<span class="strong"><strong>wordLengths: RDD[Int] = MapPartitionsRDD[2] at map at &lt;console&gt;:25</strong></span>

<span class="strong"><strong>scala&gt; wordLengths.collect</strong></span>
<span class="strong"><strong>Array[Int] = Array(3, 5, 5, 3, 6, 4, 3, 3)</strong></span>
</pre></div><p>The <code class="literal">.collect</code> method requires the entire RDD to fit in memory on the master node. It is thus either used for debugging with a reduced dataset, or at the end of a pipeline that trims down a dataset.</p><p>As you can see, RDDs offer an API much like Scala iterables. The critical difference is that RDDs are <span class="emphasis"><em>distributed</em></span> and <span class="emphasis"><em>resilient</em></span>. Let's explore what this means in practice.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec54"></a>RDDs are immutable</h3></div></div></div><p>You cannot <a id="id419" class="indexterm"></a>change an RDD once it is created. All operations on RDDs either create new RDDs or other Scala objects.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec55"></a>RDDs are lazy</h3></div></div></div><p>When you <a id="id420" class="indexterm"></a>execute operations like map and filter on a Scala collection in the interactive shell, the REPL prints the values of the new collection to screen. The same isn't true of Spark RDDs. This is because operations on RDDs are lazy: they are only evaluated when needed.</p><p>Thus, when we write:</p><div class="informalexample"><pre class="programlisting">val email = sc.textFile(...)
val words = email.flatMap { line =&gt; line.split("\\s") }</pre></div><p>We are creating an RDD, <code class="literal">words</code> that knows how to build itself from its parent RDD, <code class="literal">email</code>, which, in turn, knows that it needs to read a text file and split it into lines. However, none of the commands actually happen until we force the evaluation of the RDDs by calling an <span class="emphasis"><em>action</em></span> to return a Scala object. This is most evident if we try to read from a non-existent text file:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val inp = sc.textFile("nonexistent")</strong></span>
<span class="strong"><strong>inp: rdd.RDD[String] = MapPartitionsRDD[5] at textFile</strong></span>
</pre></div><p>We can create the <a id="id421" class="indexterm"></a>RDD without a hitch. We can even define further transformations on the RDD. The program crashes only when these transformations are finally evaluated:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; inp.count // number of lines</strong></span>
<span class="strong"><strong>org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/Users/pascal/...</strong></span>
</pre></div><p>The action <code class="literal">.count</code> is expected to return the number of elements in our RDD as an integer. Spark has no choice but to evaluate <code class="literal">inp</code>, which results in an exception.</p><p>Thus, it is probably more appropriate to think of an RDD as a pipeline of operations, rather than a more traditional collection.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec56"></a>RDDs know their lineage</h3></div></div></div><p>RDDs can only be <a id="id422" class="indexterm"></a>constructed from stable storage (for instance, by loading data from a file that is present on every node in the Spark cluster), or through a set of transformations based on other RDDs. Since RDDs are lazy, they need to know how to build themselves when needed. They do this by knowing who their parent RDD is, and what operation they need to apply to the parent. This is a well-defined process since the parent RDD is immutable.</p><p>The <code class="literal">toDebugString</code> method provides a diagram of how an RDD is constructed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; filteredWords.toDebugString</strong></span>
<span class="strong"><strong>(2) MapPartitionsRDD[6] at filter at &lt;console&gt;:27 []</strong></span>
<span class="strong"><strong> |  MapPartitionsRDD[3] at flatMap at &lt;console&gt;:23 []</strong></span>
<span class="strong"><strong> |  MapPartitionsRDD[1] at textFile at &lt;console&gt;:21 []</strong></span>
<span class="strong"><strong> |  ham/9-463msg1.txt HadoopRDD[0] at textFile at &lt;console&gt;:21 []</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec57"></a>RDDs are resilient</h3></div></div></div><p>If you run an <a id="id423" class="indexterm"></a>application on a single computer, you generally don't need to worry about hardware failure in your application: if the computer fails, your application is doomed anyway.</p><p>Distributed architectures should, by contrast, be fault-tolerant: the failure of a single machine should not crash the entire application. Spark RDDs are built with fault tolerance in mind. Let's imagine that one of the worker nodes fails, causing the destruction of some of the data associated with an RDD. Since the Spark RDD knows how to build itself from its parent, there is no permanent data loss: the elements that were lost can just be re-computed when needed on another computer.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec58"></a>RDDs are distributed</h3></div></div></div><p>When you construct an RDD, for instance from a text file, Spark will split the RDD into a number of partitions. Each partition will be entirely localized on a single machine (though there is, in general, more than one partition per machine).</p><p>Many <a id="id424" class="indexterm"></a>transformations on RDDs can be executed on each partition independently. For instance, when performing a <code class="literal">.map</code> operation, a given element in the output RDD depends on a single element in the parent: data does not need to be moved between partitions. The same is true of <code class="literal">.flatMap</code> and <code class="literal">.filter</code> operations. This means that the partition in the RDD produced by one of these operations depends on a single partition in the parent RDD.</p><p>On the other hand, a <code class="literal">.distinct</code> transformation, which removes all duplicate elements from an RDD, requires the data in a given partition to be compared to the data in every other partition. This requires <span class="emphasis"><em>shuffling</em></span> the data across the nodes. Shuffling, especially for large datasets, is an expensive operation and should be avoided if possible.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec59"></a>Transformations and actions on RDDs</h3></div></div></div><p>The set of operations supported by an RDD can be split into two categories:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<span class="strong"><strong>Transformations</strong></span> create a new RDD from the current one. Transformations are lazy: they are <a id="id425" class="indexterm"></a>not evaluated immediately.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Actions</strong></span> force the <a id="id426" class="indexterm"></a>evaluation of an RDD, and normally return a Scala object, rather than an RDD, or have some form of side-effect. Actions are evaluated immediately, triggering the execution of all the transformations that make up this RDD.</p></li></ul></div><p>In the tables below, we give some examples of useful transformations and actions. For a full, up-to-date <a id="id427" class="indexterm"></a>list, consult the Spark documentation (<a class="ulink" href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations" target="_blank">http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations</a>).</p><p>For the <a id="id428" class="indexterm"></a>examples in these tables, we assume that you have created an RDD with:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val rdd = sc.parallelize(List("quick", "brown", "quick", "dog"))</strong></span>
</pre></div><p>The following table <a id="id429" class="indexterm"></a>lists common transformations on an RDD. Recall that transformations always generate a new RDD, and that they are lazy operations:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /><col align="left" /></colgroup><tbody><tr style="border-bottom: 0.5pt solid ; "><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Transformation</p>
</td><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Notes</p>
</td><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p><span class="strong"><strong>Example (assuming</strong></span> <code class="literal">rdd</code> <span class="strong"><strong>is</strong></span> <code class="literal">{ "quick", "brown", "quick", "dog" }</code>)</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.map(func)</code>
</p>
</td><td style="" align="left" valign="top">Â </td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.map { _.size } // =&gt; { 5, 5, 5, 3 }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.filter(pred)</code>
</p>
</td><td style="" align="left" valign="top">Â </td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.filter { _.length  &lt; 4 } // =&gt; { "dog" }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.flatMap(func)</code>
</p>
</td><td style="" align="left" valign="top">Â </td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.flatMap { _.toCharArray } // =&gt; { 'q', 'u', 'i', 'c', 'k', 'b', 'r', 'o' â€¦ }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.distinct()</code>
</p>
</td><td style="" align="left" valign="top">
<p>Remove duplicate elements in RDD.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.distinct // =&gt; { "dog", "brown", "quick" }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.pipe(command, [envVars])</code>
</p>
</td><td style="" align="left" valign="top">
<p>Pipe through an external program. RDD elements are written, line-by-line, to the process's <code class="literal">stdin</code>. The output is read from <code class="literal">stdout</code>.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.pipe("tr a-z A-Z") // =&gt; { "QUICK", "BROWN", "QUICK", "DOG" }</code>
</p>
</td></tr></tbody></table></div><p>The following table describes common actions on RDDs. Recall that actions always generate a Scala type or cause a side-effect, rather than creating a new RDD. Actions force the evaluation of the RDD, triggering the execution of the transformations underpinning the RDD.</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /><col align="left" /></colgroup><tbody><tr style="border-bottom: 0.5pt solid ; "><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Action</p>
</td><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Nodes</p>
</td><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p><span class="strong"><strong>Example (assuming</strong></span> <code class="literal">rdd</code> <span class="strong"><strong>is</strong></span> <code class="literal">{ "quick", "brown", "quick", "dog" }</code>)</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.first</code>
</p>
</td><td style="" align="left" valign="top">
<p>First element in the RDD.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.first // =&gt; quick</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.collect</code>
</p>
</td><td style="" align="left" valign="top">
<p>Transform the RDD to an array (the array must be able to fit in memory on the master node).</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.collect // =&gt; Array[String]("quick", "brown", "quick", "dog")</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.count</code>
</p>
</td><td style="" align="left" valign="top">
<p>Number of elements in the RDD.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.count // =&gt; 4</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.countByValue</code>
</p>
</td><td style="" align="left" valign="top">
<p>Map of <a id="id430" class="indexterm"></a>element to the number of times this element occurs. The map must fit on the master node.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.countByValue // =&gt; Map(quick -&gt; 2, brown -&gt; 1, dog -&gt; 1)</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.take(n)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Return <a id="id431" class="indexterm"></a>an array of the first <span class="emphasis"><em>n</em></span> elements in the RDD.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.take(2) // =&gt; Array(quick, brown)</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.takeOrdered(n:Int)(implicit ordering: Ordering[T])</code>
</p>
</td><td style="" align="left" valign="top">
<p>Top <span class="emphasis"><em>n</em></span> elements in the RDD according to the element's default ordering, or the ordering passed as second argument. See the Scala docs for <code class="literal">Ordering</code> for how to define <a id="id432" class="indexterm"></a>custom comparison functions (<a class="ulink" href="http://www.scala-lang.org/api/current/index.html#scala.math.Ordering" target="_blank">http://www.scala-lang.org/api/current/index.html#scala.math.Ordering</a>).</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.takeOrdered(2) // =&gt; Array(brown, dog)</code>
</p>
<p>
<code class="literal">rdd.takeOrdered(2) (Ordering.by { _.size }) // =&gt; Array[String] = Array(dog, quick)</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.reduce(func)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Reduce the RDD according to the specified function. Uses the first element in the RDD as the base. <code class="literal">func</code> should be commutative and associative.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.map { _.size }.reduce { _ + _ } // =&gt; 18</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.aggregate(zeroValue)(seqOp, combOp)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Reduction <a id="id433" class="indexterm"></a>for cases where the reduction function returns <a id="id434" class="indexterm"></a>a value of type different to the RDD's type. In this case, we need to provide a function for reducing within a single partition (<code class="literal">seqOp</code>) and a function for combining the value of two partitions (<code class="literal">combOp</code>).</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.aggregate(0) ( _ + _.size, _ + _ ) // =&gt; 18</code>
</p>
</td></tr></tbody></table></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec60"></a>Persisting RDDs</h3></div></div></div><p>We have <a id="id435" class="indexterm"></a>learned that RDDs only retain the sequence of operations needed to construct the elements, rather than the values themselves. This, of course, drastically reduces memory usage since we do not need to keep intermediate versions of our RDDs in memory. For instance, let's assume we want to trawl through transaction logs to identify all the transactions that occurred on a particular account:</p><div class="informalexample"><pre class="programlisting">val allTransactions = sc.textFile("transaction.log")
val interestingTransactions = allTransactions.filter { 
  _.contains("Account: 123456")
}</pre></div><p>The set of all transactions will be large, while the set of transactions on the account of interest will be much smaller. Spark's policy of remembering <span class="emphasis"><em>how</em></span> to construct a dataset, rather than the dataset itself, means that we never have all the lines of our input file in memory at any one time.</p><p>There are two situations in which we may want to avoid re-computing the elements of an RDD every time we use it:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>For interactive use: we might have detected fraudulent behavior on account "123456", and we want to investigate how this might have arisen. We will probably want to perform many different exploratory calculations on this RDD, without having to re-read the entire log file every time. It therefore makes sense to persist <code class="literal">interestingTransactions</code>.</p></li><li style="list-style-type: disc"><p>When an algorithm re-uses an intermediate result, or a dataset. A canonical example is logistic regression. In logistic regression, we normally use an iterative algorithm to find the 'optimal' coefficients that minimize the loss function. At every step in our iterative algorithm, we must calculate the loss function and its gradient from the training set. We should avoid re-computing the training set (or re-loading it from an input file) if at all possible.</p></li></ul></div><p>Spark provides a <code class="literal">.persist</code> method on RDDs to achieve this. By calling <code class="literal">.persist</code> on an RDD, we tell Spark to keep the dataset in memory next time it is computed.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; words.persist</strong></span>
<span class="strong"><strong>rdd.RDD[String] = MapPartitionsRDD[3] at filter</strong></span>
</pre></div><p>Spark supports different levels of persistence, which you can tune by passing arguments to <code class="literal">.persist</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.storage.StorageLevel</strong></span>
<span class="strong"><strong>import org.apache.spark.storage.StorageLevel</strong></span>

<span class="strong"><strong>scala&gt; interestingTransactions.persist(</strong></span>
<span class="strong"><strong>  StorageLevel.MEMORY_AND_DISK)</strong></span>
<span class="strong"><strong>rdd.RDD[String] = MapPartitionsRDD[3] at filter</strong></span>
</pre></div><p>Spark provides several persistence levels, including:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">MEMORY_ONLY</code>: the default storage level. The RDD is stored in RAM. If the RDD is too big to fit in memory, parts of it will not persist, and will need to be re-computed on the fly.</p></li><li style="list-style-type: disc"><p>
<code class="literal">MEMORY_AND_DISK</code>: As much of the RDD is stored in memory as possible. If the RDD is too big, it will spill over to disk. This is only worthwhile if the RDD is expensive to compute. Otherwise, re-computing it may be faster than reading from the disk.</p></li></ul></div><p>If you persist <a id="id436" class="indexterm"></a>several RDDs and run out of memory, Spark will clear the least recently used out of memory (either discarding them or saving them to disk, depending on the chosen persistence level). RDDs also expose an <code class="literal">unpersist</code> method to explicitly tell Spark than an RDD is not needed any more.</p><p>Persisting RDDs can have a drastic impact on performance. What and how to persist therefore becomes very important when tuning a Spark application. Finding the best persistence level generally requires some tinkering, benchmarking and experimentation. The Spark <a id="id437" class="indexterm"></a>documentation provides guidelines on when to use which persistence level (<a class="ulink" href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence" target="_blank">http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence</a>), as well as <a id="id438" class="indexterm"></a>general tips on tuning memory usage (<a class="ulink" href="http://spark.apache.org/docs/latest/tuning.html" target="_blank">http://spark.apache.org/docs/latest/tuning.html</a>).</p><p>Importantly, the <code class="literal">persist</code> method does not force the evaluation of the RDD. It just notifies the Spark engine that, next time the values in this RDD are computed, they should be saved rather than discarded.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec61"></a>Key-value RDDs</h3></div></div></div><p>So far, we have only <a id="id439" class="indexterm"></a>considered RDDs of Scala value types. RDDs of more complex data types support additional operations. Spark adds many operations for <span class="emphasis"><em>key-value RDDs</em></span>: RDDs whose type parameter is a tuple <code class="literal">(K, V)</code>, for any type <code class="literal">K</code> and <code class="literal">V</code>.</p><p>Let's go back to our sample email:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val email = sc.textFile("ham/9-463msg1.txt")</strong></span>
<span class="strong"><strong>email: rdd.RDD[String] = MapPartitionsRDD[1] at textFile</strong></span>

<span class="strong"><strong>scala&gt; val words = email.flatMap { line =&gt; line.split("\\s") }</strong></span>
<span class="strong"><strong>words: rdd.RDD[String] = MapPartitionsRDD[2] at flatMap</strong></span>
</pre></div><p>Let's persist the <code class="literal">words</code> RDD in memory to avoid having to re-read the <code class="literal">email</code> file from disk repeatedly:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; words.persist</strong></span>
</pre></div><p>To access key-value operations, we just need to apply a transformation to our RDD that creates key-value pairs. Let's use the words as keys. For now, we will just use 1 for every value:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val wordsKeyValue = words.map { _ -&gt; 1 }</strong></span>
<span class="strong"><strong>wordsKeyValue: rdd.RDD[(String, Int)] = MapPartitionsRDD[32] at map </strong></span>

<span class="strong"><strong>scala&gt; wordsKeyValue.first</strong></span>
<span class="strong"><strong>(String, Int) = (Subject:,1)</strong></span>
</pre></div><p>Key-value RDDs <a id="id440" class="indexterm"></a>support several operations besides the core RDD operations. These are added through an implicit conversion, using the "pimp my library" pattern that we explored in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Scala and SQL through JDBC</em></span>. These additional transformations fall into two broad categories: <span class="emphasis"><em>by-key</em></span> transformations and <span class="emphasis"><em>joins</em></span> between RDDs.</p><p>By-key transformations are operations that aggregate the values corresponding to the same key. For instance, we can count the number of times each word appears in our email using <code class="literal">reduceByKey</code>. This method takes all the values that belong to the same key and combines them using a user-supplied function:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val wordCounts = wordsKeyValue.reduceByKey { _ + _ }</strong></span>
<span class="strong"><strong>wordCounts: rdd.RDD[(String, Int)] = ShuffledRDD[35] at reduceByKey</strong></span>

<span class="strong"><strong>scala&gt; wordCounts.take(5).foreach { println }</strong></span>
<span class="strong"><strong>(university,6)</strong></span>
<span class="strong"><strong>(under,1)</strong></span>
<span class="strong"><strong>(call,3)</strong></span>
<span class="strong"><strong>(paper,2)</strong></span>
<span class="strong"><strong>(chasm,2)</strong></span>
</pre></div><p>Note that <code class="literal">reduceByKey</code> requires (in general) shuffling the RDD, since not every occurrence of a given key will be in the same partition:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; wordCounts.toDebugString</strong></span>
<span class="strong"><strong>(2) ShuffledRDD[36] at reduceByKey at &lt;console&gt;:30 []</strong></span>
<span class="strong"><strong> +-(2) MapPartitionsRDD[32] at map at &lt;console&gt;:28 []</strong></span>
<span class="strong"><strong>    |  MapPartitionsRDD[7] at flatMap at &lt;console&gt;:23 []</strong></span>
<span class="strong"><strong>    |      CachedPartitions: 2; MemorySize: 50.3 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B</strong></span>
<span class="strong"><strong>    |  MapPartitionsRDD[3] at textFile at &lt;console&gt;:21 []</strong></span>
<span class="strong"><strong>    |      CachedPartitions: 2; MemorySize: 5.1 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B</strong></span>
<span class="strong"><strong>    |  ham/9-463msg1.txt HadoopRDD[2] at textFile at &lt;console&gt;:21 []</strong></span>
</pre></div><p>Note that key-value RDDs are not like Scala Maps: the same key can occur multiple times, and they do not support <span class="emphasis"><em>O(1)</em></span> lookup. A key-value RDD can be transformed to a Scala map using the <code class="literal">.collectAsMap</code> action:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; wordCounts.collectAsMap</strong></span>
<span class="strong"><strong>scala.collection.Map[String,Int] = Map(follow -&gt; 2, famous -&gt; 1...</strong></span>
</pre></div><p>This requires pulling the entire RDD onto the main Spark node. You therefore need to have enough memory on the main node to house the map. This is often the last stage in a pipeline that filters a large RDD to just the information that we need.</p><p>There are many by-key operations, which we describe in the table below. For the examples in the <a id="id441" class="indexterm"></a>table, we assume that <code class="literal">rdd</code> is created as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val words = sc.parallelize(List("quick", "brown","quick", "dog"))</strong></span>
<span class="strong"><strong>words: RDD[String] = ParallelCollectionRDD[25] at parallelize at &lt;console&gt;:21</strong></span>

<span class="strong"><strong>scala&gt; val rdd = words.map { word =&gt; (word -&gt; word.size) }</strong></span>
<span class="strong"><strong>rdd: RDD[(String, Int)] = MapPartitionsRDD[26] at map at &lt;console&gt;:23</strong></span>

<span class="strong"><strong>scala&gt; rdd.collect</strong></span>
<span class="strong"><strong>Array[(String, Int)] = Array((quick,5), (brown,5), (quick,5), (dog,3))</strong></span>
</pre></div><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /><col align="left" /></colgroup><tbody><tr style="border-bottom: 0.5pt solid ; "><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Transformation</p>
</td><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Notes</p>
</td><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p><span class="strong"><strong>Example (assumes</strong></span> <code class="literal">rdd</code> <span class="strong"><strong>is </strong></span> <code class="literal">{ quick -&gt; 5, brown -&gt; 5, quick -&gt; 5, dog -&gt; 3 }</code>)</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.mapValues</code>
</p>
</td><td style="" align="left" valign="top">
<p>Apply an operation to the values.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.mapValues { _ * 2 } // =&gt; { quick -&gt; 10, brown -&gt; 10, quick -&gt; 10, dog -&gt;6 }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.groupByKey</code>
</p>
</td><td style="" align="left" valign="top">
<p>Return a key-value RDD in which values corresponding to the same key are grouped into iterables.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.groupByKey // =&gt; { quick -&gt; Iterable(5, 5), brown -&gt; Iterable(5), dog -&gt; Iterable(3) }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.reduceByKey(func)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Return a key-value RDD in which values corresponding to the same key are combined using a user-supplied function.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.reduceByKey { _ + _ } // =&gt; { quick -&gt; 10, brown -&gt; 5, dog -&gt; 3 }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.keys</code>
</p>
</td><td style="" align="left" valign="top">
<p>Return an RDD of the keys.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.keys // =&gt; { quick, brown, quick, dog }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.values</code>
</p>
</td><td style="" align="left" valign="top">
<p>Return an RDD of the values.</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">rdd.values // =&gt; { 5, 5, 5, 3 }</code>
</p>
</td></tr></tbody></table></div><p>The second category of operations on key-value RDDs involves joining different RDDs together by key. This is <a id="id442" class="indexterm"></a>somewhat similar to SQL joins, where the keys are the column being joined on. Let's load a spam email and apply the same transformations we applied to our ham email:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val spamEmail = sc.textFile("spam/spmsgb17.txt")</strong></span>
<span class="strong"><strong>spamEmail: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[52] at textFile at &lt;console&gt;:24</strong></span>

<span class="strong"><strong>scala&gt; val spamWords = spamEmail.flatMap { _.split("\\s") }</strong></span>
<span class="strong"><strong>spamWords: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[53] at flatMap at &lt;console&gt;:26</strong></span>

<span class="strong"><strong>scala&gt; val spamWordCounts = spamWords.map { _ -&gt; 1 }.reduceByKey { _ + _ }</strong></span>
<span class="strong"><strong>spamWordsCount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[55] at reduceByKey at &lt;console&gt;:30</strong></span>

<span class="strong"><strong>scala&gt; spamWordCounts.take(5).foreach { println }</strong></span>
<span class="strong"><strong>(banner,3)</strong></span>
<span class="strong"><strong>(package,14)</strong></span>
<span class="strong"><strong>(call,1)</strong></span>
<span class="strong"><strong>(country,2)</strong></span>
<span class="strong"><strong>(offer,1)</strong></span>
</pre></div><p>Both <code class="literal">spamWordCounts</code> and <code class="literal">wordCounts</code> are key-value RDDs for which the keys correspond to unique words in the message, and the values are the number of times that word occurs. There will be some overlap in keys between <code class="literal">spamWordCounts</code> and <code class="literal">wordCounts</code>, since the emails will share many of the same words. Let's do an <span class="emphasis"><em>inner join</em></span> between those two RDDs to get the words that occur in both emails:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val commonWordCounts = wordCounts.join(spamWordCounts)</strong></span>
<span class="strong"><strong>res93: rdd.RDD[(String, (Int, Int))] = MapPartitionsRDD[58] at join at &lt;console&gt;:41</strong></span>

<span class="strong"><strong>scala&gt; commonWordCounts.take(5).foreach { println }</strong></span>
<span class="strong"><strong>(call,(3,1))</strong></span>
<span class="strong"><strong>(include,(6,2))</strong></span>
<span class="strong"><strong>(minute,(2,1))</strong></span>
<span class="strong"><strong>(form,(1,7))</strong></span>
<span class="strong"><strong>((,(36,5))</strong></span>
</pre></div><p>The values in the RDD resulting from an inner join will be pairs. The first element in the pair is the value for that key in the first RDD, and the second element is the value for that key in the second RDD. Thus, the word <span class="emphasis"><em>call</em></span> occurs three times in the legitimate email and once in the spam email.</p><p>Spark supports <a id="id443" class="indexterm"></a>all four join types. For instance, let's perform a left join:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val leftWordCounts = wordCounts.leftOuterJoin(spamWordCounts)</strong></span>
<span class="strong"><strong>leftWordCounts: rdd.RDD[(String, (Int, Option[Int]))] = MapPartitionsRDD[64] at leftOuterJoin at &lt;console&gt;:40</strong></span>

<span class="strong"><strong>scala&gt; leftWordCounts.take(5).foreach { println }</strong></span>
<span class="strong"><strong>(call,(3,Some(1)))</strong></span>
<span class="strong"><strong>(paper,(2,None))</strong></span>
<span class="strong"><strong>(chasm,(2,None))</strong></span>
<span class="strong"><strong>(antonio,(1,None))</strong></span>
<span class="strong"><strong>(event,(3,None))</strong></span>
</pre></div><p>Notice that the second element in our pair has type <code class="literal">Option[Int]</code>, to accommodate keys absent in <code class="literal">spamWordCounts</code>. The word <span class="emphasis"><em>paper</em></span>, for instance, occurs twice in the legitimate email and never in the spam email. In this case, it is more useful to have zeros to indicate absence, rather than <code class="literal">None</code>. Replacing <code class="literal">None</code> with a default value is simple with <code class="literal">getOrElse</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val defaultWordCounts = leftWordCounts.mapValues { </strong></span>
<span class="strong"><strong>  case(leftValue, rightValue) =&gt; (leftValue, rightValue.getOrElse(0))</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>org.apache.spark.rdd.RDD[(String, (Int, Option[Int]))] = MapPartitionsRDD[64] at leftOuterJoin at &lt;console&gt;:40</strong></span>

<span class="strong"><strong>scala&gt; defaultwordCounts.take(5).foreach { println }</strong></span>
<span class="strong"><strong>(call,(3,1))</strong></span>
<span class="strong"><strong>(paper,(2,0))</strong></span>
<span class="strong"><strong>(chasm,(2,0))</strong></span>
<span class="strong"><strong>(antonio,(1,0))</strong></span>
<span class="strong"><strong>(event,(3,0))</strong></span>
</pre></div><p>The table <a id="id444" class="indexterm"></a>below lists the most common joins on key-value RDDs:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><tbody><tr style="border-bottom: 0.5pt solid ; "><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p><span class="strong"><strong>Transformation</strong></span></p>
</td><td style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p><span class="strong"><strong>Result (assuming</strong></span> <code class="literal">rdd1</code> is <code class="literal">{ quick -&gt; 1, brown -&gt; 2, quick -&gt; 3, dog -&gt; 4 }</code> <span class="strong"><strong>and</strong></span> <code class="literal">rdd2</code> <span class="strong"><strong>is</strong></span> <code class="literal">{ quick -&gt; 78, brown -&gt; 79, fox -&gt; 80 }</code>)</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd1.join(rdd2)</code>
</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">{ quick -&gt; (1, 78), quick -&gt; (3, 78), brown -&gt; (2, 79) }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd1.leftOuterJoin(rdd2)</code>
</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">{ dog -&gt; (4, None), quick -&gt; (1, Some(78)), quick -&gt; (3, Some(78)), brown -&gt; (2, Some(79)) }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd1.rightOuterJoin(rdd2)</code>
</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">{ quick -&gt; (Some(1), 78), quick -&gt; (Some(3), 78), brown -&gt; (Some(2), 79), fox -&gt; (None, 80) }</code>
</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">rdd1.fullOuterJoin(rdd2)</code>
</p>
</td><td style="" align="left" valign="top">
<p>
<code class="literal">{ dog -&gt; (Some(4), None), quick -&gt; (Some(1), Some(78)), quick -&gt; (Some(3), Some(78)), brown -&gt; (Some(2), Some(79)), fox -&gt; (None, Some(80)) }</code>
</p>
</td></tr></tbody></table></div><p>For a complete list of <a id="id445" class="indexterm"></a>transformations, consult the API documentation for <code class="literal">PairRDDFunctions</code>, <a class="ulink" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions</a>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec62"></a>Double RDDs</h3></div></div></div><p>In the previous section, we <a id="id446" class="indexterm"></a>saw that Spark adds functionality to key-value RDDs through an implicit conversion. Similarly, Spark adds statistics functionality to RDDs of doubles. Let's extract the word frequencies for the ham message, and convert the values from integers to doubles:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val counts = wordCounts.values.map { _.toDouble }</strong></span>
<span class="strong"><strong>counts: rdd.RDD[Double] = MapPartitionsRDD[9] at map</strong></span>
</pre></div><p>We can then get summary statistics using the <code class="literal">.stats</code> action:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; counts.stats</strong></span>
<span class="strong"><strong>org.apache.spark.util.StatCounter = (count: 397, mean: 2.365239, stdev: 5.740843, max: 72.000000, min: 1.000000)</strong></span>
</pre></div><p>Thus, the most common word appears 72 times. We can also use the <code class="literal">.histogram</code> action to get an idea of the distribution of values:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; counts.histogram(5)</strong></span>
<span class="strong"><strong>(Array(1.0, 15.2, 29.4, 43.6, 57.8, 72.0),Array(391, 1, 3, 1, 1))</strong></span>
</pre></div><p>The <code class="literal">.histogram</code> method returns a pair of arrays. The first array indicates the bounds of the histogram bins, and the second is the count of elements in that bin. Thus, there are <code class="literal">391</code> words that appear <a id="id447" class="indexterm"></a>less than <code class="literal">15.2</code> times. The distribution of words is very skewed, such that a histogram with regular-sized bin is not really appropriate. We can, instead, pass in custom bins by passing an array of bin edges to the <code class="literal">histogram</code> method. For instance, we might distribute the bins logarithmically:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; counts.histogram(Array(1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0))</strong></span>
<span class="strong"><strong>res13: Array[Long] = Array(264, 94, 22, 11, 1, 4, 1)</strong></span>
</pre></div></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec96"></a>Building and running standalone programs</h2></div></div><hr /></div><p>So far, we have <a id="id448" class="indexterm"></a>interacted exclusively with Spark through the Spark shell. In the section that follows, we will build a standalone application and launch a Spark program either locally or on an EC2 cluster.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec63"></a>Running Spark applications locally</h3></div></div></div><p>The first step is to <a id="id449" class="indexterm"></a>write the <code class="literal">build.sbt</code> file, as you would if you were running a standard Scala script. The Spark binary that we downloaded needs to be run against Scala 2.10 (You need to compile Spark from source to run against <a id="id450" class="indexterm"></a>Scala 2.11. This is not difficult to do, just follow the instructions on <a class="ulink" href="http://spark.apache.org/docs/latest/building-spark.html#building-for-scala-211" target="_blank">http://spark.apache.org/docs/latest/building-spark.html#building-for-scala-211</a>).</p><div class="informalexample"><pre class="programlisting">// build.sbt file

name := "spam_mi"

scalaVersion := "2.10.5"

libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-core" % "1.4.1"
)</pre></div><p>We then run <code class="literal">sbt package</code> to compile and build a jar of our program. The jar will be built in <code class="literal">target/scala-2.10/</code>, and called <code class="literal">spam_mi_2.10-0.1-SNAPSHOT.jar</code>. You can try this with the example code provided for this chapter.</p><p>We can then run the jar locally using the <code class="literal">spark-submit</code> shell script, available in the <code class="literal">bin/</code> folder in the Spark installation directory:</p><div class="informalexample"><pre class="programlisting">$ spark-submit target/scala-2.10/spam_mi_2.10-0.1-SNAPSHOT.jar
... runs the program</pre></div><p>The resources allocated to Spark can be controlled by passing arguments to <code class="literal">spark-submit</code>. Use <code class="literal">spark-submit --help</code> to see the full list of arguments.</p><p>If the Spark programs has dependencies (for instance, on other Maven packages), it is easiest to bundle them into the application jar using the <span class="emphasis"><em>SBT</em></span> <span class="emphasis"><em>assembly</em></span> plugin. Let's imagine that our application depends on breeze-viz. The <code class="literal">build.sbt</code> file now looks like:</p><div class="informalexample"><pre class="programlisting">// build.sbt

name := "spam_mi"

scalaVersion := "2.10.5"

libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-core" % "1.5.2" % "provided",
  "org.scalanlp" %% "breeze" % "0.11.2",
  "org.scalanlp" %% "breeze-viz" % "0.11.2",
  "org.scalanlp" %% "breeze-natives" % "0.11.2"
)</pre></div><p>SBT assembly is an SBT plugin that builds <span class="emphasis"><em>fat</em></span> jars: jars that contain not only the program itself, but all the dependencies for the program.</p><p>Note that we marked Spark as "provided" in the list of dependencies, which means that Spark itself will not be included in the jar (it is provided by the Spark environment anyway). To include the SBT assembly plugin, create a file called <code class="literal">assembly.sbt</code> in the <code class="literal">project/</code> directory, with the following line:</p><div class="informalexample"><pre class="programlisting">addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.14.0")</pre></div><p>You will need to re-start <a id="id451" class="indexterm"></a>SBT for the changes to take effect. You can then create the assembly jar using the <code class="literal">assembly</code> command in SBT. This will create a jar called <code class="literal">spam_mi-assembly-0.1-SNAPSHOT.jar</code> in the <code class="literal">target/scala-2.10</code> directory. You can run this jar using <code class="literal">spark-submit</code>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec64"></a>Reducing logging output and Spark configuration</h3></div></div></div><p>Spark is, by default, very verbose. The default log-level is set to <code class="literal">INFO</code>. To avoid missing important messages, it is useful to change the log settings to <code class="literal">WARN</code>. To change the default log level system-wide, go into the <code class="literal">conf</code> directory in the directory in which you installed Spark. You should find a file called <code class="literal">log4j.properties.template</code>. Rename this file to <code class="literal">log4j.properties</code> and look for the following line:</p><div class="informalexample"><pre class="programlisting">log4j.rootCategory=INFO, console</pre></div><p>Change this line to:</p><div class="informalexample"><pre class="programlisting">log4j.rootCategory=WARN, console</pre></div><p>There are several other configuration files in that directory that you can use to alter Spark's default <a id="id452" class="indexterm"></a>behavior. For a full list of configuration options, head over to <a class="ulink" href="http://spark.apache.org/docs/latest/configuration.html" target="_blank">http://spark.apache.org/docs/latest/configuration.html</a>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec65"></a>Running Spark applications on EC2</h3></div></div></div><p>Running <a id="id453" class="indexterm"></a>Spark locally is useful for testing, but the whole point of using a distributed framework is to run programs harnessing the power of several different computers. We can set Spark up on any set of computers that can communicate with each other using HTTP. In general, we also need to set up a distributed file system like HDFS, so that we can share input files across the cluster. For the purpose of this example, we will set Spark up on an Amazon EC2 cluster.</p><p>Spark comes with a shell script, <code class="literal">ec2/spark-ec2</code>, for setting up an EC2 cluster and installing Spark. It will also install HDFS. You will need an account with Amazon Web Services (AWS) to <a id="id454" class="indexterm"></a>follow these examples (<a class="ulink" href="https://aws.amazon.com" target="_blank">https://aws.amazon.com</a>). You will need the AWS access key and secret key, which you can access through the <span class="strong"><strong>Account</strong></span> / <span class="strong"><strong>Security Credentials</strong></span> / <span class="strong"><strong>Access Credentials</strong></span> menu in the AWS web console. You need to make these available to the <code class="literal">spark-ec2</code> script through environment variables. Inject them into your current session as follows:</p><div class="informalexample"><pre class="programlisting">$ export AWS_ACCESS_KEY_ID=ABCDEF...
$ export AWS_SECRET_ACCESS_KEY=2dEf...</pre></div><p>You can also write these lines into the configuration script for your shell (your <code class="literal">.bashrc</code> file, or equivalent), to avoid having to re-enter them every time you run the <code class="literal">setup-ec2</code> script. We discussed environment variables in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Slick â€“ A Functional Interface for SQL</em></span>.</p><p>You will also need to create a key pair by clicking on <span class="strong"><strong>Key Pairs</strong></span> in the EC2 web console, creating a new key pair and downloading the certificate file. I will assume you named the key pair <code class="literal">test_ec2</code> and the certificate file <code class="literal">test_ec2.pem</code>. Make sure that the key pair is created in the <span class="emphasis"><em>N</em></span>. Virginia region (by choosing the correct region in the upper right corner of the EC2 Management console), to avoid having to specify the region explicitly in the rest of this chapter. You will need to set access permissions on the certificate file to user-readable only:</p><div class="informalexample"><pre class="programlisting">$ chmod 400 test_ec2.pem</pre></div><p>We are now ready to launch the cluster. Navigate to the <code class="literal">ec2</code> directory and run:</p><div class="informalexample"><pre class="programlisting">$ ./spark-ec2 -k test_ec2 -i ~/path/to/certificate/test_ec2.pem -s 2 launch test_cluster</pre></div><p>This will create a cluster called <code class="literal">test_cluster</code> with a master and two slaves. The number of slaves is set through the <code class="literal">-s</code> command line argument. The cluster will take a while to start up, but you can verify that the instances are launching correctly by looking at the <span class="strong"><strong>Instances</strong></span> window in the EC2 Management Console.</p><p>The setup script supports many options for customizing the type of instances, the number of hard drives and so on. You can explore these options by passing the <code class="literal">--help</code> command line option to <code class="literal">spark-ec2</code>.</p><p>The life cycle <a id="id455" class="indexterm"></a>of the cluster can be controlled by passing different commands to the <code class="literal">spark-ec2</code> script, such as:</p><div class="informalexample"><pre class="programlisting"># shut down 'test_cluster'
$ ./spark-ec2 stop test_cluster

# start 'test_cluster'
$ ./spark-ec2 -i test_ec2.pem start test_cluster

# destroy 'test_cluster'
$ ./spark-ec2 destroy test_cluster</pre></div><p>For more detail on <a id="id456" class="indexterm"></a>using Spark on EC2, consult the official documentation at <a class="ulink" href="http://spark.apache.org/docs/latest/ec2-scripts.html#running-applications" target="_blank">http://spark.apache.org/docs/latest/ec2-scripts.html#running-applications</a>.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec97"></a>Spam filtering</h2></div></div><hr /></div><p>Let's put all we've <a id="id457" class="indexterm"></a>learned to good use and do some data exploration for our spam filter. We will use the Ling-Spam email dataset: <a class="ulink" href="http://csmining.org/index.php/ling-spam-datasets.html" target="_blank">http://csmining.org/index.php/ling-spam-datasets.html</a>. The dataset contains 2412 ham emails and 481 spam emails, all of which were received by a mailing list on <a id="id458" class="indexterm"></a>linguistics. We will extract the words that are most informative of whether an email is spam or ham.</p><p>The first steps in any natural language processing workflow are to remove stop words and lemmatization. Removing stop words involves filtering very common words such as <span class="emphasis"><em>the</em></span>, <span class="emphasis"><em>this</em></span> and so on. Lemmatization involves replacing different forms of the same word with a canonical form: both <span class="emphasis"><em>colors</em></span> and <span class="emphasis"><em>color</em></span> would be mapped to <span class="emphasis"><em>color</em></span>, and <span class="emphasis"><em>organize</em></span>, <span class="emphasis"><em>organizing</em></span> and <span class="emphasis"><em>organizes</em></span> would be mapped to <span class="emphasis"><em>organize</em></span>. Removing stop words and lemmatization is very challenging, and beyond the scope of this book (if you do need to remove stop words <a id="id459" class="indexterm"></a>and lemmatize a dataset, your go-to tool should be the Stanford NLP toolkit: <a class="ulink" href="http://nlp.stanford.edu/software/corenlp.shtml" target="_blank">http://nlp.stanford.edu/software/corenlp.shtml</a>). Fortunately, the Ling-Spam e-mail dataset has been cleaned and lemmatized already (which is why the text in the emails looks strange).</p><p>When we do build the spam filter, we will use the presence of a particular word in an email as the feature for our model. We will use a <span class="emphasis"><em>bag-of-words</em></span> approach: we consider which words appear in an email, but not the word order.</p><p>Intuitively, some words will be more important than others when deciding whether an email is spam. For instance, an email that contains <span class="emphasis"><em>language</em></span> is likely to be ham, since the mailing list was for linguistics discussions, and <span class="emphasis"><em>language</em></span> is a word unlikely to be used by spammers. Conversely, words which are common to both message types, for instance <span class="emphasis"><em>hello</em></span>, are unlikely to be much use.</p><p>One way of quantifying the importance of a word in determining whether a message is spam is through the <a id="id460" class="indexterm"></a>
<span class="strong"><strong>Mutual Information</strong></span> (<span class="strong"><strong>MI</strong></span>). The mutual information is the gain in information about whether a message is ham or spam if we know that it contains a particular word. For instance, the presence of <span class="emphasis"><em>language</em></span> in a particular email is very informative as to whether that email is spam or ham. Similarly, the presence of the word <span class="emphasis"><em>dollar</em></span> is informative since it appears often in spam messages and only infrequently in ham messages. By contrast, the presence of the word <span class="emphasis"><em>morning</em></span> is uninformative, since it is approximately equally common in both spam and ham messages. The formula for the mutual information <a id="id461" class="indexterm"></a>between the presence of a particular word in an email, and whether that email is spam or ham is:</p><div class="mediaobject"><img src="graphics/4795_10_01.jpg" /></div><p>where <span class="inlinemediaobject"><img src="graphics/4795_10_02.jpg" /></span> is the joint probability of an email containing a particular word and being of that class (either ham or spam), <span class="inlinemediaobject"><img src="graphics/4795_10_03.jpg" /></span> is the probability that a particular word is present in an email, and <span class="inlinemediaobject"><img src="graphics/4795_10_04.jpg" /></span> is the probability that any email is of that class. The MI is commonly used in decision trees.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note05"></a>Note</h3><p>The derivation of the expression for the mutual information is beyond the scope of this book. The interested reader is directed to <span class="emphasis"><em>David MacKay's</em></span> excellent <span class="emphasis"><em>Information Theory, Inference, and Learning Algorithms</em></span>, especially the chapter <span class="emphasis"><em>Dependent Random Variables</em></span>.</p></div><p>A key component of our MI calculation is evaluating the probability that a word occurs in spam or ham messages. The best approximation to this probability, given our data set, is the fraction of messages a word appears in. Thus, for instance, if <span class="emphasis"><em>language</em></span> appears in 40% of messages, we will assume that the probability <span class="inlinemediaobject"><img src="graphics/4795_10_05.jpg" /></span> of language being present in any message is 0.4. Similarly, if 40% of the messages are ham, and <span class="emphasis"><em>language</em></span> appears in 50% of those, we will assume that the probability of language being present in an email, and <a id="id462" class="indexterm"></a>that email being ham is <span class="inlinemediaobject"><img src="graphics/4795_10_06.jpg" /></span>.</p><p>Let's write a <code class="literal">wordFractionInFiles</code> function to calculate the fraction of messages in which each word appears, for all the words in a given corpus. Our function will take, as argument, a path with a shell wildcard identifying a set of files, such as <code class="literal">ham/*</code>, and it will return a key-value RDD, where the keys are words and the values are the probability that that word occurs in any of those files. We will put the function in an object called <code class="literal">MutualInformation</code>.</p><p>We first give the entire code listing for this function. Don't worry if this doesn't all make sense straight-away: we explain the tricky parts in more detail just after the code. You may find it useful to type some of these commands in the shell, replacing <code class="literal">fileGlob</code> with, for instance <code class="literal">"ham/*"</code>:</p><div class="informalexample"><pre class="programlisting">// MutualInformation.scala
import org.apache.spark.{ SparkConf, SparkContext }
import org.apache.spark.SparkContext._
import org.apache.spark.rdd.RDD

object MutualInformation extends App {

  def wordFractionInFiles(sc:SparkContext)(fileGlob:String)
  :(RDD[(String, Double)], Long) = {

    // A set of punctuation words that need to be filtered out.
    val wordsToOmit = Set[String](
      "", ".", ",", ":", "-", "\"", "'", ")", 
      "(", "@", "/", "Subject:"
    )

    val messages = sc.wholeTextFiles(fileGlob)
    // wholeTextFiles generates a key-value RDD of 
    // file name -&gt; file content

    val nMessages = messages.count()

    // Split the content of each message into a Set of unique
    // words in that message, and generate a new RDD mapping:
    // message -&gt; word
    val message2Word = messages.flatMapValues {
      mailBody =&gt; mailBody.split("\\s").toSet
    }


    val message2FilteredWords = message2Word.filter { 
      case(email, word) =&gt; ! wordsToOmit(word) 
    }

    val word2Message = message2FilteredWords.map { _.swap }

    // word -&gt; number of messages it appears in.
    val word2NumberMessages = word2Message.mapValues { 
      _ =&gt; 1 
    }.reduceByKey { _ + _ }

    // word -&gt; fraction of messages it appears in
    val pPresent = word2NumberMessages.mapValues { 
      _ / nMessages.toDouble 
    }
  
    (pPresent, nMessages)
  }
}</pre></div><p>Let's play with this function in the Spark shell. To be able to access this function from the shell, we need to create a jar with the <code class="literal">MutualInformation</code> object. Write a <code class="literal">build.sbt</code> file similar to the one <a id="id463" class="indexterm"></a>presented in the previous section and package the code into a jar using <code class="literal">sbt package</code>. Then, open a Spark shell with:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ spark-shell --jars=target/scala-2.10/spam_mi_2.10-0.1-SNAPSHOT.jar</strong></span>
</pre></div><p>This will open a Spark shell with our newly created jar on the classpath. Let's run our <code class="literal">wordFractionInFiles</code> method on the <code class="literal">ham</code> emails:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import MutualInformation._</strong></span>
<span class="strong"><strong>import MutualInformation._</strong></span>

<span class="strong"><strong>scala&gt; val (fractions, nMessages) = wordFractionInFiles(sc)("ham/*")</strong></span>
<span class="strong"><strong>fractions: org.apache.spark.rdd.RDD[(String, Double)] = MapPartitionsRDD[13] at mapValues</strong></span>
<span class="strong"><strong>nMessages: Long = 2412</strong></span>
</pre></div><p>Let's get a snapshot of the <code class="literal">fractions</code> RDD:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; fractions.take(5)</strong></span>
<span class="strong"><strong>Array[(String, Double)] = Array((rule-base,0.002902155887230514), (reunion,4.1459369817578774E-4), (embarrasingly,4.1459369817578774E-4), (mller,8.291873963515755E-4), (sapore,4.1459369817578774E-4))</strong></span>
</pre></div><p>It would be nice to see the words that come up most often in ham messages. We can use the <code class="literal">.takeOrdered</code> action to take the top values of an RDD, with a custom ordering. <code class="literal">.takeOrdered</code> expects, as its second argument, an instance of the type class <code class="literal">Ordering[T]</code>, where <code class="literal">T</code> is the type parameter of our RDD: <code class="literal">(String, Double)</code> in this case. <code class="literal">Ordering[T]</code> is a trait with a single <code class="literal">compare(a:T, b:T)</code> method describing how to compare <code class="literal">a</code> and <code class="literal">b</code>. The easiest way of creating an <code class="literal">Ordering[T]</code> is through the companion object's <code class="literal">by</code> method, which defines a key by which to compare the elements of our RDD.</p><p>We want to order the <a id="id464" class="indexterm"></a>elements in our key-value RDD by the value and, since we want the most common words, rather than the least, we need to reverse that ordering:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; fractions.takeOrdered(5)(Ordering.by { - _._2 })</strong></span>
<span class="strong"><strong>res0: Array[(String, Double)] = Array((language,0.6737147595356551), (university,0.6048922056384743), (linguistic,0.5149253731343284), (information,0.45480928689883915), ('s,0.4369817578772803))</strong></span>
</pre></div><p>Unsurprisingly, <code class="literal">language</code> is present in 67% of ham emails, <code class="literal">university</code> in 60% of ham emails and so on. A similar investigation on spam messages reveals that the exclamation mark character <span class="emphasis"><em>!</em></span> is present in 83% of spam emails, <span class="emphasis"><em>our</em></span> is present in 61% and <span class="emphasis"><em>free</em></span> in 57%.</p><p>We are now in a position to start writing the body of our application to calculate the mutual information between each word and whether a message is spam or ham. We will put the body of the code in the <code class="literal">MutualInformation</code> object, which already contains the <code class="literal">wordFractionInFiles</code> method.</p><p>The first step is to create a Spark context:</p><div class="informalexample"><pre class="programlisting">// MutualInformation.scala
import org.apache.spark.{ SparkConf, SparkContext }
import org.apache.spark.SparkContext._
import org.apache.spark.rdd.RDD

object MutualInformation extends App {
  
  def wordFractionInFiles(sc:SparkContext)(fileGlob:String)
  :(RDD[(String, Double)], Long) = {
    ...
  }
  
  <span class="strong"><strong>val conf = new SparkConf().setAppName("lingSpam")</strong></span>
  <span class="strong"><strong>val sc = new SparkContext(conf)</strong></span>
</pre></div><p>Note that we did not need to do this when we were using the Spark shell because the shell comes with a pre-built context bound to the variable <code class="literal">sc</code>.</p><p>We can now calculate the conditional probabilities of a message containing a particular word given that it is <span class="emphasis"><em>spam</em></span>, <span class="inlinemediaobject"><img src="graphics/4795_10_07.jpg" /></span>. This is just the fraction of messages containing that word in the <span class="emphasis"><em>spam</em></span> corpus. This, in turn, lets us infer the joint probability of a message containing a certain word and being <span class="emphasis"><em>spam</em></span> <span class="inlinemediaobject"><img src="graphics/4795_10_08.jpg" /></span>. We will do this for all four combinations of <a id="id465" class="indexterm"></a>classes: whether any given word is present or absent in a message, and whether that message is spam or ham:</p><div class="informalexample"><pre class="programlisting">    /* Conditional probabilities RDD:
       word -&gt; P(present | spam) 
    */
    val (pPresentGivenSpam, nSpam) = wordFractionInFiles(sc)("spam/*")
    val pAbsentGivenSpam = pPresentGivenSpam.mapValues { 1.0 - _ }
    val (pPresentGivenHam, nHam) = wordFractionInFiles(sc)("ham/*")
    val pAbsentGivenHam = pPresentGivenHam.mapValues { 1.0 - _ }

    // pSpam is the fraction of spam messages
    val nMessages = nSpam + nHam
    val pSpam = nSpam / nMessages.toDouble
    
    // pHam is the fraction of ham messages
    val pHam = 1.0 - pSpam 

    /* pPresentAndSpam is a key-value RDD of joint probabilities
       word -&gt; P(word present, spam) 
    */
    val pPresentAndSpam = pPresentGivenSpam.mapValues { 
      _ * pSpam 
    }
    val pPresentAndHam = pPresentGivenHam.mapValues { _ * pHam }
    val pAbsentAndSpam = pAbsentGivenSpam.mapValues { _ * pSpam }
    val pAbsentAndHam = pAbsentGivenHam.mapValues { _ * pHam }</pre></div><p>We will re-use these RDDs in several places in the calculation, so let's tell Spark to keep them in memory to avoid having to re-calculate them:</p><div class="informalexample"><pre class="programlisting">    pPresentAndSpam.persist
    pPresentAndHam.persist
    pAbsentAndSpam.persist
    pAbsentAndHam.persist</pre></div><p>We now need to calculate the probabilities of words being present, <span class="inlinemediaobject"><img src="graphics/4795_10_03.jpg" /></span>. This is just the sum of <code class="literal">pPresentAndSpam</code> and <code class="literal">pPresentAndHam</code>, for each word. The tricky part is that not all words are present in both the ham and spam messages. We must therefore do a full outer <a id="id466" class="indexterm"></a>join of those RDDs. This will give an RDD mapping each word to a pair of <code class="literal">Option[Double]</code> values. For words absent in either the ham or spam messages, we must use a default value. A sensible default is <span class="inlinemediaobject"><img src="graphics/4795_10_09.jpg" /></span> for spam messages (a more rigorous approach would be to use <span class="emphasis"><em>additive smoothing</em></span>). This implies that the word would appear once if the corpus was twice as large.</p><div class="informalexample"><pre class="programlisting">    val pJoined = pPresentAndSpam.fullOuterJoin(pPresentAndHam)
    val pJoinedDefault = pJoined.mapValues {
      case (presentAndSpam, presentAndHam) =&gt; 
        (presentAndSpam.getOrElse(0.5/nSpam * pSpam), 
        presentAndHam.getOrElse(0.5/nHam * pHam))
    }</pre></div><p>Note that we could also have chosen 0 as the default value. This complicates the information gain calculation somewhat, since we cannot just take the log of a zero value, and it seems unlikely that a particular word has exactly zero probability of occurring in an email.</p><p>We can now construct an RDD mapping words to <span class="inlinemediaobject"><img src="graphics/4795_10_03.jpg" /></span>, the probability that a word exists in either a spam or a ham message:</p><div class="informalexample"><pre class="programlisting">    val pPresent = pJoinedDefault.mapValues { 
      case(presentAndHam, presentAndSpam) =&gt; 
        presentAndHam + presentAndSpam 
    }
    pPresent.persist

    val pAbsent = pPresent.mapValues { 1.0 - _ }
    pAbsent.persist</pre></div><p>We now have all the RDDs that we need to calculate the mutual information between the presence of a word in a message and whether it is ham or spam. We need to bring them all together using the equation for the mutual information outlined earlier.</p><p>We will start by <a id="id467" class="indexterm"></a>defining a helper method that, given an RDD of joint probabilities <span class="emphasis"><em>P(X, Y)</em></span> and marginal probabilities <span class="emphasis"><em>P(X)</em></span> and <span class="emphasis"><em>P(Y)</em></span>, calculates <span class="inlinemediaobject"><img src="graphics/4795_10_10.jpg" /></span>. Here, <span class="emphasis"><em>P(X)</em></span> could, for instance, be the probability of a word being present in a message <span class="inlinemediaobject"><img src="graphics/4795_10_03.jpg" /></span> and <span class="emphasis"><em>P(Y)</em></span> would be the probability that that message is <span class="emphasis"><em>spam</em></span>, <span class="inlinemediaobject"><img src="graphics/4795_10_11.jpg" /></span>:</p><div class="informalexample"><pre class="programlisting">    def miTerm(
      pXYs:RDD[(String, Double)], 
      pXs:RDD[(String, Double)], 
      pY: Double,
      default: Double // for words absent in PXY
    ):RDD[(String, Double)] = 
      pXs.leftOuterJoin(pXYs).mapValues { 
        case (pX, Some(pXY)) =&gt; pXY * math.log(pXY/(pX*pY)) 
        case (pX, None) =&gt; default * math.log(default/(pX*pY))
    }</pre></div><p>We can use our function to calculate the four terms in the mutual information sum:</p><div class="informalexample"><pre class="programlisting">    val miTerms = List(
      miTerm(pPresentAndSpam, pPresent, pSpam, 0.5/nSpam * pSpam),
      miTerm(pPresentAndHam, pPresent, pHam, 0.5/nHam * pHam),
      miTerm(pAbsentAndSpam, pAbsent, pSpam, 0.5/nSpam * pSpam),
      miTerm(pAbsentAndHam, pAbsent, pHam, 0.5/nHam * pHam)
    )</pre></div><p>Finally, we just need to sum those four terms together:</p><div class="informalexample"><pre class="programlisting">    val mutualInformation = miTerms.reduce { 
      (term1, term2) =&gt; term1.join(term2).mapValues { 
         case (l, r) =&gt; l + r 
      } 
    }</pre></div><p>The RDD <code class="literal">mutualInformation</code> is a key-value RDD mapping each word to a measure of how informative the presence of that word is in discerning whether a message is spam or ham. Let's print out the twenty words that are most informative of whether a message is ham or spam:</p><div class="informalexample"><pre class="programlisting">    mutualInformation.takeOrdered(20)(Ordering.by { - _._2 })
      .foreach { println }</pre></div><p>Let's run this <a id="id468" class="indexterm"></a>using <code class="literal">spark-submit</code>:</p><div class="informalexample"><pre class="programlisting">$ sbt package
$ spark-submit target/scala-2.10/spam_mi_2.10-0.1-SNAPSHOT.jar
(!,0.1479941771292119)
(language,0.14574624861510874)
(remove,0.11380645864246142)
(free,0.1073496947123657)
(university,0.10695975885487692)
(money,0.07531772498093084)
(click,0.06887598051593441)
(our,0.058950906866052394)
(today,0.05485248095680509)
(sell,0.05385519653184113)
(english,0.053509319455430575)
(business,0.05299311289740539)
(market,0.05248394151802276)
(product,0.05096229706182162)
(million,0.050233193237964546)
(linguistics,0.04990172586630499)
(internet,0.04974101556655623)
(company,0.04941817269989519)
(%,0.04890193809823071)
(save,0.04861393414892205)</pre></div><p>Thus, we find that the presence of words like <code class="literal">language</code> or <code class="literal">free</code> or <code class="literal">!</code> carry the most information, because they are almost exclusively present in either just spam messages or just ham messages. A very simple classification algorithm could just take the top 10 (by mutual information) spam words, and the top 10 ham words and see whether a message contains more spam words or ham words. We will explore machine learning algorithms for classification in more depth in <a class="link" href="#" linkend="ch12">Chapter 12</a>, <span class="emphasis"><em>Distributed Machine Learning with MLlib</em></span>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec98"></a>Lifting the hood</h2></div></div><hr /></div><p>In the last section of this chapter, we will discuss, very briefly, how Spark works internally. For a more detailed discussion, see the <span class="emphasis"><em>References</em></span> section at the end of the chapter.</p><p>When you open a Spark context, either explicitly or by launching the Spark shell, Spark starts a web UI with details of how the current task and past tasks have executed. Let's see this in action for the example mutual information program we wrote in the last section. To prevent the context from shutting down when the program completes, you can insert a call to <code class="literal">readLine</code> as the last line of the <code class="literal">main</code> method (after the call to <code class="literal">takeOrdered</code>). This expects input from the user, and will therefore pause program execution until you press <span class="emphasis"><em>enter</em></span>.</p><p>To access the UI, point your browser to <code class="literal">127.0.0.1:4040</code>. If you have other instances of the Spark shell running, the port may be <code class="literal">4041</code>, or <code class="literal">4042</code> and so on.</p><div class="mediaobject"><img src="graphics/4795_10_12.jpg" /></div><p>The first page of the UI tells us that our application contains three <span class="emphasis"><em>jobs</em></span>. A job occurs as the result of an action. There are, indeed, three actions in our application: the first two are called within the <code class="literal">wordFractionInFiles</code> function:</p><div class="informalexample"><pre class="programlisting">val nMessages = messages.count()</pre></div><p>The last job results from the call to <code class="literal">takeOrdered</code>, which forces the execution of the entire pipeline of RDD transformations that calculate the mutual information.</p><p>The web UI lets us delve deeper into each job. Click on the <code class="literal">takeOrdered</code> job in the job table. You will get taken to a page that describes the job in more detail:</p><div class="mediaobject"><img src="graphics/4795_10_13.jpg" /></div><p>Of particular interest is the <span class="strong"><strong>DAG visualization</strong></span> entry. This is a graph of the execution plan to fulfill the action, and provides a glimpse of the inner workings of Spark.</p><p>When you define a job by calling an action on an RDD, Spark looks at the RDD's lineage and constructs a graph mapping the dependencies: each RDD in the lineage is represented by a node, with directed edges going from this RDD's parent to itself. This type of graph is called a <span class="strong"><strong>directed </strong></span>
<a id="id469" class="indexterm"></a>
<span class="strong"><strong>acyclic graph</strong></span> (<span class="strong"><strong>DAG</strong></span>), and is a data structure useful for dependency resolution. Let's explore the DAG for the <code class="literal">takeOrdered</code> job in our program using the web UI. The graph is quite complex, and it is therefore easy to get lost, so here is a simplified reproduction that only lists the RDDs bound to variable names in the program.</p><div class="mediaobject"><img src="graphics/4795_10_14.jpg" /></div><p>As you can see, at the bottom of the graph, we have the <code class="literal">mutualInformation </code>RDD. This is the RDD that we need to construct for our action. This RDD depends on the intermediate elements in the sum, <code class="literal">igFragment1</code>, <code class="literal">igFragment2</code>, and so on. We can work our way back through the list of dependencies until we reach the other end of the graph: RDDs that do not depend on other RDDs, only on external sources.</p><p>Once the graph is built, the Spark engines formulates a plan to execute the job. The plan starts with the RDDs that only have external dependencies (such as RDDs built by loading files from disk or fetching from a database) or RDDs that already have cached data. Each arrow along the graph is translated to a set of <span class="emphasis"><em>tasks</em></span>, with each task applying a transformation to a partition of the data.</p><p>Tasks are grouped into <span class="emphasis"><em>stages</em></span>. A stage consists of a set of tasks that can all be performed without needing an intermediate shuffle.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec99"></a>Data shuffling and partitions</h2></div></div><hr /></div><p>To understand <a id="id470" class="indexterm"></a>data shuffling in Spark, we first need to understand how <a id="id471" class="indexterm"></a>data is partitioned in RDDs. When we create an RDD by, for instance, loading a file from HDFS, or reading a file in local storage, Spark has no control over what bits of data are distributed in which partitions. This becomes a problem for key-value RDDs: these often require knowing where occurrences of a particular key are, for instance to perform a join. If the key can occur anywhere in the RDD, we have to look through every partition to find the key.</p><p>To prevent this, Spark allows the definition of a <span class="emphasis"><em>partitioner</em></span> on key-value RDDs. A partitioner is an attribute of the RDD that determines which partition a particular key lands in. When an RDD has a partitioner set, the location of a key is entirely determined by the partitioner, and not by the RDD's history, or the number of keys. Two different RDDs with the same partitioner will map the same key to the same partition.</p><p>Partitions impact performance through their effect on transformations. There are two types of transformations on key-value RDDs:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Narrow transformations, like <code class="literal">mapValues</code>. In narrow transformations, the data to compute a partition in the child RDD resides on a single partition in the parent. The data processing for a narrow transformation can therefore be performed entirely locally, without needing to communicate data between nodes.</p></li><li style="list-style-type: disc"><p>Wide transformations, like <code class="literal">reduceByKey</code>. In wide transformations, the data to compute any single partition can reside on all the partitions in the parent. The RDD resulting from a wide transformation will, in general, have a partitioner set. For instance, the output of a <code class="literal">reduceByKey</code> transformation are hash-partitioned by default: the partition that a particular key ends up in is determined by <code class="literal">hash(key) % numPartitions</code>.</p></li></ul></div><p>Thus, in our mutual information example, the RDDs <code class="literal">pPresentAndSpam</code> and <code class="literal">pPresentAndHam</code> will have the same partition structure since they both have the default hash partitioner. All descendent RDDs retain the same keys, all the way down to <code class="literal">mutualInformation</code>. The word <code class="literal">language</code>, for instance, will be in the same partition for each RDD.</p><p>Why does all this matter? If an RDD has a partitioner set, this partitioner is retained through all subsequent narrow transformations originating from this RDD. Let's go back to our mutual information example. The RDDs <code class="literal">pPresentGivenHam</code> and <code class="literal">pPresentGivenSpam</code> both originate from <code class="literal">reduceByKey</code> operations, and they both have string keys. They will therefore both have the same hash-partitioner (unless we explicitly set a different partitioner). This partitioner is retained as we construct <code class="literal">pPresentAndSpam</code> and <code class="literal">pPresentAndHam</code>. When we construct <code class="literal">pPresent</code>, we perform a full outer join of <code class="literal">pPresentAndSpam</code> and <code class="literal">pPresentAndHam</code>. Since both these RDDs have the same partitioner, the child RDD <code class="literal">pPresent</code> has narrow dependencies: we can just join the first partition of <code class="literal">pPresentAndSpam</code> with the first partition of <code class="literal">pPresentAndHam</code>, the second partition of <code class="literal">pPresentAndSpam</code> with the second partition of <code class="literal">pPresentAndHam</code> and so on, since any string key will be hashed to the same partition in both RDDs. By contrast, without partitioner, we would have to join the data in each partition of <code class="literal">pPresentAndSpam</code> with <a id="id472" class="indexterm"></a>every partition of <code class="literal">pPresentAndSpam</code>. This would require sending data across the network to all the nodes holding <code class="literal">pPresentAndSpam</code>, a time-consuming exercise.</p><p>This process of having to send <a id="id473" class="indexterm"></a>the data to construct a child RDD across the network, as a result of wide dependencies, is called <span class="emphasis"><em>shuffling</em></span>. Much of the art of optimizing a Spark program involves reducing shuffling and, when shuffling is necessary, reducing the amount of shuffling.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec100"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we explored the basics of Spark and learned how to construct and manipulate RDDs. In the next chapter, we will learn about Spark SQL and DataFrames, a set of implicit conversions that allow us to manipulate RDDs in a manner similar to pandas DataFrames, and how to interact with different data sources using Spark.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec101"></a>Reference</h2></div></div><hr /></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<span class="emphasis"><em>Learning Spark</em></span>, by <span class="emphasis"><em>Holden Karau</em></span>, <span class="emphasis"><em>Andy Konwinski</em></span>, <span class="emphasis"><em>Patrick Wendell</em></span>, and <span class="emphasis"><em>Matei Zaharia</em></span>, <span class="emphasis"><em>O'Reilly</em></span>, provides a much more complete introduction to Spark that this chapter can provide. I thoroughly recommend it.</p></li><li style="list-style-type: disc"><p>If you are interested in learning more about information theory, I recommend <span class="emphasis"><em>David MacKay's</em></span> book <span class="emphasis"><em>Information Theory, Inference, and Learning Algorithms</em></span>.</p></li><li style="list-style-type: disc"><p>
<span class="emphasis"><em>Information Retrieval</em></span>, by <span class="emphasis"><em>Manning</em></span>, <span class="emphasis"><em>Raghavan</em></span>, and <span class="emphasis"><em>SchÃ¼tze</em></span>, describes how to analyze textual data (including lemmatization and stemming). An online </p></li><li style="list-style-type: disc"><p>On the Ling-Spam <a id="id474" class="indexterm"></a>dataset, and how to analyze it: <a class="ulink" href="http://www.aueb.gr/users/ion/docs/ir_memory_based_antispam_filtering.pdf" target="_blank">http://www.aueb.gr/users/ion/docs/ir_memory_based_antispam_filtering.pdf</a>.</p></li><li style="list-style-type: disc"><p>This blog post <a id="id475" class="indexterm"></a>delves into the Spark Web UI in more detail. <a class="ulink" href="https://databricks.com/blog/2015/06/22/understanding-your-spark-application-through-visualization.html" target="_blank">https://databricks.com/blog/2015/06/22/understanding-your-spark-application-through-visualization.html</a>.</p></li><li style="list-style-type: disc"><p>This blog <a id="id476" class="indexterm"></a>post, by <span class="emphasis"><em>Sandy Ryza</em></span>, is the first in a two-part series discussing Spark internals, and how to leverage them to improve performance: <a class="ulink" href="http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/" target="_blank">http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/</a>.</p></li></ul></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch11"></a>ChapterÂ 11.Â Spark SQL and DataFrames</h2></div></div></div><p>In the previous chapter, we learned how to build a simple distributed application using Spark. The data that we used took the form of a set of e-mails stored as text files.</p><p>We learned that <a id="id477" class="indexterm"></a>Spark was built around the concept of <span class="strong"><strong>resilient distributed datasets</strong></span> (<span class="strong"><strong>RDDs</strong></span>). We explored several types of RDDs: simple RDDs of strings, key-value RDDs, and RDDs of doubles. In the case of key-value RDDs and RDDs of doubles, Spark added functionality beyond that of the simple RDDs through implicit <a id="id478" class="indexterm"></a>conversions. There is one important type of RDD that we have not <a id="id479" class="indexterm"></a>explored yet: <span class="strong"><strong>DataFrames</strong></span> (previously called <span class="strong"><strong>SchemaRDD</strong></span>). DataFrames allow the manipulation of objects significantly more complex than those we have explored to date.</p><p>A DataFrame is a distributed tabular data structure, and is therefore very useful for representing and manipulating structured data. In this chapter, we will first investigate DataFrames through the Spark shell, and then use the Ling-spam e-mail dataset, presented in the previous chapter, to see how DataFrames can be integrated in a machine learning pipeline.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec102"></a>DataFrames â€“ a whirlwind introduction</h2></div></div><hr /></div><p>Let's start by <a id="id480" class="indexterm"></a>opening a Spark shell:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ spark-shell</strong></span>
</pre></div><p>Let's imagine that we are interested in running analytics on a set of patients to estimate their overall health level. We have measured, for each patient, their height, weight, age, and whether they smoke.</p><p>We might represent the readings for each patient as a case class (you might wish to write some of this in a text editor and paste it into the Scala shell using <code class="literal">:paste</code>):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class PatientReadings(</strong></span>
<span class="strong"><strong>  val patientId: Int,</strong></span>
<span class="strong"><strong>  val heightCm: Int,</strong></span>
<span class="strong"><strong>  val weightKg: Int,</strong></span>
<span class="strong"><strong>  val age:Int,    </strong></span>
<span class="strong"><strong>  val isSmoker:Boolean  </strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>defined class PatientReadings</strong></span>
</pre></div><p>We would, typically, have many thousands of patients, possibly stored in a database or a CSV file. We will worry about <a id="id481" class="indexterm"></a>how to interact with external sources later in this chapter. For now, let's just hard-code a few readings directly in the shell:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val readings = List(</strong></span>
<span class="strong"><strong>  PatientReadings(1, 175, 72, 43, false),</strong></span>
<span class="strong"><strong>  PatientReadings(2, 182, 78, 28, true),</strong></span>
<span class="strong"><strong>  PatientReadings(3, 164, 61, 41, false),</strong></span>
<span class="strong"><strong>  PatientReadings(4, 161, 62, 43, true)</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>List[PatientReadings] = List(...</strong></span>
</pre></div><p>We can convert <code class="literal">readings</code> to an RDD by using <code class="literal">sc.parallelize</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val readingsRDD = sc.parallelize(readings)</strong></span>
<span class="strong"><strong>readingsRDD: RDD[PatientReadings] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:25</strong></span>
</pre></div><p>Note that the type parameter of our RDD is <code class="literal">PatientReadings</code>. Let's convert the RDD to a DataFrame using the <code class="literal">.toDF</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val readingsDF = readingsRDD.toDF</strong></span>
<span class="strong"><strong>readingsDF: sql.DataFrame = [patientId: int, heightCm: int, weightKg: int, age: int, isSmoker: boolean]</strong></span>
</pre></div><p>We have created a DataFrame where each row corresponds to the readings for a specific patient, and the columns correspond to the different features:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true|</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
</pre></div><p>The easiest way to create a DataFrame is to use the <code class="literal">toDF</code> method on an RDD. We can convert any <code class="literal">RDD[T]</code>, where <code class="literal">T</code> is a case class or a tuple, to a DataFrame. Spark will map each attribute of the case class to a column of the appropriate type in the DataFrame. It uses reflection to discover the names and types of the attributes. There are several other ways of constructing DataFrames, both from RDDs and from external sources, which we will explore later in this chapter.</p><p>DataFrames support many operations for manipulating the rows and columns. For instance, let's add <a id="id482" class="indexterm"></a>a column for the <span class="strong"><strong>Body Mass Index</strong></span> (<span class="strong"><strong>BMI</strong></span>). The BMI <a id="id483" class="indexterm"></a>is a common way of aggregating <span class="emphasis"><em>height</em></span> and <span class="emphasis"><em>weight</em></span> to decide if someone is overweight or underweight. The formula for the BMI is:</p><div class="mediaobject"><img src="graphics/4795_11_01.jpg" /></div><p>Let's start by creating a column of the height in meters:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val heightM = readingsDF("heightCm") / 100.0     </strong></span>
<span class="strong"><strong>heightM: sql.Column = (heightCm / 100.0)</strong></span>
</pre></div><p>
<code class="literal">heightM</code> has data type <code class="literal">Column</code>, representing a column of data in a DataFrame. Columns support many arithmetic and comparison operators that apply element-wise across the column (similarly to Breeze vectors encountered in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>). Operations on columns are lazy: the <code class="literal">heightM</code> column is not actually computed when defined. Let's now define a BMI column:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val bmi = readingsDF("weightKg") / (heightM*heightM)</strong></span>
<span class="strong"><strong>bmi: sql.Column = (weightKg / ((heightCm / 100.0) * (heightCm / 100.0)))</strong></span>
</pre></div><p>It would be useful to add the <code class="literal">bmi</code> column to our readings DataFrame. Since DataFrames, like RDDs, are immutable, we must define a new DataFrame that is identical to <code class="literal">readingsDF</code>, but with an additional column for the BMI. We can do this using the <code class="literal">withColumn</code> method, which takes, as its arguments, the name of the new column and a <code class="literal">Column</code> instance:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val readingsWithBmiDF = readingsDF.withColumn("BMI", bmi)</strong></span>
<span class="strong"><strong>readingsWithBmiDF: sql.DataFrame = [heightCm: int, weightKg: int, age: int, isSmoker: boolean, BMI: double]</strong></span>
</pre></div><p>All the operations we have seen so far are <span class="emphasis"><em>transformations</em></span>: they define a pipeline of operations that create new DataFrames. These transformations are executed when we call an <span class="strong"><strong>action</strong></span>, such as <code class="literal">show</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsWithBmiDF.show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|               BMI|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|23.510204081632654|</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true| 23.54788069073783|</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|22.679952409280194|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|  23.9188302920412|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
</pre></div><p>Besides creating additional columns, DataFrames also support filtering rows that satisfy a certain predicate. For instance, we can select all smokers:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsWithBmiDF.filter {</strong></span>
<span class="strong"><strong>  readingsWithBmiDF("isSmoker") </strong></span>
<span class="strong"><strong>}.show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|              BMI|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true|23.54788069073783|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true| 23.9188302920412|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
</pre></div><p>Or, to select everyone who weighs more than 70 kgs:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsWithBmiDF.filter { </strong></span>
<span class="strong"><strong>  readingsWithBmiDF("weightKg") &gt; 70 </strong></span>
<span class="strong"><strong>}.show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|               BMI|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|23.510204081632654|</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true| 23.54788069073783|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
</pre></div><p>It can become <a id="id484" class="indexterm"></a>cumbersome to keep repeating the DataFrame name in an expression. Spark defines the operator <code class="literal">$</code> to refer to a column in the current DataFrame. Thus, the <code class="literal">filter</code> expression above could have been written more succinctly using:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsWithBmiDF.filter { $"weightKg" &gt; 70 }.show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|               BMI|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|23.510204081632654|</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true| 23.54788069073783|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
</pre></div><p>The <code class="literal">.filter</code> method is overloaded. It accepts either a column of Boolean values, as above, or a string identifying a Boolean column in the current DataFrame. Thus, to filter our <code class="literal">readingsWithBmiDF</code> DataFrame to sub-select smokers, we could also have used the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsWithBmiDF.filter("isSmoker").show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|              BMI|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true|23.54788069073783|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true| 23.9188302920412|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
</pre></div><p>When comparing for <a id="id485" class="indexterm"></a>equality, you must compare columns with the special <span class="emphasis"><em>triple-equals</em></span> operator:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsWithBmiDF.filter { $"age" === 28 }.show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|              BMI|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true|23.54788069073783|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+-----------------+</strong></span>
</pre></div><p>Similarly, you must use <code class="literal">!==</code> to select rows that are not equal to a value:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsWithBmiDF.filter { $"age" !== 28 }.show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|               BMI|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|23.510204081632654|</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|22.679952409280194|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|  23.9188302920412|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+------------------+</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec103"></a>Aggregation operations</h2></div></div><hr /></div><p>We have seen <a id="id486" class="indexterm"></a>how to apply an operation to every row in a DataFrame to create a new column, and we have seen how to use filters to build new DataFrames with a sub-set of rows from the original DataFrame. The last set of operations on DataFrames is grouping operations, equivalent to the <code class="literal">GROUP BY</code> statement in SQL. Let's calculate the average BMI for smokers and non-smokers. We must first tell Spark to group the DataFrame by a column (the <code class="literal">isSmoker</code> column, in this case), and then apply an aggregation operation (averaging, in this case) to reduce each group:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val smokingDF = readingsWithBmiDF.groupBy(</strong></span>
<span class="strong"><strong>  "isSmoker").agg(avg("BMI"))</strong></span>
<span class="strong"><strong>smokingDF: org.apache.spark.sql.DataFrame = [isSmoker: boolean, AVG(BMI): double]</strong></span>
</pre></div><p>This has created a new DataFrame with two columns: the grouping column and the column over which we aggregated. Let's show this DataFrame:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; smokingDF.show</strong></span>
<span class="strong"><strong>+--------+------------------+</strong></span>
<span class="strong"><strong>|isSmoker|          AVG(BMI)|</strong></span>
<span class="strong"><strong>+--------+------------------+</strong></span>
<span class="strong"><strong>|    true|23.733355491389517|</strong></span>
<span class="strong"><strong>|   false|23.095078245456424|</strong></span>
<span class="strong"><strong>+--------+------------------+</strong></span>
</pre></div><p>Besides averaging, there are several operators for performing the aggregation across each group. We outline <a id="id487" class="indexterm"></a>some of the more important ones in the table below, but, for <a id="id488" class="indexterm"></a>a full list, consult the <span class="emphasis"><em>Aggregate functions</em></span> section of <a class="ulink" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$" target="_blank">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$</a>:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left" /><col align="left" /></colgroup><thead><tr><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Operator</p>
</th><th style="border-bottom: 0.5pt solid ; " align="left" valign="bottom">
<p>Notes</p>
</th></tr></thead><tbody><tr><td style="" align="left" valign="top">
<p>
<code class="literal">avg(column)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Group averages of the values in the specified column.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">count(column)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Number of elements in each group in the specified column.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">countDistinct(column, ... )</code>
</p>
</td><td style="" align="left" valign="top">
<p>Number of distinct elements in each group. This can also accept multiple columns to return the count of unique elements across several columns.</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">first(column), last(column)</code>
</p>
</td><td style="" align="left" valign="top">
<p>First/last element in each group</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">max(column), min(column)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Largest/smallest element in each group</p>
</td></tr><tr><td style="" align="left" valign="top">
<p>
<code class="literal">sum(column)</code>
</p>
</td><td style="" align="left" valign="top">
<p>Sum of the values in each group</p>
</td></tr></tbody></table></div><p>Each aggregation operator takes either the name of a column, as a string, or an expression of type <code class="literal">Column</code>. The latter allows aggregation of compound expressions. If we wanted the average height, in meters, of the smokers and non-smokers in our sample, we could use:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.groupBy("isSmoker").agg { </strong></span>
<span class="strong"><strong>  avg($"heightCm"/100.0) </strong></span>
<span class="strong"><strong>}.show</strong></span>
<span class="strong"><strong>+--------+-----------------------+</strong></span>
<span class="strong"><strong>|isSmoker|AVG((heightCm / 100.0))|</strong></span>
<span class="strong"><strong>+--------+-----------------------+</strong></span>
<span class="strong"><strong>|    true|                  1.715|</strong></span>
<span class="strong"><strong>|   false|     1.6949999999999998|</strong></span>
<span class="strong"><strong>+--------+-----------------------+</strong></span>
</pre></div><p>We can also use compound expressions to define the column on which to group. For instance, to count the number of patients in each <code class="literal">age</code> group, increasing by decade, we can use:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.groupBy(floor($"age"/10)).agg(count("*")).show</strong></span>
<span class="strong"><strong>+-----------------+--------+</strong></span>
<span class="strong"><strong>|FLOOR((age / 10))|count(1)|</strong></span>
<span class="strong"><strong>+-----------------+--------+</strong></span>
<span class="strong"><strong>|              4.0|       3|</strong></span>
<span class="strong"><strong>|              2.0|       1|</strong></span>
<span class="strong"><strong>+-----------------+--------+</strong></span>
</pre></div><p>We have used the <a id="id489" class="indexterm"></a>short-hand <code class="literal">"*"</code> to indicate a count over every column.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec104"></a>Joining DataFrames together</h2></div></div><hr /></div><p>So far, we have <a id="id490" class="indexterm"></a>only considered operations on a single DataFrame. Spark also offers SQL-like joins to combine DataFrames. Let's assume that we have another DataFrame mapping the patient id to a (systolic) blood pressure measurement. We will assume we have the data as a list of pairs mapping patient IDs to blood pressures:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val bloodPressures = List((1 -&gt; 110), (3 -&gt; 100), (4 -&gt; 125))</strong></span>
<span class="strong"><strong>bloodPressures: List[(Int, Int)] = List((1,110), (3,100), (4,125))</strong></span>

<span class="strong"><strong>scala&gt; val bloodPressureRDD = sc.parallelize(bloodPressures)</strong></span>
<span class="strong"><strong>res16: rdd.RDD[(Int, Int)] = ParallelCollectionRDD[74] at parallelize at &lt;console&gt;:24</strong></span>
</pre></div><p>We can construct a DataFrame from this RDD of tuples. However, unlike when constructing DataFrames from RDDs of case classes, Spark cannot infer column names. We must therefore pass these explicitly to <code class="literal">.toDF</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val bloodPressureDF = bloodPressureRDD.toDF(</strong></span>
<span class="strong"><strong>  "patientId", "bloodPressure")</strong></span>
<span class="strong"><strong>bloodPressureDF: DataFrame = [patientId: int, bloodPressure: int]</strong></span>

<span class="strong"><strong>scala&gt; bloodPressureDF.show</strong></span>
<span class="strong"><strong>+---------+-------------+</strong></span>
<span class="strong"><strong>|patientId|bloodPressure|</strong></span>
<span class="strong"><strong>+---------+-------------+</strong></span>
<span class="strong"><strong>|        1|          110|</strong></span>
<span class="strong"><strong>|        3|          100|</strong></span>
<span class="strong"><strong>|        4|          125|</strong></span>
<span class="strong"><strong>+---------+-------------+</strong></span>
</pre></div><p>Let's join <code class="literal">bloodPressureDF</code> with <code class="literal">readingsDF</code>, using the patient ID as the join key:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.join(bloodPressureDF, </strong></span>
<span class="strong"><strong>  readingsDF("patientId") === bloodPressureDF("patientId")</strong></span>
<span class="strong"><strong>).show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+---------+-------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|patientId|bloodPressure|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+---------+-------------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|        1|          110|</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|        3|          100|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|        4|          125|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+---------+-------------+</strong></span>
</pre></div><p>This performs an <span class="emphasis"><em>inner join</em></span>: only patient IDs present in both DataFrames are included in the result. The type of join can be passed as an extra argument to <code class="literal">join</code>. For instance, we can perform a <span class="emphasis"><em>left join</em></span>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.join(bloodPressureDF,</strong></span>
<span class="strong"><strong>  readingsDF("patientId") === bloodPressureDF("patientId"),</strong></span>
<span class="strong"><strong>  "leftouter"</strong></span>
<span class="strong"><strong>).show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+---------+-------------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|patientId|bloodPressure|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+---------+-------------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|        1|          110|</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true|     null|         null|</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|        3|          100|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|        4|          125|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+---------+-------------+</strong></span>
</pre></div><p>Possible join types are <a id="id491" class="indexterm"></a>
<code class="literal">inner</code>, <code class="literal">outer</code>, <code class="literal">leftouter</code>, <code class="literal">rightouter</code>, or <code class="literal">leftsemi</code>. These should all be familiar, apart from <code class="literal">leftsemi</code>, which corresponds to a <span class="emphasis"><em>left semi join</em></span>.<code class="literal"> </code>This is the same as an inner join, but only the columns on the left-hand side are retained after the join. It is thus a way to filter a DataFrame for rows which are present in another DataFrame.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec105"></a>Custom functions on DataFrames</h2></div></div><hr /></div><p>So far, we have <a id="id492" class="indexterm"></a>only used built-in functions to operate on DataFrame columns. While these are often sufficient, we sometimes need greater flexibility. Spark <a id="id493" class="indexterm"></a>lets us apply custom transformations to every row through <span class="strong"><strong>user-defined functions</strong></span> (<span class="strong"><strong>UDFs</strong></span>). Let's assume that we want to use the equation that we derived in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>, for the probability of a person being male, given their height and weight. We calculated that the decision boundary was given by:</p><div class="mediaobject"><img src="graphics/4795_11_02.jpg" /></div><p>Any person with <span class="emphasis"><em>f &gt; 0</em></span> is more likely to be male than female, given their height and weight and the training set used for <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Manipulating Data with Breeze</em></span> (which was based on students, so is unlikely to be representative of the population as a whole). To convert from a height in centimeters to the normalized height, <span class="emphasis"><em>rescaledHeight</em></span>, we can use this formula:</p><div class="mediaobject"><img src="graphics/4795_11_03.jpg" /></div><p>Similarly, to convert a weight (in kilograms) to the normalized weight, <span class="emphasis"><em>rescaledWeight</em></span>, we <a id="id494" class="indexterm"></a>can use:</p><div class="mediaobject"><img src="graphics/4795_11_04.jpg" /></div><p>The average and standard deviation of the <span class="emphasis"><em>height</em></span> and <span class="emphasis"><em>weight</em></span> are calculated from the training set. Let's write a Scala function that returns whether a person is more likely to be male, given their height and weight:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; def likelyMale(height:Int, weight:Int):Boolean = {</strong></span>
<span class="strong"><strong>  val rescaledHeight = (height - 171.0)/8.95</strong></span>
<span class="strong"><strong>  val rescaledWeight = (weight - 65.7)/13.4</strong></span>
<span class="strong"><strong>  -0.75 + 2.48*rescaledHeight + 2.23*rescaledWeight &gt; 0</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>To use this function on Spark DataFrames, we need to register it as a <span class="strong"><strong>user-defined function</strong></span> (<span class="strong"><strong>UDF</strong></span>). This <a id="id495" class="indexterm"></a>transforms our function, which accepts integer arguments, into one that accepts column arguments:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val likelyMaleUdf = sqlContext.udf.register(</strong></span>
<span class="strong"><strong>  "likelyMaleUdf", likelyMale _)</strong></span>
<span class="strong"><strong>likelyMaleUdf: org.apache.spark.sql.UserDefinedFunction = UserDefinedFunction(&lt;function2&gt;,BooleanType,List())</strong></span>
</pre></div><p>To register a UDF, we must have access to a <code class="literal">sqlContext</code> instance. The SQL context provides the entry point for DataFrame operations. The Spark shell creates a SQL context at startup, bound to the variable <code class="literal">sqlContext</code>, and destroys it when the shell session is closed.</p><p>The first argument passed to the <code class="literal">register</code> function is the name of the UDF (we will use the UDF name later when we write SQL statements on the DataFrame, but you can ignore it for now). We can then use the UDF just like the built-in transformations included in Spark:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val likelyMaleColumn = likelyMaleUdf(</strong></span>
<span class="strong"><strong>  readingsDF("heightCm"), readingsDF("weightKg"))</strong></span>
<span class="strong"><strong>likelyMaleColumn: org.apache.spark.sql.Column = UDF(heightCm,weightKg)</strong></span>

<span class="strong"><strong>scala&gt; readingsDF.withColumn("likelyMale", likelyMaleColumn).show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+----------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|likelyMale|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+----------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|      true|</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true|      true|</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|     false|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|     false|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+----------+</strong></span>
</pre></div><p>As you can see, Spark applies the function underlying the UDF to every row in the DataFrame. We are <a id="id496" class="indexterm"></a>not limited to using UDFs to create new columns. We can also use them in <code class="literal">filter</code> expressions. For instance, to select rows likely to correspond to women:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.filter(</strong></span>
<span class="strong"><strong>  ! likelyMaleUdf($"heightCm", $"weightKg")</strong></span>
<span class="strong"><strong>).show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
</pre></div><p>Using UDFs lets us define arbitrary Scala functions to transform rows, giving tremendous additional power for data manipulation.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec106"></a>DataFrame immutability and persistence</h2></div></div><hr /></div><p>DataFrames, like <a id="id497" class="indexterm"></a>RDDs, are immutable. When you define a <a id="id498" class="indexterm"></a>transformation on a DataFrame, this always creates a new DataFrame. The original DataFrame cannot be modified in place (this is notably different to pandas DataFrames, for instance).</p><p>Operations on DataFrames can be grouped into two: <span class="emphasis"><em>transformations</em></span>, which result in the creation of a new DataFrame, and <span class="emphasis"><em>actions</em></span>, which usually return a Scala type or have a side-effect. Methods like <code class="literal">filter</code> or <code class="literal">withColumn</code> are transformations, while methods like <code class="literal">show</code> or <code class="literal">head</code> are actions.</p><p>Transformations are lazy, much like transformations on RDDs. When you generate a new DataFrame by transforming an existing DataFrame, this results in the elaboration of an execution plan for creating the new DataFrame, but the data itself is not transformed immediately. You can <a id="id499" class="indexterm"></a>access the execution plan with the <code class="literal">queryExecution</code> <a id="id500" class="indexterm"></a>method.</p><p>When you call an action on a DataFrame, Spark processes the action as if it were a regular RDD: it implicitly builds a direct acyclic graph to resolve dependencies, processing the transformations needed to build the DataFrame on which the action was called.</p><p>Much like RDDs, we can persist DataFrames in memory or on disk:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.persist</strong></span>
<span class="strong"><strong>readingsDF.type = [patientId: int, heightCm: int,...]</strong></span>
</pre></div><p>This works in the same way as persisting RDDs: next time the RDD is calculated, it will be kept in memory (provided there is enough space), rather than discarded. The level of persistence can also be set:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.storage.StorageLevel</strong></span>
<span class="strong"><strong>import org.apache.spark.storage.StorageLevel</strong></span>

<span class="strong"><strong>scala&gt; readingsDF.persist(StorageLevel.MEMORY_AND_DISK)</strong></span>
<span class="strong"><strong>readingsDF.type = [patientId: int, heightCm: int, ...]</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec107"></a>SQL statements on DataFrames</h2></div></div><hr /></div><p>By now, you will <a id="id501" class="indexterm"></a>have noticed that many operations on DataFrames are inspired by SQL operations. Additionally, Spark allows us to register <a id="id502" class="indexterm"></a>DataFrames as tables and query them with SQL statements directly. We can therefore build a temporary database as part of the program flow.</p><p>Let's register <code class="literal">readingsDF</code> as a temporary table:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; readingsDF.registerTempTable("readings")</strong></span>
</pre></div><p>This registers a temporary table that can be used in SQL queries. Registering a temporary table relies on the presence of a SQL context. The temporary tables are destroyed when the SQL context is destroyed (when we close the shell, for instance).</p><p>Let's explore what we can do with our temporary tables and the SQL context. We can first get a list of all the tables currently registered with the context:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; sqlContext.tables</strong></span>
<span class="strong"><strong>DataFrame = [tableName: string, isTemporary: boolean]</strong></span>
</pre></div><p>This returns a DataFrame. In general, all operations on a SQL context that return data return DataFrames:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; sqlContext.tables.show</strong></span>
<span class="strong"><strong>+---------+-----------+</strong></span>
<span class="strong"><strong>|tableName|isTemporary|</strong></span>
<span class="strong"><strong>+---------+-----------+</strong></span>
<span class="strong"><strong>| readings|       true|</strong></span>
<span class="strong"><strong>+---------+-----------+</strong></span>
</pre></div><p>We can query this table <a id="id503" class="indexterm"></a>by passing SQL statements to the SQL <a id="id504" class="indexterm"></a>context:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; sqlContext.sql("SELECT * FROM readings").show</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
<span class="strong"><strong>|patientId|heightCm|weightKg|age|isSmoker|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
<span class="strong"><strong>|        1|     175|      72| 43|   false|</strong></span>
<span class="strong"><strong>|        2|     182|      78| 28|    true|</strong></span>
<span class="strong"><strong>|        3|     164|      61| 41|   false|</strong></span>
<span class="strong"><strong>|        4|     161|      62| 43|    true|</strong></span>
<span class="strong"><strong>+---------+--------+--------+---+--------+</strong></span>
</pre></div><p>Any UDFs registered with the <code class="literal">sqlContext</code> are available through the name given to them when they were registered. We can therefore use them in SQL queries:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; sqlContext.sql("""</strong></span>
<span class="strong"><strong>SELECT </strong></span>
<span class="strong"><strong>  patientId, </strong></span>
<span class="strong"><strong>  likelyMaleUdf(heightCm, weightKg) AS likelyMale</strong></span>
<span class="strong"><strong>FROM readings</strong></span>
<span class="strong"><strong>""").show</strong></span>
<span class="strong"><strong>+---------+----------+</strong></span>
<span class="strong"><strong>|patientId|likelyMale|</strong></span>
<span class="strong"><strong>+---------+----------+</strong></span>
<span class="strong"><strong>|        1|      true|</strong></span>
<span class="strong"><strong>|        2|      true|</strong></span>
<span class="strong"><strong>|        3|     false|</strong></span>
<span class="strong"><strong>|        4|     false|</strong></span>
<span class="strong"><strong>+---------+----------+</strong></span>
</pre></div><p>You might wonder why one would want to register DataFrames as temporary tables and run SQL queries on those tables, when the same functionality is available directly on DataFrames. The main reason is for interacting with external tools. Spark can run a SQL engine that exposes a JDBC interface, meaning that programs that know how to interact with a SQL database will be able to make use of the temporary tables.</p><p>We don't have the space <a id="id505" class="indexterm"></a>to cover how to set up a distributed SQL engine in this book, but you can find details in <a id="id506" class="indexterm"></a>the Spark documentation (<a class="ulink" href="http://spark.apache.org/docs/latest/sql-programming-guide.html#distributed-sql-engine" target="_blank">http://spark.apache.org/docs/latest/sql-programming-guide.html#distributed-sql-engine</a>).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec108"></a>Complex data types â€“ arrays, maps, and structs</h2></div></div><hr /></div><p>So far, all <a id="id507" class="indexterm"></a>the elements in our DataFrames were simple types. DataFrames support three <a id="id508" class="indexterm"></a>additional collection types: arrays, maps, and structs.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl2sec66"></a>Structs</h3></div></div></div><p>The first compound <a id="id509" class="indexterm"></a>type that we will look at is the <span class="strong"><strong>struct</strong></span>. A struct is similar to a case class: it stores a set of key-value pairs, with a fixed set of keys. If we convert an RDD of a case class containing nested case classes to a DataFrame, Spark will convert the nested objects to a struct.</p><p>Let's imagine that we want to serialize Lords of the Ring characters. We might use the following object model:</p><div class="informalexample"><pre class="programlisting">case class Weapon(name:String, weaponType:String)
case class LotrCharacter(name:String, val weapon:Weapon)</pre></div><p>We want to create a DataFrame of <code class="literal">LotrCharacter</code> instances. Let's create some dummy data:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val characters = List(</strong></span>
<span class="strong"><strong>  LotrCharacter("Gandalf", Weapon("Glamdring", "sword")),</strong></span>
<span class="strong"><strong>  LotrCharacter("Frodo", Weapon("Sting", "dagger")),</strong></span>
<span class="strong"><strong>  LotrCharacter("Aragorn", Weapon("Anduril", "sword"))</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>characters: List[LotrCharacter] = List(LotrCharacter...</strong></span>

<span class="strong"><strong>scala&gt; val charactersDF = sc.parallelize(characters).toDF</strong></span>
<span class="strong"><strong>charactersDF: DataFrame = [name: string, weapon: struct&lt;name:string,weaponType:string&gt;]</strong></span>

<span class="strong"><strong>scala&gt; charactersDF.printSchema</strong></span>
<span class="strong"><strong>root</strong></span>
<span class="strong"><strong> |-- name: string (nullable = true)</strong></span>
<span class="strong"><strong> |-- weapon: struct (nullable = true)</strong></span>
<span class="strong"><strong> |    |-- name: string (nullable = true)</strong></span>
<span class="strong"><strong> |    |-- weaponType: string (nullable = true)</strong></span>

<span class="strong"><strong>scala&gt; charactersDF.show</strong></span>
<span class="strong"><strong>+-------+-----------------+</strong></span>
<span class="strong"><strong>|   name|           weapon|</strong></span>
<span class="strong"><strong>+-------+-----------------+</strong></span>
<span class="strong"><strong>|Gandalf|[Glamdring,sword]|</strong></span>
<span class="strong"><strong>|  Frodo|   [Sting,dagger]|</strong></span>
<span class="strong"><strong>|Aragorn|  [Anduril,sword]|</strong></span>
<span class="strong"><strong>+-------+-----------------+</strong></span>
</pre></div><p>The <code class="literal">weapon</code> attribute in the case class was converted to a struct column in the DataFrame. To extract sub-fields from a struct, we can pass the field name to the column's <code class="literal">.apply</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val weaponTypeColumn = charactersDF("weapon")("weaponType")</strong></span>
<span class="strong"><strong>weaponTypeColumn: org.apache.spark.sql.Column = weapon[weaponType]</strong></span>
</pre></div><p>We can use this derived <a id="id510" class="indexterm"></a>column just as we would any other column. For instance, let's filter our DataFrame to only contain characters who wield a sword:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; charactersDF.filter { weaponTypeColumn === "sword" }.show</strong></span>
<span class="strong"><strong>+-------+-----------------+</strong></span>
<span class="strong"><strong>|   name|           weapon|</strong></span>
<span class="strong"><strong>+-------+-----------------+</strong></span>
<span class="strong"><strong>|Gandalf|[Glamdring,sword]|</strong></span>
<span class="strong"><strong>|Aragorn|  [Anduril,sword]|</strong></span>
<span class="strong"><strong>+-------+-----------------+</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl2sec67"></a>Arrays</h3></div></div></div><p>Let's return to the <a id="id511" class="indexterm"></a>earlier example, and assume that, besides height, weight, and age measurements, we also have phone numbers for our patients. Each patient might have zero, one, or more phone numbers. We will define a new case class and new dummy data:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class PatientNumbers(</strong></span>
<span class="strong"><strong>  patientId:Int, phoneNumbers:List[String])</strong></span>
<span class="strong"><strong>defined class PatientNumbers</strong></span>

<span class="strong"><strong>scala&gt; val numbers = List(</strong></span>
<span class="strong"><strong>  PatientNumbers(1, List("07929123456")),</strong></span>
<span class="strong"><strong>  PatientNumbers(2, List("07929432167", "07929234578")),</strong></span>
<span class="strong"><strong>  PatientNumbers(3, List.empty),</strong></span>
<span class="strong"><strong>  PatientNumbers(4, List("07927357862"))</strong></span>
<span class="strong"><strong>)</strong></span>

<span class="strong"><strong>scala&gt; val numbersDF = sc.parallelize(numbers).toDF</strong></span>
<span class="strong"><strong>numbersDF: org.apache.spark.sql.DataFrame = [patientId: int, phoneNumbers: array&lt;string&gt;]</strong></span>
</pre></div><p>The <code class="literal">List[String]</code> array in our case class gets translated to an <code class="literal">array&lt;string&gt;</code> data type:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; numbersDF.printSchema</strong></span>
<span class="strong"><strong>root</strong></span>
<span class="strong"><strong> |-- patientId: integer (nullable = false)</strong></span>
<span class="strong"><strong> |-- phoneNumbers: array (nullable = true)</strong></span>
<span class="strong"><strong> |    |-- element: string (containsNull = true)</strong></span>
</pre></div><p>As with structs, we can construct a column for a specific index the array. For instance, we can select the first <a id="id512" class="indexterm"></a>element in each array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val bestNumberColumn = numbersDF("phoneNumbers")(0)</strong></span>
<span class="strong"><strong>bestNumberColumn: org.apache.spark.sql.Column = phoneNumbers[0]</strong></span>

<span class="strong"><strong>scala&gt; numbersDF.withColumn("bestNumber", bestNumberColumn).show</strong></span>
<span class="strong"><strong>+---------+--------------------+-----------+</strong></span>
<span class="strong"><strong>|patientId|        phoneNumbers| bestNumber|</strong></span>
<span class="strong"><strong>+---------+--------------------+-----------+</strong></span>
<span class="strong"><strong>|        1|   List(07929123456)|07929123456|</strong></span>
<span class="strong"><strong>|        2|List(07929432167,...|07929432167|</strong></span>
<span class="strong"><strong>|        3|              List()|       null|</strong></span>
<span class="strong"><strong>|        4|   List(07927357862)|07927357862|</strong></span>
<span class="strong"><strong>+---------+--------------------+-----------+</strong></span>
</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl2sec68"></a>Maps</h3></div></div></div><p>The last compound <a id="id513" class="indexterm"></a>data type is the map. Maps are similar to structs inasmuch as they store key-value pairs, but the set of keys is not fixed when the DataFrame is created. They can thus store arbitrary key-value pairs.</p><p>Scala maps will be converted to DataFrame maps when the DataFrame is constructed. They can then be queried in a manner similar to structs.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec109"></a>Interacting with data sources</h2></div></div><hr /></div><p>A major challenge in <a id="id514" class="indexterm"></a>data science or engineering is dealing with the wealth of input and output formats for persisting data. We might receive or send data as CSV files, JSON files, or through a SQL database, to name a few.</p><p>Spark provides a unified API for serializing and de-serializing DataFrames to and from different data sources.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl2sec69"></a>JSON files</h3></div></div></div><p>Spark supports loading <a id="id515" class="indexterm"></a>data from JSON files, provided that each line in the JSON file corresponds to a single JSON object. Each object will be mapped to a DataFrame <a id="id516" class="indexterm"></a>row. JSON arrays are mapped to arrays, and embedded objects are mapped to structs.</p><p>This section would be a little dry without some data, so let's generate some from the GitHub API. Unfortunately, the GitHub API does not return JSON formatted as a single object per line. The code repository for this chapter contains a script, <code class="literal">FetchData.scala</code> which will download and format JSON entries for Martin Odersky's repositories, saving the objects to a file named <code class="literal">odersky_repos.json</code> (go ahead and change the GitHub user in <code class="literal">FetchData.scala</code> if you want). You can also download a pre-constructed data file from <a class="ulink" href="http://data.scala4datascience.com/odersky_repos.json" target="_blank">data.scala4datascience.com/odersky_repos.json</a>.</p><p>Let's dive into the Spark shell and load this data into a DataFrame. Reading from a JSON file is as simple as passing the file name to the <code class="literal">sqlContext.read.json</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val df = sqlContext.read.json("odersky_repos.json")</strong></span>
<span class="strong"><strong>df: DataFrame = [archive_url: string, assignees_url: ...]</strong></span>
</pre></div><p>Reading from a JSON file loads data as a DataFrame. Spark automatically infers the schema from the JSON documents. There are many columns in our DataFrame. Let's sub-select a few to get a more manageable DataFrame:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val reposDF = df.select("name", "language", "fork", "owner")</strong></span>
<span class="strong"><strong>reposDF: DataFrame = [name: string, language: string, ...]    </strong></span>

<span class="strong"><strong>scala&gt; reposDF.show</strong></span>
<span class="strong"><strong>+----------------+----------+-----+--------------------+</strong></span>
<span class="strong"><strong>|            name|  language| fork|               owner|</strong></span>
<span class="strong"><strong>+----------------+----------+-----+--------------------+</strong></span>
<span class="strong"><strong>|           dotty|     Scala| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|        frontend|JavaScript| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|           scala|     Scala| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|      scala-dist|     Scala| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|scala.github.com|JavaScript| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|          scalax|     Scala|false|[https://avatars....|</strong></span>
<span class="strong"><strong>|            sips|       CSS|false|[https://avatars....|</strong></span>
<span class="strong"><strong>+----------------+----------+-----+--------------------+</strong></span>
</pre></div><p>Let's save the DataFrame back to JSON:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; reposDF.write.json("repos_short.json")</strong></span>
</pre></div><p>If you look at the files present in the directory in which you are running the Spark shell, you will notice a <code class="literal">repos_short.json</code> directory. Inside it, you will see files named <code class="literal">part-000000</code>, <code class="literal">part-000001</code>, and so on. When serializing JSON, each partition of the DataFrame is serialized independently. If you are running this on several machines, you will find parts of the serialized output on each computer.</p><p>You may, optionally, pass <a id="id517" class="indexterm"></a>a <code class="literal">mode</code> argument to control how Spark deals with the case <a id="id518" class="indexterm"></a>of an existing <code class="literal">repos_short.json</code> file:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.sql.SaveMode</strong></span>
<span class="strong"><strong>import org.apache.spark.sql.SaveMode</strong></span>

<span class="strong"><strong>scala&gt; reposDF.write.mode(</strong></span>
<span class="strong"><strong>  SaveMode.Overwrite).json("repos_short.json")</strong></span>
</pre></div><p>Available save modes are <code class="literal">ErrorIfExists</code>, <code class="literal">Append</code> (only available for Parquet files), <code class="literal">Overwrite</code>, and <code class="literal">Ignore</code> (do not save if the file exists already).</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl2sec70"></a>Parquet files</h3></div></div></div><p>Apache Parquet is a <a id="id519" class="indexterm"></a>popular file format well-suited for storing tabular data. It is <a id="id520" class="indexterm"></a>often used for serialization in the Hadoop ecosystem, since it allows for efficient extraction of specific columns and rows without having to read the entire file.</p><p>Serialization and deserialization of Parquet files is identical to JSON, with the substitution of <code class="literal">json</code> with <code class="literal">parquet</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; reposDF.write.parquet("repos_short.parquet")</strong></span>

<span class="strong"><strong>scala&gt; val newDF = sqlContext.read.parquet("repos_short.parquet")</strong></span>
<span class="strong"><strong>newDF: DataFrame = [name: string, language: string, fo...]</strong></span>

<span class="strong"><strong>scala&gt; newDF.show</strong></span>
<span class="strong"><strong>+----------------+----------+-----+--------------------+</strong></span>
<span class="strong"><strong>|            name|  language| fork|               owner|</strong></span>
<span class="strong"><strong>+----------------+----------+-----+--------------------+</strong></span>
<span class="strong"><strong>|           dotty|     Scala| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|        frontend|JavaScript| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|           scala|     Scala| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|      scala-dist|     Scala| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|scala.github.com|JavaScript| true|[https://avatars....|</strong></span>
<span class="strong"><strong>|          scalax|     Scala|false|[https://avatars....|</strong></span>
<span class="strong"><strong>|            sips|       CSS|false|[https://avatars....|</strong></span>
<span class="strong"><strong>+----------------+----------+-----+--------------------+</strong></span>
</pre></div><p>In general, Parquet will be more space-efficient than JSON for storing large collections of objects. Parquet is also much more efficient at retrieving specific columns or rows, if the partition can be inferred from the row. Parquet is thus advantageous over JSON unless you need the output to <a id="id521" class="indexterm"></a>be human-readable, or de-serializable by an <a id="id522" class="indexterm"></a>external program.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec110"></a>Standalone programs</h2></div></div><hr /></div><p>So far, we have been <a id="id523" class="indexterm"></a>using Spark SQL and DataFrames through the Spark shell. To use it in standalone programs, you will need to create it explicitly, from a Spark context:</p><div class="informalexample"><pre class="programlisting">val conf = new SparkConf().setAppName("applicationName")
val sc = new SparkContext(conf)
val sqlContext = new org.apache.spark.sql.SQLContext(sc)</pre></div><p>Additionally, importing the <code class="literal">implicits</code> object nested in <code class="literal">sqlContext</code> allows the conversions of RDDs to DataFrames:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">import sqlContext.implicits._</code>
</pre></div><p>We will use DataFrames extensively in the next chapter to manipulate data to get it ready for use with MLlib.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec111"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we explored Spark SQL and DataFrames. DataFrames add a rich layer of abstraction on top of Spark's core engine, greatly facilitating the manipulation of tabular data. Additionally, the source API allows the serialization and de-serialization of DataFrames from a rich variety of data files.</p><p>In the next chapter, we will build on our knowledge of Spark and DataFrames to build a spam filter using MLlib.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch11lvl1sec112"></a>References</h2></div></div><hr /></div><p>DataFrames are a relatively recent addition to Spark. There is thus still a dearth of literature and <a id="id524" class="indexterm"></a>documentation. The first port of call should be the Scala docs, available at: <a class="ulink" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame" target="_blank">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame</a>.</p><p>The <a id="id525" class="indexterm"></a>Scaladocs for operations available on the DataFrame <code class="literal">Column</code> type can be found at: <a class="ulink" href="http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.Column" target="_blank">http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.Column</a>.</p><p>There is also <a id="id526" class="indexterm"></a>extensive documentation on the Parquet file format: <a class="ulink" href="https://parquet.apache.org" target="_blank">https://parquet.apache.org</a>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch12"></a>ChapterÂ 12.Â Distributed Machine Learning with MLlib</h2></div></div></div><p>Machine learning describes the construction of algorithms that make predictions from data. It is a core component of most data science pipelines, and is often seen to be the component adding the most value: the accuracy of the machine learning algorithm determines the success of the data science endeavor. It is also, arguably, the section of the data science pipeline that requires the most knowledge from fields beyond software engineering: a machine learning expert will be familiar, not just with algorithms, but also with statistics and with the business domain.</p><p>Choosing and tuning a <a id="id527" class="indexterm"></a>machine learning algorithm to solve a particular problem involves significant exploratory analysis to try and determine which features are relevant, how features are correlated, whether there are outliers in the dataset, and so on. Designing suitable machine learning pipelines is difficult. Add on an additional layer of complexity resulting from the size of datasets and the need for scalability, and you have a real challenge.</p><p>
<span class="strong"><strong>MLlib</strong></span> helps mitigate this <a id="id528" class="indexterm"></a>difficulty. MLlib is a component of Spark that provides machine learning algorithms on top of the core Spark libraries. It offers a set of learning algorithms that parallelize well over distributed datasets.</p><p>MLlib has evolved into two <a id="id529" class="indexterm"></a>separate layers. MLlib itself contains the core algorithms, and <span class="strong"><strong>ml</strong></span>, also <a id="id530" class="indexterm"></a>called the <span class="emphasis"><em>pipeline API</em></span>, defines an API for gluing algorithms together and provides a higher level of abstraction. The two libraries differ in the data types on which they operate: the original MLlib predates the introduction of DataFrames, and acts mainly on RDDs of feature vectors. The pipeline API operates on DataFrames.</p><p>In this chapter, we will study the newer pipeline API, diving into MLlib only when the functionality is missing from the pipeline API.</p><p>This chapter does not try to teach the machine learning fundamentals behind the algorithms that we present. We assume that the reader has a good enough grasp of machine learning tools and techniques to understand, at least superficially, what the algorithms presented here do, and we defer to better authors for in-depth explanations of the mechanics of statistical learning (we present several references at the end of the chapter).</p><p>MLlib is a rich library <a id="id531" class="indexterm"></a>that is evolving rapidly. This chapter does not aim to give a complete overview of the library. We will work through the construction of a machine learning pipeline to train a spam filter, learning about the parts of MLlib that we need along the way. Having read this chapter, you will have an understanding of how the different parts of the library fit together, and can use the online documentation, or a more specialized book (see references at the end of this chapter) to learn about the parts of MLlib not covered here.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec113"></a>Introducing MLlib â€“ Spam classification</h2></div></div><hr /></div><p>Let's introduce MLlib <a id="id532" class="indexterm"></a>with a concrete example. We will look at spam classification using the Ling-Spam dataset that we used in the <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Distributed Batch Processing with Spark</em></span>. We will create a spam filter that uses logistic regression to estimate the probability that a given message is spam.</p><p>We will run through examples using the Spark shell, but you will find an analogous program in <code class="literal">LogisticRegressionDemo.scala</code> among the examples for this chapter. If you have not installed Spark, refer to <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Distributed Batch Processing with Spark</em></span>, for installation instructions.</p><p>Let's start by loading the <a id="id533" class="indexterm"></a>e-mails in the Ling-Spam dataset. If you have not done this for <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Distributed Batch Processing with Spark</em></span>, download the data from <a class="ulink" href="http://data.scala4datascience.com/ling-spam.tar.gz" target="_blank">data.scala4datascience.com/ling-spam.tar.gz</a> or <a class="ulink" href="http://data.scala4datascience.com/ling-spam.zip" target="_blank">data.scala4datascience.com/ling-spam.zip</a>, depending on whether you want a <code class="literal">tar.gz</code> file or a <code class="literal">zip</code> file, and unpack the archive. This will create a <code class="literal">spam</code> directory and a <code class="literal">ham</code> directory containing spam and ham messages, respectively.</p><p>Let's use the <code class="literal">wholeTextFiles</code> method to load spam and ham e-mails:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val spamText = sc.wholeTextFiles("spam/*")</strong></span>
<span class="strong"><strong>spamText: RDD[(String, String)] = spam/...</strong></span>

<span class="strong"><strong>scala&gt; val hamText = sc.wholeTextFiles("ham/*")</strong></span>
<span class="strong"><strong>hamText: RDD[(String, String)] = ham/...</strong></span>
</pre></div><p>The <code class="literal">wholeTextFiles</code> method creates a key-value RDD where the keys are the file names and the values are the contents of the files:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; spamText.first</strong></span>
<span class="strong"><strong>(String, String) =</strong></span>
<span class="strong"><strong>(file:spam/spmsga1.txt,"Subject: great part-time summer job! ...")</strong></span>

<span class="strong"><strong>scala&gt; spamText.count</strong></span>
<span class="strong"><strong>Long = 481</strong></span>
</pre></div><p>The algorithms in the pipeline API work on DataFrames. We must therefore convert our key-value RDDs to DataFrames. We define a new case class, <code class="literal">LabelledDocument</code>, which contains a message text <a id="id534" class="indexterm"></a>and a category label identifying whether a message is <code class="literal">spam</code> or <code class="literal">ham</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class LabelledDocument(</strong></span>
<span class="strong"><strong>  fileName:String, </strong></span>
<span class="strong"><strong>  text:String, </strong></span>
<span class="strong"><strong>  category:String</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>defined class LabelledDocument</strong></span>

<span class="strong"><strong>scala&gt; val spamDocuments = spamText.map {</strong></span>
<span class="strong"><strong>  case (fileName, text) =&gt; </strong></span>
<span class="strong"><strong>    LabelledDocument(fileName, text, "spam")</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>spamDocuments: RDD[LabelledDocument] = MapPartitionsRDD[2] at map</strong></span>

<span class="strong"><strong>scala&gt; val hamDocuments = hamText.map {</strong></span>
<span class="strong"><strong>  case (fileName, text) =&gt; </strong></span>
<span class="strong"><strong>    LabelledDocument(fileName, text, "ham")</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>hamDocuments: RDD[LabelledDocument] = MapPartitionsRDD[3] at map</strong></span>
</pre></div><p>To create models, we will need all the documents in a single DataFrame. Let's therefore take the union of our two <code class="literal">LabelledDocument</code> RDDs, and transform that to a DataFrame. The <code class="literal">union</code> method concatenates RDDs together:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val allDocuments = spamDocuments.union(hamDocuments)</strong></span>
<span class="strong"><strong>allDocuments: RDD[LabelledDocument] = UnionRDD[4] at union</strong></span>

<span class="strong"><strong>scala&gt; val documentsDF = allDocuments.toDF</strong></span>
<span class="strong"><strong>documentsDF: DataFrame = [fileName: string, text: string, category: string]</strong></span>
</pre></div><p>Let's do some basic checks to verify that we have loaded all the documents. We start by persisting the DataFrame in memory to avoid having to re-create it from the raw text files.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; documentsDF.persist</strong></span>
<span class="strong"><strong>documentsDF.type = [fileName: string, text: string, category: string]</strong></span>

<span class="strong"><strong>scala&gt; documentsDF.show</strong></span>
<span class="strong"><strong>+--------------------+--------------------+--------+</strong></span>
<span class="strong"><strong>|            fileName|                text|category|</strong></span>
<span class="strong"><strong>+--------------------+--------------------+--------+</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: great pa...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: auto ins...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: want bes...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: email 57...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: n't miss...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: amaze wo...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: help loa...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: beat irs...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: email 57...|    spam|</strong></span>
<span class="strong"><strong>|file:/Users/pasca...|Subject: best , b...|    spam|</strong></span>
<span class="strong"><strong>|...                                               |</strong></span>
<span class="strong"><strong>+--------------------+--------------------+--------+</strong></span>

<span class="strong"><strong>scala&gt; documentsDF.groupBy("category").agg(count("*")).show</strong></span>
<span class="strong"><strong>+--------+--------+</strong></span>
<span class="strong"><strong>|category|COUNT(1)|</strong></span>
<span class="strong"><strong>+--------+--------+</strong></span>
<span class="strong"><strong>|    spam|     481|</strong></span>
<span class="strong"><strong>|     ham|    2412|</strong></span>
<span class="strong"><strong>+--------+--------+</strong></span>
</pre></div><p>Let's now split the DataFrame into a training set and a test set. We will use the test set to validate the model that we build. For now, we will just use a single split, training the model on 70% of the data <a id="id535" class="indexterm"></a>and testing it on the remaining 30%. In the next section, we will look at cross-validation, which provides more rigorous way to check the accuracy of our models.</p><p>We can achieve this 70-30 split using the DataFrame's <code class="literal">.randomSplit</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val Array(trainDF, testDF) = documentsDF.randomSplit(</strong></span>
<span class="strong"><strong>  Array(0.7, 0.3))</strong></span>
<span class="strong"><strong>trainDF: DataFrame = [fileName: string, text: string, category: string]</strong></span>
<span class="strong"><strong>testDF: DataFrame = [fileName: string, text: string, category: string]</strong></span>
</pre></div><p>The <code class="literal">.randomSplit</code> method takes an array of weights and returns an array of DataFrames, of approximately the size specified by the weights. For instance, we passed weights <code class="literal">0.7</code> and <code class="literal">0.3</code>, indicating that any given row has a 70% chance of ending up in <code class="literal">trainDF</code>, and a 30% chance of ending up in <code class="literal">testDF</code>. Note that this means the split DataFrames are not of fixed size: <code class="literal">trainDF</code> is approximately, but not exactly, 70% the size of <code class="literal">documentsDF</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; trainDF.count / documentsDF.count.toDouble</strong></span>
<span class="strong"><strong>Double = 0.7013480815762184</strong></span>
</pre></div><p>If you need a fixed size sample, use the DataFrame's <code class="literal">.sample</code> method to obtain <code class="literal">trainDF</code> and filter <code class="literal">documentDF</code> for rows not in <code class="literal">trainDF</code>.</p><p>We are now in a position to start using MLlib. Our attempt at classification will involve performing logistic regression on <span class="emphasis"><em>term-frequency vectors</em></span>: we will count how often each word appears in each <a id="id536" class="indexterm"></a>message, and use the frequency of occurrence as a feature. Before jumping into the code, let's take a step back and discuss the structure of machine learning pipelines.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec114"></a>Pipeline components</h2></div></div><hr /></div><p>Pipelines consist of a <a id="id537" class="indexterm"></a>set of components joined together such that the DataFrame produced by one component is used as input for the next component. The components available are split into two classes: <span class="emphasis"><em>transformers</em></span> and <span class="emphasis"><em>estimators</em></span>.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec71"></a>Transformers</h3></div></div></div><p>
<span class="strong"><strong>Transformers</strong></span> transform <a id="id538" class="indexterm"></a>one DataFrame into another, normally by appending one or more columns.</p><p>The first step in our spam classification algorithm is to split each message into an array of words. This is called <a id="id539" class="indexterm"></a>
<span class="strong"><strong>tokenization</strong></span>. We can use the <code class="literal">Tokenizer</code> <a id="id540" class="indexterm"></a>transformer, provided by MLlib:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.ml.feature._</strong></span>
<span class="strong"><strong>import org.apache.spark.ml.feature._</strong></span>

<span class="strong"><strong>scala&gt; val tokenizer = new Tokenizer()</strong></span>
<span class="strong"><strong>tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_75559f60e8cf </strong></span>
</pre></div><p>The behavior of transformers can be customized through getters and setters. The easiest way of obtaining a list of the parameters available is to call the <code class="literal">.explainParams</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; println(tokenizer.explainParams)</strong></span>
<span class="strong"><strong>inputCol: input column name (undefined)</strong></span>
<span class="strong"><strong>outputCol: output column name (default: tok_75559f60e8cf__output)</strong></span>
</pre></div><p>We see that the behavior of a <code class="literal">Tokenizer</code> instance can be customized using two parameters: <code class="literal">inputCol</code> and <code class="literal">outputCol</code>, describing the header of the column containing the input (the string to be tokenized) and the output (the array of words), respectively. We can set these parameters using the <code class="literal">setInputCol</code> and <code class="literal">setOutputCol</code> methods.</p><p>We set <code class="literal">inputCol</code> to <code class="literal">"text"</code>, since that is what the column is called in our training and test DataFrames. We will set <code class="literal">outputCol</code> to <code class="literal">"words"</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; tokenizer.setInputCol("text").setOutputCol("words")</strong></span>
<span class="strong"><strong>org.apache.spark.ml.feature.Tokenizer = tok_75559f60e8cf</strong></span>
</pre></div><p>In due course, we will integrate <code class="literal">tokenizer</code> into a pipeline, but, for now, let's just use it to transform the training DataFrame, to verify that it works correctly.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val tokenizedDF = tokenizer.transform(trainDF)</strong></span>
<span class="strong"><strong>tokenizedDF: DataFrame = [fileName: string, text: string, category: string, words: array&lt;string&gt;]</strong></span>

<span class="strong"><strong>scala&gt; tokenizedDF.show</strong></span>
<span class="strong"><strong>+--------------+----------------+--------+--------------------+</strong></span>
<span class="strong"><strong>|      fileName|            text|category|               words|</strong></span>
<span class="strong"><strong>+--------------+----------------+--------+--------------------+</strong></span>
<span class="strong"><strong>|file:/Users...|Subject: auto...|    spam|[subject:, auto, ...|</strong></span>
<span class="strong"><strong>|file:/Users...|Subject: want...|    spam|[subject:, want, ...|</strong></span>
<span class="strong"><strong>|file:/Users...|Subject: n't ...|    spam|[subject:, n't, m...|</strong></span>
<span class="strong"><strong>|file:/Users...|Subject: amaz...|    spam|[subject:, amaze,...|</strong></span>
<span class="strong"><strong>|file:/Users...|Subject: help...|    spam|[subject:, help, ...|</strong></span>
<span class="strong"><strong>|file:/Users...|Subject: beat...|    spam|[subject:, beat, ...|</strong></span>
<span class="strong"><strong>|...                                                          |</strong></span>
<span class="strong"><strong>+--------------+----------------+--------+--------------------+</strong></span>
</pre></div><p>The <code class="literal">tokenizer</code> transformer produces a new DataFrame with an additional column, <code class="literal">words</code>, containing an array of the words in the <code class="literal">text</code> column.</p><p>Clearly, we can use our <a id="id541" class="indexterm"></a>
<code class="literal">tokenizer</code> to transform any DataFrame with the correct <a id="id542" class="indexterm"></a>schema. We could, for instance, use it on the test set. Much of machine learning involves calling the same (or a very similar) pipeline on different data sets. By providing the pipeline abstraction, MLlib facilitates reasoning about complex machine learning algorithms consisting of many cleaning, transformation, and modeling components.</p><p>The next step in our pipeline is to calculate the frequency of occurrence of each word in each message. We will eventually use these frequencies as features in our algorithm. We will use the <code class="literal">HashingTF</code> transformer to transform from arrays of words to word frequency vectors for each message.</p><p>The <code class="literal">HashingTF</code> transformer constructs a sparse vector of word frequencies from input iterables. Each element in the word array gets transformed to a hash code. This hash code is truncated to a value between <span class="emphasis"><em>0</em></span> and a large number <span class="emphasis"><em>n</em></span>, the total number of elements in the output vector. The term frequency vector is just the number of occurrences of the truncated hash.</p><p>Let's run through an example manually to understand how this works. We will calculate the term frequency vector for <code class="literal">Array("the", "dog", "jumped", "over", "the")</code>. Let's set <span class="emphasis"><em>n</em></span>, the number of elements in the sparse output vector, to 16 for this example. The first step is to calculate the hash code for each element in our array. We can use the built-in <code class="literal">##</code> method, which calculates a hash code for any object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val words = Array("the", "dog", "jumped", "over", "the")</strong></span>
<span class="strong"><strong>words: Array[String] = Array(the, dog, jumped, over, the)</strong></span>

<span class="strong"><strong>scala&gt; val hashCodes = words.map { _.## }</strong></span>
<span class="strong"><strong>hashCodes: Array[Int] = Array(114801, 99644, -1148867251, 3423444, 114801)</strong></span>
</pre></div><p>To transform the hash <a id="id543" class="indexterm"></a>codes into valid vector indices, we take the modulo of each hash <a id="id544" class="indexterm"></a>by the size of the vector (<code class="literal">16</code>, in this case):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val indices = hashCodes.map { code =&gt; Math.abs(code % 16) }</strong></span>
<span class="strong"><strong>indices: Array[Int] = Array(1, 12, 3, 4, 1)</strong></span>
</pre></div><p>We can then create a mapping from indices to the number of times that index appears:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val indexFrequency = indices.groupBy(identity).mapValues {</strong></span>
<span class="strong"><strong>  _.size.toDouble</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>indexFrequency: Map[Int,Double] = Map(4 -&gt; 1.0, 1 -&gt; 2.0, 3 -&gt; 1.0, 12 -&gt; 1.0)</strong></span>
</pre></div><p>Finally, we can convert this map to a sparse vector, where the value at each element in the vector is the frequency with which this particular index occurs:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.mllib.linalg._</strong></span>
<span class="strong"><strong>import org.apache.spark.mllib.linalg._</strong></span>

<span class="strong"><strong>scala&gt; val termFrequencies = Vectors.sparse(16, indexFrequency.toSeq)</strong></span>
<span class="strong"><strong>termFrequencies: linalg.Vector = (16,[1,3,4,12],[2.0,1.0,1.0,1.0])</strong></span>
</pre></div><p>Note that the <code class="literal">.toString</code> output for a sparse vector consists of three elements: the total size of the vector, followed by two lists: the first is a series of indices, and the second is a series of values at those indices.</p><p>Using a sparse vector provides a compact and efficient way of representing the frequency of occurrence of words in the message, and is exactly how <code class="literal">HashingTF</code> works under the hood. The disadvantage is that the mapping from words to indices is not necessarily unique: truncating hash codes by the length of the vector will map different strings to the same index. This is known <a id="id545" class="indexterm"></a>as a <span class="emphasis"><em>collision</em></span>. The solution is to make <span class="emphasis"><em>n</em></span> large enough that the frequency of collisions is minimized.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip18"></a>Tip</h3><p>
<code class="literal">HashingTF</code> is similar <a id="id546" class="indexterm"></a>to building a hash table (for example, a Scala map) whose keys are words and whose values are the number of times that word occurs in the message, with one important difference: it does not attempt to deal with hash collisions. Thus, if two words map to the same hash, they will have the wrong frequency. There are two advantages to using this algorithm over just constructing a hash table:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>We do not have to maintain a list of distinct words in memory.</p></li><li style="list-style-type: disc"><p>Each e-mail can be transformed to a vector independently of all others: we do not have to reduce over different partitions to get the set of keys in the map. This greatly <a id="id547" class="indexterm"></a>eases applying this algorithm to each e-mail in a distributed manner, since we can apply the <code class="literal">HashingTF</code> transformation on each <a id="id548" class="indexterm"></a>partition independently.</p></li></ul></div><p>The main disadvantage is that we must use machine learning algorithms that can take advantage of the sparse representation efficiently. This is the case with logistic regression, which we will use here.</p></div><p>As you might expect, the <code class="literal">HashingTF</code> transformer takes, as parameters, the input and output columns. It also takes a parameter defining the number of distinct hash buckets in the vector. Increasing the number of buckets decreases the number of collisions. In practice, a value between <span class="inlinemediaobject"><img src="graphics/4795_12_01.jpg" /></span> and <span class="inlinemediaobject"><img src="graphics/4795_12_02.jpg" /></span> is recommended.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val hashingTF = (new HashingTF()</strong></span>
<span class="strong"><strong>  .setInputCol("words")</strong></span>
<span class="strong"><strong>  .setOutputCol("features")</strong></span>
<span class="strong"><strong>  .setNumFeatures(1048576))</strong></span>
<span class="strong"><strong>hashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_3b78eca9595c</strong></span>

<span class="strong"><strong>scala&gt; val hashedDF = hashingTF.transform(tokenizedDF)</strong></span>
<span class="strong"><strong>hashedDF: DataFrame = [fileName: string, text: string, category: string, words: array&lt;string&gt;, features: vector]</strong></span>

<span class="strong"><strong>scala&gt; hashedDF.select("features").show</strong></span>
<span class="strong"><strong>+--------------------+</strong></span>
<span class="strong"><strong>|            features|</strong></span>
<span class="strong"><strong>+--------------------+</strong></span>
<span class="strong"><strong>|(1048576,[0,33,36...|</strong></span>
<span class="strong"><strong>|(1048576,[0,36,40...|</strong></span>
<span class="strong"><strong>|(1048576,[0,33,34...|</strong></span>
<span class="strong"><strong>|(1048576,[0,33,36...|</strong></span>
<span class="strong"><strong>|(1048576,[0,33,34...|</strong></span>
<span class="strong"><strong>|(1048576,[0,33,34...|</strong></span>
<span class="strong"><strong>+--------------------+</strong></span>
</pre></div><p>Each element in the <code class="literal">features</code> column is a sparse vector:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.sql.Row</strong></span>
<span class="strong"><strong>import org.apache.spark.sql.Row</strong></span>

<span class="strong"><strong>scala&gt; val firstRow = hashedDF.select("features").first</strong></span>
<span class="strong"><strong>firstRow: org.apache.spark.sql.Row = ...</strong></span>

<span class="strong"><strong>scala&gt; val Row(v:Vector) = firstRow</strong></span>
<span class="strong"><strong>v: Vector = (1048576,[0,33,36,37,...],[1.0,3.0,4.0,1.0,...])</strong></span>
</pre></div><p>We can thus interpret <a id="id549" class="indexterm"></a>our vector as: the word that hashes to element <code class="literal">33</code> occurs three <a id="id550" class="indexterm"></a>times, the word that hashes to element <code class="literal">36</code> occurs four times etc.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec72"></a>Estimators</h3></div></div></div><p>We now have the <a id="id551" class="indexterm"></a>features ready for logistic regression. The last step prior to running logistic regression is to create the target variable. We will transform the <code class="literal">category</code> column in our DataFrame to a binary 0/1 target column. Spark provides a <code class="literal">StringIndexer</code> class that replaces a set of strings in a column with doubles. A <code class="literal">StringIndexer</code> is not a <a id="id552" class="indexterm"></a>transformer: it must first be 'fitted' to a set of categories to calculate the mapping from string to numeric value. This introduces the second class of components in the pipeline API: <span class="emphasis"><em>estimators</em></span>.</p><p>Unlike a transformer, which works "out of the box", an estimator must be fitted to a DataFrame. For our string indexer, the fitting process involves obtaining the list of unique strings (<code class="literal">"spam"</code> and <code class="literal">"ham"</code>) and mapping each of these to a double. The fitting process outputs a transformer which can be used on subsequent DataFrames.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val indexer = (new StringIndexer()</strong></span>
<span class="strong"><strong>  .setInputCol("category")</strong></span>
<span class="strong"><strong>  .setOutputCol("label"))</strong></span>
<span class="strong"><strong>indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_16db03fd0546</strong></span>

<span class="strong"><strong>scala&gt; val indexTransform = indexer.fit(trainDF)</strong></span>
<span class="strong"><strong>indexTransform: StringIndexerModel = strIdx_16db03fd0546</strong></span>
</pre></div><p>The transformer produced by the fitting process has a <code class="literal">labels</code> attribute describing the mapping it applies:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; indexTransform.labels</strong></span>
<span class="strong"><strong>Array[String] = Array(ham, spam)</strong></span>
</pre></div><p>Each label will get mapped to its index in the array: thus, our transformer maps <code class="literal">ham</code> to <code class="literal">0</code> and <code class="literal">spam</code> to <code class="literal">1</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val labelledDF = indexTransform.transform(hashedDF)</strong></span>
<span class="strong"><strong>labelledDF: org.apache.spark.sql.DataFrame = [fileName: string, text: string, category: string, words: array&lt;string&gt;, features: vector, label: double]</strong></span>

<span class="strong"><strong>scala&gt; labelledDF.select("category", "label").distinct.show</strong></span>
<span class="strong"><strong>+--------+-----+</strong></span>
<span class="strong"><strong>|category|label|</strong></span>
<span class="strong"><strong>+--------+-----+</strong></span>
<span class="strong"><strong>|     ham|  0.0|</strong></span>
<span class="strong"><strong>|    spam|  1.0|</strong></span>
<span class="strong"><strong>+--------+-----+</strong></span>
</pre></div><p>We now have the feature <a id="id553" class="indexterm"></a>vectors and classification labels in the correct format for logistic regression. The component for performing logistic regression is an estimator: it is fitted to a training DataFrame to create a trained model. The model can then be used to <a id="id554" class="indexterm"></a>transform test DataFrames.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.ml.classification.LogisticRegression</strong></span>
<span class="strong"><strong>import org.apache.spark.ml.classification.LogisticRegression</strong></span>

<span class="strong"><strong>scala&gt; val classifier = new LogisticRegression().setMaxIter(50)</strong></span>
<span class="strong"><strong>classifier: LogisticRegression = logreg_a5e921e7c1a1 </strong></span>
</pre></div><p>The <code class="literal">LogisticRegression</code> estimator expects the feature column to be named <code class="literal">"features"</code> and the label column (the target) to be named <code class="literal">"label"</code>, by default. There is no need to set these explicitly, since they match the column names set by <code class="literal">hashingTF</code> and <code class="literal">indexer</code>. There are several parameters that can be set to control how logistic regression works:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; println(classifier.explainParams)</strong></span>
<span class="strong"><strong>elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)</strong></span>
<span class="strong"><strong>fitIntercept: whether to fit an intercept term (default: true)</strong></span>
<span class="strong"><strong>labelCol: label column name (default: label)</strong></span>
<span class="strong"><strong>maxIter: maximum number of iterations (&gt;= 0) (default: 100, current: 50)</strong></span>
<span class="strong"><strong>regParam: regularization parameter (&gt;= 0) (default: 0.0)</strong></span>
<span class="strong"><strong>threshold: threshold in binary classification prediction, in range [0, 1] (default: 0.5)</strong></span>
<span class="strong"><strong>tol: the convergence tolerance for iterative algorithms (default: 1.0E-6)</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>For now, we just set the <a id="id555" class="indexterm"></a>
<code class="literal">maxIter</code> parameter. We will look at the effect of other <a id="id556" class="indexterm"></a>parameters, such as regularization, later on. Let's now fit the classifier to <code class="literal">labelledDF</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val trainedClassifier = classifier.fit(labelledDF)</strong></span>
<span class="strong"><strong>trainedClassifier: LogisticRegressionModel = logreg_353d18f6a5f0</strong></span>
</pre></div><p>This produces a transformer that we can use on a DataFrame with a <code class="literal">features</code> column. The transformer appends a <code class="literal">prediction</code> column and a <code class="literal">probability</code> column. We can, for instance use <code class="literal">trainedClassifier</code> to transform <code class="literal">labelledDF</code>, the training set itself:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val labelledDFWithPredictions = trainedClassifier.transform(</strong></span>
<span class="strong"><strong>  labelledDF)</strong></span>
<span class="strong"><strong>labelledDFWithPredictions: DataFrame = [fileName: string, ...</strong></span>

<span class="strong"><strong>scala&gt; labelledDFWithPredictions.select($"label", $"prediction").show</strong></span>
<span class="strong"><strong>+-----+----------+</strong></span>
<span class="strong"><strong>|label|prediction|</strong></span>
<span class="strong"><strong>+-----+----------+</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>|  1.0|       1.0|</strong></span>
<span class="strong"><strong>+-----+----------+</strong></span>
</pre></div><p>A quick way of checking the performance of our model is to just count the number of misclassified messages:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; labelledDFWithPredictions.filter { </strong></span>
<span class="strong"><strong>  $"label" !== $"prediction" </strong></span>
<span class="strong"><strong>}.count</strong></span>
<span class="strong"><strong>Long = 1</strong></span>
</pre></div><p>In this case, logistic regression managed to correctly classify every message but one in the training set. This is perhaps unsurprising, given the large number of features and the relatively clear demarcation between the words used in spam and legitimate e-mails.</p><p>Of course, the real test of a model is not how well it performs on the training set, but how well it performs on a test set. To test this, we could just push the test DataFrame through the same stages that we used to train the model, replacing estimators with the fitted transformer that they produced. MLlib provides the <span class="emphasis"><em>pipeline</em></span> abstraction to facilitate this: we wrap an ordered list of transformers and estimators in a pipeline. This pipeline is then fitted to a DataFrame corresponding to the training set. The fitting produces a <code class="literal">PipelineModel</code> <a id="id557" class="indexterm"></a>instance, equivalent to the pipeline but with estimators replaced by <a id="id558" class="indexterm"></a>transformers, as shown in this diagram:</p><div class="mediaobject"><img src="graphics/4795_12_03.jpg" /></div><p>Let's construct the pipeline for our logistic regression spam filter:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.ml.Pipeline</strong></span>
<span class="strong"><strong>import org.apache.spark.ml.Pipeline</strong></span>

<span class="strong"><strong>scala&gt; val pipeline = new Pipeline().setStages(</strong></span>
<span class="strong"><strong>  Array(indexer, tokenizer, hashingTF, classifier)</strong></span>
<span class="strong"><strong>)</strong></span>
<span class="strong"><strong>pipeline: Pipeline = pipeline_7488113e284d</strong></span>
</pre></div><p>Once the pipeline is defined, we fit it to the DataFrame holding the training set: </p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val fittedPipeline = pipeline.fit(trainDF)</strong></span>
<span class="strong"><strong>fittedPipeline: org.apache.spark.ml.PipelineModel = pipeline_089525c6f100</strong></span>
</pre></div><p>When fitting a pipeline to a DataFrame, estimators and transformers are treated differently:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Transformers are applied to the DataFrame and copied, as is, into the pipeline model.</p></li><li style="list-style-type: disc"><p>Estimators are fitted to the DataFrame, producing a transformer. The transformer is then applied to the DataFrame, and appended to the pipeline model.</p></li></ul></div><p>We can now apply the pipeline model to the test set:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val testDFWithPredictions = fittedPipeline.transform(testDF)</strong></span>
<span class="strong"><strong>testDFWithPredictions: DataFrame = [fileName: string, ...</strong></span>
</pre></div><p>This has added a <a id="id559" class="indexterm"></a>
<code class="literal">prediction</code> column to the DataFrame with the predictions of our logistic regression model. To measure the performance of our algorithm, we calculate the <a id="id560" class="indexterm"></a>classification error on the test set:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; testDFWithPredictions.filter { </strong></span>
<span class="strong"><strong>  $"label" !== $"prediction" </strong></span>
<span class="strong"><strong>}.count</strong></span>
<span class="strong"><strong>Long = 20</strong></span>
</pre></div><p>Thus, our naive logistic regression algorithm, with no model selection, or regularization, mis-classifies 2.3% of e-mails. You may, of course, get slightly different results, since the train-test split was random.</p><p>Let's save the training and test DataFrames, with predictions, as <code class="literal">parquet</code> files:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.sql.SaveMode</strong></span>
<span class="strong"><strong>import org.apache.spark.sql.SaveMode</strong></span>

<span class="strong"><strong>scala&gt; (labelledDFWithPredictions</strong></span>
<span class="strong"><strong>  .select("fileName", "label", "prediction", "probability")</strong></span>
<span class="strong"><strong>  .write.mode(SaveMode.Overwrite)</strong></span>
<span class="strong"><strong>  .parquet("transformedTrain.parquet"))</strong></span>

<span class="strong"><strong>scala&gt; (testDFWithPredictions</strong></span>
<span class="strong"><strong>  .select("fileName", "label", "prediction", "probability")</strong></span>
<span class="strong"><strong>  .write.mode(SaveMode.Overwrite)</strong></span>
<span class="strong"><strong>  .parquet("transformedTest.parquet"))</strong></span>
</pre></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip20"></a>Tip</h3><p>In spam classification, a false positive is considerably worse than a false negative: it is much worse to classify a legitimate message as spam, than it is to let a spam message through. To account for this, we could increase the threshold for classification: only messages that score, for instance, 0.7 or above would get classified as spam. This raises the obvious question of choosing the right threshold. One way to do this would be to investigate the false positive rate incurred in the test set for different thresholds, and choosing the lowest threshold to give us an acceptable false positive rate. A good way of visualizing this is to use ROC <a id="id561" class="indexterm"></a>curves, which we will investigate in the next <a id="id562" class="indexterm"></a>section.</p></div></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec115"></a>Evaluation</h2></div></div><hr /></div><p>Unfortunately, the <a id="id563" class="indexterm"></a>functionality for evaluating model quality in the pipeline API remains limited, as of version 1.5.2. Logistic regression does output a summary containing several evaluation metrics (available through the <code class="literal">summary</code> attribute on the trained model), but these are calculated on the training set. In general, we want to evaluate the performance of the model both on the training set and on a separate test set. We will therefore dive down to the underlying MLlib layer to access evaluation metrics.</p><p>MLlib provides a module, <code class="literal">org.apache.spark.mllib.evaluation</code>, with a set of classes for assessing the quality of a model. We will use the <code class="literal">BinaryClassificationMetrics</code> class here, since spam classification is a binary classification problem. Other evaluation classes provide metrics for multi-class models, regression models and ranking models.</p><p>As in the previous section, we will illustrate the concepts in the shell, but you will find analogous code in the <code class="literal">ROC.scala</code> script in the code examples for this chapter. We will use <span class="emphasis"><em>breeze-viz</em></span> to plot curves, so, when starting the shell, we must ensure that the relevant libraries are on the classpath. We will use SBT assembly, as described in <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Distributed Batch Processing with Spark</em></span> (specifically, the <span class="emphasis"><em>Building and running standalone programs</em></span> section), to create a JAR with the required dependencies. We will then pass this JAR to the Spark shell, allowing us to import breeze-viz. Let's write a <code class="literal">build.sbt</code> file that declares a dependency on breeze-viz:</p><div class="informalexample"><pre class="programlisting">// build.sbt
name := "spam_filter"

scalaVersion := "2.10.5"

libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-core" % "1.5.2" % "provided",
  "org.apache.spark" %% "spark-mllib" % "1.5.2" % "provided",
  "org.scalanlp" %% "breeze" % "0.11.2",
  "org.scalanlp" %% "breeze-viz" % "0.11.2",
  "org.scalanlp" %% "breeze-natives" % "0.11.2"
)</pre></div><p>Package the dependencies into a jar with:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sbt assembly</strong></span>
</pre></div><p>This will create a jar called <code class="literal">spam_filter-assembly-0.1-SNAPSHOT.jar</code> in the <code class="literal">target/scala-2.10</code>/ directory. To include this jar in the Spark shell, re-start the shell with the <code class="literal">--jars</code> command line argument:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ spark-shell --jars=target/scala-2.10/spam_filter-assembly-0.1-SNAPSHOT.jar</strong></span>
</pre></div><p>To verify that the packaging worked correctly, try to import <code class="literal">breeze.plot</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import breeze.plot._</strong></span>
<span class="strong"><strong>import breeze.plot._</strong></span>
</pre></div><p>Let's load the test set, with <a id="id564" class="indexterm"></a>predictions, which we created in the previous section and saved as a <code class="literal">parquet</code> file:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val testDFWithPredictions = sqlContext.read.parquet(</strong></span>
<span class="strong"><strong>  "transformedTest.parquet")</strong></span>
<span class="strong"><strong>testDFWithPredictions: org.apache.spark.sql.DataFrame = [fileName: string, label: double, prediction: double, probability: vector]</strong></span>
</pre></div><p>The <code class="literal">BinaryClassificationMetrics</code> object expects an <code class="literal">RDD[(Double, Double)]</code> object of pairs of scores (the probability assigned by the classifier that a particular e-mail is spam) and labels (whether an e-mail is actually spam). We can extract this RDD from our DataFrame:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.mllib.linalg.Vector</strong></span>
<span class="strong"><strong>import org.apache.spark.mllib.linalg.Vector</strong></span>

<span class="strong"><strong>scala&gt; import org.apache.spark.sql.Row</strong></span>
<span class="strong"><strong>import org.apache.spark.sql.Row</strong></span>

<span class="strong"><strong>scala&gt; val scoresLabels = testDFWithPredictions.select(</strong></span>
<span class="strong"><strong>  "probability", "label").map {</strong></span>
<span class="strong"><strong>    case Row(probability:Vector, label:Double) =&gt; </strong></span>
<span class="strong"><strong>      (probability(1), label)</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[3] at map at &lt;console&gt;:23</strong></span>

<span class="strong"><strong>scala&gt; scoresLabels.take(5).foreach(println)</strong></span>
<span class="strong"><strong>(0.9999999967713409,1.0)</strong></span>
<span class="strong"><strong>(0.9999983827108793,1.0)</strong></span>
<span class="strong"><strong>(0.9982059900606365,1.0)</strong></span>
<span class="strong"><strong>(0.9999790713978142,1.0)</strong></span>
<span class="strong"><strong>(0.9999999999999272,1.0)</strong></span>
</pre></div><p>We can now construct the <code class="literal">BinaryClassificationMetrics</code> instance:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics</strong></span>
<span class="strong"><strong>import mllib.evaluation.BinaryClassificationMetrics</strong></span>

<span class="strong"><strong>scala&gt; val bm = new BinaryClassificationMetrics(scoresLabels)</strong></span>
<span class="strong"><strong>bm: BinaryClassificationMetrics = mllib.evaluation.BinaryClassificationMetrics@254ed9ba</strong></span>
</pre></div><p>The <code class="literal">BinaryClassificationMetrics</code> objects contain many useful metrics for evaluating the performance of a classification model. We will look at the <span class="strong"><strong>receiver operating </strong></span>
<a id="id565" class="indexterm"></a>
<span class="strong"><strong>characteristic</strong></span> (<span class="strong"><strong>ROC</strong></span>) curve.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip21"></a>Tip</h3><p>
<span class="strong"><strong>ROC Curves</strong></span>
</p><p>Imagine gradually decreasing, from 1.0, the probability threshold at which we assume a particular e-mail is spam. Clearly, when the threshold is set to 1.0, no e-mails will get classified as spam. This means that there will be no <span class="strong"><strong>false positives</strong></span> (ham messages which we incorrectly classify as spam), but it also means that there will be no <span class="strong"><strong>true positives</strong></span> (spam messages that we correctly identify as spam): all spam e-mails will be incorrectly identified as ham.</p><p>As we gradually <a id="id566" class="indexterm"></a>lower the probability threshold at which we assume a particular e-mail is spam, our spam filter will, hopefully, start identifying a large fraction of e-mails as spam. The vast majority of these will, if our algorithm is well-designed, be real spam. Thus, our rate of true positives increases. As we gradually lower the threshold, we start classifying messages about which we are less sure of as spam. This will increase the number of messages correctly identified as spam, but it will also increase the number of false positives.</p><p>The ROC curve plots, for each threshold value, the fraction of true positives against the fraction of false positives. In the best case, the curve is always 1: this happens when all spam messages are given a score of 1.0, and all ham messages are given a score of 0.0. By contrast, the worst case happens when the curve is a diagonal <span class="emphasis"><em>P(true positive) = P(false positive)</em></span>, which occurs when our algorithm does no better than random. In general, ROC curves fall somewhere in between, forming a convex shell above the diagonal. The deeper this shell, the better our algorithm.</p><div class="mediaobject"><img src="graphics/4795_12_roc.jpg" /></div><p>(left) ROC curve for a model performing much better than random: the curve reaches very high true positive rates for a low false positive rate.</p><p>(middle) ROC curve for a model performing significantly better than random.</p><p>(right) ROC curve for a model performing only marginally better than random: the true positive rate is only marginally larger than the rate of false positives, for any given threshold, meaning that nearly half the examples are misclassified.</p></div><p>We can calculate an array of points on the ROC curve using the <code class="literal">.roc</code> method on our <code class="literal">BinaryClassificationMetrics</code> instance. This returns an <code class="literal">RDD[(Double, Double)]</code> of (<span class="emphasis"><em>false positive</em></span>, <span class="emphasis"><em>true positive</em></span>) fractions for each threshold value. We can collect this as an array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val rocArray = bm.roc.collect</strong></span>
<span class="strong"><strong>rocArray: Array[(Double, Double)] = Array((0.0,0.0), (0.0,0.16793893129770993), ...</strong></span>
</pre></div><p>Of course, an <a id="id567" class="indexterm"></a>array of numbers is not very enlightening, so let's plot the ROC curve with breeze-viz. We start by transforming our array of pairs into two arrays, one of false positives and one of true positives:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val falsePositives = rocArray.map { _._1 }</strong></span>
<span class="strong"><strong>falsePositives: Array[Double] = Array(0.0, 0.0, 0.0, 0.0, 0.0, ...</strong></span>

<span class="strong"><strong>scala&gt; val truePositives = rocArray.map { _._2 }</strong></span>
<span class="strong"><strong>truePositives: Array[Double] = Array(0.0, 0.16793893129770993, 0.19083969465...</strong></span>
</pre></div><p>Let's plot these two arrays:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import breeze.plot._</strong></span>
<span class="strong"><strong>import breeze.plot.</strong></span>

<span class="strong"><strong>scala&gt; val f = Figure()</strong></span>
<span class="strong"><strong>f: breeze.plot.Figure = breeze.plot.Figure@3aa746cd</strong></span>

<span class="strong"><strong>scala&gt; val p = f.subplot(0)</strong></span>
<span class="strong"><strong>p: breeze.plot.Plot = breeze.plot.Plot@5ed1438a</strong></span>

<span class="strong"><strong>scala&gt; p += plot(falsePositives, truePositives)</strong></span>
<span class="strong"><strong>p += plot(falsePositives, truePositives)</strong></span>

<span class="strong"><strong>scala&gt; p.xlabel = "false positives"</strong></span>
<span class="strong"><strong>p.xlabel: String = false positives</strong></span>

<span class="strong"><strong>scala&gt; p.ylabel = "true positives"</strong></span>
<span class="strong"><strong>p.ylabel: String = true positives</strong></span>

<span class="strong"><strong>scala&gt; p.title = "ROC"</strong></span>
<span class="strong"><strong>p.title: String = ROC</strong></span>

<span class="strong"><strong>scala&gt; f.refresh</strong></span>
</pre></div><p>The ROC curve hits <span class="emphasis"><em>1.0</em></span> for a small value of x: that is, we retrieve all true positives at the cost of relatively few false positives. To visualize the curve more accurately, it is instructive to limit the range on the <span class="emphasis"><em>x</em></span>-axis from <span class="emphasis"><em>0</em></span> to <span class="emphasis"><em>0.1</em></span>.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; p.xlim = (0.0, 0.1)</strong></span>
<span class="strong"><strong>p.xlim: (Double, Double) = (0.0,0.1)</strong></span>
</pre></div><p>We also need to tell breeze-viz to use appropriate tick spacing, which requires going down to the <a id="id568" class="indexterm"></a>JFreeChart layer underlying breeze-viz:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.jfree.chart.axis.NumberTickUnit</strong></span>
<span class="strong"><strong>import org.jfree.chart.axis.NumberTickUnit</strong></span>

<span class="strong"><strong>scala&gt; p.xaxis.setTickUnit(new NumberTickUnit(0.01))</strong></span>

<span class="strong"><strong>scala&gt; p.yaxis.setTickUnit(new NumberTickUnit(0.1))</strong></span>
</pre></div><p>We can now save the graph:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; f.saveas("roc.png")</strong></span>
</pre></div><p>This produces the following graph, stored in <code class="literal">roc.png</code>:</p><div class="mediaobject"><img src="graphics/4795_12_05.jpg" /><div class="caption"><p>ROC curve for spam classification with logistic regression. Note that we have limited the false positive axis at 0.1</p></div></div><p>By looking at the graph, we see that we can filter out 85% of spam without a single <span class="strong"><strong>false positive</strong></span>. Of course, we would need a larger test set to really validate this assumption.</p><p>A graph is useful <a id="id569" class="indexterm"></a>to really understand the behavior of a model. Sometimes, however, we just want to have a single measure of the quality of a model. The area under the ROC curve can be a good such metric:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; bm.areaUnderROC</strong></span>
<span class="strong"><strong>res21: Double = 0.9983061235861147</strong></span>
</pre></div><p>This can be interpreted as follows: given any two messages randomly drawn from the test set, one of which is ham, and one of which is spam, there is a 99.8% probability that the model assigned a greater likelihood of spam to the spam message than to the ham message.</p><p>Other useful measures of model quality are the precision and recall for particular thresholds, or <a id="id570" class="indexterm"></a>the F1 score. All of these are provided by the <code class="literal">BinaryClassificationMetrics</code> instance. The API documentation lists the methods available: <a class="ulink" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.BinaryClassificationMetrics" target="_blank">https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.BinaryClassificationMetrics</a>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec116"></a>Regularization in logistic regression</h2></div></div><hr /></div><p>One of the <a id="id571" class="indexterm"></a>dangers of machine learning is over-fitting: the <a id="id572" class="indexterm"></a>algorithm captures not only the signal in the training set, but also the statistical noise that results from the finite size of the training set.</p><p>A way to mitigate over-fitting in logistic regression is to use regularization: we impose a penalty for large values of the parameters when optimizing. We can do this by adding a penalty to the cost function that is proportional to the magnitude of the parameters. Formally, we re-write the logistic regression cost function (described in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Manipulating Data with Breeze</em></span>) as:</p><div class="mediaobject"><img src="graphics/4795_12_06.jpg" /></div><p>where <span class="inlinemediaobject"><img src="graphics/4795_12_07.jpg" /></span> is the normal logistic regression cost function:</p><div class="mediaobject"><img src="graphics/4795_12_08.jpg" /></div><p>Here, <span class="emphasis"><em>params</em></span> is the vector of parameters, <span class="inlinemediaobject"><img src="graphics/4795_12_09.jpg" /></span> is the vector of features for the <span class="emphasis"><em>i<sup>th</sup></em></span> training example, and <span class="inlinemediaobject"><img src="graphics/4795_12_11.jpg" /></span> is <span class="emphasis"><em>1</em></span> if the <span class="emphasis"><em>i</em></span>
<span class="emphasis"><em>th</em></span> training example is spam, and <span class="emphasis"><em>0</em></span> otherwise. This is identical to the logistic regression cost-function introduced in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Manipulating data with Breeze</em></span>, apart from the addition of the regularization term <span class="inlinemediaobject"><img src="graphics/4795_12_12.jpg" /></span>, the <span class="inlinemediaobject"><img src="graphics/4795_12_13.jpg" /></span> norm of the parameter vector. The most common value of <span class="emphasis"><em>n</em></span> is 2, in which case <span class="inlinemediaobject"><img src="graphics/4795_12_14.jpg" /></span> is just the magnitude of the parameter vector:</p><div class="mediaobject"><img src="graphics/4795_12_15.jpg" /></div><p>The additional regularization term drives the algorithm to reduce the magnitude of the parameter vector. When using regularization, features must all have comparable magnitude. This is commonly achieved by normalizing the features. The logistic regression estimator provided by MLlib normalizes all features by default. This can be turned off with the <code class="literal">setStandardization</code> parameter.</p><p>Spark has two <a id="id573" class="indexterm"></a>hyperparameters that can be tweaked to control <a id="id574" class="indexterm"></a>regularization:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">
The type of regularization, set with the <code class="literal">elasticNetParam</code> parameter. A value of 0 indicates <span class="inlinemediaobject"><img src="graphics/4795_12_16.jpg" /></span> regularization.
</li><li style="list-style-type: disc">
The degree of regularization (<span class="inlinemediaobject"><img src="graphics/4795_12_17.jpg" /></span> in the cost function), set with the <code class="literal">regParam</code> parameter. A high value of the regularization parameter indicates a strong regularization. In general, the greater the danger of over-fitting, the larger the regularization parameter ought to be.
</li></ul></div><p>Let's create a new logistic regression instance that uses regularization:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val lrWithRegularization = (new LogisticRegression()</strong></span>
<span class="strong"><strong>  .setMaxIter(50))</strong></span>
<span class="strong"><strong>lrWithRegularization: LogisticRegression = logreg_16b65b325526</strong></span>

<span class="strong"><strong>scala&gt; lrWithRegularization.setElasticNetParam(0) lrWithRegularization.type = logreg_1e3584a59b3a</strong></span>
</pre></div><p>To choose the appropriate value of <span class="inlinemediaobject"><img src="graphics/4795_12_17.jpg" /></span>, we fit the pipeline to the training set and calculate the classification error on the test set for several values of <span class="inlinemediaobject"><img src="graphics/4795_12_17.jpg" /></span>. Further on in the chapter, we will learn about cross-validation in MLlib, which provides a much more rigorous way of choosing hyper-parameters.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val lambdas = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)</strong></span>
<span class="strong"><strong>lambdas: Array[Double] = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)</strong></span>

<span class="strong"><strong>scala&gt; lambdas foreach { lambda =&gt;</strong></span>
<span class="strong"><strong>  lrWithRegularization.setRegParam(lambda)</strong></span>
<span class="strong"><strong>  val pipeline = new Pipeline().setStages(</strong></span>
<span class="strong"><strong>    Array(indexer, tokenizer, hashingTF, lrWithRegularization))</strong></span>
<span class="strong"><strong>  val model = pipeline.fit(trainDF)</strong></span>
<span class="strong"><strong>  val transformedTest = model.transform(testDF)</strong></span>
<span class="strong"><strong>  val classificationError = transformedTest.filter { </strong></span>
<span class="strong"><strong>    $"prediction" !== $"label"</strong></span>
<span class="strong"><strong>  }.count</strong></span>
<span class="strong"><strong>  println(s"$lambda =&gt; $classificationError")</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>0 =&gt; 20</strong></span>
<span class="strong"><strong>1.0E-12 =&gt; 20</strong></span>
<span class="strong"><strong>1.0E-10 =&gt; 20</strong></span>
<span class="strong"><strong>1.0E-8 =&gt; 23</strong></span>
</pre></div><p>For our <a id="id575" class="indexterm"></a>example, we see that any attempt to add L<sub>2</sub><a id="id576" class="indexterm"></a> regularization leads to a decrease in classification accuracy.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec117"></a>Cross-validation and model selection</h2></div></div><hr /></div><p>In the previous <a id="id577" class="indexterm"></a>example, we validated our approach by withholding 30% of the data when training, and testing on this subset. This approach is not particularly rigorous: the exact result changes depending on the random train-test split. Furthermore, if we wanted to test several different hyperparameters (or different models) to choose the best one, we would, unwittingly, choose the model that best reflects the specific rows in our test set, rather than the population as a whole.</p><p>This can be overcome with <span class="emphasis"><em>cross-validation</em></span>. We have already encountered cross-validation in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Parallel Collections and Futures</em></span>. In that chapter, we used random subsample cross-validation, where we created the train-test split randomly.</p><p>In this chapter, we will use <a id="id578" class="indexterm"></a>
<span class="strong"><strong>k-fold cross-validation</strong></span>: we split the training set into <span class="emphasis"><em>k</em></span> parts (where, typically, <span class="emphasis"><em>k</em></span> is <span class="emphasis"><em>10</em></span> or <span class="emphasis"><em>3</em></span>) and use <span class="emphasis"><em>k-1</em></span> parts as the training set and the last as the test set. The train/test cycle is repeated <span class="emphasis"><em>k</em></span> times, keeping a different part as test set each time.</p><p>Cross-validation is commonly used to choose the best set of hyperparameters for a model. To illustrate choosing suitable hyperparameters, we will go back to our regularized logistic regression example. Instead of intuiting the hyper-parameters ourselves, we will choose the hyper-parameters that give us the best cross-validation score.</p><p>We will explore setting both the regularization type (through <code class="literal">elasticNetParam</code>) and the degree of regularization (through <code class="literal">regParam</code>). A crude, but effective way to find good values of the parameters is to perform a grid search: we calculate the cross-validation score for every pair of values of the regularization parameters of interest.</p><p>We can build a grid of parameters using MLlib's <code class="literal">ParamGridBuilder</code>.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}</strong></span>
<span class="strong"><strong>import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}</strong></span>

<span class="strong"><strong>scala&gt; val paramGridBuilder = new ParamGridBuilder()</strong></span>
<span class="strong"><strong>paramGridBuilder: ParamGridBuilder = ParamGridBuilder@1dd694d0</strong></span>
</pre></div><p>To add <a id="id579" class="indexterm"></a>hyper-parameters over which to optimize to the grid, we use the <code class="literal">addGrid</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val lambdas = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)</strong></span>
<span class="strong"><strong>Array[Double] = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)</strong></span>

<span class="strong"><strong>scala&gt; val elasticNetParams = Array(0.0, 1.0)</strong></span>
<span class="strong"><strong>elasticNetParams: Array[Double] = Array(0.0, 1.0)</strong></span>

<span class="strong"><strong>scala&gt; paramGridBuilder.addGrid(</strong></span>
<span class="strong"><strong>  lrWithRegularization.regParam, lambdas).addGrid(</strong></span>
<span class="strong"><strong>  lrWithRegularization.elasticNetParam, elasticNetParams)</strong></span>
<span class="strong"><strong>paramGridBuilder.type = ParamGridBuilder@1dd694d0</strong></span>
</pre></div><p>Once all the dimensions are added, we can just call the <code class="literal">build</code> method on the builder to build the grid:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val paramGrid = paramGridBuilder.build</strong></span>
<span class="strong"><strong>paramGrid: Array[org.apache.spark.ml.param.ParamMap] =</strong></span>
<span class="strong"><strong>Array({</strong></span>
<span class="strong"><strong>  logreg_f7dfb27bed7d-elasticNetParam: 0.0,</strong></span>
<span class="strong"><strong>  logreg_f7dfb27bed7d-regParam: 0.0</strong></span>
<span class="strong"><strong>}, {</strong></span>
<span class="strong"><strong>  logreg_f7dfb27bed7d-elasticNetParam: 1.0,</strong></span>
<span class="strong"><strong>  logreg_f7dfb27bed7d-regParam: 0.0</strong></span>
<span class="strong"><strong>} ...)</strong></span>

<span class="strong"><strong>scala&gt; paramGrid.length</strong></span>
<span class="strong"><strong>Int = 8</strong></span>
</pre></div><p>As we can see, the grid is just a one-dimensional array of sets of parameters to pass to the logistic regression model prior to fitting.</p><p>The next step in setting up the cross-validation pipeline is to define a metric for comparing model performance. Earlier in the chapter, we saw how to use <code class="literal">BinaryClassificationMetrics</code> to estimate the quality of a model. Unfortunately, the <code class="literal">BinaryClassificationMetrics</code> class is part of the core MLLib API, rather than the new pipeline API, and is thus not (easily) compatible. The pipeline API offers a <code class="literal">BinaryClassificationEvaluator</code> class instead. This class works directly on DataFrames, and thus fits perfectly into the pipeline API flow:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator</strong></span>
<span class="strong"><strong>import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator</strong></span>

<span class="strong"><strong>scala&gt; val evaluator = new BinaryClassificationEvaluator()</strong></span>
<span class="strong"><strong>evaluator: BinaryClassificationEvaluator = binEval_64b08538f1a2</strong></span>

<span class="strong"><strong>scala&gt; println(evaluator.explainParams)</strong></span>
<span class="strong"><strong>labelCol: label column name (default: label)</strong></span>
<span class="strong"><strong>metricName: metric name in evaluation (areaUnderROC|areaUnderPR) (default: areaUnderROC)</strong></span>
<span class="strong"><strong>rawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction)</strong></span>
</pre></div><p>From the parameter list, we see that the <code class="literal">BinaryClassificationEvaluator</code> class supports two metrics: the area under the ROC curve, and the area under the precision-recall curve. It expects, as input, a DataFrame containing a <code class="literal">label</code> column (the model truth) and a <code class="literal">rawPrediction</code> column (the column containing the probability that an e-mail is spam or ham).</p><p>We now have all <a id="id580" class="indexterm"></a>the parameters we need to run cross-validation. We first build the pipeline, and then pass the pipeline, the evaluator and the array of parameters over which to run the cross-validation to an instance of <code class="literal">CrossValidator</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val pipeline = new Pipeline().setStages(Array(indexer, tokenizer, hashingTF, lrWithRegularization))</strong></span>
<span class="strong"><strong>pipeline: Pipeline = pipeline_3ed29f72a4cc</strong></span>

<span class="strong"><strong>scala&gt; val crossval = (new CrossValidator()</strong></span>
<span class="strong"><strong>  .setEstimator(pipeline)</strong></span>
<span class="strong"><strong>  .setEvaluator(evaluator)</strong></span>
<span class="strong"><strong>  .setEstimatorParamMaps(paramGrid)</strong></span>
<span class="strong"><strong>  .setNumFolds(3))</strong></span>
<span class="strong"><strong>crossval: CrossValidator = cv_5ebfa1143a9d  </strong></span>
</pre></div><p>We will now fit <code class="literal">crossval</code> to <code class="literal">trainDF</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val cvModel = crossval.fit(trainDF)</strong></span>
<span class="strong"><strong>cvModel: CrossValidatorModel = cv_5ebfa1143a9d</strong></span>
</pre></div><p>This step can take a fairly long time (over an hour on a single machine). This creates a transformer, <code class="literal">cvModel</code>, corresponding to the logistic regression object with the parameters that best represent <code class="literal">trainDF</code>. We can use it to predict the classification error on the test DataFrame:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; cvModel.transform(testDF).filter { </strong></span>
<span class="strong"><strong>  $"prediction" !== $"label" </strong></span>
<span class="strong"><strong>}.count</strong></span>
<span class="strong"><strong>Long = 20</strong></span>
</pre></div><p>Cross-validation <a id="id581" class="indexterm"></a>has therefore resulted in a model that performs identically to the original, naive logistic regression model with no hyper-parameters. <code class="literal">cvModel</code> also contains a list of the evaluation score for each set of parameter in the parameter grid:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; cvModel.avgMetrics</strong></span>
<span class="strong"><strong>Array[Double] = Array(0.996427805316161, ...)</strong></span>
</pre></div><p>The easiest way to relate this to the hyper-parameters is to zip it with <code class="literal">cvModel.getEstimatorParamMaps</code>. This gives us a list of (<span class="emphasis"><em>hyperparameter values</em></span>, <span class="emphasis"><em>cross-validation score</em></span>) pairs:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val params2score = cvModel.getEstimatorParamMaps.zip(</strong></span>
<span class="strong"><strong>  cvModel.avgMetrics)</strong></span>
<span class="strong"><strong>Array[(ml.param.ParamMap,Double)] = Array(({</strong></span>
<span class="strong"><strong>  logreg_8f107aabb304-elasticNetParam: 0.0,</strong></span>
<span class="strong"><strong>  logreg_8f107aabb304-regParam: 0.0</strong></span>
<span class="strong"><strong>},0.996427805316161),...</strong></span>

<span class="strong"><strong>scala&gt; params2score.foreach {</strong></span>
<span class="strong"><strong>  case (params, score) =&gt; </strong></span>
<span class="strong"><strong>    val lambda = params(lrWithRegularization.regParam)</strong></span>
<span class="strong"><strong>    val elasticNetParam = params(</strong></span>
<span class="strong"><strong>      lrWithRegularization.elasticNetParam)</strong></span>
<span class="strong"><strong>    val l2Orl1 = if(elasticNetParam == 0.0) "L2" else "L1"</strong></span>
<span class="strong"><strong>    println(s"$l2Orl1, $lambda =&gt; $score")</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>L2, 0.0 =&gt; 0.996427805316161</strong></span>
<span class="strong"><strong>L1, 0.0 =&gt; 0.996427805316161</strong></span>
<span class="strong"><strong>L2, 1.0E-12 =&gt; 0.9964278053175655</strong></span>
<span class="strong"><strong>L1, 1.0E-12 =&gt; 0.9961429402772803</strong></span>
<span class="strong"><strong>L2, 1.0E-10 =&gt; 0.9964382546369551</strong></span>
<span class="strong"><strong>L1, 1.0E-10 =&gt; 0.9962223090037103</strong></span>
<span class="strong"><strong>L2, 1.0E-8 =&gt; 0.9964159754613495</strong></span>
<span class="strong"><strong>L1, 1.0E-8 =&gt; 0.9891008277659763</strong></span>
</pre></div><p>The best set of hyper-parameters correspond to L<sub>2</sub> regularization with a regularization parameter of <code class="literal">1E-10</code>, though this only corresponds to a tiny improvement in AUC.</p><p>This completes <a id="id582" class="indexterm"></a>our spam filter example. We have successfully trained a spam filter for this particular Ling-Spam dataset. To obtain better results, one could experiment with better feature extraction: we could remove stop words or use TF-IDF vectors, rather than just term frequency vectors as features, and we could add additional features like the length of messages, or even <span class="emphasis"><em>n-grams</em></span>. We could also experiment with non-linear algorithms, such as random forest. All of these steps would be straightforward to add to the pipeline.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec118"></a>Beyond logistic regression</h2></div></div><hr /></div><p>We have concentrated <a id="id583" class="indexterm"></a>on logistic regression in this chapter, but MLlib offers many alternative algorithms that will capture non-linearity in the data more effectively. The consistency of the pipeline API makes it easy to try out different algorithms and see how they perform. The pipeline API offers decision trees, random forest and gradient boosted trees for classification, as well as a simple feed-forward neural network, which is still experimental. It offers lasso and ridge regression and decision trees for regression, as well as PCA for dimensionality reduction.</p><p>The lower level MLlib API also offers principal component analysis for dimensionality reduction, several clustering methods including <span class="emphasis"><em>k</em></span>-means and latent Dirichlet allocation and recommender systems using alternating least squares.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec119"></a>Summary</h2></div></div><hr /></div><p>MLlib tackles the challenge of devising scalable machine learning algorithms head-on. In this chapter, we used it to train a simple scalable spam filter. MLlib is a vast, rapidly evolving library. The best way to learn more about what it can offer is to try and port code that you might have written using another library (such as scikit-learn).</p><p>In the next chapter, we will look at how to build web APIs and interactive visualizations to share our results with the rest of the world.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec120"></a>References</h2></div></div><hr /></div><p>The best reference is the online documentation, including:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The pipeline <a id="id584" class="indexterm"></a>API: <a class="ulink" href="http://spark.apache.org/docs/latest/ml-features.html" target="_blank">http://spark.apache.org/docs/latest/ml-features.html</a>
</p></li><li style="list-style-type: disc"><p>A full list of <a id="id585" class="indexterm"></a>transformers: <a class="ulink" href="http://spark.apache.org/docs/latest/mllib-guide.html#sparkml-high-level-apis-for-ml-pipelines" target="_blank">http://spark.apache.org/docs/latest/mllib-guide.html#sparkml-high-level-apis-for-ml-pipelines</a>
</p></li></ul></div><p>
<span class="emphasis"><em>Advanced Analytics with Spark</em></span>, by <span class="emphasis"><em>Sandy Ryza</em></span>, <span class="emphasis"><em>Uri Laserson</em></span>, <span class="emphasis"><em>Sean Owen</em></span> and <span class="emphasis"><em>Josh Wills</em></span> provides a detailed and up-to-date introduction to machine learning with Spark.</p><p>There are several books that introduce machine learning in more detail than we can here. We have mentioned <span class="emphasis"><em>The Elements of Statistical Learning</em></span>, by <span class="emphasis"><em>Friedman</em></span>, <span class="emphasis"><em>Tibshirani</em></span> and <span class="emphasis"><em>Hastie</em></span> several times in this book. It is one of the most complete introductions to the mathematical underpinnings of machine learning currently available.</p><p>Andrew Ng's <a id="id586" class="indexterm"></a>Machine Learning course on <a class="ulink" href="https://www.coursera.org/" target="_blank">https://www.coursera.org/</a> provides a good introduction to machine learning. It uses Octave/MATLAB as the programming language, but should be straightforward to adapt to Breeze and Scala.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch13"></a>ChapterÂ 13.Â Web APIs with Play</h2></div></div></div><p>In the first 12 chapters of this book, we introduced basic tools and libraries for anyone wanting to build data science applications: we learned how to interact with SQL and MongoDB databases, how to build fast batch processing applications using Spark, how to apply state-of-the-art machine learning algorithms using MLlib, and how to build modular concurrent applications in Akka.</p><p>In the last chapters of this book, we will branch out to look at a web framework: <span class="emphasis"><em>Play</em></span>. You might wonder why a web framework would feature in a data science book; surely such topics are best left to software engineers or web developers. Data scientists, however, rarely exist in a vacuum. They often need to communicate results or insights to stakeholders. As compelling as an ROC curve may be to someone well versed in statistics, it may not carry as much weight with less technical people. Indeed, it can be much easier to sell insights when they are accompanied by an engaging visualization.</p><p>Many modern interactive data visualization applications are web applications running in a web browser. Often, these <a id="id587" class="indexterm"></a>involve <span class="strong"><strong>D3.js</strong></span>, a JavaScript library for building data-driven web pages. In this chapter and the next, we will look at integrating D3 with Scala.</p><p>Writing a web application is a complex endeavor. We will split this task over this chapter and the next. In this chapter, we will learn how to write a REST API that we can use as backend for our application, or query in its own right. In the next chapter, we will look at integrating front-end code with Play to query the API exposed by the backend and display it using D3. We assume at least a basic familiarity with HTTP in this chapter: you should have read <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, at least.</p><p>Many data scientists or aspiring data scientists are unlikely to be familiar with the inner workings of web technologies. Learning how to build complex websites or web APIs can be daunting. This chapter therefore starts with a general discussion of dynamic websites and the architecture of web applications. If you are already familiar with server-side programming and with web frameworks, you can easily skip over the first few sections.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec121"></a>Client-server applications</h2></div></div><hr /></div><p>A website works <a id="id588" class="indexterm"></a>through the interaction between two computers: the client and the server. If you enter the URL <a class="ulink" href="http://www.github.com/pbugnion/s4ds/graphs" target="_blank">www.github.com/pbugnion/s4ds/graphs</a> in a web browser, your browser queries one of the GitHub servers. The <a id="id589" class="indexterm"></a>server will look though its database for information concerning the repository that you are interested in. It will serve this information as HTML, CSS, and JavaScript to your computer. Your browser is then responsible for interpreting this response in the correct way.</p><p>If you look at the URL in question, you will notice that there are several graphs on that page. Unplug your internet connection and you can still interact with the graphs. All the information necessary for interacting with the graphs was transferred, as JavaScript, when you loaded that webpage. When you play with the graphs, the CPU cycles necessary to make those changes happen are spent on <span class="emphasis"><em>your</em></span> computer, not a GitHub server. The code is executed <span class="emphasis"><em>client-side</em></span>. Conversely, when you request information about a new repository, that request is handled by a GitHub server. It is said to be handled <span class="emphasis"><em>server-side</em></span>.</p><p>A web framework like Play can be used on the server. For client-side code, we can only use a language that the client browser will understand: HTML for the layout, CSS for the styling and JavaScript, or languages that can compile to JavaScript, for the logic.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec122"></a>Introduction to web frameworks</h2></div></div><hr /></div><p>This section is a brief <a id="id590" class="indexterm"></a>introduction to how modern web applications are designed. Go ahead and skip it if you already feel comfortable writing backend code.</p><p>Loosely, a web framework is a set of tools and code libraries for building web applications. To understand what a web framework provides, let's take a step back and think about what you would need to do if you did not have one.</p><p>You want to write a program that listens on port 80 and sends HTML (or JSON or XML) back to clients that request it. This is simple if you are serving the same file back to every client: just load the HTML from file when you start the server, and send it to clients who request it.</p><p>So far, so good. But what if you now want to customize the HTML based on the client request? You might choose to respond differently based on part of the URL that the client put in his browser, or based on specific elements in the HTTP request. For instance, the product page on <a class="ulink" href="http://amazon.com" target="_blank">amazon.com</a> is different to the payment page. You need to write code to parse the URL and the request, and then route the request to the relevant handler.</p><p>You might now want to customize the HTML returned dynamically, based on specific elements of the request. The page for every product on <a class="ulink" href="http://amazon.com" target="_blank">amazon.com</a> follows the same outline, but specific elements are different. It would be wasteful to store the entire HTML content for every product. A better way is to store the details for each product in a database and inject them into an HTML template when a client requests information on that product. You can do this with a <span class="emphasis"><em>template processor</em></span>. Of course, writing a good template processor is difficult.</p><p>You might deploy your web framework and realize that it cannot handle the traffic directed to it. You decide that handlers responding to client requests should run asynchronously. You now have to deal with concurrency.</p><p>A web framework <a id="id591" class="indexterm"></a>essentially provides the wires to bind everything together. Besides bundling an HTTP server, most frameworks will have a router that automatically routes a request, based on the URL, to the correct handler. In most cases, the handler will run asynchronously, giving you much better scalability. Many frameworks have a template processor that lets you write HTML (or sometimes JSON or XML) templates intuitively. Some web frameworks also provide functionality for accessing a database, for parsing JSON or XML, for formulating HTTP requests and for localization and internationalization.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec123"></a>Model-View-Controller architecture</h2></div></div><hr /></div><p>Many web <a id="id592" class="indexterm"></a>frameworks impose program architectures: it is difficult to provide wires to bind disparate components together without making some assumptions about what those components are. The <span class="strong"><strong>Model-View-Controller</strong></span> (<span class="strong"><strong>MVC</strong></span>) architecture is particularly popular on the Web, and it is the architecture the Play framework assumes. Let's look at each component in turn:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The model is the data underlying the application. For example, I expect the application underlying GitHub has models for users, repositories, organizations, pull requests and so on. In the Play framework, a model is often an instance of a case class. The core responsibility of the model is to remember the current state of the application.</p></li><li style="list-style-type: disc"><p>Views are representations of a model or a set of models on the screen.</p></li><li style="list-style-type: disc"><p>The controller handles client interactions, possibly changing the model. For instance, if you <span class="emphasis"><em>star</em></span> a project on GitHub, the controller will update the relevant models. Controllers normally carry very little application state: remembering things is the job of the models.</p><div class="mediaobject"><img src="graphics/4795_13_01.jpg" /><div class="caption"><p>MVC architecture: the state of the application is provided by the model. The view provides a visual representation of the model to the user, and the controller handles logic: what to do when the user presses a button or submits a form.</p></div></div></li></ul></div><p>The MVC framework works well because it decouples the user interface from the underlying data and structures the flow of actions: a controller can update the model state or the view, a <a id="id593" class="indexterm"></a>model can send signals to the view to tell it to update, and the view merely displays that information. The model carries no information related to the user interface. This separation of concerns results in an easier mental model of information flow, better encapsulation and greater testability.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec124"></a>Single page applications</h2></div></div><hr /></div><p>The client-server <a id="id594" class="indexterm"></a>duality adds a degree of complication to the elegant MVC architecture. Where should the model reside? What about the controller? Traditionally, the model and the controller ran almost entirely on the server, which just pushed the relevant HTML view to the client.</p><p>The growth in client-side JavaScript frameworks, such AngularJS, has resulted in a gradual shift to putting more code in the client. Both the controller and a temporary version of the model typically run client-side. The server just functions as a web API: if, for instance, the user updates the model, the controller will send an HTTP request to the server informing it of the change.</p><p>It then makes sense to think of the program running server-side and the one running client-side as two separate applications: the server persists data in databases, for instance, and provides a programmatic interface to this data, usually as a web service returning JSON or XML data. The client-side program maintains its own model and controller, and polls the server whenever it needs a new model, or whenever it needs to inform the server that the persistent view of the model should be changed.</p><p>Taken to the extreme, this <a id="id595" class="indexterm"></a>results in <span class="strong"><strong>Single-Page Applications</strong></span>. In a single-page application, the first time the client requests a page from the server, he receives the HTML and the JavaScript necessary to build the framework for the entire application. If the client needs further data from the server, he will poll the server's API. This data is returned as JSON or XML.</p><p>This might seem a little complicated in the abstract, so let's think how the Amazon website might be structured as a single-page application. We will just concern ourselves with the products page here, since that's complicated enough. Let's imagine  that you are on the home page, and you hit a link for a particular product. The application running on your computer knows how to display products, for instance through an HTML template. The JavaScript also has a prototype for the model, such as:</p><div class="informalexample"><pre class="programlisting">{
    product_id: undefined,
    product_name: undefined,
    product_price: undefined,
    ...
}</pre></div><p>What it's currently missing is knowledge of what data to put in those fields for the product you have just selected: there is no way that information could have been sent to your computer when the website loaded, since there was no way to know what product you might click on (and sending information about every product would be prohibitively costly). So the Amazon client sends a request to the server for information on that product. The Amazon server replies with a JSON object (or maybe XML). The client then updates its model with that information. When the update is complete, an event is fired to update the view:</p><div class="mediaobject"><img src="graphics/4795_13_02.jpg" /><div class="caption"><p>Client-server communications in a single-page application: when the client first accesses the website, it receives <a id="id596" class="indexterm"></a>HTML, CSS and JavaScript files that contain the entire logic for the application. From then on, the client only uses the server as an API when it requests additional data. The application running in the user's web browser and the one running on the server are nearly independent. The only coupling is through the structure of the API exposed by the server.</p></div></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec125"></a>Building an application</h2></div></div><hr /></div><p>In this chapter and the <a id="id597" class="indexterm"></a>next, we will build a single-page application that relies on an API written in Play. We will build a webpage that looks like this:</p><div class="mediaobject"><img src="graphics/4795_13_03.jpg" /></div><p>The user enters the name of someone on GitHub and can view a list of their repositories and a chart summarizing what language they use. You can find the application deployed at <code class="literal">app.scala4datascience.com</code>. Go ahead and give it a whirl.</p><p>To get a glimpse of the <a id="id598" class="indexterm"></a>innards, type <code class="literal">app.scala4datascience.com/api/repos/odersky</code>. This returns a JSON object like:</p><div class="informalexample"><pre class="programlisting">[{"name":"dotty","language":"Scala","is_fork":true,"size":14653},
{"name":"frontend","language":"JavaScript","is_fork":true,"size":392},
{"name":"legacy-svn-scala","language":"Scala","is_fork":true,"size":296706},
...</pre></div><p>We will build the API in this chapter, and write the front-end code in the next chapter.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec126"></a>The Play framework</h2></div></div><hr /></div><p>The Play framework is <a id="id599" class="indexterm"></a>a web framework built on top of Akka. It has a proven track record in industry, and is thus a reliable choice for building scalable web applications.</p><p>Play is an <span class="emphasis"><em>opinionated</em></span> web framework: it expects you to follow the MVC architecture, and it has a strong opinion about the tools you should be using. It comes bundled with its own JSON and XML parsers, with its own tools for accessing external APIs, and with recommendations for how to access databases.</p><p>Web applications are much more complex than the command line scripts we have been developing in this book, because there are many more components: the backend code, routing information, HTML templates, JavaScript files, images, and so on. The Play framework makes strong assumptions about the directory structure for your project. Building that structure from scratch is both mind-numbingly boring and easy to get wrong. Fortunately, we can use <a id="id600" class="indexterm"></a>
<span class="strong"><strong>Typesafe activators</strong></span> to bootstrap the project (you can also download the code from the Git repository in <a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a> but I encourage you to start the project from a basic activator structure and code along instead, using the finished version as an example).</p><p>Typesafe activator is a <a id="id601" class="indexterm"></a>custom version of SBT that includes templates to get Scala programmers up and running quickly. To install activator, you can either download <a id="id602" class="indexterm"></a>a JAR from <a class="ulink" href="https://www.typesafe.com/activator/download" target="_blank">https://www.typesafe.com/activator/download</a>, or, on Mac OS, via homebrew:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ brew install typesafe-activator</strong></span>
</pre></div><p>You can then launch the activator console from the terminal. If you downloaded activator:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ ./path/to/activator/activator new</strong></span>
</pre></div><p>Or, if you installed via Homebrew:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ activator new</strong></span>
</pre></div><p>This starts a new project in the current directory. It starts by asking what template you want to start with. Choose <code class="literal">play-scala</code>. It then asks for a name for your application. I chose <code class="literal">ghub-display</code>, but go ahead and be creative!</p><p>Let's explore the newly created project structure (I have only retained the most important files):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>â”œâ”€â”€ app</strong></span>
<span class="strong"><strong>â”‚   â”œâ”€â”€ controllers</strong></span>
<span class="strong"><strong>â”‚   â”‚   â””â”€â”€ Application.scala</strong></span>
<span class="strong"><strong>â”‚   â””â”€â”€ views</strong></span>
<span class="strong"><strong>â”‚       â”œâ”€â”€ main.scala.html</strong></span>
<span class="strong"><strong>â”‚       â””â”€â”€ index.scala.html</strong></span>
<span class="strong"><strong>â”œâ”€â”€ build.sbt</strong></span>
<span class="strong"><strong>â”œâ”€â”€ conf</strong></span>
<span class="strong"><strong>â”‚   â”œâ”€â”€ application.conf</strong></span>
<span class="strong"><strong>â”‚   â””â”€â”€ routes</strong></span>
<span class="strong"><strong>â”œâ”€â”€ project</strong></span>
<span class="strong"><strong>â”‚   â”œâ”€â”€ build.properties</strong></span>
<span class="strong"><strong>â”‚   â””â”€â”€ plugins.sbt</strong></span>
<span class="strong"><strong>â”œâ”€â”€ public</strong></span>
<span class="strong"><strong>â”‚   â”œâ”€â”€ images</strong></span>
<span class="strong"><strong>â”‚   â”‚   â””â”€â”€ favicon.png</strong></span>
<span class="strong"><strong>â”‚   â”œâ”€â”€ javascripts</strong></span>
<span class="strong"><strong>â”‚   â”‚   â””â”€â”€ hello.js</strong></span>
<span class="strong"><strong>â”‚   â””â”€â”€ stylesheets</strong></span>
<span class="strong"><strong>â”‚       â””â”€â”€ main.css</strong></span>
<span class="strong"><strong>â””â”€â”€ test</strong></span>
<span class="strong"><strong>    â”œâ”€â”€ ApplicationSpec.scala</strong></span>
<span class="strong"><strong>    â””â”€â”€ IntegrationSpec.scala</strong></span>
</pre></div><p>Let's run the app:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ ./activator</strong></span>
<span class="strong"><strong>[ghub-display] $ run</strong></span>
</pre></div><p>Head over to your browser and navigate to the URL <code class="literal">127.0.0.1:9000/</code>. The page may take a few seconds to load. Once it is loaded, you should see a default page that says <span class="strong"><strong>Your application is ready</strong></span>.</p><p>Before we modify <a id="id603" class="indexterm"></a>anything, let's walk through how this happens. When you ask your browser to take you to <code class="literal">127.0.0.1:9000/</code>, your browser sends an HTTP request to the server listening at that address (in this case, the Netty server bundled with Play). The request is a GET request for the route <code class="literal">/</code>. The Play framework looks in <code class="literal">conf/routes</code> to see if it has a route satisfying <code class="literal">/</code>:</p><div class="informalexample"><pre class="programlisting">$ cat conf/routes
# Home page
GET     /                           controllers.Application.index
...</pre></div><p>We see that the <code class="literal">conf/routes</code> file does contain the route <code class="literal">/</code> for GET requests. The second part of that line, <code class="literal">controllers.Application.index</code>, is the name of a Scala function to handle that route (more on that in a moment). Let's experiment. Change the route end-point to <code class="literal">/hello</code>. Refresh your browser without changing the URL. This will trigger recompilation of the application. You should now see an error page:</p><div class="mediaobject"><img src="graphics/4795_13_04.jpg" /></div><p>The error page tells you that the app does not have an action for the route <code class="literal">/</code> any more. If you navigate to <code class="literal">127.0.0.1:9000/hello</code>, you should see the landing page again.</p><p>Besides learning a little of how routing works, we have also learned two things about developing Play applications:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>In development mode, code gets recompiled when you refresh your browser and there have been code changes</p></li><li style="list-style-type: disc"><p>Compilation and runtime errors get propagated to the web page</p></li></ul></div><p>Let's change the route back to <code class="literal">/</code>. There is a lot more to say on routing, but it can wait till we start building our application.</p><p>The <code class="literal">conf/routes</code> file tells <a id="id604" class="indexterm"></a>the Play framework to use the method <code class="literal">controllers.Application.index</code> to handle requests to <code class="literal">/</code>. Let's look at the <code class="literal">Application.scala</code> file in <code class="literal">app/controllers</code>, where the <code class="literal">index</code> method is defined:</p><div class="informalexample"><pre class="programlisting">// app/controllers/Application.scala
package controllers

import play.api._
import play.api.mvc._

class Application extends Controller {

  def index = Action {
    Ok(views.html.index("Your new application is ready."))
  }

}</pre></div><p>We see that <code class="literal">controllers.Application.index</code> refers to the method <code class="literal">index</code> in the class <code class="literal">Application</code>. This method has return type <code class="literal">Action</code>. An <code class="literal">Action</code> is just a function that maps HTTP requests to responses. Before explaining this in more detail, let's change the action to:</p><div class="informalexample"><pre class="programlisting">def index = Action {
  Ok("hello, world")
}</pre></div><p>Refresh your browser and you should see the landing page replaced with <code class="literal">"hello world"</code>. By having our action return <code class="literal">Ok("hello, world")</code>, we are asking Play to return an HTTP response with status code 200 (indicating that the request was successful) and the body <code class="literal">"hello world"</code>.</p><p>Let's go back to the original content of <code class="literal">index</code>:</p><div class="informalexample"><pre class="programlisting">Action {
  Ok(views.html.index("Your new application is ready.")) 
}</pre></div><p>We can see that this calls the method <code class="literal">views.html.index</code>. This might appear strange, because there is no <code class="literal">views</code> package anywhere. However, if you look at the <code class="literal">app/views</code> directory, you will notice <a id="id605" class="indexterm"></a>two files: <code class="literal">index.scala.html</code> and <code class="literal">main.scala.html</code>. These are templates, which, at compile time, get transformed into Scala functions. Let's have a look at <code class="literal">main.scala.html</code>:</p><div class="informalexample"><pre class="programlisting">// app/views/main.scala.html
@(title: String)(content: Html)

&lt;!DOCTYPE html&gt;

&lt;html lang="en"&gt;
    &lt;head&gt;
        &lt;title&gt;@title&lt;/title&gt;
        &lt;!-- not so important stuff --&gt;
    &lt;/head&gt;
    &lt;body&gt;
        @content
    &lt;/body&gt;
&lt;/html&gt;</pre></div><p>At compile time, this template is compiled to a function <code class="literal">main(title:String)(content:Html)</code> in the package <code class="literal">views.html</code>. Notice that the function package and name comes from the template file name, and the function arguments come from the first line of the template. The template contains embedded <code class="literal">@title</code> and <code class="literal">@content</code> values, which get filled in by the arguments to the function. Let's experiment with this in a Scala console:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ activator console</strong></span>
<span class="strong"><strong>scala&gt; import views.html._</strong></span>
<span class="strong"><strong>import views.html._</strong></span>

<span class="strong"><strong>scala&gt; val title = "hello"</strong></span>
<span class="strong"><strong>title: String = hello</strong></span>

<span class="strong"><strong>scala&gt; val content = new play.twirl.api.Html("&lt;b&gt;World&lt;/b&gt;")</strong></span>
<span class="strong"><strong>content: play.twirl.api.Html = &lt;b&gt;World&lt;/b&gt;</strong></span>

<span class="strong"><strong>scala&gt; main(title)(content)</strong></span>
<span class="strong"><strong>res8: play.twirl.api.HtmlFormat.Appendable =</strong></span>
<span class="strong"><strong>&lt;!DOCTYPE html&gt;</strong></span>

<span class="strong"><strong>&lt;html lang="en"&gt;</strong></span>
<span class="strong"><strong>    &lt;head&gt;</strong></span>
<span class="strong"><strong>        &lt;title&gt;hello&lt;/title&gt;</strong></span>
<span class="strong"><strong>        &lt;!-- not so important stuff --&gt;</strong></span>
<span class="strong"><strong>    &lt;/head&gt;</strong></span>
<span class="strong"><strong>    &lt;body&gt;</strong></span>
<span class="strong"><strong>        &lt;b&gt;World&lt;/b&gt;</strong></span>
<span class="strong"><strong>    &lt;/body&gt;</strong></span>
<span class="strong"><strong>&lt;/html&gt;</strong></span>
</pre></div><p>We can call <code class="literal">views.html.main</code>, just like we would call a normal Scala function. The arguments we pass in get embedded in the correct place, as defined by the template in <code class="literal">views/main.scala.html</code>.</p><p>This concludes our introductory tour of Play. Let's briefly go over what we have learnt: when a request reaches the <a id="id606" class="indexterm"></a>Play server, the server reads the URL and the HTTP verb and checks that these exist in its <code class="literal">conf/routes</code> file. It will then pass the request to the <code class="literal">Action</code> defined by the controller for that route. This <code class="literal">Action </code>returns an HTTP response that gets fed back to the browser. In constructing the response, the <code class="literal">Action</code> may make use of a template, which, as far as it is concerned is just a function <code class="literal">(arguments list) =&gt; String</code> or <code class="literal">(arguments list) =&gt; HTML</code>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec127"></a>Dynamic routing</h2></div></div><hr /></div><p>Routing, as we saw, is <a id="id607" class="indexterm"></a>the mapping of HTTP requests to Scala handlers. Routes are stored in <code class="literal">conf/routes</code>. A route is defined by an HTTP verb, followed by the end-point, followed by a Scala function:</p><div class="informalexample"><pre class="programlisting">// verb   // end-point              // Scala handler
GET       /                         controllers.Application.index</pre></div><p>We learnt to add new routes by just adding lines to the <code class="literal">routes</code> file. We are not limited to static routes, however. The Play framework lets us include wild cards in routes. The value of the wild card can be passed as an argument to the controller. To see how this works, let's create a controller that takes the name of a person as argument. In the <code class="literal">Application</code> object in <code class="literal">app.controllers</code>, add:</p><div class="informalexample"><pre class="programlisting">// app/controllers/Application.scala

class Application extends Controller {

  ...

  def hello(name:String) = Action {
    Ok(s"hello, $name")
  }
}</pre></div><p>We can now define a route handled by this controller:</p><div class="informalexample"><pre class="programlisting">// conf/routes
GET  /hello/<span class="strong"><strong>:name</strong></span>             controllers.Application.hello(<span class="strong"><strong>name</strong></span>)</pre></div><p>If you now point your browser to <code class="literal">127.0.0.1:9000/hello/Jim</code>, you will see <span class="strong"><strong>hello, Jim</strong></span> appear on the screen.</p><p>Any string between <code class="literal">:</code> and <a id="id608" class="indexterm"></a>the following <code class="literal">/</code> is treated as a wild card: it will match any combination of characters. The value of the wild card can be passed to the controller. Note that the wild card can appear anywhere in the URL, and there can be more than one wild card. The following are all valid route definitions, for instance:</p><div class="informalexample"><pre class="programlisting">GET /hello/person-<span class="strong"><strong>:name</strong></span>        controllers.Application.hello(name)
// ... matches /hello/person-Jim

GET /hello/<span class="strong"><strong>:name</strong></span>/picture  controllers.Application.pictureFor(name)
// ... matches /hello/Jim/picture

GET /hello/<span class="strong"><strong>:first</strong></span>/<span class="strong"><strong>:last</strong></span> controllers.Application.hello(first, last)
// ... matches /hello/john/doe</pre></div><p>There are many other options for selecting routes and passing arguments to the controller. Consult the documentation for the <a id="id609" class="indexterm"></a>Play framework for a full discussion on the routing possibilities: <a class="ulink" href="https://www.playframework.com/documentation/2.4.x/ScalaRouting" target="_blank">https://www.playframework.com/documentation/2.4.x/ScalaRouting</a>.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip23"></a>Tip</h3><p>
<span class="strong"><strong>URL design</strong></span>
</p><p>It is generally considered <a id="id610" class="indexterm"></a>best practice to leave the URL as simple as possible. The URL should reflect the hierarchical structure of the information of the website, rather than the underlying implementation. GitHub is a very good example of this: its URLs make intuitive sense. For instance, the URL for the repository for this book is:</p><p>
<a class="ulink" href="https://github.com/pbugnion/s4ds" target="_blank">https://github.com/pbugnion/s4ds</a>
</p><p>To access the issues page for that repository, add <code class="literal">/issues</code> to the route. To access the first <a id="id611" class="indexterm"></a>issue, add <code class="literal">/1</code> to that route. These are called <span class="strong"><strong>semantic URLs</strong></span> (<a class="ulink" href="https://en.wikipedia.org/wiki/Semantic_URL" target="_blank">https://en.wikipedia.org/wiki/Semantic_URL</a>).</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec128"></a>Actions</h2></div></div><hr /></div><p>We have talked about <a id="id612" class="indexterm"></a>routes, and how to pass parameters to controllers. Let's now talk about what we can do with the controller.</p><p>The method defined in the route must return a <code class="literal">play.api.mvc.Action</code> instance. The <code class="literal">Action</code> type is a thin wrapper around the type <code class="literal">Request[A] =&gt; Result</code>, where <code class="literal">Request[A]</code> identifies an HTTP request and <code class="literal">Result</code> is an HTTP response.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec73"></a>Composing the response</h3></div></div></div><p>An HTTP response, as we <a id="id613" class="indexterm"></a>saw in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, is composed of:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>the status code (such as 200 for a successful response, or 404 for a missing page)</p></li><li style="list-style-type: disc"><p>the response headers, a key-value list indicating metadata related to the response</p></li><li style="list-style-type: disc"><p>The response body. This can be HTML for web pages, or JSON, XML or plain text (or many other formats). This is generally the bit that we are really interested in.</p></li></ul></div><p>The Play framework defines a <code class="literal">play.api.mvc.Result</code> object that symbolizes a response. The object contains a <code class="literal">header</code> attribute with the status code and the headers, and a <code class="literal">body</code> attribute containing the body.</p><p>The simplest way to generate a <code class="literal">Result</code> is to use one of the factory methods in <code class="literal">play.api.mvc.Results</code>. We have already seen the <code class="literal">Ok</code> method, which generates a response with status code 200:</p><div class="informalexample"><pre class="programlisting">def hello(name:String) = Action {
  Ok("hello, $name")
}</pre></div><p>Let's take a step back and open a Scala console so we can understand how this works:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ activator console</strong></span>
<span class="strong"><strong>scala&gt; import play.api.mvc._</strong></span>
<span class="strong"><strong>import play.api.mvc._</strong></span>

<span class="strong"><strong>scala&gt; val res = Results.Ok("hello, world")</strong></span>
<span class="strong"><strong>res: play.api.mvc.Result = Result(200, Map(Content-Type -&gt; text/plain; charset=utf-8))</strong></span>

<span class="strong"><strong>scala&gt; res.header.status</strong></span>
<span class="strong"><strong>Int = 200</strong></span>

<span class="strong"><strong>scala&gt; res.header.headers</strong></span>
<span class="strong"><strong>Map[String,String] = Map(Content-Type -&gt; text/plain; charset=utf-8)</strong></span>

<span class="strong"><strong>scala&gt; res.body</strong></span>
<span class="strong"><strong>play.api.libs.iteratee.Enumerator[Array[Byte]] = play.api.libs.iteratee.Enumerator$$anon$18@5fb83873</strong></span>
</pre></div><p>We can see how the <code class="literal">Results.Ok(...)</code> creates a <code class="literal">Result</code> object with status <code class="literal">200</code> and (in this case), a single header denoting the content type. The body is a bit more complicated: it is an enumerator that can be pushed onto the output stream when needed. The enumerator contains the argument passed to <code class="literal">Ok</code>: <code class="literal">"hello, world"</code>, in this case.</p><p>There are many factory <a id="id614" class="indexterm"></a>methods in <code class="literal">Results</code> for returning different status codes. Some of the more relevant ones are:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">Action { Results.NotFound }</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">Action { Results.BadRequest("bad request") }</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">Action { Results.InternalServerError("error") }</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">Action { Results.Forbidden }</code>
</p></li><li style="list-style-type: disc"><p>
<code class="literal">Action { Results.Redirect("/home") }</code>
</p></li></ul></div><p>For a full list of <code class="literal">Result</code> factories, consult <a id="id615" class="indexterm"></a>the API documentation for Results (<a class="ulink" href="https://www.playframework.com/documentation/2.4.x/api/scala/index.html#play.api.mvc.Results" target="_blank">https://www.playframework.com/documentation/2.4.x/api/scala/index.html#play.api.mvc.Results</a>).</p><p>We have, so far, been limiting ourselves to passing strings as the content of the <code class="literal">Ok</code> result: <code class="literal">Ok("hello, world")</code>. We are not, however, limited to passing strings. We can pass a JSON object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import play.api.libs.json._</strong></span>
<span class="strong"><strong>import play.api.libs.json._</strong></span>

<span class="strong"><strong>scala&gt; val jsonObj = Json.obj("hello" -&gt; "world")</strong></span>
<span class="strong"><strong>jsonObj: play.api.libs.json.JsObject = {"hello":"world"}</strong></span>

<span class="strong"><strong>scala&gt; Results.Ok(jsonObj)</strong></span>
<span class="strong"><strong>play.api.mvc.Result = Result(200, Map(Content-Type -&gt; application/json; charset=utf-8))</strong></span>
</pre></div><p>We will cover interacting with JSON in more detail when we start building the API. We can also pass HTML as the content. This is most commonly the case when returning a view:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val htmlObj = views.html.index("hello")</strong></span>
<span class="strong"><strong>htmlObj: play.twirl.api.HtmlFormat.Appendable =</strong></span>

<span class="strong"><strong>&lt;!DOCTYPE html&gt;</strong></span>

<span class="strong"><strong>&lt;html lang="en"&gt;</strong></span>
<span class="strong"><strong>    &lt;head&gt;</strong></span>
<span class="strong"><strong>...</strong></span>

<span class="strong"><strong>scala&gt; Results.Ok(htmlObj)</strong></span>
<span class="strong"><strong>play.api.mvc.Result = Result(200, Map(Content-Type -&gt; text/html; charset=utf-8))</strong></span>
</pre></div><p>Note how the <code class="literal">Content-Type</code> <a id="id616" class="indexterm"></a>header is set based on the type of content passed to <code class="literal">Ok</code>. The <code class="literal">Ok</code> factory uses the <code class="literal">Writeable</code> type class to convert its argument to the body of the response. Thus, any content type for which a <code class="literal">Writeable</code> type class exists can be used as argument to <code class="literal">Ok</code>. If you are unfamiliar with type classes, you might want to read the <span class="emphasis"><em>Looser coupling with type classes</em></span> section in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Scala and SQL through JDBC</em></span>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec74"></a>Understanding and parsing the request</h3></div></div></div><p>We now know how to <a id="id617" class="indexterm"></a>formulate (basic) responses. The other half of the equation is the HTTP request. Recall that an <code class="literal">Action</code> is just a function mapping <code class="literal">Request =&gt; Result</code>. We can access the request using:</p><div class="informalexample"><pre class="programlisting">def hello(name:String) = Action { <span class="strong"><strong>request</strong></span> =&gt; 
  ...
}</pre></div><p>One of the reasons for needing a reference to the request is to access parameters in the query string. Let's modify the <code class="literal">Hello, &lt;name&gt;</code> example that we wrote earlier to, optionally, include a title in the query string. Thus, a URL could be formatted as <code class="literal">/hello/Jim?title=Dr</code>. The <code class="literal">request</code> instance exposes the <code class="literal">getQueryString</code> method for accessing specific keys in the query string. This method returns <code class="literal">Some[String]</code> if the key is present in the query, or <code class="literal">None</code> otherwise. We can re-write our <code class="literal">hello</code> controller as:</p><div class="informalexample"><pre class="programlisting">def hello(name:String) = Action { request =&gt;
  val title = request.getQueryString("title")
  val titleString = title.map { _ + " " }.getOrElse("")
  Ok(s"Hello, $titleString$name")
}</pre></div><p>Try this out by accessing the URL <code class="literal">127.0.0.1:9000/hello/Odersky?title=Dr</code> in your browser. The browser should display <code class="literal">Hello, Dr Odersky</code>.</p><p>We have, so far, been concentrating on GET requests. These do not have a body. Other types of HTTP request, most commonly POST requests, do contain a body. Play lets the user pass <span class="emphasis"><em>body parsers</em></span> when defining the action. The request body will be passed through the body parser, which will convert it from a byte stream to a Scala type. As a very simple example, let's define a <a id="id618" class="indexterm"></a>new route that accepts POST requests:</p><div class="informalexample"><pre class="programlisting">POST      /hello            controllers.Application.helloPost</pre></div><p>We will apply the predefined <code class="literal">parse.text</code> body parser to the incoming request body. This converts the body of the request to a string. The <code class="literal">helloPost</code> controller looks like:</p><div class="informalexample"><pre class="programlisting">def helloPost = Action(<span class="strong"><strong>parse.text</strong></span>) { request =&gt;
  Ok("Hello. You told me: " + request.body)
}</pre></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip24"></a>Tip</h3><p>You cannot test POST requests easily in the browser. You can use cURL instead. cURL is a command line utility for dispatching HTTP requests. It is installed by default on Mac OS and should be available via the package manager on Linux distributions. The following will send a POST request with <code class="literal">"I think that Scala is great"</code> in the body:</p><div class="informalexample"><pre class="programlisting">$ curl --data "I think that Scala is great" --header "Content-type:text/plain"  127.0.0.1:9000/hello</pre></div><p>This prints the following line to the terminal:</p><p>
<code class="literal">Hello. You told me: I think that Scala is great</code>
</p></div><p>There are several types of built-in body parsers:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<code class="literal">parse.file(new File("filename.txt"))</code> will save the body to a file.</p></li><li style="list-style-type: disc"><p>
<code class="literal">parse.json</code> will parse the body as JSON (we will learn more about interacting with JSON in the next section).</p></li><li style="list-style-type: disc"><p>
<code class="literal">parse.xml</code> will parse the body as XML.</p></li><li style="list-style-type: disc"><p>
<code class="literal">parse.urlFormEncoded</code> will parse the body as returned by submitting an HTML form. The <code class="literal">request.body</code> attribute is a Scala map from <code class="literal">String</code> to <code class="literal">Seq[String]</code>, mapping each form element to its value(s).</p></li></ul></div><p>For a full list of body <a id="id619" class="indexterm"></a>parsers, the best source is the Scala API documentation <a id="id620" class="indexterm"></a>for <code class="literal">play.api.mvc.BodyParsers.parse</code> available at: <a class="ulink" href="https://www.playframework.com/documentation/2.5.x/api/scala/index.html#play.api.mvc.BodyParsers$parse$" target="_blank">https://www.playframework.com/documentation/2.5.x/api/scala/index.html#play.api.mvc.BodyParsers$parse$</a>.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec129"></a>Interacting with JSON</h2></div></div><hr /></div><p>JSON, as we <a id="id621" class="indexterm"></a>discovered in previous chapters, is becoming the de-facto language for communicating structured data over HTTP. If you develop a web application or a web API, it is likely that you will have to consume or emit JSON, or both.</p><p>In <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, we learned how to parse JSON through <code class="literal">json4s</code>. The Play framework includes its own JSON parser and emitter. Fortunately, it behaves in much the same way as <code class="literal">json4s</code>.</p><p>Let's imagine that we are building an API that summarizes information about GitHub repositories. Our API will emit a JSON array listing a user's repositories when queried about a specific user (much like the GitHub API, but with just a subset of fields).</p><p>Let's start by defining a model for the repository. In Play applications, models are normally stored in the folder <code class="literal">app/models</code>, in the <code class="literal">models</code> package:</p><div class="informalexample"><pre class="programlisting">// app/models/Repo.scala

package models

case class Repo (
  val name:String,
  val language:String,
  val isFork: Boolean,
  val size: Long
)</pre></div><p>Let's add a route to our application that serves arrays of repos for a particular user. In <code class="literal">conf/routes</code>, add the following line:</p><div class="informalexample"><pre class="programlisting">// conf/routes
GET   /api/repos/:username       controllers.Api.repos(username)</pre></div><p>Let's now implement the framework for the controller. We will create a new controller for our API, imaginatively called <code class="literal">Api</code>. For now, we will just have the controller return dummy data. This is what the code looks like (we will explain the details shortly):</p><div class="informalexample"><pre class="programlisting">// app/controllers/Api.scala
package controllers
import play.api._
import play.api.mvc._
import play.api.libs.json._

import models.Repo

class Api extends Controller {

  // Some dummy data.
  val data = List[Repo](
    Repo("dotty", "Scala", true, 14315),
    Repo("frontend", "JavaScript", true, 392)
  )

  // Typeclass for converting Repo -&gt; JSON
  implicit val writesRepos = new Writes[Repo] {
    def writes(repo:Repo) = Json.obj(
      "name" -&gt; repo.name,
      "language" -&gt; repo.language,
      "is_fork" -&gt; repo.isFork,
      "size" -&gt; repo.size
    )
  }

  // The controller
  def repos(username:String) = Action {
    
    val repoArray = Json.toJson(data) 
    // toJson(data) relies on existence of 
    // `Writes[List[Repo]]` type class in scope

    Ok(repoArray)
  }
}</pre></div><p>If you point your web <a id="id622" class="indexterm"></a>browser to <code class="literal">127.0.0.1:9000/api/repos/odersky</code>, you should now see the following JSON object:</p><div class="informalexample"><pre class="programlisting">[{"name":"dotty","language":"Scala","is_fork":true,"size":14315},{"name":"frontend","language":"JavaScript","is_fork":true,"size":392}]</pre></div><p>The only tricky part of this code is the conversion from <code class="literal">Repo</code> to JSON. We call <code class="literal">Json.toJson</code> on <code class="literal">data</code>, an instance of type <code class="literal">List[Repo]</code>. The <code class="literal">toJson</code> method relies on the existence of a type class <code class="literal">Writes[T]</code> for the type <code class="literal">T</code> passed to it.</p><p>The Play framework makes extensive use of type classes to define how to convert models to specific formats. Recall that we learnt how to write type classes in the context of SQL and MongoDB. The Play framework's expectations are very similar: for the <code class="literal">Json.toJson</code> method to work on an instance of type <code class="literal">Repo</code>, there must be a <code class="literal">Writes[Repo]</code> implementation available that specifies how to transform <code class="literal">Repo</code> objects to JSON.</p><p>In the Play framework, the <code class="literal">Writes[T]</code> type class defines a single method:</p><div class="informalexample"><pre class="programlisting">trait Writes[T] {
  def writes(obj:T):Json
}</pre></div><p>
<code class="literal">Writes</code> methods for built-in simple types and for collections are already built into the Play framework, so we do not need to worry about defining <code class="literal">Writes[Boolean]</code>, for instance.</p><p>The <code class="literal">Writes[Repo]</code> instance <a id="id623" class="indexterm"></a>is commonly defined either directly in the controller, if it is just used for that controller, or in the <code class="literal">Repo</code> companion object, where it can be used across several controllers. For simplicity, we just embedded it in the controller.</p><p>Note how type-classes allow for separation of concerns. The model just defines the <code class="literal">Repo</code> type, without attaching any behavior. The <code class="literal">Writes[Repo]</code> type class just knows how to convert from a <code class="literal">Repo</code> instance to JSON, but knows nothing of the context in which it is used. Finally, the controller just knows how to create a JSON HTTP response.</p><p>Congratulations, you have just defined a web API that returns JSON! In the next section, we will learn how to fetch data from the GitHub web API to avoid constantly returning the same array.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec130"></a>Querying external APIs and consuming JSON</h2></div></div><hr /></div><p>So far, we have <a id="id624" class="indexterm"></a>learnt how to provide the user with a dummy JSON <a id="id625" class="indexterm"></a>array of repositories in response to a request to <code class="literal">/api/repos/:username</code>. In this section, we will replace the dummy data with the user's actual repositories, dowloaded from GitHub.</p><p>In <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span>, we learned how to query the GitHub API using Scala's <code class="literal">Source.fromURL</code> method and <code class="literal">scalaj-http</code>. It should come as no surprise that the Play framework implements its own library for interacting with external web services.</p><p>Let's edit the <code class="literal">Api</code> controller to fetch information about a user's repositories from GitHub, rather than using dummy data. When called with a username as argument, the controller will:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>Send a GET request to the GitHub API for that user's repositories.</p></li><li><p>Interpret the response, converting the body from a JSON object to a <code class="literal">List[Repo]</code>.</p></li><li><p>Convert from the <code class="literal">List[Repo]</code> to a JSON array, forming the response.</p></li></ol></div><p>We start by giving the <a id="id626" class="indexterm"></a>full code listing before explaining the thornier <a id="id627" class="indexterm"></a>parts in detail:</p><div class="informalexample"><pre class="programlisting">// app/controllers/Api.scala

package controllers

import play.api._
import play.api.mvc._
import play.api.libs.ws.WS // query external APIs
import play.api.Play.current
import play.api.libs.json._ // parsing JSON
import play.api.libs.functional.syntax._
import play.api.libs.concurrent.Execution.Implicits.defaultContext

import models.Repo

class Api extends Controller {

  // type class for Repo -&gt; Json conversion
  implicit val writesRepo = new Writes[Repo] {
    def writes(repo:Repo) = Json.obj(
      "name" -&gt; repo.name,
      "language" -&gt; repo.language,
      "is_fork" -&gt; repo.isFork,
      "size" -&gt; repo.size
    )
  }

  // type class for Github Json -&gt; Repo conversion
  implicit val readsRepoFromGithub:Reads[Repo] = (
    (JsPath \ "name").read[String] and
    (JsPath \ "language").read[String] and
    (JsPath \ "fork").read[Boolean] and
    (JsPath \ "size").read[Long]
  )(Repo.apply _)

  // controller
  def repos(username:String) = Action.async {

    // GitHub URL
    val url = s"https://api.github.com/users/$username/repos"
    val response = WS.url(url).get() // compose get request

    // "response" is a Future
    response.map { r =&gt;
      // executed when the request completes
      if (r.status == 200) {

        // extract a list of repos from the response body
        val reposOpt = Json.parse(r.body).validate[List[Repo]]
        reposOpt match {
          // if the extraction was successful:
          case JsSuccess(repos, _) =&gt; Ok(Json.toJson(repos))

          // If there was an error during the extraction
          case _ =&gt; InternalServerError
        }
      }
      else {
        // GitHub returned something other than 200
        NotFound
      }
      
    }
  }

}</pre></div><p>If you have written <a id="id628" class="indexterm"></a>all this, point your browser to, for instance, <code class="literal">127.0.0.1:9000/api/repos/odersky</code> to see the list of repositories owned by Martin Odersky:</p><div class="informalexample"><pre class="programlisting">[{"name":"dotty","language":"Scala","is_fork":true,"size":14653},{"name":"frontend","language":"JavaScript","is_fork":true,"size":392},...</pre></div><p>This code sample is <a id="id629" class="indexterm"></a>a lot to take in, so let's break it down.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec75"></a>Calling external web services</h3></div></div></div><p>The first <a id="id630" class="indexterm"></a>step in querying external APIs is to import the <code class="literal">WS</code> object, which defines factory methods for creating HTTP requests. These factory methods rely on a reference to an implicit Play application in the namespace. The easiest way to ensure this is the case is to import <code class="literal">play.api.Play.current</code>, a reference to the current application.</p><p>Let's ignore the <code class="literal">readsRepoFromGithub</code> type class for now and jump straight to the controller body. The URL that we want to hit with a GET request is <code class="literal">"https://api.github.com/users/$username/repos"</code>, with the appropriate value for <code class="literal">$username</code>. We create a GET request with <code class="literal">WS.url(url).get()</code>. We can also add headers to an existing request. For instance, to specify the content type, we could have written:</p><div class="informalexample"><pre class="programlisting">WS.url(url).withHeaders("Content-Type" -&gt; "application/json").get()</pre></div><p>We can use headers to pass a GitHub OAuth token using:</p><div class="informalexample"><pre class="programlisting">val token = "2502761d..."
WS.url(url).withHeaders("Authorization" -&gt; s"token $token").get()</pre></div><p>To formulate a POST request, rather than a GET request, replace the final <code class="literal">.get()</code> with <code class="literal">.post(data)</code>. Here, <code class="literal">data</code> can be JSON, XML or a string.</p><p>Adding <code class="literal">.get</code> or <code class="literal">.post</code> fires the request, returning a <code class="literal">Future[WSResponse]</code>. You should, by now, be familiar with futures. By writing <code class="literal">response.map { r =&gt; ... }</code>, we specify a transformation to be executed on the future result, when it returns. The transformation verifies the response's status, returning <code class="literal">NotFound</code> if the status code of the response is anything but 200.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec76"></a>Parsing JSON</h3></div></div></div><p>If the status code is 200, the <a id="id631" class="indexterm"></a>callback parses the response body to JSON and converts the parsed JSON to a <code class="literal">List[Repo]</code> instance. We already know how to convert from a <code class="literal">Repo</code> object to JSON using the <code class="literal">Writes[Repo]</code> type class. The converse, going from JSON to a <code class="literal">Repo</code> object, is a little more challenging, because we have to account for incorrectly formatted JSON. To this effect, the Play framework provides the <code class="literal">.validate[T]</code> method on JSON objects. This method tries to convert the JSON to an instance of type <code class="literal">T</code>, returning <code class="literal">JsSuccess</code> if the JSON is well-formatted, or <code class="literal">JsError</code> otherwise (similar to Scala's <code class="literal">Try</code> object). The <code class="literal">.validate</code> method relies on the existence of a type class <code class="literal">Reads[Repo]</code>. Let's experiment with a Scala console:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ activator console</strong></span>

<span class="strong"><strong>scala&gt; import play.api.libs.json._</strong></span>
<span class="strong"><strong>import play.api.libs.json._</strong></span>

<span class="strong"><strong>scala&gt; val s = """ </strong></span>
<span class="strong"><strong>  { "name": "dotty", "size": 150, "language": "Scala", "fork": true }</strong></span>
<span class="strong"><strong>"""</strong></span>
<span class="strong"><strong>s: String = "</strong></span>
<span class="strong"><strong>  { "name": "dotty", "size": 150, "language": "Scala", "fork": true }</strong></span>
<span class="strong"><strong>"</strong></span>

<span class="strong"><strong>scala&gt; val parsedJson = Json.parse(s)</strong></span>
<span class="strong"><strong>parsedJson: play.api.libs.json.JsValue = {"name":"dotty","size":150,"language":"Scala","fork":true}</strong></span>
</pre></div><p>Using <code class="literal">Json.parse</code> converts a string to an instance of <code class="literal">JsValue</code>, the super-type for JSON instances. We can access specific fields in <code class="literal">parsedJson</code> using XPath-like syntax (if you are not familiar with XPath-like syntax, you might want to read <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Slick â€“ A Functional Interface for SQL</em></span>):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; parsedJson \ "name"</strong></span>
<span class="strong"><strong>play.api.libs.json.JsLookupResult = JsDefined("dotty")</strong></span>
</pre></div><p>XPath-like lookups return <a id="id632" class="indexterm"></a>an instance with type <code class="literal">JsLookupResult</code>. This takes two values: either <code class="literal">JsDefined</code>, if the path is valid, or <code class="literal">JsUndefined</code> if it is not:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; parsedJson \ "age"</strong></span>
<span class="strong"><strong>play.api.libs.json.JsLookupResult = JsUndefined('age' is undefined on object: {"name":"dotty","size":150,"language":"Scala","fork":true})</strong></span>
</pre></div><p>To go from a <code class="literal">JsLookupResult</code> instance to a String in a type-safe way, we can use the <code class="literal">.validate[String]</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; (parsedJson \ "name").validate[String]</strong></span>
<span class="strong"><strong>play.api.libs.json.JsResult[String] = JsSuccess(dotty,) </strong></span>
</pre></div><p>The <code class="literal">.validate[T]</code> method returns either <code class="literal">JsSuccess</code> if the <code class="literal">JsDefined</code> instance could be successfully cast to <code class="literal">T</code>, or <code class="literal">JsError</code> otherwise. To illustrate the latter, let's try validating this as an <code class="literal">Int</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; (parsedJson \ "name").validate[Int]</strong></span>
<span class="strong"><strong>dplay.api.libs.json.JsResult[Int] = JsError(List((,List(ValidationError(List(error.expected.jsnumber),WrappedArray())))))</strong></span>
</pre></div><p>Calling <code class="literal">.validate</code> on an instance of type <code class="literal">JsUndefined</code> also returns in a <code class="literal">JsError</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; (parsedJson \ "age").validate[Int]</strong></span>
<span class="strong"><strong>play.api.libs.json.JsResult[Int] = JsError(List((,List(ValidationError(List('age' is undefined on object: {"name":"dotty","size":150,"language":"Scala","fork":true}),WrappedArray())))))</strong></span>
</pre></div><p>To convert from an instance of <code class="literal">JsResult[T]</code> to an instance of type <code class="literal">T</code>, we can use pattern matching:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val name = (parsedJson \ "name").validate[String] match {</strong></span>
<span class="strong"><strong>  case JsSuccess(n, _) =&gt; n</strong></span>
<span class="strong"><strong>  case JsError(e) =&gt; throw new IllegalStateException(</strong></span>
<span class="strong"><strong>    s"Error extracting name: $e")</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>name: String = dotty</strong></span>
</pre></div><p>We can now use <code class="literal">.validate</code> to cast JSON to simple types in a type-safe manner. But, in the code example, we used <code class="literal">.validate[Repo]</code>. This works provided a <code class="literal">Reads[Repo]</code> type class is implicitly available in the namespace.</p><p>The most common way of defining <code class="literal">Reads[T]</code> type classes is through a DSL provided in <code class="literal">import play.api.libs.functional.syntax._</code>. The DSL works by chaining operations returning either <code class="literal">JsSuccess</code> or <code class="literal">JsError</code> together. Discussing exactly how this DSL works is outside the scope of this chapter (see, for instance, the Play framework documentation page on JSON combinators: <a class="ulink" href="https://www.playframework.com/documentation/2.4.x/ScalaJsonCombinators" target="_blank">https://www.playframework.com/documentation/2.4.x/ScalaJsonCombinators</a>). We will stick to <a id="id633" class="indexterm"></a>discussing the syntax.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import play.api.libs.functional.syntax._</strong></span>
<span class="strong"><strong>import play.api.libs.functional.syntax._</strong></span>

<span class="strong"><strong>scala&gt; import models.Repo</strong></span>
<span class="strong"><strong>import models.Repo</strong></span>

<span class="strong"><strong>scala&gt; implicit val readsRepoFromGithub:Reads[Repo] = (</strong></span>
<span class="strong"><strong>  (JsPath \ "name").read[String] and</strong></span>
<span class="strong"><strong>  (JsPath \ "language").read[String] and</strong></span>
<span class="strong"><strong>  (JsPath \ "fork").read[Boolean] and</strong></span>
<span class="strong"><strong>  (JsPath \ "size").read[Long]</strong></span>
<span class="strong"><strong>)(Repo.apply _)</strong></span>
<span class="strong"><strong>readsRepoFromGithub: play.api.libs.json.Reads[models.Repo] = play.api.libs.json.Reads$$anon$8@a198ddb</strong></span>
</pre></div><p>The <code class="literal">Reads</code> type class is defined in two stages. The first chains together <code class="literal">read[T]</code> methods with <code class="literal">and</code>, combining successes and errors. The second uses the apply method of the companion object of a case class (or <code class="literal">Tuple</code> instance) to construct the object, provided the first stage completed successfully. Now that we have defined the type class, we can call <code class="literal">validate[Repo]</code> on a <code class="literal">JsValue</code> object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val repoOpt = parsedJson.validate[Repo]</strong></span>
<span class="strong"><strong>play.api.libs.json.JsResult[models.Repo] = JsSuccess(Repo(dotty,Scala,true,150),)</strong></span>
</pre></div><p>We can then use pattern matching to extract the <code class="literal">Repo</code> object from the <code class="literal">JsSuccess</code> instance:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val JsSuccess(repo, _) = repoOpt</strong></span>
<span class="strong"><strong>repo: models.Repo = Repo(dotty,Scala,true,150)</strong></span>
</pre></div><p>We have, so far, only talked about validating single repos. The Play framework defines type classes for collection types, so, provided <code class="literal">Reads[Repo]</code> is defined, <code class="literal">Reads[List[Repo]]</code> will also be defined.</p><p>Now that we understand how to extract Scala objects from JSON, let's get back to the code. If we manage to successfully convert the repositories to a <code class="literal">List[Repo]</code>, we emit it again as JSON. Of course, converting from GitHub's JSON representation of a repository to a Scala object, and from that Scala object directly to our JSON representation of the object, might seem convoluted. However, if this were a real application, we would have additional logic. We could, for <a id="id634" class="indexterm"></a>instance, store repos in a cache, and try and fetch from that cache instead of querying the GitHub API. Converting from JSON to Scala objects as early as possible decouples the code that we write from the way GitHub returns repositories.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec77"></a>Asynchronous actions</h3></div></div></div><p>The last bit of the <a id="id635" class="indexterm"></a>code sample that is new is the call to <code class="literal">Action.async</code>, rather than just <code class="literal">Action</code>. Recall that an <code class="literal">Action</code> instance is a thin wrapper around a <code class="literal">Request =&gt; Result</code> method. Our code, however, returns a <code class="literal">Future[Result]</code>, rather than a <code class="literal">Result</code>. When that is the case, use the <code class="literal">Action.async</code> to construct the action, rather than <code class="literal">Action</code> directly. Using <code class="literal">Action.async</code> tells the Play framework that the code creating the <code class="literal">Action</code> is asynchronous.</p></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec131"></a>Creating APIs with Play: a summary</h2></div></div><hr /></div><p>In the last section, we <a id="id636" class="indexterm"></a>deployed an API that responds to GET requests. Since this is a lot to take in, let's summarize how to go about API creation:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>Define appropriate routes in<code class="literal"> /conf/routes</code>, using wildcards in the URL as needed.</p></li><li><p>Create Scala case classes in<code class="literal"> /app/models</code> to represent the models used by the API.</p></li><li><p>Create <code class="literal">Write[T]</code> methods to write models to JSON or XML so that they can be returned by the API.</p></li><li><p>Bind the routes to controllers. If the controllers need to do more than a trivial amount a work, wrap the work in a future to avoid blocking the server.</p></li></ol></div><p>There are many more useful components of the Play framework that you are likely to need, such as, for instance, how to use Slick to access SQL databases. We do not, unfortunately, have time to cover these in this introduction. The Play framework has extensive, well-written documentation that will fill the gaping holes in this tutorial.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec132"></a>Rest APIs: best practice</h2></div></div><hr /></div><p>As the Internet matures, REST (representational state transfer) APIs are emerging as the most reliable design pattern <a id="id637" class="indexterm"></a>for web APIs. An API is described as <span class="emphasis"><em>RESTful</em></span> if it follows these guiding principles:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>The API is designed as a set of resources. For instance, the GitHub API provides information about users, repositories, followers, etc. Each user, or repository, is a specific resource. Each resource can be addressed through a different HTTP end-point.</p></li><li style="list-style-type: disc"><p>The URLs should be simple and should identify the resource clearly. For instance, <code class="literal">api.github.com/users/odersky</code> is simple and tells us clearly that we should expect information about the user Martin Odersky.</p></li><li style="list-style-type: disc"><p>There is no <span class="emphasis"><em>world resource</em></span> that contains all the information about the system. Instead, top-level resources contain links to more specialized resources. For instance, the user resource in the GitHub API contains links to that user's repositories and that user's followers, rather than having all that information embedded in the user resource directly.</p></li><li style="list-style-type: disc"><p>The API should be discoverable. The response to a request for a specific resource should contain URLs for related resources. When you query the user resource on GitHub, the response contains the URL for accessing that user's followers, repositories etc. The client should use the URLs provided by the API, rather than attempting to construct them client-side. This makes the client less brittle to changes in the API.</p></li><li style="list-style-type: disc"><p>There should be as little state maintained on the server as possible. For instance, when querying the GitHub API, we must pass the authentication token with every request, rather than expecting our authentication status to be <span class="emphasis"><em>remembered</em></span> on the server. Having each interaction be independent of the history provides much better scalability: if any interaction can be handled by any server, load balancing is much easier.</p></li></ul></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec133"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we introduced the Play framework as a tool for building web APIs. We built an API that returns a JSON array of a user's GitHub repositories. In the next chapter, we will build on this API and construct a single-page application to represent this data graphically.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec134"></a>References</h2></div></div><hr /></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>This Wikipedia <a id="id638" class="indexterm"></a>page gives information on semantic URLs: <a class="ulink" href="https://en.wikipedia.org/wiki/Semantic_URL" target="_blank">https://en.wikipedia.org/wiki/Semantic_URL</a> and <a class="ulink" href="http://apiux.com/2013/04/03/url-design-restful-web-services/" target="_blank">http://apiux.com/2013/04/03/url-design-restful-web-services/</a>.</p></li><li style="list-style-type: disc"><p>For a much more in depth discussion of the Play framework, I suggest <span class="emphasis"><em>Play Framework Essentials</em></span> by <span class="emphasis"><em>Julien Richard-Foy</em></span>.</p></li><li style="list-style-type: disc"><p>
<span class="emphasis"><em>REST in Practice: Hypermedia and Systems Architecture</em></span>, by <span class="emphasis"><em>Jim Webber</em></span>, <span class="emphasis"><em>Savas Parastatidis</em></span> and <span class="emphasis"><em>Ian Robinson</em></span> describes how to architect REST APIs.</p></li></ul></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch14"></a>ChapterÂ 14.Â Visualization with D3 and the Play Framework</h2></div></div></div><p>In the previous chapter, we learned about the Play framework, a web framework for Scala. We built an API that returns a JSON array describing a user's GitHub repositories.</p><p>In this chapter, we will construct a fully-fledged web application that displays a table and a chart describing a user's <a id="id639" class="indexterm"></a>repositories. We will learn to integrate <span class="strong"><strong>D3.js</strong></span>, a JavaScript library for building data-driven web pages, with the Play framework. This will set you on the path to building compelling interactive visualizations that showcase results obtained with machine learning.</p><p>This chapter assumes that you are familiar with HTML, CSS, and JavaScript. We present references at the end of the chapter. You should also have read the previous chapter.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec135"></a>GitHub user data</h2></div></div><hr /></div><p>We will build a <a id="id640" class="indexterm"></a>single-page application that uses, as its backend, the API developed in the previous chapter. The application contains a form where the user enters the login name for a GitHub account. The application queries the API to get a list of repositories for that user and displays them on the screen as both a table and a pie chart summarizing programming language use for that user:</p><div class="mediaobject"><img src="graphics/4795_14_01.jpg" /></div><p>To see a live <a id="id641" class="indexterm"></a>version of the application, head over to <a class="ulink" href="http://app.scala4datascience.com" target="_blank">http://app.scala4datascience.com</a>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec136"></a>Do I need a backend?</h2></div></div><hr /></div><p>In the previous <a id="id642" class="indexterm"></a>chapter, we learned about the client-server model that underpins how the internet works: when you enter a website URL in your browser, the server serves HTML, CSS, and JavaScript to your browser, which then renders it in the appropriate manner.</p><p>What does this all mean for you? Arguably the second question that you should be asking yourself when building a web application is whether you need to do any server-side processing (right after "is this really going to be worth the effort?"). Could you just create an HTML web-page with some JavaScript?</p><p>You can get away without a backend if the data needed to build the whole application is small enough: typically a few megabytes. If your application is larger, you will need a backend to transfer just the data the client currently needs. Surprisingly, you can often build visualizations without a backend: while data science is accustomed to dealing with terabytes of data, the goal of the data science process is often condensing these huge data sets to a few meaningful numbers.</p><p>Having a backend also lets you include logic invisible to the client. If you need to validate a password, you clearly cannot send the code to do that to the client computer: it needs to happen out of sight, on the server.</p><p>If your application is small enough and you do not need to do any server-side processing, stop reading this chapter, brush up on your JavaScript if you have to, and forget about Scala for now. Not having to worry about building a backend will make your life easier.</p><p>Clearly, however, we do not have that freedom for the application that we want to build: the user could enter the name of anyone on GitHub. Finding information about that user requires a backend with <a id="id643" class="indexterm"></a>access to tremendous storage and querying capacity (which we simulate by just forwarding the request to the GitHub API and re-interpreting the response).</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec137"></a>JavaScript dependencies through web-jars</h2></div></div><hr /></div><p>One of the <a id="id644" class="indexterm"></a>challenges of developing web applications is that we are writing two quasi-separate programs: the server-side program and the <a id="id645" class="indexterm"></a>client-side program. These generally require different technologies. In particular, for any but the most trivial application, we must keep track of JavaScript libraries, and integrate processing the JavaScript code (for instance, for minification) in the build process.</p><p>The Play framework manages JavaScript dependencies through <span class="emphasis"><em>web-jars</em></span>. These are just JavaScript libraries packaged as jars. They are deployed on Maven Central, which means that we can just add them as dependencies to our <code class="literal">build.sbt</code> file. For this application, we will need the following JavaScript libraries:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Require.js, a library for writing modular JavaScript</p></li><li style="list-style-type: disc"><p>JQuery</p></li><li style="list-style-type: disc"><p>Bootstrap</p></li><li style="list-style-type: disc"><p>Underscore.js, a library that adds many functional constructs and client-side templating.</p></li><li style="list-style-type: disc"><p>D3, the graph plotting library</p></li><li style="list-style-type: disc"><p>NVD3, a graph library built on top of D3</p></li></ul></div><p>If you are planning on coding up the examples provided in this chapter, the easiest will be for you to start from the <a id="id646" class="indexterm"></a>code for the previous chapter (You can download the code for <a class="link" href="#" linkend="ch13">Chapter 13</a>, <span class="emphasis"><em>Web APIs with Play</em></span>, from GitHub: <a class="ulink" href="https://github.com/pbugnion/s4ds/tree/master/chap13" target="_blank">https://github.com/pbugnion/s4ds/tree/master/chap13</a>). We will assume this as a starting point here onwards.</p><p>Let's include the dependencies on the web-jars in the <code class="literal">build.sbt</code> file:</p><div class="informalexample"><pre class="programlisting">libraryDependencies ++= Seq(
  "org.webjars" % "requirejs" % "2.1.22",
  "org.webjars" % "jquery" % "2.1.4",
  "org.webjars" % "underscorejs" % "1.8.3",
  "org.webjars" % "nvd3" % "1.8.1",
  "org.webjars" % "d3js" % "3.5.6",
  "org.webjars" % "bootstrap" % "3.3.6"
)</pre></div><p>Fetch the modules <a id="id647" class="indexterm"></a>by running <code class="literal">activator </code>
<a id="id648" class="indexterm"></a>
<code class="literal">update</code>. Once you have done this, you will notice the JavaScript libraries in <code class="literal">target/web/public/main/lib</code>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec138"></a>Towards a web application: HTML templates</h2></div></div><hr /></div><p>In the previous <a id="id649" class="indexterm"></a>chapter, we briefly saw how to construct HTML templates by <a id="id650" class="indexterm"></a>interleaving Scala snippets in an HTML file. We saw that templates are compiled to Scala functions, and we learned how to call these functions from the controllers.</p><p>In single-page applications, the majority of the logic governing what is actually displayed in the browser resides in the client-side JavaScript, not in the server. The pages served by the server contain the bare-bones HTML framework.</p><p>Let's create the HTML layout for our application. We will save this in <code class="literal">views/index.scala.html</code>. The template will just contain the layout for the application, but will not contain any information about any user's repositories. To fetch that information, the application will have to query the API developed in the previous chapter. The template does not take any parameters, since all the dynamic HTML generation will happen client-side.</p><p>We use the Bootstrap <a id="id651" class="indexterm"></a>grid layout to control the HTML layout. If you are not familiar with Bootstrap layouts, consult the documentation at <a class="ulink" href="http://getbootstrap.com/css/#grid-example-basic" target="_blank">http://getbootstrap.com/css/#grid-example-basic</a>.</p><div class="informalexample"><pre class="programlisting">// app/views/index.scala.html
&lt;!DOCTYPE html&gt;

&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;title&gt;Github User display&lt;/title&gt;
    &lt;link rel="stylesheet" media="screen" 
      href="@routes.Assets.versioned("stylesheets/main.css")"&gt;
    &lt;link rel="shortcut icon" type="image/png"
      href="@routes.Assets.versioned("images/favicon.png")"&gt;
    &lt;link rel="stylesheet" media="screen" 
      href=@routes.Assets.versioned("lib/nvd3/nv.d3.css") &gt;
    &lt;link rel="stylesheet" media="screen"
      href=@routes.Assets.versioned(
      "lib/bootstrap/css/bootstrap.css")&gt;
  &lt;/head&gt;

  &lt;body&gt;
    &lt;div class="container"&gt;

      &lt;!-- Title row --&gt;
      &lt;div class="row"&gt;
        &lt;h1&gt;Github user search&lt;/h1&gt;
      &lt;/div&gt;

      &lt;!-- User search row --&gt;
      &lt;div class="row"&gt;
        &lt;label&gt;Github user: &lt;/label&gt;
        &lt;input type="text" id="user-selection"&gt;
        &lt;span id="searching-span"&gt;&lt;/span&gt; &lt;hr /&gt;
      &lt;/div&gt;

      &lt;!-- Results row --&gt;
      &lt;div id="response" class="row"&gt;&lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div><p>In the HTML head, we link the CSS stylesheets that we need for the application. Instead of specifying the path explicitly, we use the <code class="literal">@routes.Assets.versioned(...)</code> function. This resolves <a id="id652" class="indexterm"></a>to a URI corresponding to the location where the assets are stored post-compilation. The argument passed to the function should be the path from <code class="literal">target/web/public/main</code> to the asset you need.</p><p>We want to serve the compiled version of this view when the user accesses the route <code class="literal">/</code> on our server. We therefore need to add this route to <code class="literal">conf/routes</code>:</p><div class="informalexample"><pre class="programlisting"># conf/routes
GET   /      controllers.Application.index</pre></div><p>The route is served by the <code class="literal">index</code> function in the <code class="literal">Application</code> controller. All this controller needs to do is serve the <code class="literal">index</code> view:</p><div class="informalexample"><pre class="programlisting">// app/controllers/Application.scala
package controllers

import play.api._
import play.api.mvc._

class Application extends Controller {

  def index = Action {
    Ok(views.html.index())
  }
}</pre></div><p>Start the Play framework by running <code class="literal">activator run</code> in the root directory of the application and point your web browser to <code class="literal">127.0.0.1:9000/</code>. You should see the framework for our web application. Of course, the application does not do anything yet, since we have not <a id="id653" class="indexterm"></a>written any of the JavaScript logic yet.</p><div class="mediaobject"><img src="graphics/4795_14_02.jpg" /></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec139"></a>Modular JavaScript through RequireJS</h2></div></div><hr /></div><p>The <a id="id654" class="indexterm"></a>simplest way of injecting JavaScript libraries into the <a id="id655" class="indexterm"></a>namespace is to add them to the HTML framework via <code class="literal">&lt;script&gt;...&lt;/script&gt;</code> tags in the HTML header. For instance, to add JQuery, we would add the following line to the head of the document:</p><div class="informalexample"><pre class="programlisting">&lt;script src=@routes.Assets.versioned("lib/jquery/jquery.js") type="text/javascript"&gt;&lt;/script&gt;</pre></div><p>While this works, it does not scale well to large applications, since every library gets imported into the global namespace. Modern client-side JavaScript frameworks such as AngularJS provide an alternative way of defining and loading modules that preserve encapsulation.</p><p>We will use RequireJS. In a nutshell, RequireJS lets us encapsulate JavaScript modules through functions. For instance, if we wanted to write a module <code class="literal">example</code> that contains a function for hiding a <code class="literal">div</code>, we would define the module as follows:</p><div class="informalexample"><pre class="programlisting">// example.js
define(["jquery", "underscore"], function($, _) {

  // hide a div
  function hide(div_name) {
    $(div_name).hide() ;
  }

  // what the module exports.
  return { "hide": hide }

}) ;</pre></div><p>We encapsulate our module as a callback in a function called <code class="literal">define</code>. The <code class="literal">define</code> function takes two arguments: a list of dependencies, and a function definition. The <code class="literal">define</code> function binds the dependencies to the arguments list of the callback: in this case, functions in JQuery will be bound to <code class="literal">$</code> and functions in Underscore will be bound to <code class="literal">_</code>. This creates a module which exposes whatever the callback function returns. In this case, we export the <code class="literal">hide</code> function, binding it to the name <code class="literal">"hide"</code>. Our example module thus exposes the <code class="literal">hide</code> function.</p><p>To load this <a id="id656" class="indexterm"></a>module, we pass it as a dependency <a id="id657" class="indexterm"></a>to the module in which we want to use it:</p><div class="informalexample"><pre class="programlisting">define(["example"], function(example) {

  function hide_all() {
<span class="strong"><strong>    example.hide</strong></span>("#top") ;
<span class="strong"><strong>    example.hide</strong></span>("#bottom") ;
  }

  return { "hide_all": hide_all } ;
});</pre></div><p>Notice how the functions in <code class="literal">example</code> are encapsulated, rather than existing in the global namespace. We call them through <code class="literal">example.&lt;function-name&gt;</code>. Furthermore, any functions or variables defined internally to the <code class="literal">example</code> module remain private.</p><p>Sometimes, we want JavaScript code to exist outside of modules. This is often the case for the script that bootstraps the application. For these, replace <code class="literal">define</code> with <code class="literal">require</code>:</p><div class="informalexample"><pre class="programlisting">require(["jquery", "example"], function($, example) {
  $(document).ready(function() {
    example.hide("#header") ;
  });
}) ;</pre></div><p>Now that we have an overview of RequireJS, how do we use it in the Play framework? The first step is to add the dependency on the RequireJS web jar, which we have done. The Play framework also adds a RequireJS SBT plugin (<a class="ulink" href="https://github.com/sbt/sbt-rjs" target="_blank">https://github.com/sbt/sbt-rjs</a>), which should be installed by default if you used the <code class="literal">play-scala</code> activator. If this is missing, it can be added with the following line in <code class="literal">plugins.sbt</code>:</p><div class="informalexample"><pre class="programlisting">// project/plugins.sbt

addSbtPlugin("com.typesafe.sbt" % "sbt-rjs" % "1.0.7")</pre></div><p>We also need to add the plugin to the list of stages. This allows the plugin to manipulate the JavaScript assets when packaging the application as a jar. Add the following line to <code class="literal">build.sbt</code>:</p><div class="informalexample"><pre class="programlisting">pipelineStages := Seq(rjs)</pre></div><p>You will <a id="id658" class="indexterm"></a>need to restart the activator for the changes to take effect.</p><p>We are now ready to <a id="id659" class="indexterm"></a>use RequireJS in our application. We can use it by adding the following line in the head section of our view:</p><div class="informalexample"><pre class="programlisting">// index.scala.html

&lt;html&gt;
  &lt;head&gt;
...

    &lt;script
      type="text/javascript"
      src=@routes.Assets.versioned("lib/requirejs/require.js").url
      data-main=@routes.Assets.versioned("javascripts/main.js").url&gt;
    &lt;/script&gt;

  &lt;/head&gt;
...
&lt;/html&gt;</pre></div><p>When the view is compiled, this is resolved to tags like:</p><div class="informalexample"><pre class="programlisting">&lt;script type="text/javascript" 
  data-main="/assets/javascripts/main.js" 
  src="/assets/lib/requirejs/require.min.js"&gt;
&lt;/script&gt;</pre></div><p>The argument passed to <code class="literal">data-main</code> is the entry point for our application. When RequireJS loads, it will execute <code class="literal">main.js</code>. That script must therefore bootstrap our application. In particular, it should contain a configuration object for RequireJS, to make it aware of <a id="id660" class="indexterm"></a>where all the libraries are.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec140"></a>Bootstrapping the applications</h2></div></div><hr /></div><p>When we linked <code class="literal">require.js</code> to our application, we told it to use <code class="literal">main.js</code> as our entry point. To <a id="id661" class="indexterm"></a>test that this works, let's start by entering a dummy <code class="literal">main.js</code>. JavaScript files in Play applications go in <code class="literal">/public/javascripts</code>:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/main.js

require([], function() {
  console.log("hello, JavaScript"); 
});</pre></div><p>To verify that this worked, head to <code class="literal">127.0.0.1:9000</code> and open the browser console. You should see <code class="literal">"hello, JavaScript"</code> in the console.</p><p>Let's now write a more useful <code class="literal">main.js</code>. We will start by configuring RequireJS, giving it the location of modules we will use in our application. Unfortunately, NVD3, the graph library that we <a id="id662" class="indexterm"></a>use, does not play very well with RequireJS so we have to use an ugly hack to make it work. This complicates our <code class="literal">main.js</code> file somewhat:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/main.js

(function (requirejs) {
  'use strict';

  // -- RequireJS config --
  requirejs.config({
    // path to the web jars. These definitions allow us 
    // to use "jquery", rather than "../lib/jquery/jquery",
    // when defining module dependencies.
    paths: {
      "jquery": "../lib/jquery/jquery",
      "underscore": "../lib/underscorejs/underscore",
      "d3": "../lib/d3js/d3",
      "nvd3": "../lib/nvd3/nv.d3",
      "bootstrap": "../lib/bootstrap/js/bootstrap"
    },

    shim: {
      // hack to get nvd3 to work with requirejs.
      // see this so question:
      // http://stackoverflow.com/questions/13157704/how-to-integrate-d3-with-require-js#comment32647365_13171592        
      nvd3: {
        deps: ["d3.global"],
        exports: "nv"
      },
      bootstrap : { deps :['jquery'] }
    }

  }) ;
})(requirejs) ;

// hack to get nvd3 to work with requirejs.
// see this so question on Stack Overflow:
// http://stackoverflow.com/questions/13157704/how-to-integrate-d3-with-require-js#comment32647365_13171592
define("d3.global", ["d3"], function(d3global) {
  d3 = d3global;
});

require([], function() {
  // Our application
  console.log("hello, JavaScript");
}) ;</pre></div><p>Now that we have <a id="id663" class="indexterm"></a>the configuration in place, we can dig into the JavaScript part of the application.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec141"></a>Client-side program architecture</h2></div></div><hr /></div><p>The basic idea is simple: the user searches for the name of someone on GitHub in the input box. When <a id="id664" class="indexterm"></a>he enters a name, we fire a request to the API designed earlier in this chapter. When the response from the API returns, the program binds that response to a model and emits an event notifying that the model has been changed. The views listen for this event and refresh from the model in response.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch14lvl2sec78"></a>Designing the model</h3></div></div></div><p>Let's start by <a id="id665" class="indexterm"></a>defining the client-side model. The model holds information regarding the repos of the user currently displayed. It gets filled in after the first search.</p><div class="informalexample"><pre class="programlisting">// public/javascripts/model.js

define([], function(){
   return {
    ghubUser: "", // last name that was searched for
    exists: true, // does that person exist on github?
    repos: [] // list of repos
  } ;
});</pre></div><p>To see a populated value of the model, head to the complete application example on <code class="literal">app.scala4datascience.com</code>, open a JavaScript console in your browser, search for a user (for example, <code class="literal">odersky</code>) in the application and type the following in the console:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; require(["model"], function(model) { console.log(model) ; }) </strong></span>
<span class="strong"><strong>{ghubUser: "odersky", exists: true, repos: Array}</strong></span>

<span class="strong"><strong>&gt; require(["model"], function(model) { </strong></span>
<span class="strong"><strong>  console.log(model.repos[0]); </strong></span>
<span class="strong"><strong>})</strong></span>
<span class="strong"><strong>{name: "dotty", language: "Scala", is_fork: true, size: 14653}</strong></span>
</pre></div><p>These import <a id="id666" class="indexterm"></a>the <code class="literal">"model"</code> module, bind it to the variable <code class="literal">model</code>, and then print information to the console.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch14lvl2sec79"></a>The event bus</h3></div></div></div><p>We need a <a id="id667" class="indexterm"></a>mechanism for informing the views when the model is updated, since the views need to refresh from the new model. This is commonly handled through <span class="emphasis"><em>events</em></span> in web applications. JQuery lets us bind callbacks to specific events. The <a id="id668" class="indexterm"></a>callback is executed when that event occurs.</p><p>For instance, to bind a callback to the event <code class="literal">"custom-event"</code>, enter the following in a JavaScript console:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; $(window).on("custom-event", function() { </strong></span>
<span class="strong"><strong>  console.log("custom event received") ; </strong></span>
<span class="strong"><strong>});</strong></span>
</pre></div><p>We can fire the event using:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; $(window).trigger("custom-event"); </strong></span>
<span class="strong"><strong>custom event received</strong></span>
</pre></div><p>Events in JQuery require an <span class="emphasis"><em>event </em></span>bus, a DOM element on which the event is registered. In this case, we used the <code class="literal">window</code> DOM element as our event bus, but any JQuery element would have served. Centralizing event definitions to a single module is helpful. We will, therefore, create an <code class="literal">events</code> module containing two functions: <code class="literal">trigger</code>, which triggers an event (specified by a string) and <code class="literal">on</code>, which binds a callback to a specific event:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/events.js

define(["jquery"], function($) {

  var bus = $(window) ; // widget to use as an event bus

  function trigger(eventType) {
    $(bus).trigger(eventType) ;
  }

  function on(eventType, f) {
    $(bus).on(eventType, f) ;
  }

  return {
    "trigger": trigger,
    "on": on
  } ;
});</pre></div><p>We can now emit and receive events using the <code class="literal">events</code> module. You can test this out in a JavaScript console on <a id="id669" class="indexterm"></a>the live version of the application (at <code class="literal">app.scala4datascience.com</code>). Let's start by registering a listener:</p><div class="informalexample"><pre class="programlisting">&gt; require(["events"], function(events) {
  // register event listener
  events.on("hello_event", function() {
    console.log("Received event") ;
  }) ;
}); </pre></div><p>If we now trigger the event <code class="literal">"hello_event"</code>, the listener prints <code class="literal">"Received event"</code>:</p><div class="informalexample"><pre class="programlisting">&gt; require(["events"], function(events) {
  // trigger the event
  events.trigger("hello_event") ;
}) ;</pre></div><p>Using events allows us to <a id="id670" class="indexterm"></a>decouple the controller from the views. The controller does not need to know anything about the views, and vice-versa. The controller just needs to emit a <code class="literal">"model_updated"</code> event when the model is updated, and the views need to refresh from the model when they receive that event.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch14lvl2sec80"></a>AJAX calls through JQuery</h3></div></div></div><p>We can <a id="id671" class="indexterm"></a>now write the controller for our application. When the user enters a name in the text input, we query the API, update the model and trigger a <code class="literal">model_updated</code> event.</p><p>We use JQuery's <code class="literal">$.getJSON</code> function to query our API. This function takes a URL as its first argument, and a callback as its second argument. The API call is asynchronous: <code class="literal">$.getJSON</code> returns immediately after execution. All request processing must, therefore, be done in the callback. The callback is called if the request is successful, but we can define additional <a id="id672" class="indexterm"></a>handlers that are always called, or called on failure. Let's try this out in the browser console (either your own, if you are running the API developed in the previous chapter, or on <code class="literal">app.scala4datascience.com</code>). Recall that the API is listening to the end-point <code class="literal">/api/repos/:user</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; $.getJSON("/api/repos/odersky", function(data) { </strong></span>
<span class="strong"><strong>  console.log("API response:");</strong></span>
<span class="strong"><strong>  console.log(data);</strong></span>
<span class="strong"><strong>  console.log(data[0]); </strong></span>
<span class="strong"><strong>}) ;</strong></span>
<span class="strong"><strong>{readyState: 1, getResponseHeader: function, ...}</strong></span>

<span class="strong"><strong>API response:</strong></span>
<span class="strong"><strong>[Object, Object, Object, Object, Object, ...]</strong></span>
<span class="strong"><strong>{name: "dotty", language: "Scala", is_fork: true, size: 14653}</strong></span>
</pre></div><p>
<code class="literal">getJSON</code> returns immediately. A few tenths of a second later, the API responds, at which point the response gets fed through the callback.</p><p>The callback only gets executed on success. It takes, as its argument, the JSON object returned by the API. To bind a callback that is executed when the API request fails, call the <code class="literal">.fail</code> method on the return value of <code class="literal">getJSON</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; $.getJSON("/api/repos/junk123456", function(data) { </strong></span>
<span class="strong"><strong>  console.log("called on success"); </strong></span>
<span class="strong"><strong>}).fail(function() { </strong></span>
<span class="strong"><strong>  console.log("called on failure") ; </strong></span>
<span class="strong"><strong>}) ;</strong></span>
<span class="strong"><strong>{readyState: 1, getResponseHeader: function, ...}</strong></span>

<span class="strong"><strong>called on failure</strong></span>
</pre></div><p>We can also use the <code class="literal">.always</code> method on the return value of <code class="literal">getJSON</code> to specify a callback that is executed, whether the API query was successful or not.</p><p>Now that we know how to use <code class="literal">$.getJSON</code> to query our API, we can write the controller. The controller listens for changes to the <code class="literal">#user-selection</code> input field. When a change occurs, it fires an AJAX request to the API for information on that user. It binds a callback which updates the model when the API replies with a list of repositories. We will define a <a id="id673" class="indexterm"></a>
<code class="literal">controller</code> module that exports a single function, <code class="literal">initialize</code>, that creates the event listeners:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/controller.js
define(["jquery", "events", "model"], function($, events, model) {

  function initialize() {
    $("#user-selection").change(function() {

      var user = $("#user-selection").val() ;
      console.log("Fetching information for " + user) ;

      // Change cursor to a 'wait' symbol 
      // while we wait for the API to respond
      $("*").css({"cursor": "wait"}) ; 

      $.getJSON("/api/repos/" + user, function(data) {
        // Executed on success
        model.exists = true ;
        model.repos = data ;
      }).fail(function() {
        // Executed on failure
        model.exists = false ;
        model.repos = [] ;
      }).always(function() {
        // Always executed
        model.ghubUser = user ;

        // Restore cursor
        $("*").css({"cursor": "initial"}) ;

        // Tell the rest of the application 
        // that the model has been updated.
        events.trigger("model_updated") ;
      });
    }) ;
  } ;

  return { "initialize": initialize };

});</pre></div><p>Our controller module just exposes the <code class="literal">initialize </code>method. Once the initialization is performed, the controller interacts with the rest of the application through event listeners. We will call the controller's <code class="literal">initialize</code> method in <code class="literal">main.js</code>. Currently, the last lines of that file are just an empty <code class="literal">require</code> block. Let's import our controller and initialize it:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/main.js

require(["controller"], function(controller) {
  controller.initialize();
});</pre></div><p>To test that this works, we can bind a dummy listener to the <code class="literal">"model_updated"</code> event. For instance, we <a id="id674" class="indexterm"></a>could log the current model to the browser JavaScript console with the following snippet (which you can write directly in the JavaScript console):</p><div class="informalexample"><pre class="programlisting">&gt; require(["events", "model"], 
function(events, model) {
  events.on("model_updated", function () { 
    console.log("model_updated event received"); 
    console.log(model); 
  });
}); </pre></div><p>If you then search for a user, the model will be printed to the console. We now have the controller in place. The last step is writing the views.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch14lvl2sec81"></a>Response views</h3></div></div></div><p>If the request fails, we <a id="id675" class="indexterm"></a>just display <span class="strong"><strong>Not found</strong></span> in the response div. This part is the easiest to code up, so let's do that first. We define an <code class="literal">initialize</code> <a id="id676" class="indexterm"></a>method that generates the view. The view then listens for the <code class="literal">"model_updated"</code> event, which is fired by the controller after it updates the model. Once the initialization is complete, the only way to interact with the response view is through <code class="literal">"model_updated"</code> events:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/responseView.js

define(["jquery", "model", "events"],
function($, model, events) {

  var failedResponseHtml = 
    "&lt;div class='col-md-12'&gt;Not found&lt;/div&gt;" ;

  function initialize() {
    events.on("model_updated", function() {
      if (model.exists) {
        // success â€“ we will fill this in later.
        console.log("model exists")
      }
      else {
        // failure â€“ the user entered
        // is not a valid GitHub login 
        $("#response").html(failedResponseHtml) ;
      }
    }) ;
  }

  return { "initialize": initialize } ;

});</pre></div><p>To bootstrap the <a id="id677" class="indexterm"></a>view, we must call the initialize function from <a id="id678" class="indexterm"></a>
<code class="literal">main.js</code>. Just add a dependency on <code class="literal">responseView</code> in the require block, and call <code class="literal">responseView.initialize()</code>. With these modifications, the final <code class="literal">require</code> block in <code class="literal">main.js</code> is:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/main.js

require(["controller", "responseView"],
function(controller, responseView) {
  controller.initialize();
  responseView.initialize() ;
}) ;</pre></div><p>You can check that this all works by entering junk in the user input to deliberately cause the API request to fail.</p><p>When the user enters a valid GitHub login name and the API returns a list of repos, we must display those on the screen. We display a table and a pie chart that aggregates the repository sizes by language. We will define the pie chart and the table in two separate modules, called <code class="literal">repoGraph.js</code> and <code class="literal">repoTable.js</code>. Let's assume those exist for now and that they expose a <code class="literal">build</code> method that accepts a <code class="literal">model</code> and the name of a <code class="literal">div</code> in which to appear.</p><p>Let's update the code for <code class="literal">responseView</code> to accommodate the user entering a valid GitHub user name:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/responseView.js

define(["jquery", "model", "events", <span class="strong"><strong>"repoTable", "repoGraph"</strong></span>],
function($, model, events, <span class="strong"><strong>repoTable, repoGraph</strong></span>) {

  // HTHML to inject when the model represents a valid user 
<span class="strong"><strong>  var successfulResponseHtml = </strong></span>
<span class="strong"><strong>    "&lt;div class='col-md-6' id='response-table'&gt;&lt;/div&gt;" +</strong></span>
<span class="strong"><strong>    "&lt;div class='col-md-6' id='response-graph'&gt;&lt;/div&gt;" ;</strong></span>

  // HTML to inject when the model is for a non-existent user
  var failedResponseHtml = 
    "&lt;div class='col-md-12'&gt;Not found&lt;/div&gt;" ;

  function initialize() {
    events.on("model_updated", function() {
      if (model.exists) {
<span class="strong"><strong>        $("#response").html(successfulResponseHtml) ;</strong></span>
<span class="strong"><strong>        repoTable.build(model, "#response-table") ;</strong></span>
<span class="strong"><strong>        repoGraph.build(model, "#response-graph") ;</strong></span>
      }
      else {
        $("#response").html(failedResponseHtml) ;
      }
    }) ;
  }

  return { "initialize": initialize } ;

});</pre></div><p>Let's walk through what happens in the event of a successful API call. We inject the following bit of <a id="id679" class="indexterm"></a>HTML in the <code class="literal">#response</code> div:</p><div class="informalexample"><pre class="programlisting">var successfulResponseHtml = 
  "&lt;div class='col-md-6' id='response-table'&gt;&lt;/div&gt;" +
  "&lt;div class='col-md-6' id='response-graph'&gt;&lt;/div&gt;" ;</pre></div><p>This adds two HTML divs, one for the table of repositories, and the other for the graph. We use Bootstrap classes to split the response div vertically.</p><p>Let's now turn our attention <a id="id680" class="indexterm"></a>to the table view, which needs to expose a single <code class="literal">build</code> method, as described in the previous section. We will just display the repositories in an HTML table. We will use <span class="emphasis"><em>Underscore templates</em></span> to build the table dynamically. Underscore templates work much like string interpolation in Scala: we define a template with placeholders. Let's try this in a browser console:</p><div class="informalexample"><pre class="programlisting">&gt; require(["underscore"], function(_) {
  var myTemplate = <span class="strong"><strong>_.template</strong></span>(
    "Hello, &lt;%= title %&gt; &lt;%= name %&gt;!"
  ) ;
});</pre></div><p>This creates a <a id="id681" class="indexterm"></a>
<code class="literal">myTemplate</code> function which accepts an object with attributes <code class="literal">title</code> and <code class="literal">name</code>:</p><div class="informalexample"><pre class="programlisting">&gt; require(["underscore"], function(_) {
  var myTemplate = _.template( ... ); 
  var person = { title: "Dr.", name: "Odersky" } ;
  console.log(<span class="strong"><strong>myTemplate(person)</strong></span>) ;
});</pre></div><p>Underscore templates <a id="id682" class="indexterm"></a>thus provide a convenient mechanism for formatting an object as a string. We will create a template for each row in our table, and pass the model for each repository to the template:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/repoTable.js

define(["underscore", "jquery"], function(_, $) {

  // Underscore template for each row
  var rowTemplate = _.template("&lt;tr&gt;" +
    "&lt;td&gt;&lt;%= name %&gt;&lt;/td&gt;" +
    "&lt;td&gt;&lt;%= language %&gt;&lt;/td&gt;" +
    "&lt;td&gt;&lt;%= size %&gt;&lt;/td&gt;" +
    "&lt;/tr&gt;") ;

  // template for the table
  var repoTable = _.template(
    "&lt;table id='repo-table' class='table'&gt;" +
      "&lt;thead&gt;" +
        "&lt;tr&gt;" +
          "&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Language&lt;/th&gt;&lt;th&gt;Size&lt;/th&gt;" +
        "&lt;/tr&gt;" +
      "&lt;/thead&gt;" +
      "&lt;tbody&gt;" +
        "&lt;%= tbody %&gt;" +
      "&lt;/tbody&gt;" +
    "&lt;/table&gt;") ;

  // Builds a table for a model
  function build(model, divName) {
    var tbody = "" ;
    _.each(model.repos, function(repo) {
      tbody += rowTemplate(repo) ;
    }) ;
    var table = repoTable({tbody: tbody}) ;
    $(divName).html(table) ;
  }

  return { "build": build } ;
}) ;</pre></div></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec142"></a>Drawing plots with NVD3</h2></div></div><hr /></div><p>D3 is a <a id="id683" class="indexterm"></a>library that offers low-level components for building interactive visualizations in JavaScript. By offering the low-level components, it gives a huge degree of <a id="id684" class="indexterm"></a>flexibility to the developer. The learning curve can, however, be quite steep. In this example, we will use NVD3, a library which provides pre-made graphs for D3. This can greatly speed up initial development. We will place the code in the file <code class="literal">repoGraph.js</code> and expose a single method, <code class="literal">build</code>, which takes, as arguments, a model and a div and draws a pie chart in that div. The pie chart will aggregate language use across all the user's repositories.</p><p>The code for generating a pie chart is nearly identical to the example given in the NVD3 documentation, available at <a class="ulink" href="http://nvd3.org/examples/pie.html" target="_blank">http://nvd3.org/examples/pie.html</a>. The data passed to the graph must be available as <a id="id685" class="indexterm"></a>an array of objects. Each object must contain a <code class="literal">label</code> field and a <code class="literal">size</code> field. The <code class="literal">label</code> field identifies the language, and the <code class="literal">size</code> field is the total size of all the repositories for that user written in that language. The following would be a valid data array:</p><div class="informalexample"><pre class="programlisting">[ 
  { label: "Scala", size: 1234 },
  { label: "Python", size: 4567 }
]</pre></div><p>To get the data in this format, we must aggregate sizes across the repositories written in a particular language in our model. We write the <code class="literal">generateDataFromModel</code> function to transform the <code class="literal">repos</code> array in the model to an array suitable for NVD3. The crux of the aggregation is performed by a call to Underscore's <code class="literal">groupBy</code> method, to group repositories by language. This method works exactly like Scala's <code class="literal">groupBy</code> method. With this in mind, the <code class="literal">generateDataFromModel</code> function is:</p><div class="informalexample"><pre class="programlisting">// public/javascripts/repoGraph.js

define(["underscore", "d3", "nvd3"], 
function(_, d3, nv) {

  // Aggregate the repo size by language.
  // Returns an array of objects like:
  // [ { label: "Scala", size: 1245}, 
  //   { label: "Python", size: 432 } ]
  function generateDataFromModel(model) {

    // Build an initial object mapping each
    // language to the repositories written in it
    var language2Repos = _.groupBy(model.repos, 
      function(repo) { return repo.language ; }) ;

    // Map each { "language":  [ list of repos ], ...} 
    // pairs to a single document { "language": totalSize }
    // where totalSize is the sum of the individual repos.
    var plotObjects = _.map(language2Repos, 
      function(repos, language) {
        var sizes = _.map(repos, function(repo) { 
          return repo.size; 
        });
        // Sum over the sizes using 'reduce'
        var totalSize = _.reduce(sizes, 
          function(memo, size) { return memo + size; },
        0) ;
        return { label: language, size: totalSize } ;
      }) ;

     return plotObjects;
  }</pre></div><p>We can now <a id="id686" class="indexterm"></a>build the pie chart, using NVD3's <code class="literal">addGraph</code> <a id="id687" class="indexterm"></a>method:</p><div class="informalexample"><pre class="programlisting">  // Build the chart.
  function build(model, divName) {
    var transformedModel = generateDataFromModel(model) ;
    nv.addGraph(function() {

      var height = 350;
      var width = 350; 

      var chart = nv.models.pieChart()
        .x(function (d) { return d.label ; })
        .y(function (d) { return d.size ;})
        .width(width)
        .height(height) ;

      d3.select(divName).append("svg")
        .datum(transformedModel)
        .transition()
        .duration(350)
        .attr('width', width)
        .attr('height', height)
        .call(chart) ;

      return chart ;
    });
  }

  return { "build" : build } ;

});</pre></div><p>This was the <a id="id688" class="indexterm"></a>last component of our application. Point your browser to <code class="literal">127.0.0.1:9000</code> and you should see the application running.</p><p>Congratulations! We <a id="id689" class="indexterm"></a>have built a fully-functioning single-page web application.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec143"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we learned how to write a fully-featured web application with the Play framework. Congratulations on making it this far. Building web applications are likely to push many data scientists beyond their comfort zone, but knowing enough about the web to build basic applications will allow you to share your results in a compelling, engaging manner, as well as facilitate communications with software engineers and web developers.</p><p>This concludes our whistle stop tour of Scala libraries. Over the course of this book, we have learned how to tackle linear algebra and optimization problems efficiently using Breeze, how to insert and query data in SQL databases in a functional manner, and both how to interact with web APIs and how to create them. We have reviewed some of tools available to the data scientist for writing concurrent or parallel applications, from parallel collections and futures to Spark via Akka. We have seen how pervasive these constructs are in Scala libraries, from futures in the Play framework to Akka as the backbone of Spark. If you have read this far, pat yourself on the back.</p><p>This books gives you the briefest of introduction to the libraries it covers, hopefully just enough to give you a taste of what each tool is good for, what you could accomplish with it, and how it fits in the wider Scala ecosystem. If you decide to use any of these in your data science pipeline, you will need to read the documentation in more detail, or a more complete reference book. The references listed at the end of each chapter should provide a good starting point.</p><p>Both Scala and data science are evolving rapidly. Do not stay wedded to a particular toolkit or concept. Remain on top of current developments and, above all, remain pragmatic: find the right tool for the right job. Scala and the libraries discussed here will often be that tool, but not always: sometimes, a shell command or a short Python script will be more effective. Remember also that programming skills are but one aspect of the data scientist's body of knowledge. Even if you want to specialize in the engineering side of data science, learn about the problem domain and the mathematical underpinnings of machine learning.</p><p>Most importantly, if you have taken the time to read this book, it is likely that you view programming and data science as more than a day job. Coding in Scala can be satisfying and rewarding, so have fun and be awesome!</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec144"></a>References</h2></div></div><hr /></div><p>There are thousands of HTML and CSS tutorials dotted around the web. A simple Google search will give you a much better idea of the resources available than any list of references I can provide.</p><p>Mike Bostock's website has a wealth of beautiful D3 visualizations: <a class="ulink" href="http://bost.ocks.org/mike/." target="_blank">http://bost.ocks.org/mike/.</a> To understand a bit more about D3, I recommend <span class="emphasis"><em>Scott Murray's Interactive Data Visualization for the Web</em></span>.</p><p>You may also wish to consult the references given in the previous chapter for reference books on the Play framework and designing REST APIs.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="appendix" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="appA"></a>AppendixÂ A.Â Pattern Matching and Extractors</h2></div></div></div><p>Pattern matching is a powerful tool for control flow in Scala. It is often underused and under-estimated by people coming to Scala from imperative languages.</p><p>Let's start with a few examples of pattern matching before diving into the theory. We start by defining a tuple:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val names = ("Pascal", "Bugnion")</strong></span>
<span class="strong"><strong>names: (String, String) = (Pascal,Bugnion)</strong></span>
</pre></div><p>We can use pattern matching to extract the elements of this tuple and bind them to variables:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val (firstName, lastName) = names</strong></span>
<span class="strong"><strong>firstName: String = Pascal</strong></span>
<span class="strong"><strong>lastName: String = Bugnion</strong></span>
</pre></div><p>We just extracted the two elements of the <code class="literal">names</code> tuple, binding them to the variables <code class="literal">firstName</code> and <code class="literal">lastName</code>. Notice how the left-hand side defines a pattern that the right-hand side must match: we are declaring that the variable <code class="literal">names</code> must be a two-element tuple. To make the pattern more specific, we could also have specified the expected types of the elements in the tuple:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val (firstName:String, lastName:String) = names</strong></span>
<span class="strong"><strong>firstName: String = Pascal</strong></span>
<span class="strong"><strong>lastName: String = Bugnion</strong></span>
</pre></div><p>What happens if the pattern on the left-hand side does not match the right-hand side?</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val (firstName, middleName, lastName) = names</strong></span>
<span class="strong"><strong>&lt;console&gt;:13: error: constructor cannot be instantiated to expected type;</strong></span>
<span class="strong"><strong>found   : (T1, T2, T3)</strong></span>
<span class="strong"><strong>required: (String, String)</strong></span>
<span class="strong"><strong>   val (firstName, middleName, lastName) = names</strong></span>
</pre></div><p>This results in a compile error. Other types of pattern matching failures result in runtime errors.</p><p>Pattern matching is very expressive. To achieve the same behavior without pattern matching, you would have to do the following explicitly:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>Verify that the variable <code class="literal">names</code> is a two-element tuple</p></li><li style="list-style-type: disc"><p>Extract the first element and bind it to <code class="literal">firstName</code>
</p></li><li style="list-style-type: disc"><p>Extract the second element and bind it to <code class="literal">lastName</code>
</p></li></ul></div><p>If we expect certain elements in the tuple to have specific values, we can verify this as part of the pattern match. For instance, we can verify that the first element of the <code class="literal">names</code> tuple matches <code class="literal">"Pascal"</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val ("Pascal", lastName) = names</strong></span>
<span class="strong"><strong>lastName: String = Bugnion</strong></span>
</pre></div><p>Besides tuples, we can also match on Scala collections:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val point = Array(1, 2, 3)</strong></span>
<span class="strong"><strong>point: Array[Int] = Array(1, 2, 3)</strong></span>

<span class="strong"><strong>scala&gt; val Array(x, y, z) = point</strong></span>
<span class="strong"><strong>x: Int = 1</strong></span>
<span class="strong"><strong>y: Int = 2</strong></span>
<span class="strong"><strong>z: Int = 3</strong></span>
</pre></div><p>Notice the similarity between this pattern matching and array construction:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val point = Array(x, y, z)</strong></span>
<span class="strong"><strong>point: Array[Int] = Array(1, 2, 3)</strong></span>
</pre></div><p>Syntactically, Scala expresses pattern matching as the reverse process to instance construction. We can think of pattern matching as the deconstruction of an object, binding the object's constituent parts to variables.</p><p>When matching against collections, one is sometimes only interested in matching the first element, or the first few elements, and discarding the rest of the collection, whatever its length. The operator <code class="literal">_*</code> will match against any number of elements:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val Array(x, _*) = point</strong></span>
<span class="strong"><strong>x: Int = 1</strong></span>
</pre></div><p>By default, the part of the pattern matched by the <code class="literal">_*</code> operator is not bound to a variable. We can capture it as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val Array(x, xs @ _*) = point</strong></span>
<span class="strong"><strong>x: Int = 1</strong></span>
<span class="strong"><strong>xs: Seq[Int] = Vector(2, 3)</strong></span>
</pre></div><p>Besides tuples and collections, we can also match against case classes. Let's start by defining a case representing a name:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class Name(first: String, last: String)</strong></span>
<span class="strong"><strong>defined class Name</strong></span>

<span class="strong"><strong>scala&gt; val name = Name("Martin", "Odersky")</strong></span>
<span class="strong"><strong>name: Name = Name(Martin,Odersky)</strong></span>
</pre></div><p>We can match against instances of <code class="literal">Name</code> in much the same way we matched against tuples:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val Name(firstName, lastName) = name</strong></span>
<span class="strong"><strong>firstName: String = Martin</strong></span>
<span class="strong"><strong>lastName: String = Odersky</strong></span>
</pre></div><p>All these patterns can also be used in <code class="literal">match</code> statements:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; def greet(name:Name) = name match {</strong></span>
<span class="strong"><strong>  case Name("Martin", "Odersky") =&gt; "An honor to meet you"</strong></span>
<span class="strong"><strong>  case Name(first, "Bugnion") =&gt; "Wow! A family member!"</strong></span>
<span class="strong"><strong>  case Name(first, last) =&gt; s"Hello, $first"</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>greet: (name: Name)String</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec145"></a>Pattern matching in for comprehensions</h2></div></div><hr /></div><p>Pattern matching <a id="id690" class="indexterm"></a>is useful in <span class="emphasis"><em>for</em></span> comprehensions for extracting items from a collection that match a specific pattern. Let's build a collection of <code class="literal">Name</code> instances:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val names = List(Name("Martin", "Odersky"), </strong></span>
<span class="strong"><strong>  Name("Derek", "Wyatt"))</strong></span>
<span class="strong"><strong>names: List[Name] = List(Name(Martin,Odersky), Name(Derek,Wyatt))</strong></span>
</pre></div><p>We can use pattern matching to extract the internals of the class in a for-comprehension:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; for { Name(first, last) &lt;- names } yield first</strong></span>
<span class="strong"><strong>List[String] = List(Martin, Derek)</strong></span>
</pre></div><p>So far, nothing terribly ground-breaking. But what if we wanted to extract the surname of everyone whose first name is <code class="literal">"Martin"</code>?</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; for { Name("Martin", last) &lt;- names } yield last</strong></span>
<span class="strong"><strong>List[String] = List(Odersky)</strong></span>
</pre></div><p>Writing <code class="literal">Name("Martin", last) &lt;- names</code> extracts the elements of names that match the pattern. You might <a id="id691" class="indexterm"></a>think that this is a contrived example, and it is, but the examples in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>Web APIs</em></span> demonstrate the usefulness and versatility of this language pattern, for instance, for extracting specific fields from JSON objects.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec146"></a>Pattern matching internals</h2></div></div><hr /></div><p>If you define a case <a id="id692" class="indexterm"></a>class, as we saw with <code class="literal">Name</code>, you get pattern matching against the constructor <span class="emphasis"><em>for free</em></span>. You should be using case classes to represent your data as much as possible, thus reducing the need to implement your own pattern matching. It is nevertheless useful to understand how pattern matching works.</p><p>When you create a case class, Scala automatically builds a companion object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; case class Name(first: String, last: String)</strong></span>
<span class="strong"><strong>defined class Name</strong></span>

<span class="strong"><strong>scala&gt; Name.&lt;tab&gt;</strong></span>
<span class="strong"><strong>apply   asInstanceOf   curried   isInstanceOf   toString   tupled   unapply</strong></span>
</pre></div><p>The method used (internally) for pattern matching is <code class="literal">unapply</code>. This method takes, as argument, an object and returns <code class="literal">Option[T],</code> where <code class="literal">T</code> is a tuple of the values of the case class.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val name = Name("Martin", "Odersky")</strong></span>
<span class="strong"><strong>name: Name = Name(Martin,Odersky)</strong></span>

<span class="strong"><strong>scala&gt; Name.unapply(name)</strong></span>
<span class="strong"><strong>Option[(String, String)] = Some((Martin,Odersky))</strong></span>
</pre></div><p>The <code class="literal">unapply</code> method is an <span class="emphasis"><em>extractor</em></span>. It plays the opposite role of the constructor: it takes an object and extracts the list of parameters needed to construct that object. When you write <code class="literal">val Name(firstName, lastName)</code>, or when you use <code class="literal">Name</code> as a case in a match statement, Scala calls <code class="literal">Name.unapply</code> on what you are matching against. A value of <code class="literal">Some[(String, String)]</code> implies a pattern match, while a value of <code class="literal">None</code> implies that the pattern fails.</p><p>To write custom extractors, you just need an object with an <code class="literal">unapply</code> method. While <code class="literal">unapply</code> normally resides in the companion object of a class that you are deconstructing, this need not be the case. In fact, it does not need to correspond to an existing class at all. For instance, let's define a <code class="literal">NonZeroDouble</code> extractor that matches any non-zero double:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; object NonZeroDouble { </strong></span>
<span class="strong"><strong>  def unapply(d:Double):Option[Double] = {</strong></span>
<span class="strong"><strong>    if (d == 0.0) { None } else { Some(d) }  </strong></span>
<span class="strong"><strong>  }</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>defined object NonZeroDouble</strong></span>

<span class="strong"><strong>scala&gt; val NonZeroDouble(denominator) = 5.5</strong></span>
<span class="strong"><strong>denominator: Double = 5.5</strong></span>

<span class="strong"><strong>scala&gt; val NonZeroDouble(denominator) = 0.0</strong></span>
<span class="strong"><strong>scala.MatchError: 0.0 (of class java.lang.Double)</strong></span>
<span class="strong"><strong>  ... 43 elided</strong></span>
</pre></div><p>We defined an extractor for <code class="literal">NonZeroDouble</code>, despite the absence of a corresponding <code class="literal">NonZeroDouble</code> class.</p><p>This <code class="literal">NonZeroDouble </code>
<a id="id693" class="indexterm"></a>extractor would be useful in a match object. For instance, let's define a <code class="literal">safeDivision</code> function that returns a default value when the denominator is zero:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; def safeDivision(numerator:Double, </strong></span>
<span class="strong"><strong>  denominator:Double, fallBack:Double) =</strong></span>
<span class="strong"><strong>    denominator match {</strong></span>
<span class="strong"><strong>      case NonZeroDouble(d) =&gt; numerator / d</strong></span>
<span class="strong"><strong>      case _ =&gt; fallBack</strong></span>
<span class="strong"><strong>    }</strong></span>
<span class="strong"><strong>safeDivision: (numerator: Double, denominator: Double, fallBack: Double)Double</strong></span>

<span class="strong"><strong>scala&gt; safeDivision(5.0, 2.0, 100.0)</strong></span>
<span class="strong"><strong>Double = 2.5</strong></span>

<span class="strong"><strong>scala&gt; safeDivision(5.0, 0.0, 100.0)</strong></span>
<span class="strong"><strong>Double = 100.0</strong></span>
</pre></div><p>This is a trivial example because the <code class="literal">NonZeroDouble.unapply</code> method is so simple, but you can hopefully see the usefulness and expressiveness, if we were to define a more complex test. Defining custom extractors lets you define powerful control flow constructs to leverage <code class="literal">match</code> statements. More importantly, they enable the client using the extractors to think about control flow declaratively: the client can declare that they need a <code class="literal">NonZeroDouble</code>, rather than <a id="id694" class="indexterm"></a>instructing the compiler to check whether the value is zero.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec147"></a>Extracting sequences</h2></div></div><hr /></div><p>The previous section <a id="id695" class="indexterm"></a>explains extraction from case classes, and how to write custom extractors, but it does not explain how extraction works on sequences:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val Array(a, b) = Array(1, 2)</strong></span>
<span class="strong"><strong>a: Int = 1</strong></span>
<span class="strong"><strong>b: Int = 2</strong></span>
</pre></div><p>Rather than relying on an <code class="literal">unapply</code> method, sequences rely on an <code class="literal">unapplySeq</code> method defined in the companion object. This is expected to return an <code class="literal">Option[Seq[A]]</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; Array.unapplySeq(Array(1, 2))</strong></span>
<span class="strong"><strong>Option[IndexedSeq[Int]] = Some(Vector(1, 2))</strong></span>
</pre></div><p>Let's write an example. We will write an extractor for Breeze vectors (which do not currently support pattern matching). To avoid clashing with the <code class="literal">DenseVector</code> companion object, we will write our <code class="literal">unapplySeq</code> in a separate object, called <code class="literal">DV</code>. All our <code class="literal">unapplySeq</code> method needs to do is convert its argument to a Scala <code class="literal">Vector</code> instance. To avoid muddying the concepts with generics, we will write this implementation for <code class="literal">[Double]</code> vectors only:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; import breeze.linalg._</strong></span>
<span class="strong"><strong>import breeze.linalg._</strong></span>

<span class="strong"><strong>scala&gt; object DV {</strong></span>
<span class="strong"><strong>  // Just need to convert to a Scala vector.</strong></span>
<span class="strong"><strong>  def unapplySeq(v:DenseVector[Double]) = Some(v.toScalaVector)</strong></span>
<span class="strong"><strong>}</strong></span>
<span class="strong"><strong>defined object DV</strong></span>
</pre></div><p>Let's try our new extractor implementation:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>scala&gt; val vec = DenseVector(1.0, 2.0, 3.0)</strong></span>
<span class="strong"><strong>vec: breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)</strong></span>

<span class="strong"><strong>scala&gt; val DV(x, y, z) = vec</strong></span>
<span class="strong"><strong>x: Double = 1.0</strong></span>
<span class="strong"><strong>y: Double = 2.0</strong></span>
<span class="strong"><strong>z: Double = 3.0</strong></span>
</pre></div></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec148"></a>Summary</h2></div></div><hr /></div><p>Pattern matching is a powerful tool for control flow. It encourages the programmer to think declaratively: declare that you expect a variable to match a certain pattern, rather than explicitly tell the computer how to check that it matches this pattern. This can save many lines of code and enhance clarity.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">
<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec149"></a>Reference</h2></div></div><hr /></div><p>For an overview of pattern <a id="id696" class="indexterm"></a>matching in Scala, there is no better reference than <span class="emphasis"><em>Programming in Scala</em></span>, by <span class="emphasis"><em>Martin Odersky</em></span>, <span class="emphasis"><em>Bill Venners</em></span>, and <span class="emphasis"><em>Lex Spoon</em></span>. An online version of the first edition is available at: <a class="ulink" href="https://www.artima.com/pins1ed/case-classes-and-pattern-matching.html" target="_blank">https://www.artima.com/pins1ed/case-classes-and-pattern-matching.html</a>.</p><p>
<span class="emphasis"><em>Daniel Westheide's</em></span> blog <a id="id697" class="indexterm"></a>covers slightly more advanced Scala constructs, and is a very useful read: <a class="ulink" href="http://danielwestheide.com/blog/2012/11/21/the-neophytes-guide-to-scala-part-1-extractors.html" target="_blank">http://danielwestheide.com/blog/2012/11/21/the-neophytes-guide-to-scala-part-1-extractors.html</a>.</p></div></div></div></div>
ï»¿<div class="reader-container col-sm-12 col-lg-offset-1 col-lg-10 col-xl-offset-2 col-xl-8"><div class="row"><div style="position:relative;" class="book-content">

    <div id="backindex">
      <h1 class="title">Index</h1>
      <h2>A</h2>
      <ul>
        <li>actions / <a href="#ch13lvl1sec128" title="Actions" class="link">Actions</a><ul><li>asynchronous actions / <a href="#ch13lvl1sec130" title="Asynchronous actions" class="link">Asynchronous actions</a></li></ul></li>
        <li>actors<ul><li>as people / <a href="#ch09lvl1sec74" title="Actors as people" class="link">Actors as people</a></li><li>constructing / <a href="#ch09lvl1sec77" title="Actor construction" class="link">Actor construction</a>, <a href="#ch09lvl1sec78" title="Anatomy of an actor" class="link">Anatomy of an actor</a>, <a href="#ch09lvl1sec79" title="Follower network crawler" class="link">Follower network crawler</a></li><li>fetcher / <a href="#ch09lvl1sec80" title="Fetcher actors" class="link">Fetcher actors</a></li></ul></li>
        <li>aggregate functions<ul><li>URL / <a href="#ch11lvl1sec103" title="Aggregation operations" class="link">Aggregation operations</a></li></ul></li>
        <li>aggregation operations<ul><li>about / <a href="#ch11lvl1sec103" title="Aggregation operations" class="link">Aggregation operations</a></li></ul></li>
        <li>aggregations<ul><li>with Group by / <a href="#ch06lvl1sec50" title="Aggregations with &quot;Group by&quot;" class="link">Aggregations with "Group by"</a></li></ul></li>
        <li>Akka documentation / <a href="#ch09lvl1sec90" title="What we have not talked about" class="link">What we have not talked about</a></li>
        <li>Akka library / <a href="#ch04lvl1sec33" title="Futures example â€“ stock price fetcher" class="link">Futures example â€“ stock price fetcher</a></li>
        <li>Amazon Web Services (AWS)<ul><li>URL / <a href="#ch10lvl1sec96" title="Running Spark applications on EC2" class="link">Running Spark applications on EC2</a></li></ul></li>
        <li>Apache Parquet<ul><li>about / <a href="#ch11lvl1sec109" title="Parquet files" class="link">Parquet files</a></li></ul></li>
        <li>APIs<ul><li>creating, with Play / <a href="#ch13lvl1sec131" title="Creating APIs with Play: a summary" class="link">Creating APIs with Play: a summary</a></li></ul></li>
        <li>application<ul><li>building / <a href="#ch13lvl1sec125" title="Building an application" class="link">Building an application</a></li></ul></li>
        <li>applications<ul><li>Bootstrapping / <a href="#ch14lvl1sec140" title="Bootstrapping the applications" class="link">Bootstrapping the applications</a></li></ul></li>
        <li>Arrays / <a href="#ch07lvl1sec55" title="A whirlwind tour of JSON" class="link">A whirlwind tour of JSON</a></li>
        <li>arrays<ul><li>about / <a href="#ch11lvl1sec108" title="Complex data types â€“ arrays, maps, and structs" class="link">Complex data types â€“ arrays, maps, and structs</a>, <a href="#ch11lvl1sec108" title="Arrays" class="link">Arrays</a></li></ul></li>
        <li>authentication<ul><li>HTTP headers, adding / <a href="#ch07lvl1sec60" title="Authentication â€“ adding HTTP headers" class="link">Authentication â€“ adding HTTP headers</a></li></ul></li>
      </ul>
      <h2>B</h2>
      <ul>
        <li>backend<ul><li>need for / <a href="#ch14lvl1sec136" title="Do I need a backend?" class="link">Do I need a backend?</a></li></ul></li>
        <li>BinaryClassificationMetrics instance<ul><li>URL / <a href="#ch12lvl1sec115" title="Evaluation" class="link">Evaluation</a></li></ul></li>
        <li>BLAS library / <a href="#ch02lvl1sec17" title="Basic Breeze data types" class="link">Basic Breeze data types</a></li>
        <li>Body Mass Index (BMI) / <a href="#ch11lvl1sec102" title="DataFrames â€“ a whirlwind introduction" class="link">DataFrames â€“ a whirlwind introduction</a></li>
        <li>BooleanColumnExtensionMethods class<ul><li>URL / <a href="#ch06lvl1sec49" title="Operations on columns" class="link">Operations on columns</a></li></ul></li>
        <li>Bootstrap layouts<ul><li>URL / <a href="#ch14lvl1sec138" title="Towards a web application: HTML templates" class="link">Towards a web application: HTML templates</a></li></ul></li>
        <li>Breeze<ul><li>code, examples / <a href="#ch02lvl1sec14" title="Code examples" class="link">Code examples</a></li><li>installing / <a href="#ch02lvl1sec15" title="Installing Breeze" class="link">Installing Breeze</a></li><li>help, getting / <a href="#ch02lvl1sec16" title="Getting help on Breeze" class="link">Getting help on Breeze</a></li><li>Wiki page, on GitHub / <a href="#ch02lvl1sec16" title="Getting help on Breeze" class="link">Getting help on Breeze</a></li><li>data types / <a href="#ch02lvl1sec17" title="Basic Breeze data types" class="link">Basic Breeze data types</a></li><li>alternatives / <a href="#ch02lvl1sec20" title="Alternatives to Breeze" class="link">Alternatives to Breeze</a></li><li>URL / <a href="#ch02lvl1sec22" title="References" class="link">References</a></li><li>API documents, URL / <a href="#ch02lvl1sec22" title="References" class="link">References</a></li><li>diving into / <a href="#ch03lvl1sec23" title="Diving into Breeze" class="link">Diving into Breeze</a></li></ul></li>
        <li>Breeze-viz<ul><li>about / <a href="#ch03lvl1sec28" title="Managing without documentation" class="link">Managing without documentation</a></li><li>URL / <a href="#ch03lvl1sec28" title="Managing without documentation" class="link">Managing without documentation</a></li><li>reference / <a href="#ch03lvl1sec29" title="Breeze-viz reference" class="link">Breeze-viz reference</a></li></ul></li>
      </ul>
      <h2>C</h2>
      <ul>
        <li>Casbah<ul><li>URL / <a href="#ch08lvl1sec68" title="Casbah query DSL" class="link">Casbah query DSL</a>, <a href="#ch08lvl1sec72" title="References" class="link">References</a></li><li>about / <a href="#ch08lvl1sec70" title="Beyond Casbah" class="link">Beyond Casbah</a></li></ul></li>
        <li>Casbah query DSL<ul><li>about / <a href="#ch08lvl1sec68" title="Casbah query DSL" class="link">Casbah query DSL</a></li></ul></li>
        <li>case classes<ul><li>used, for pattern matching / <a href="#ch07lvl1sec57" title="JSON in Scala â€“ an exercise in pattern matching" class="link">JSON in Scala â€“ an exercise in pattern matching</a></li><li>used, for extraction / <a href="#ch07lvl1sec58" title="Extraction using case classes" class="link">Extraction using case classes</a></li><li>as messages / <a href="#ch09lvl1sec76" title="Case classes as messages" class="link">Case classes as messages</a></li></ul></li>
        <li>client-server applications<ul><li>about / <a href="#ch13lvl1sec121" title="Client-server applications" class="link">Client-server applications</a></li></ul></li>
        <li>client-side program<ul><li>architecture / <a href="#ch14lvl1sec141" title="Client-side program architecture" class="link">Client-side program architecture</a></li><li>model, designing / <a href="#ch14lvl1sec141" title="Designing the model" class="link">Designing the model</a></li><li>event bus / <a href="#ch14lvl1sec141" title="The event bus" class="link">The event bus</a></li><li>AJAX calls, thorugh JQuery / <a href="#ch14lvl1sec141" title="AJAX calls through JQuery" class="link">AJAX calls through JQuery</a></li><li>response views / <a href="#ch14lvl1sec141" title="Response views" class="link">Response views</a></li></ul></li>
        <li>collision / <a href="#ch12lvl1sec114" title="Transformers" class="link">Transformers</a></li>
        <li>complex queries / <a href="#ch08lvl1sec67" title="Complex queries" class="link">Complex queries</a></li>
        <li>configuration options<ul><li>URL / <a href="#ch10lvl1sec96" title="Reducing logging output and Spark configuration" class="link">Reducing logging output and Spark configuration</a></li></ul></li>
        <li>Connection class<ul><li>API documentation, URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li></ul></li>
        <li>context bound / <a href="#ch05lvl1sec43" title="Coding against type classes" class="link">Coding against type classes</a></li>
        <li>cross-validation<ul><li>and model selection / <a href="#ch12lvl1sec117" title="Cross-validation and model selection" class="link">Cross-validation and model selection</a></li></ul></li>
        <li>custom supervisor strategies / <a href="#ch09lvl1sec88" title="Custom supervisor strategies" class="link">Custom supervisor strategies</a></li>
        <li>custom type serialization<ul><li>about / <a href="#ch08lvl1sec69" title="Custom type serialization" class="link">Custom type serialization</a></li></ul></li>
      </ul>
      <h2>D</h2>
      <ul>
        <li>data access layer<ul><li>about / <a href="#ch05lvl1sec44" title="Creating a data access layer" class="link">Creating a data access layer</a></li></ul></li>
        <li>database metadata<ul><li>accessing / <a href="#ch06lvl1sec51" title="Accessing database metadata" class="link">Accessing database metadata</a></li></ul></li>
        <li>DataFrames<ul><li>about / <a href="#ch11lvl1sec102" title="DataFrames â€“ a whirlwind introduction" class="link">DataFrames â€“ a whirlwind introduction</a></li><li>joining, together / <a href="#ch11lvl1sec104" title="Joining DataFrames together" class="link">Joining DataFrames together</a></li><li>custom functions / <a href="#ch11lvl1sec105" title="Custom functions on DataFrames" class="link">Custom functions on DataFrames</a></li><li>immutability / <a href="#ch11lvl1sec106" title="DataFrame immutability and persistence" class="link">DataFrame immutability and persistence</a></li><li>persistence / <a href="#ch11lvl1sec106" title="DataFrame immutability and persistence" class="link">DataFrame immutability and persistence</a></li><li>SQL statements / <a href="#ch11lvl1sec107" title="SQL statements on DataFrames" class="link">SQL statements on DataFrames</a></li></ul></li>
        <li>data mapper pattern<ul><li>URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li></ul></li>
        <li>data science<ul><li>about / <a href="#ch01lvl1sec08" title="Data science" class="link">Data science</a></li><li>programming in / <a href="#ch01lvl1sec09" title="Programming in data science" class="link">Programming in data science</a></li></ul></li>
        <li>dataset<ul><li>URL / <a href="#ch02lvl1sec17" title="Data preprocessing and feature engineering" class="link">Data preprocessing and feature engineering</a></li></ul></li>
        <li>data shuffling<ul><li>about / <a href="#ch10lvl1sec99" title="Data shuffling and partitions" class="link">Data shuffling and partitions</a></li></ul></li>
        <li>data sources<ul><li>interacting with / <a href="#ch11lvl1sec109" title="Interacting with data sources" class="link">Interacting with data sources</a></li><li>JSON files / <a href="#ch11lvl1sec109" title="JSON files" class="link">JSON files</a></li><li>Parquet files / <a href="#ch11lvl1sec109" title="Parquet files" class="link">Parquet files</a></li></ul></li>
        <li>data types<ul><li>about / <a href="#ch11lvl1sec108" title="Complex data types â€“ arrays, maps, and structs" class="link">Complex data types â€“ arrays, maps, and structs</a></li></ul></li>
        <li>data types, Breeze<ul><li>about / <a href="#ch02lvl1sec17" title="Basic Breeze data types" class="link">Basic Breeze data types</a></li><li>vectors / <a href="#ch02lvl1sec17" title="Vectors" class="link">Vectors</a></li><li>matrices / <a href="#ch02lvl1sec17" title="Matrices" class="link">Matrices</a></li><li>vectors, building / <a href="#ch02lvl1sec17" title="Building vectors and matrices" class="link">Building vectors and matrices</a></li><li>matrices, building / <a href="#ch02lvl1sec17" title="Building vectors and matrices" class="link">Building vectors and matrices</a></li><li>indexing / <a href="#ch02lvl1sec17" title="Advanced indexing and slicing" class="link">Advanced indexing and slicing</a></li><li>slicing / <a href="#ch02lvl1sec17" title="Advanced indexing and slicing" class="link">Advanced indexing and slicing</a></li><li>vectors, mutating / <a href="#ch02lvl1sec17" title="Mutating vectors and matrices" class="link">Mutating vectors and matrices</a></li><li>matrices, mutating / <a href="#ch02lvl1sec17" title="Mutating vectors and matrices" class="link">Mutating vectors and matrices</a></li><li>matrix multiplication / <a href="#ch02lvl1sec17" title="Matrix multiplication, transposition, and the orientation of vectors" class="link">Matrix multiplication, transposition, and the orientation of vectors</a></li><li>matrix transposition / <a href="#ch02lvl1sec17" title="Matrix multiplication, transposition, and the orientation of vectors" class="link">Matrix multiplication, transposition, and the orientation of vectors</a></li><li>vectors, orientation / <a href="#ch02lvl1sec17" title="Matrix multiplication, transposition, and the orientation of vectors" class="link">Matrix multiplication, transposition, and the orientation of vectors</a></li><li>data preprocessing / <a href="#ch02lvl1sec17" title="Data preprocessing and feature engineering" class="link">Data preprocessing and feature engineering</a></li><li>feature engineering / <a href="#ch02lvl1sec17" title="Data preprocessing and feature engineering" class="link">Data preprocessing and feature engineering</a></li><li>function optimization / <a href="#ch02lvl1sec17" title="Breeze â€“ function optimization" class="link">Breeze â€“ function optimization</a></li><li>numerical derivatives / <a href="#ch02lvl1sec17" title="Numerical derivatives" class="link">Numerical derivatives</a></li><li>regularization / <a href="#ch02lvl1sec17" title="Regularization" class="link">Regularization</a></li></ul></li>
        <li>DenseVector or DenseMatrix<ul><li>URL / <a href="#ch02lvl1sec17" title="Vectors" class="link">Vectors</a></li></ul></li>
        <li>directed acyclic graph (DAG) / <a href="#ch10lvl1sec98" title="Lifting the hood" class="link">Lifting the hood</a></li>
        <li>documents<ul><li>inserting / <a href="#ch08lvl1sec65" title="Inserting documents" class="link">Inserting documents</a></li></ul></li>
        <li>drivers<ul><li>URL / <a href="#ch06lvl1sec47" title="Importing Slick" class="link">Importing Slick</a></li></ul></li>
        <li>dynamic routing<ul><li>about / <a href="#ch13lvl1sec127" title="Dynamic routing" class="link">Dynamic routing</a></li></ul></li>
      </ul>
      <h2>E</h2>
      <ul>
        <li>element-wise operators<ul><li>pitfalls / <a href="#ch02lvl1sec17" title="Vectors" class="link">Vectors</a></li></ul></li>
        <li>estimators<ul><li>about / <a href="#ch12lvl1sec114" title="Estimators" class="link">Estimators</a></li></ul></li>
        <li>evaluation<ul><li>about / <a href="#ch12lvl1sec115" title="Evaluation" class="link">Evaluation</a></li></ul></li>
        <li>event bus / <a href="#ch14lvl1sec141" title="The event bus" class="link">The event bus</a></li>
        <li>example data<ul><li>acquiring / <a href="#ch10lvl1sec94" title="Acquiring the example data" class="link">Acquiring the example data</a></li></ul></li>
        <li>execution contexts<ul><li>parallel execution, controlling with / <a href="#ch04lvl1sec33" title="Controlling parallel execution with execution contexts" class="link">Controlling parallel execution with execution contexts</a></li></ul></li>
        <li>extraction<ul><li>used, for case classes / <a href="#ch07lvl1sec58" title="Extraction using case classes" class="link">Extraction using case classes</a></li></ul></li>
      </ul>
      <h2>F</h2>
      <ul>
        <li>Federal Election Commission (FEC)<ul><li>about / <a href="#ch06lvl1sec47" title="FEC data" class="link">FEC data</a></li><li>URL / <a href="#ch06lvl1sec47" title="FEC data" class="link">FEC data</a></li></ul></li>
        <li>Federal Election Commission (FEC) data<ul><li>about / <a href="#ch06lvl1sec47" title="FEC data" class="link">FEC data</a></li><li>URL / <a href="#ch06lvl1sec47" title="FEC data" class="link">FEC data</a></li><li>Slick, importing / <a href="#ch06lvl1sec47" title="Importing Slick" class="link">Importing Slick</a></li><li>schema, defining / <a href="#ch06lvl1sec47" title="Defining the schema" class="link">Defining the schema</a></li><li>database, connecting to / <a href="#ch06lvl1sec47" title="Connecting to the database" class="link">Connecting to the database</a></li><li>tables, creating / <a href="#ch06lvl1sec47" title="Creating tables" class="link">Creating tables</a></li><li>inserting / <a href="#ch06lvl1sec47" title="Inserting data" class="link">Inserting data</a></li><li>querying / <a href="#ch06lvl1sec47" title="Querying data" class="link">Querying data</a></li></ul></li>
        <li>floating point format<ul><li>URL / <a href="#ch06lvl1sec47" title="Defining the schema" class="link">Defining the schema</a></li></ul></li>
        <li>follower network crawler / <a href="#ch09lvl1sec86" title="Follower network crawler" class="link">Follower network crawler</a>, <a href="#ch09lvl1sec87" title="Fault tolerance" class="link">Fault tolerance</a></li>
        <li>function optimization / <a href="#ch02lvl1sec17" title="Breeze â€“ function optimization" class="link">Breeze â€“ function optimization</a></li>
        <li>futures<ul><li>about / <a href="#ch04lvl1sec33" title="Futures" class="link">Futures</a></li><li>URL / <a href="#ch04lvl1sec33" title="Futures" class="link">Futures</a>, <a href="#ch04lvl1sec35" title="References" class="link">References</a></li><li>result, using / <a href="#ch04lvl1sec33" title="Future composition â€“ using a future's result" class="link">Future composition â€“ using a future's result</a></li><li>blocking until completion / <a href="#ch04lvl1sec33" title="Blocking until completion" class="link">Blocking until completion</a></li><li>parallel execution, controlling with execution contexts / <a href="#ch04lvl1sec33" title="Controlling parallel execution with execution contexts" class="link">Controlling parallel execution with execution contexts</a></li><li>stock price fetchers example / <a href="#ch04lvl1sec33" title="Futures example â€“ stock price fetcher" class="link">Futures example â€“ stock price fetcher</a></li><li>concurrency and exception handling / <a href="#ch07lvl1sec59" title="Concurrency and exception handling with futures" class="link">Concurrency and exception handling with futures</a></li></ul></li>
      </ul>
      <h2>G</h2>
      <ul>
        <li>GitHub<ul><li>follower's graph / <a href="#ch09lvl1sec73" title="GitHub follower graph" class="link">GitHub follower graph</a></li><li>URL / <a href="#ch14lvl1sec137" title="JavaScript dependencies through web-jars" class="link">JavaScript dependencies through web-jars</a></li></ul></li>
        <li>GitHub API<ul><li>URL / <a href="#ch07lvl1sec62" title="References" class="link">References</a></li></ul></li>
        <li>GitHub servers<ul><li>URL / <a href="#ch13lvl1sec121" title="Client-server applications" class="link">Client-server applications</a></li></ul></li>
        <li>GitHub user data<ul><li>about / <a href="#ch14lvl1sec135" title="GitHub user data" class="link">GitHub user data</a></li><li>URL / <a href="#ch14lvl1sec135" title="GitHub user data" class="link">GitHub user data</a></li></ul></li>
        <li>Group by<ul><li>aggregations with / <a href="#ch06lvl1sec50" title="Aggregations with &quot;Group by&quot;" class="link">Aggregations with "Group by"</a></li></ul></li>
      </ul>
      <h2>H</h2>
      <ul>
        <li>HashingTF / <a href="#ch12lvl1sec114" title="Transformers" class="link">Transformers</a></li>
        <li>headers<ul><li>adding, to HTTP requests in Scala / <a href="#ch07lvl1sec60" title="Adding headers to HTTP requests in Scala" class="link">Adding headers to HTTP requests in Scala</a></li></ul></li>
        <li>Hello world<ul><li>with Akka / <a href="#ch09lvl1sec75" title="Hello world with Akka" class="link">Hello world with Akka</a></li></ul></li>
        <li>HTML templates<ul><li>about / <a href="#ch14lvl1sec138" title="Towards a web application: HTML templates" class="link">Towards a web application: HTML templates</a></li></ul></li>
        <li>HTTP<ul><li>about / <a href="#ch07lvl1sec60" title="HTTP â€“ a whirlwind overview" class="link">HTTP â€“ a whirlwind overview</a></li></ul></li>
        <li>HTTP headers<ul><li>adding / <a href="#ch07lvl1sec60" title="Authentication â€“ adding HTTP headers" class="link">Authentication â€“ adding HTTP headers</a></li></ul></li>
      </ul>
      <h2>I</h2>
      <ul>
        <li>indexing / <a href="#ch02lvl1sec17" title="Advanced indexing and slicing" class="link">Advanced indexing and slicing</a></li>
        <li>invokers<ul><li>about / <a href="#ch06lvl1sec48" title="Invokers" class="link">Invokers</a></li></ul></li>
      </ul>
      <h2>J</h2>
      <ul>
        <li>java.sql.Types package<ul><li>API documentation, URL / <a href="#ch05lvl1sec38" title="JDBC summary" class="link">JDBC summary</a></li></ul></li>
        <li>JavaScipt dependencies<ul><li>through web-jars / <a href="#ch14lvl1sec137" title="JavaScript dependencies through web-jars" class="link">JavaScript dependencies through web-jars</a></li></ul></li>
        <li>JDBC<ul><li>about / <a href="#ch05lvl1sec36" title="Interacting with JDBC" class="link">Interacting with JDBC</a></li><li>first steps / <a href="#ch05lvl1sec37" title="First steps with JDBC" class="link">First steps with JDBC</a></li><li>database server, connecting to / <a href="#ch05lvl1sec37" title="Connecting to a database server" class="link">Connecting to a database server</a></li><li>tables, creating / <a href="#ch05lvl1sec37" title="Creating tables" class="link">Creating tables</a></li><li>data, inserting / <a href="#ch05lvl1sec37" title="Inserting data" class="link">Inserting data</a></li><li>data, reading / <a href="#ch05lvl1sec37" title="Reading data" class="link">Reading data</a></li><li>summary / <a href="#ch05lvl1sec38" title="JDBC summary" class="link">JDBC summary</a></li><li>functional wrappers / <a href="#ch05lvl1sec39" title="Functional wrappers for JDBC" class="link">Functional wrappers for JDBC</a></li><li>connections, with loan pattern / <a href="#ch05lvl1sec40" title="Safer JDBC connections with the loan pattern" class="link">Safer JDBC connections with the loan pattern</a></li><li>connections enriching, with pimp my library pattern / <a href="#ch05lvl1sec41" title="Enriching JDBC statements with the &quot;pimp my library&quot; pattern" class="link">Enriching JDBC statements with the "pimp my library" pattern</a></li><li>result sets in stream, wrapping / <a href="#ch05lvl1sec42" title="Wrapping result sets in a stream" class="link">Wrapping result sets in a stream</a></li><li>API documentation, URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li><li>versus Slick / <a href="#ch06lvl1sec52" title="Slick versus JDBC" class="link">Slick versus JDBC</a></li></ul></li>
        <li>JFreeChart documentation<ul><li>URL / <a href="#ch03lvl1sec24" title="Customizing plots" class="link">Customizing plots</a></li></ul></li>
        <li>JSON<ul><li>about / <a href="#ch07lvl1sec55" title="A whirlwind tour of JSON" class="link">A whirlwind tour of JSON</a></li><li>interacting with / <a href="#ch13lvl1sec129" title="Interacting with JSON" class="link">Interacting with JSON</a></li><li>external APIs, querying / <a href="#ch13lvl1sec130" title="Querying external APIs and consuming JSON" class="link">Querying external APIs and consuming JSON</a></li><li>consuming / <a href="#ch13lvl1sec130" title="Querying external APIs and consuming JSON" class="link">Querying external APIs and consuming JSON</a></li><li>parsing / <a href="#ch13lvl1sec130" title="Parsing JSON" class="link">Parsing JSON</a></li></ul></li>
        <li>JSON4S types / <a href="#ch07lvl1sec57" title="JSON4S types" class="link">JSON4S types</a></li>
        <li>JSON files<ul><li>about / <a href="#ch11lvl1sec109" title="JSON files" class="link">JSON files</a></li></ul></li>
        <li>JSON in Scala<ul><li>about / <a href="#ch07lvl1sec57" title="JSON in Scala â€“ an exercise in pattern matching" class="link">JSON in Scala â€“ an exercise in pattern matching</a></li><li>JSON4S types / <a href="#ch07lvl1sec57" title="JSON4S types" class="link">JSON4S types</a></li><li>fields extracting, XPath used / <a href="#ch07lvl1sec57" title="Extracting fields using XPath" class="link">Extracting fields using XPath</a></li></ul></li>
      </ul>
      <h2>K</h2>
      <ul>
        <li>k-fold cross-validation / <a href="#ch12lvl1sec117" title="Cross-validation and model selection" class="link">Cross-validation and model selection</a></li>
      </ul>
      <h2>L</h2>
      <ul>
        <li>L-BFGS method / <a href="#ch02lvl1sec17" title="Breeze â€“ function optimization" class="link">Breeze â€“ function optimization</a></li>
        <li>LAPACK library / <a href="#ch02lvl1sec17" title="Basic Breeze data types" class="link">Basic Breeze data types</a></li>
        <li>lazy computation<ul><li>about / <a href="#ch02lvl1sec19" title="Towards re-usable code" class="link">Towards re-usable code</a></li></ul></li>
        <li>LET IT CRASH blog<ul><li>URL / <a href="#ch09lvl1sec92" title="References" class="link">References</a></li></ul></li>
        <li>life-cycle hooks<ul><li>about / <a href="#ch09lvl1sec89" title="Life-cycle hooks" class="link">Life-cycle hooks</a></li></ul></li>
        <li>line type<ul><li>customizing / <a href="#ch03lvl1sec25" title="Customizing the line type" class="link">Customizing the line type</a></li></ul></li>
        <li>Ling-Spam dataset<ul><li>URL / <a href="#ch10lvl1sec101" title="Reference" class="link">Reference</a>, <a href="#ch12lvl1sec113" title="Introducing MLlib â€“ Spam classification" class="link">Introducing MLlib â€“ Spam classification</a></li></ul></li>
        <li>Ling-Spam email dataset<ul><li>URL / <a href="#ch10lvl1sec94" title="Acquiring the example data" class="link">Acquiring the example data</a>, <a href="#ch10lvl1sec97" title="Spam filtering" class="link">Spam filtering</a></li></ul></li>
        <li>loan pattern / <a href="#ch05lvl1sec37" title="Reading data" class="link">Reading data</a><ul><li>JDBC connections with / <a href="#ch05lvl1sec40" title="Safer JDBC connections with the loan pattern" class="link">Safer JDBC connections with the loan pattern</a></li></ul></li>
        <li>logistic regression<ul><li>about / <a href="#ch02lvl1sec18" title="An example â€“ logistic regression" class="link">An example â€“ logistic regression</a>, <a href="#ch12lvl1sec118" title="Beyond logistic regression" class="link">Beyond logistic regression</a></li><li>regularization / <a href="#ch12lvl1sec116" title="Regularization in logistic regression" class="link">Regularization in logistic regression</a></li></ul></li>
        <li>looser coupling<ul><li>with type classes / <a href="#ch05lvl1sec43" title="Looser coupling with type classes" class="link">Looser coupling with type classes</a></li><li>type classes / <a href="#ch05lvl1sec43" title="Type classes" class="link">Type classes</a></li><li>coding, against type classes / <a href="#ch05lvl1sec43" title="Coding against type classes" class="link">Coding against type classes</a></li><li>type classes, using / <a href="#ch05lvl1sec43" title="When to use type classes" class="link">When to use type classes</a></li><li>type classes, benefits / <a href="#ch05lvl1sec43" title="Benefits of type classes" class="link">Benefits of type classes</a></li></ul></li>
      </ul>
      <h2>M</h2>
      <ul>
        <li>Machine Learning course<ul><li>URL / <a href="#ch12lvl1sec120" title="References" class="link">References</a></li></ul></li>
        <li>maps<ul><li>about / <a href="#ch11lvl1sec108" title="Maps" class="link">Maps</a></li></ul></li>
        <li>matrices<ul><li>about / <a href="#ch02lvl1sec17" title="Matrices" class="link">Matrices</a></li><li>building / <a href="#ch02lvl1sec17" title="Building vectors and matrices" class="link">Building vectors and matrices</a></li><li>mutating / <a href="#ch02lvl1sec17" title="Mutating vectors and matrices" class="link">Mutating vectors and matrices</a></li></ul></li>
        <li>message<ul><li>passing, between actors / <a href="#ch09lvl1sec82" title="Message passing between actors" class="link">Message passing between actors</a></li></ul></li>
        <li>message sender<ul><li>accessing / <a href="#ch09lvl1sec84" title="Accessing the sender of a message" class="link">Accessing the sender of a message</a></li></ul></li>
        <li>MLlib / <a href="#ch02lvl1sec17" title="Breeze â€“ function optimization" class="link">Breeze â€“ function optimization</a><ul><li>spam classification / <a href="#ch12lvl1sec113" title="Introducing MLlib â€“ Spam classification" class="link">Introducing MLlib â€“ Spam classification</a></li></ul></li>
        <li>Model-View-Controller (MVC)<ul><li>architecture / <a href="#ch13lvl1sec123" title="Model-View-Controller architecture" class="link">Model-View-Controller architecture</a></li></ul></li>
        <li>modular JavaScript<ul><li>through RequireJS / <a href="#ch14lvl1sec139" title="Modular JavaScript through RequireJS" class="link">Modular JavaScript through RequireJS</a></li></ul></li>
        <li>MongoDB<ul><li>about / <a href="#ch08lvl1sec63" title="MongoDB" class="link">MongoDB</a></li><li>manual installation, URL / <a href="#ch08lvl1sec63" title="MongoDB" class="link">MongoDB</a></li><li>connecting, with Casbah / <a href="#ch08lvl1sec64" title="Connecting to MongoDB with Casbah" class="link">Connecting to MongoDB with Casbah</a></li><li>authentication, connecting with / <a href="#ch08lvl1sec64" title="Connecting with authentication" class="link">Connecting with authentication</a></li><li>reference documentation, URL / <a href="#ch08lvl1sec67" title="Complex queries" class="link">Complex queries</a></li></ul></li>
        <li>MTable instances<ul><li>URL / <a href="#ch06lvl1sec51" title="Accessing database metadata" class="link">Accessing database metadata</a></li></ul></li>
        <li>Mutual Information (MI) / <a href="#ch10lvl1sec97" title="Spam filtering" class="link">Spam filtering</a></li>
      </ul>
      <h2>N</h2>
      <ul>
        <li>NumericColumnExtensionMethods class<ul><li>URL / <a href="#ch06lvl1sec49" title="Operations on columns" class="link">Operations on columns</a></li></ul></li>
        <li>NVD3<ul><li>used, for drawing plots / <a href="#ch14lvl1sec142" title="Drawing plots with NVD3" class="link">Drawing plots with NVD3</a></li><li>URL / <a href="#ch14lvl1sec142" title="Drawing plots with NVD3" class="link">Drawing plots with NVD3</a></li></ul></li>
      </ul>
      <h2>O</h2>
      <ul>
        <li>object-oriented design patterns<ul><li>URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li></ul></li>
        <li>objects<ul><li>extracting, from database / <a href="#ch08lvl1sec66" title="Extracting objects from the database" class="link">Extracting objects from the database</a></li></ul></li>
        <li>Objects / <a href="#ch07lvl1sec55" title="A whirlwind tour of JSON" class="link">A whirlwind tour of JSON</a></li>
        <li>operations<ul><li>on columns / <a href="#ch06lvl1sec49" title="Operations on columns" class="link">Operations on columns</a></li></ul></li>
        <li>Ordering<ul><li>URL / <a href="#ch10lvl1sec95" title="Transformations and actions on RDDs" class="link">Transformations and actions on RDDs</a></li></ul></li>
      </ul>
      <h2>P</h2>
      <ul>
        <li>package.scala source file<ul><li>URL / <a href="#ch03lvl1sec29" title="Breeze-viz reference" class="link">Breeze-viz reference</a></li></ul></li>
        <li>PaintScale.scala source file<ul><li>URL / <a href="#ch03lvl1sec26" title="More advanced scatter plots" class="link">More advanced scatter plots</a></li></ul></li>
        <li>parallel collections<ul><li>about / <a href="#ch04lvl1sec32" title="Parallel collections" class="link">Parallel collections</a></li><li>limitations / <a href="#ch04lvl1sec32" title="Limitations of parallel collections" class="link">Limitations of parallel collections</a></li><li>error handling / <a href="#ch04lvl1sec32" title="Error handling" class="link">Error handling</a></li><li>parallelism level, setting / <a href="#ch04lvl1sec32" title="Setting the parallelism level" class="link">Setting the parallelism level</a></li><li>cross-validation with / <a href="#ch04lvl1sec32" title="An example â€“ cross-validation with parallel collections" class="link">An example â€“ cross-validation with parallel collections</a></li></ul></li>
        <li>parallel execution<ul><li>controlling, with execution contexts / <a href="#ch04lvl1sec33" title="Controlling parallel execution with execution contexts" class="link">Controlling parallel execution with execution contexts</a></li></ul></li>
        <li>Parquet files<ul><li>URL / <a href="#ch11lvl1sec112" title="References" class="link">References</a></li></ul></li>
        <li>parsers<ul><li>URL / <a href="#ch13lvl1sec128" title="Understanding and parsing the request" class="link">Understanding and parsing the request</a></li></ul></li>
        <li>pattern matchin<ul><li>case classes used / <a href="#ch07lvl1sec57" title="JSON in Scala â€“ an exercise in pattern matching" class="link">JSON in Scala â€“ an exercise in pattern matching</a></li></ul></li>
        <li>Pattern matching<ul><li>for comprehensions / <a href="#ch14lvl1sec145" title="Pattern matching in for comprehensions" class="link">Pattern matching in for comprehensions</a></li><li>internals / <a href="#ch14lvl1sec146" title="Pattern matching internals" class="link">Pattern matching internals</a></li><li>URL / <a href="#ch14lvl1sec149" title="Reference" class="link">Reference</a></li></ul></li>
        <li>permanence spectrum / <a href="#ch01lvl1sec09" title="Programming in data science" class="link">Programming in data science</a></li>
        <li>persistence level<ul><li>URL / <a href="#ch10lvl1sec95" title="Persisting RDDs" class="link">Persisting RDDs</a></li></ul></li>
        <li>Pimp my Library pattern<ul><li>URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li></ul></li>
        <li>pimp my library pattern<ul><li>URL / <a href="#ch05lvl1sec41" title="Enriching JDBC statements with the &quot;pimp my library&quot; pattern" class="link">Enriching JDBC statements with the "pimp my library" pattern</a></li></ul></li>
        <li>pimp my library pattern <ul><li>used, for enriching JDBC statements / <a href="#ch05lvl1sec41" title="Enriching JDBC statements with the &quot;pimp my library&quot; pattern" class="link">Enriching JDBC statements with the "pimp my library" pattern</a></li></ul></li>
        <li>pipeline<ul><li>about / <a href="#ch12lvl1sec114" title="Pipeline components" class="link">Pipeline components</a></li><li>transformers / <a href="#ch12lvl1sec114" title="Transformers" class="link">Transformers</a></li><li>estimators / <a href="#ch12lvl1sec114" title="Estimators" class="link">Estimators</a></li></ul></li>
        <li>pipeline API<ul><li>URL / <a href="#ch12lvl1sec120" title="References" class="link">References</a></li></ul></li>
        <li>Play framework / <a href="#ch04lvl1sec33" title="Futures example â€“ stock price fetcher" class="link">Futures example â€“ stock price fetcher</a><ul><li>about / <a href="#ch13lvl1sec126" title="The Play framework" class="link">The Play framework</a></li><li>URL / <a href="#ch13lvl1sec127" title="Dynamic routing" class="link">Dynamic routing</a></li></ul></li>
        <li>plots<ul><li>customizing / <a href="#ch03lvl1sec24" title="Customizing plots" class="link">Customizing plots</a></li><li>drawing, with NVD3 / <a href="#ch14lvl1sec142" title="Drawing plots with NVD3" class="link">Drawing plots with NVD3</a></li></ul></li>
        <li>PreparedStatement API documentation<ul><li>URL / <a href="#ch05lvl1sec37" title="Inserting data" class="link">Inserting data</a></li></ul></li>
        <li>PreparedStatement class<ul><li>API documentation, URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li></ul></li>
      </ul>
      <h2>Q</h2>
      <ul>
        <li>queue control<ul><li>and pull pattern / <a href="#ch09lvl1sec83" title="Queue control and the pull pattern" class="link">Queue control and the pull pattern</a></li></ul></li>
      </ul>
      <h2>R</h2>
      <ul>
        <li>receiver operating characteristic (ROC) curve / <a href="#ch12lvl1sec115" title="Evaluation" class="link">Evaluation</a></li>
        <li>regularization / <a href="#ch02lvl1sec17" title="Regularization" class="link">Regularization</a><ul><li>in logistic regression / <a href="#ch12lvl1sec116" title="Regularization in logistic regression" class="link">Regularization in logistic regression</a></li></ul></li>
        <li>request<ul><li>parsing / <a href="#ch13lvl1sec128" title="Understanding and parsing the request" class="link">Understanding and parsing the request</a></li></ul></li>
        <li>RequireJS<ul><li>modular JavaScript through / <a href="#ch14lvl1sec139" title="Modular JavaScript through RequireJS" class="link">Modular JavaScript through RequireJS</a></li></ul></li>
        <li>resilient applications<ul><li>building / <a href="#ch04lvl1sec33" title="Futures" class="link">Futures</a></li></ul></li>
        <li>Resilient distributed datasets (RDD)<ul><li>about / <a href="#ch10lvl1sec95" title="Resilient distributed datasets" class="link">Resilient distributed datasets</a></li><li>immutability / <a href="#ch10lvl1sec95" title="RDDs are immutable" class="link">RDDs are immutable</a></li><li>operations, executing / <a href="#ch10lvl1sec95" title="RDDs are lazy" class="link">RDDs are lazy</a></li><li>constructing / <a href="#ch10lvl1sec95" title="RDDs know their lineage" class="link">RDDs know their lineage</a></li><li>resiliency / <a href="#ch10lvl1sec95" title="RDDs are resilient" class="link">RDDs are resilient</a></li><li>distribution / <a href="#ch10lvl1sec95" title="RDDs are distributed" class="link">RDDs are distributed</a></li><li>transformations / <a href="#ch10lvl1sec95" title="Transformations and actions on RDDs" class="link">Transformations and actions on RDDs</a></li><li>actions / <a href="#ch10lvl1sec95" title="Transformations and actions on RDDs" class="link">Transformations and actions on RDDs</a></li><li>operations, URL / <a href="#ch10lvl1sec95" title="Transformations and actions on RDDs" class="link">Transformations and actions on RDDs</a></li><li>persisting / <a href="#ch10lvl1sec95" title="Persisting RDDs" class="link">Persisting RDDs</a></li><li>Key-value / <a href="#ch10lvl1sec95" title="Key-value RDDs" class="link">Key-value RDDs</a></li><li>double / <a href="#ch10lvl1sec95" title="Double RDDs" class="link">Double RDDs</a></li></ul></li>
        <li>response<ul><li>composing / <a href="#ch13lvl1sec128" title="Composing the response" class="link">Composing the response</a></li></ul></li>
        <li>response views / <a href="#ch14lvl1sec141" title="Response views" class="link">Response views</a></li>
        <li>Rest APIs<ul><li>about / <a href="#ch13lvl1sec132" title="Rest APIs: best practice" class="link">Rest APIs: best practice</a></li></ul></li>
        <li>results<ul><li>URL / <a href="#ch13lvl1sec128" title="Composing the response" class="link">Composing the response</a></li></ul></li>
        <li>ResultSet interface<ul><li>API documentation, URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li></ul></li>
        <li>routing<ul><li>about / <a href="#ch09lvl1sec81" title="Routing" class="link">Routing</a></li></ul></li>
      </ul>
      <h2>S</h2>
      <ul>
        <li>Scala<ul><li>and data science / <a href="#ch01lvl1sec08" title="Data science" class="link">Data science</a></li><li>uses / <a href="#ch01lvl1sec10" title="Why Scala?" class="link">Why Scala?</a>, <a href="#ch01lvl1sec10" title="Scala encourages immutability" class="link">Scala encourages immutability</a>, <a href="#ch01lvl1sec10" title="Easier parallelism" class="link">Easier parallelism</a></li><li>static typing and type inference / <a href="#ch01lvl1sec10" title="Static typing and type inference" class="link">Static typing and type inference</a></li><li>and functional programs / <a href="#ch01lvl1sec10" title="Scala and functional programs" class="link">Scala and functional programs</a></li><li>null pointer uncertainty / <a href="#ch01lvl1sec10" title="Null pointer uncertainty" class="link">Null pointer uncertainty</a></li><li>interoperability, with Java / <a href="#ch01lvl1sec10" title="Interoperability with Java" class="link">Interoperability with Java</a></li><li>drawbacks / <a href="#ch01lvl1sec11" title="When not to use Scala" class="link">When not to use Scala</a></li><li>references / <a href="#ch01lvl1sec13" title="References" class="link">References</a></li><li>URL / <a href="#ch11lvl1sec112" title="References" class="link">References</a></li></ul></li>
        <li>Scala constructs<ul><li>URL / <a href="#ch14lvl1sec149" title="Reference" class="link">Reference</a></li></ul></li>
        <li>scatter plot matrix plots<ul><li>about / <a href="#ch03lvl1sec27" title="Multi-plot example â€“ scatterplot matrix plots" class="link">Multi-plot example â€“ scatterplot matrix plots</a></li></ul></li>
        <li>scatter plots<ul><li>about / <a href="#ch03lvl1sec26" title="More advanced scatter plots" class="link">More advanced scatter plots</a></li></ul></li>
        <li>schema<ul><li>defining / <a href="#ch06lvl1sec47" title="Defining the schema" class="link">Defining the schema</a></li></ul></li>
        <li>semantic URLs / <a href="#ch13lvl1sec127" title="Dynamic routing" class="link">Dynamic routing</a>, <a href="#ch13lvl1sec134" title="References" class="link">References</a></li>
        <li>sequences<ul><li>extracting / <a href="#ch14lvl1sec147" title="Extracting sequences" class="link">Extracting sequences</a></li></ul></li>
        <li>shuffling / <a href="#ch10lvl1sec99" title="Data shuffling and partitions" class="link">Data shuffling and partitions</a></li>
        <li>single page applications<ul><li>about / <a href="#ch13lvl1sec124" title="Single page applications" class="link">Single page applications</a></li></ul></li>
        <li>slicing / <a href="#ch02lvl1sec17" title="Advanced indexing and slicing" class="link">Advanced indexing and slicing</a></li>
        <li>Slick<ul><li>importing / <a href="#ch06lvl1sec47" title="Importing Slick" class="link">Importing Slick</a></li><li>arguments, URL / <a href="#ch06lvl1sec47" title="Defining the schema" class="link">Defining the schema</a></li><li>joins, URL / <a href="#ch06lvl1sec48" title="Invokers" class="link">Invokers</a></li><li>versus JDBC / <a href="#ch06lvl1sec52" title="Slick versus JDBC" class="link">Slick versus JDBC</a></li><li>URL / <a href="#ch06lvl1sec54" title="References" class="link">References</a></li></ul></li>
        <li>spam filtering<ul><li>about / <a href="#ch10lvl1sec97" title="Spam filtering" class="link">Spam filtering</a></li></ul></li>
        <li>Spark<ul><li>installing / <a href="#ch10lvl1sec93" title="Installing Spark" class="link">Installing Spark</a></li><li>URL / <a href="#ch10lvl1sec93" title="Installing Spark" class="link">Installing Spark</a>, <a href="#ch11lvl1sec107" title="SQL statements on DataFrames" class="link">SQL statements on DataFrames</a></li><li>on EC2, URL / <a href="#ch10lvl1sec96" title="Running Spark applications on EC2" class="link">Running Spark applications on EC2</a></li><li>data shuffling / <a href="#ch10lvl1sec99" title="Data shuffling and partitions" class="link">Data shuffling and partitions</a></li><li>Web UI, URL / <a href="#ch10lvl1sec101" title="Reference" class="link">Reference</a></li><li>internals, URL / <a href="#ch10lvl1sec101" title="Reference" class="link">Reference</a></li></ul></li>
        <li>Spark applications<ul><li>running, locally / <a href="#ch10lvl1sec96" title="Running Spark applications locally" class="link">Running Spark applications locally</a></li><li>URL / <a href="#ch10lvl1sec96" title="Running Spark applications locally" class="link">Running Spark applications locally</a></li><li>running, on EC2 / <a href="#ch10lvl1sec96" title="Running Spark applications on EC2" class="link">Running Spark applications on EC2</a></li></ul></li>
        <li>Spark notebooks<ul><li>URL / <a href="#ch03lvl1sec30" title="Data visualization beyond breeze-viz" class="link">Data visualization beyond breeze-viz</a></li></ul></li>
        <li>SQL statements<ul><li>on DataFrames / <a href="#ch11lvl1sec107" title="SQL statements on DataFrames" class="link">SQL statements on DataFrames</a></li></ul></li>
        <li>stand-alone programs<ul><li>building / <a href="#ch10lvl1sec96" title="Building and running standalone programs" class="link">Building and running standalone programs</a></li></ul></li>
        <li>standalone programs<ul><li>about / <a href="#ch11lvl1sec110" title="Standalone programs" class="link">Standalone programs</a></li></ul></li>
        <li>Stanford NLP toolkit<ul><li>URL / <a href="#ch10lvl1sec97" title="Spam filtering" class="link">Spam filtering</a></li></ul></li>
        <li>stateful actors / <a href="#ch09lvl1sec85" title="Stateful actors" class="link">Stateful actors</a></li>
        <li>StringColumnExtensionMethods class<ul><li>URL / <a href="#ch06lvl1sec49" title="Operations on columns" class="link">Operations on columns</a></li></ul></li>
        <li>structs<ul><li>about / <a href="#ch11lvl1sec108" title="Structs" class="link">Structs</a></li></ul></li>
      </ul>
      <h2>T</h2>
      <ul>
        <li>tokenization<ul><li>about / <a href="#ch12lvl1sec114" title="Transformers" class="link">Transformers</a></li></ul></li>
        <li>tokens<ul><li>URL / <a href="#ch07lvl1sec60" title="Authentication â€“ adding HTTP headers" class="link">Authentication â€“ adding HTTP headers</a></li></ul></li>
        <li>transformations<ul><li>URL / <a href="#ch10lvl1sec95" title="Key-value RDDs" class="link">Key-value RDDs</a></li></ul></li>
        <li>transformers<ul><li>about / <a href="#ch12lvl1sec114" title="Transformers" class="link">Transformers</a></li><li>URL / <a href="#ch12lvl1sec120" title="References" class="link">References</a></li></ul></li>
        <li>try/catch statements<ul><li>versus Try type / <a href="#ch04lvl1sec32" title="Error handling" class="link">Error handling</a></li></ul></li>
        <li>Try type<ul><li>versus try/catch statements / <a href="#ch04lvl1sec32" title="Error handling" class="link">Error handling</a></li><li>URL / <a href="#ch04lvl1sec35" title="References" class="link">References</a></li></ul></li>
        <li>tuning memory usage<ul><li>URL / <a href="#ch10lvl1sec95" title="Persisting RDDs" class="link">Persisting RDDs</a></li></ul></li>
        <li>type classes<ul><li>loose coupling with / <a href="#ch05lvl1sec43" title="Looser coupling with type classes" class="link">Looser coupling with type classes</a></li><li>about / <a href="#ch05lvl1sec43" title="Type classes" class="link">Type classes</a></li><li>coding against / <a href="#ch05lvl1sec43" title="Coding against type classes" class="link">Coding against type classes</a></li><li>usage / <a href="#ch05lvl1sec43" title="When to use type classes" class="link">When to use type classes</a></li><li>benefits / <a href="#ch05lvl1sec43" title="Benefits of type classes" class="link">Benefits of type classes</a></li><li>URL / <a href="#ch05lvl1sec46" title="References" class="link">References</a></li></ul></li>
        <li>Typesafe activators<ul><li>about / <a href="#ch13lvl1sec126" title="The Play framework" class="link">The Play framework</a></li><li>URL / <a href="#ch13lvl1sec126" title="The Play framework" class="link">The Play framework</a></li></ul></li>
      </ul>
      <h2>U</h2>
      <ul>
        <li>URL design / <a href="#ch13lvl1sec127" title="Dynamic routing" class="link">Dynamic routing</a></li>
        <li>user-defined function (UDF) / <a href="#ch11lvl1sec105" title="Custom functions on DataFrames" class="link">Custom functions on DataFrames</a></li>
        <li>user-defined functions (UDFs) / <a href="#ch11lvl1sec105" title="Custom functions on DataFrames" class="link">Custom functions on DataFrames</a></li>
      </ul>
      <h2>V</h2>
      <ul>
        <li>vectors<ul><li>about / <a href="#ch02lvl1sec17" title="Vectors" class="link">Vectors</a></li><li>dense / <a href="#ch02lvl1sec17" title="Dense and sparse vectors and the vector trait" class="link">Dense and sparse vectors and the vector trait</a></li><li>sparse / <a href="#ch02lvl1sec17" title="Dense and sparse vectors and the vector trait" class="link">Dense and sparse vectors and the vector trait</a></li><li>trait / <a href="#ch02lvl1sec17" title="Dense and sparse vectors and the vector trait" class="link">Dense and sparse vectors and the vector trait</a></li><li>building / <a href="#ch02lvl1sec17" title="Building vectors and matrices" class="link">Building vectors and matrices</a></li><li>mutating / <a href="#ch02lvl1sec17" title="Mutating vectors and matrices" class="link">Mutating vectors and matrices</a></li></ul></li>
      </ul>
      <h2>W</h2>
      <ul>
        <li>web-jars<ul><li>JavaScipt dependencies through / <a href="#ch14lvl1sec137" title="JavaScript dependencies through web-jars" class="link">JavaScript dependencies through web-jars</a></li></ul></li>
        <li>web APIs<ul><li>querying / <a href="#ch07lvl1sec56" title="Querying web APIs" class="link">Querying web APIs</a></li></ul></li>
        <li>web application<ul><li>about / <a href="#ch14lvl1sec138" title="Towards a web application: HTML templates" class="link">Towards a web application: HTML templates</a></li></ul></li>
        <li>web frameworks<ul><li>about / <a href="#ch13lvl1sec122" title="Introduction to web frameworks" class="link">Introduction to web frameworks</a></li></ul></li>
        <li>web services<ul><li>external web services, calling / <a href="#ch13lvl1sec130" title="Calling external web services" class="link">Calling external web services</a></li></ul></li>
      </ul>
      <h2>X</h2>
      <ul>
        <li>XPath
<ul><li>used, for extracting fields / <a href="#ch07lvl1sec57" title="Extracting fields using XPath" class="link">Extracting fields using XPath</a></li></ul></li>
        <li>XPath DSL / <a href="#ch07lvl1sec57" title="Extracting fields using XPath" class="link">Extracting fields using XPath</a></li>
      </ul>
    </div>
  </div></div></div>
</div></div></div></body></html>
